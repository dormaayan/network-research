{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import sklearn\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"complete-frame.csv\"\n",
    "CSV_MINER_PATH = \"testminereffectiveness.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_rename1 (row):\n",
    "    return row['path_test'].split('/')[len(row['path_test'].split('/')) - 1].split('.')[0]\n",
    "\n",
    "def label_rename2 (row):\n",
    "    return row['path_src'].split('/')[len(row['path_src'].split('/')) - 1].split('.')[0]\n",
    "\n",
    "def load_quartile(frame):\n",
    "    low, high = frame.mutation.quantile([0.25,0.75])\n",
    "    frame_low = frame.query('mutation<{low}'.format(low=low))\n",
    "    frame_high = frame.query('mutation>{high}'.format(high=high))\n",
    "    frame_low['mutation'] = 0\n",
    "    frame_high['mutation'] = 1\n",
    "    frame = pd.concat([frame_low, frame_high], ignore_index=True)\n",
    "    frame = frame.sample(frac=1).reset_index(drop=True)\n",
    "    return frame;\n",
    "\n",
    "def load_frame():\n",
    "    \n",
    "    d = {'TestClassName' : 'ClassName', 'Vocabulary' : 'Vocabulary_prod', 'Non Whithe Characters' : 'Non Whithe Characters_prod',\n",
    "     'No. Method Invoctions' : 'No. Method Invoctions_prod',\n",
    "    'AST size' : 'AST size_prod', 'Max Depth' : 'Max Depth_prod', 'Sum Depths' : 'Sum Depths_prod',\n",
    "     'Avg Depth' : 'Avg Depth_prod', 'Branching' : 'Branching_prod', 'Dexterity' : 'Dexterity_prod',\n",
    "    'No. Expressions' : 'No. Expressions_prod', 'No. Try' : 'No. Try_prod', 'No. Catch' : 'No. Catch_prod',\n",
    "     'No. Loop' : 'No. Loop_prod', 'No. Conditions' : 'No. Conditions_prod', 'No. Else' : 'No. Else_prod'}\n",
    "    \n",
    "    frame1 = pd.read_csv(CSV_PATH, sep=\",\")\n",
    "    frame1 = frame1.sample(frac=1).reset_index(drop=True)\n",
    "    frame1['TestClassName'] = frame1.apply(lambda row: label_rename1(row), axis=1)\n",
    "    frame1['ClassName'] = frame1.apply(lambda row: label_rename2(row), axis=1)\n",
    "        \n",
    "    \n",
    "    frame2 = pd.read_csv(CSV_MINER_PATH, sep=',')\n",
    "    \n",
    "    frame3 = pd.read_csv(CSV_MINER_PATH, sep=',')\n",
    "    frame3 = frame3.rename(columns = d, errors = 'raise')\n",
    "    frame3 = frame3.drop(['No. Tests', 'Bad API', 'Junit', 'Hamcrest', 'Mockito', 'NÂº','Project'], axis=1)\n",
    "    \n",
    "    \n",
    "    frame = pd.merge(frame1, frame2, on='TestClassName')\n",
    "    \n",
    "    frame = pd.merge(frame, frame3, on='ClassName')\n",
    "    \n",
    "\n",
    "    frame = frame.drop(['project', 'module', 'path_test','test_name','path_src',\n",
    "                        'commit', 'class_name'], axis=1)\n",
    "    frame = frame.sample(frac=1).reset_index(drop=True)\n",
    "    frame = frame.dropna()\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def load_all_test_data_dynamic(frame):\n",
    "    columns = ['isAssertionRoulette',\n",
    "       'isEagerTest', 'isLazyTest', 'isMysteryGuest',\n",
    "       'isSensitiveEquality', 'isResourceOptimism', 'isForTestersOnly',\n",
    "       'isIndirectTesting', 'LOC_test', 'HALSTEAD_test', 'RFC_test', 'CBO_test', 'MPC_test', 'IFC_test',\n",
    "       'DAC_test', 'DAC2_test', 'LCOM1_test', 'LCOM2_test', 'LCOM3_test',\n",
    "       'LCOM4_test', 'CONNECTIVITY_test', 'LCOM5_test', 'COH_test',\n",
    "       'TCC_test', 'LCC_test', 'ICH_test', 'WMC_test', 'NOA_test',\n",
    "       'NOPA_test', 'NOP_test', 'McCABE_test', 'BUSWEIMER_test', 'test_readability', 'No. Tests',\n",
    "       'Vocabulary', 'Non Whithe Characters', 'No. Method Invoctions',\n",
    "       'AST size', 'Max Depth', 'Sum Depths', 'Avg Depth', 'Branching',\n",
    "       'Dexterity', 'No. Expressions', 'No. Try', 'No. Catch', 'No. Loop',\n",
    "       'No. Conditions', 'No. Else', 'Bad API', 'Junit', 'Hamcrest',\n",
    "       'Mockito'] # 'line_coverage']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "\n",
    "def load_all_prod_data(frame):\n",
    "    columns = ['LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod',    \n",
    "       'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability', 'Vocabulary_prod', 'Non Whithe Characters_prod',\n",
    "       'No. Method Invoctions_prod', 'AST size_prod', 'Max Depth_prod',\n",
    "       'Sum Depths_prod', 'Avg Depth_prod', 'Branching_prod',\n",
    "       'Dexterity_prod', 'No. Expressions_prod', 'No. Try_prod',\n",
    "       'No. Catch_prod', 'No. Loop_prod', 'No. Conditions_prod',\n",
    "       'No. Else_prod']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "\n",
    "def load_all_data(frame):\n",
    "    columns = ['isAssertionRoulette',\n",
    "       'isEagerTest', 'isLazyTest', 'isMysteryGuest',\n",
    "       'isSensitiveEquality', 'isResourceOptimism', 'isForTestersOnly',\n",
    "       'isIndirectTesting', 'LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod', 'LOC_test',\n",
    "       'HALSTEAD_test', 'RFC_test', 'CBO_test', 'MPC_test', 'IFC_test',\n",
    "       'DAC_test', 'DAC2_test', 'LCOM1_test', 'LCOM2_test', 'LCOM3_test',\n",
    "       'LCOM4_test', 'CONNECTIVITY_test', 'LCOM5_test', 'COH_test',\n",
    "       'TCC_test', 'LCC_test', 'ICH_test', 'WMC_test', 'NOA_test',\n",
    "       'NOPA_test', 'NOP_test', 'McCABE_test', 'BUSWEIMER_test',\n",
    "       'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability', 'test_readability', 'No. Tests',\n",
    "       'Vocabulary', 'Non Whithe Characters', 'No. Method Invoctions',\n",
    "       'AST size', 'Max Depth', 'Sum Depths', 'Avg Depth', 'Branching',\n",
    "       'Dexterity', 'No. Expressions', 'No. Try', 'No. Catch', 'No. Loop',\n",
    "       'No. Conditions', 'No. Else', 'Bad API', 'Junit', 'Hamcrest',\n",
    "       'Mockito', 'Vocabulary_prod', 'Non Whithe Characters_prod',\n",
    "       'No. Method Invoctions_prod', 'AST size_prod', 'Max Depth_prod',\n",
    "       'Sum Depths_prod', 'Avg Depth_prod', 'Branching_prod',\n",
    "       'Dexterity_prod', 'No. Expressions_prod', 'No. Try_prod',\n",
    "       'No. Catch_prod', 'No. Loop_prod', 'No. Conditions_prod',\n",
    "       'No. Else_prod']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      isAssertionRoulette  isEagerTest  isLazyTest  isMysteryGuest  \\\n",
       " 0                       1            1           0               0   \n",
       " 1                       1            1           0               0   \n",
       " 2                       0            0           0               1   \n",
       " 3                       0            0           0               0   \n",
       " 4                       1            0           0               0   \n",
       " ...                   ...          ...         ...             ...   \n",
       " 2678                    1            0           0               0   \n",
       " 2679                    1            1           0               0   \n",
       " 2680                    1            1           0               0   \n",
       " 2681                    1            0           0               0   \n",
       " 2682                    1            0           0               0   \n",
       " \n",
       "       isSensitiveEquality  isResourceOptimism  isForTestersOnly  \\\n",
       " 0                       0                   0                 0   \n",
       " 1                       0                   0                 0   \n",
       " 2                       0                   0                 0   \n",
       " 3                       0                   0                 0   \n",
       " 4                       0                   0                 0   \n",
       " ...                   ...                 ...               ...   \n",
       " 2678                    0                   0                 0   \n",
       " 2679                    0                   0                 0   \n",
       " 2680                    0                   0                 0   \n",
       " 2681                    0                   0                 0   \n",
       " 2682                    0                   0                 0   \n",
       " \n",
       "       isIndirectTesting  LOC_prod  HALSTEAD_prod  ...  Sum Depths_prod  \\\n",
       " 0                     0       630        4826.10  ...           5864.0   \n",
       " 1                     0       361        4105.42  ...           2089.0   \n",
       " 2                     0        81         676.96  ...            178.0   \n",
       " 3                     0       102         526.72  ...            772.0   \n",
       " 4                     0        98         531.83  ...            572.0   \n",
       " ...                 ...       ...            ...  ...              ...   \n",
       " 2678                  1       195         828.84  ...           1594.0   \n",
       " 2679                  0      1243        8043.34  ...           7829.0   \n",
       " 2680                  0      1194        7361.81  ...           6811.0   \n",
       " 2681                  0       242        1307.66  ...           1270.0   \n",
       " 2682                  0       108         583.45  ...            656.0   \n",
       " \n",
       "       Avg Depth_prod  Branching_prod  Dexterity_prod  No. Expressions_prod  \\\n",
       " 0               3.06            1.71            50.0                1619.0   \n",
       " 1               2.63            1.23            40.0                 572.0   \n",
       " 2               8.90            7.50            24.0                  50.0   \n",
       " 3               3.54            1.41            27.0                 185.0   \n",
       " 4               5.40            4.14            30.0                 143.0   \n",
       " ...              ...             ...             ...                   ...   \n",
       " 2678            3.98            1.80            33.0                 350.0   \n",
       " 2679            2.49            2.22            46.0                2579.0   \n",
       " 2680            2.81            1.81            41.0                1999.0   \n",
       " 2681            2.82            1.29            28.0                 399.0   \n",
       " 2682            5.17            3.11            27.0                 161.0   \n",
       " \n",
       "       No. Try_prod  No. Catch_prod  No. Loop_prod  No. Conditions_prod  \\\n",
       " 0              1.0             1.0            4.0                 35.0   \n",
       " 1              0.0             0.0           11.0                  3.0   \n",
       " 2              0.0             0.0            0.0                  1.0   \n",
       " 3              1.0             1.0            3.0                  4.0   \n",
       " 4              0.0             0.0            0.0                  2.0   \n",
       " ...            ...             ...            ...                  ...   \n",
       " 2678           7.0             7.0            0.0                 10.0   \n",
       " 2679           0.0             0.0            4.0                 60.0   \n",
       " 2680           0.0             0.0            6.0                 67.0   \n",
       " 2681           0.0             0.0            0.0                 17.0   \n",
       " 2682           0.0             0.0            0.0                  2.0   \n",
       " \n",
       "       No. Else_prod  \n",
       " 0              12.0  \n",
       " 1               0.0  \n",
       " 2               1.0  \n",
       " 3               0.0  \n",
       " 4               0.0  \n",
       " ...             ...  \n",
       " 2678            2.0  \n",
       " 2679           12.0  \n",
       " 2680           24.0  \n",
       " 2681           11.0  \n",
       " 2682            0.0  \n",
       " \n",
       " [2681 rows x 101 columns],       mutation\n",
       " 0     0.516209\n",
       " 1     0.657143\n",
       " 2     0.733333\n",
       " 3     0.093750\n",
       " 4     1.000000\n",
       " ...        ...\n",
       " 2678  0.766667\n",
       " 2679  0.087001\n",
       " 2680  0.200798\n",
       " 2681  0.000000\n",
       " 2682  1.000000\n",
       " \n",
       " [2681 rows x 1 columns], 101)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_all_data(load_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>mutation</th>\n",
       "      <th>no_mutations</th>\n",
       "      <th>line_coverage</th>\n",
       "      <th>isAssertionRoulette</th>\n",
       "      <th>isEagerTest</th>\n",
       "      <th>isLazyTest</th>\n",
       "      <th>isMysteryGuest</th>\n",
       "      <th>isSensitiveEquality</th>\n",
       "      <th>isResourceOptimism</th>\n",
       "      <th>...</th>\n",
       "      <th>Sum Depths_prod</th>\n",
       "      <th>Avg Depth_prod</th>\n",
       "      <th>Branching_prod</th>\n",
       "      <th>Dexterity_prod</th>\n",
       "      <th>No. Expressions_prod</th>\n",
       "      <th>No. Try_prod</th>\n",
       "      <th>No. Catch_prod</th>\n",
       "      <th>No. Loop_prod</th>\n",
       "      <th>No. Conditions_prod</th>\n",
       "      <th>No. Else_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>com.google.debugging.sourcemap.Base64</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>30</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2670.0</td>\n",
       "      <td>2.792887</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>37.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>com.google.javascript.jscomp.ImplicitNullabili...</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>917.0</td>\n",
       "      <td>3.322464</td>\n",
       "      <td>1.663043</td>\n",
       "      <td>35.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>com.google.javascript.jscomp.RecordFunctionInf...</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>46</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>449.0</td>\n",
       "      <td>3.680328</td>\n",
       "      <td>1.991803</td>\n",
       "      <td>28.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>io.reactivex.internal.operators.flowable.Flowa...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1323.0</td>\n",
       "      <td>4.955056</td>\n",
       "      <td>3.411985</td>\n",
       "      <td>33.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>com.google.javascript.jscomp.InlineObjectLiterals</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3216.0</td>\n",
       "      <td>2.644737</td>\n",
       "      <td>1.156250</td>\n",
       "      <td>39.0</td>\n",
       "      <td>943.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>io.reactivex.internal.operators.maybe.MaybeIgn...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>474.0</td>\n",
       "      <td>5.096774</td>\n",
       "      <td>3.204301</td>\n",
       "      <td>27.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>org.apache.commons.collections4.set.MapBackedSet</td>\n",
       "      <td>0.969072</td>\n",
       "      <td>97</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>956.0</td>\n",
       "      <td>5.031579</td>\n",
       "      <td>4.789474</td>\n",
       "      <td>35.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>com.google.javascript.jscomp.ClosureOptimizePr...</td>\n",
       "      <td>0.927419</td>\n",
       "      <td>248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>2.824534</td>\n",
       "      <td>1.397516</td>\n",
       "      <td>33.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>io.reactivex.internal.operators.observable.Obs...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>726.0</td>\n",
       "      <td>4.624204</td>\n",
       "      <td>2.490446</td>\n",
       "      <td>28.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>org.apache.commons.math3.stat.descriptive.Sync...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>73</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>959.0</td>\n",
       "      <td>7.210526</td>\n",
       "      <td>11.466165</td>\n",
       "      <td>22.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows Ã 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             class_name  mutation  \\\n",
       "3                 com.google.debugging.sourcemap.Base64  0.933333   \n",
       "14    com.google.javascript.jscomp.ImplicitNullabili...  0.950000   \n",
       "16    com.google.javascript.jscomp.RecordFunctionInf...  0.956522   \n",
       "17    io.reactivex.internal.operators.flowable.Flowa...  1.000000   \n",
       "18    com.google.javascript.jscomp.InlineObjectLiterals  1.000000   \n",
       "...                                                 ...       ...   \n",
       "2649  io.reactivex.internal.operators.maybe.MaybeIgn...  1.000000   \n",
       "2650   org.apache.commons.collections4.set.MapBackedSet  0.969072   \n",
       "2658  com.google.javascript.jscomp.ClosureOptimizePr...  0.927419   \n",
       "2663  io.reactivex.internal.operators.observable.Obs...  1.000000   \n",
       "2666  org.apache.commons.math3.stat.descriptive.Sync...  1.000000   \n",
       "\n",
       "      no_mutations  line_coverage  isAssertionRoulette  isEagerTest  \\\n",
       "3               30       0.941176                    1            1   \n",
       "14              20       1.000000                    0            0   \n",
       "16              46       0.961538                    1            1   \n",
       "17               8       1.000000                    1            0   \n",
       "18               6       1.000000                    0            0   \n",
       "...            ...            ...                  ...          ...   \n",
       "2649             2       1.000000                    0            0   \n",
       "2650            97       0.968750                    0            0   \n",
       "2658           248       1.000000                    0            0   \n",
       "2663             3       1.000000                    1            0   \n",
       "2666            73       1.000000                    0            0   \n",
       "\n",
       "      isLazyTest  isMysteryGuest  isSensitiveEquality  isResourceOptimism  \\\n",
       "3              0               0                    0                   0   \n",
       "14             0               0                    0                   0   \n",
       "16             0               0                    0                   0   \n",
       "17             0               0                    1                   0   \n",
       "18             0               0                    0                   0   \n",
       "...          ...             ...                  ...                 ...   \n",
       "2649           0               0                    0                   0   \n",
       "2650           0               0                    0                   0   \n",
       "2658           0               0                    0                   0   \n",
       "2663           0               0                    0                   0   \n",
       "2666           0               0                    0                   0   \n",
       "\n",
       "      ...  Sum Depths_prod  Avg Depth_prod  Branching_prod  Dexterity_prod  \\\n",
       "3     ...           2670.0        2.792887        0.995816            37.0   \n",
       "14    ...            917.0        3.322464        1.663043            35.0   \n",
       "16    ...            449.0        3.680328        1.991803            28.0   \n",
       "17    ...           1323.0        4.955056        3.411985            33.0   \n",
       "18    ...           3216.0        2.644737        1.156250            39.0   \n",
       "...   ...              ...             ...             ...             ...   \n",
       "2649  ...            474.0        5.096774        3.204301            27.0   \n",
       "2650  ...            956.0        5.031579        4.789474            35.0   \n",
       "2658  ...           1819.0        2.824534        1.397516            33.0   \n",
       "2663  ...            726.0        4.624204        2.490446            28.0   \n",
       "2666  ...            959.0        7.210526       11.466165            22.0   \n",
       "\n",
       "      No. Expressions_prod  No. Try_prod  No. Catch_prod  No. Loop_prod  \\\n",
       "3                    792.0           0.0             0.0           16.0   \n",
       "14                   216.0           0.0             0.0            2.0   \n",
       "16                   133.0           0.0             0.0            0.0   \n",
       "17                   322.0           1.0             1.0            0.0   \n",
       "18                   943.0           0.0             0.0           13.0   \n",
       "...                    ...           ...             ...            ...   \n",
       "2649                 119.0           0.0             0.0            0.0   \n",
       "2650                 252.0           0.0             0.0            1.0   \n",
       "2658                 532.0           0.0             0.0            4.0   \n",
       "2663                 168.0           1.0             1.0            0.0   \n",
       "2666                 224.0           0.0             0.0            0.0   \n",
       "\n",
       "      No. Conditions_prod  No. Else_prod  \n",
       "3                     9.0            0.0  \n",
       "14                    8.0            0.0  \n",
       "16                    2.0            0.0  \n",
       "17                    3.0            1.0  \n",
       "18                   29.0            9.0  \n",
       "...                   ...            ...  \n",
       "2649                  1.0            0.0  \n",
       "2650                  1.0            0.0  \n",
       "2658                 20.0            6.0  \n",
       "2663                  5.0            1.0  \n",
       "2666                  0.0            0.0  \n",
       "\n",
       "[622 rows x 106 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame1 = pd.read_csv('good_tests.csv', sep=\",\")\n",
    "frame1['TestClassName'] = frame1.apply(lambda row: label_rename1(row), axis=1)\n",
    "frame2 = load_frame() #pd.read_csv(CSV_MINER_PATH, sep=',')\n",
    "\n",
    "frame = frame2[frame2['TestClassName'].isin(frame1['TestClassName'].to_list())]\n",
    "frame = frame.drop(['TestClassName', 'ClassName', 'Project'], axis=1)\n",
    "frame.to_csv ('good_tests_extended.csv', index = False, header=True)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>mutation</th>\n",
       "      <th>no_mutations</th>\n",
       "      <th>line_coverage</th>\n",
       "      <th>isAssertionRoulette</th>\n",
       "      <th>isEagerTest</th>\n",
       "      <th>isLazyTest</th>\n",
       "      <th>isMysteryGuest</th>\n",
       "      <th>isSensitiveEquality</th>\n",
       "      <th>isResourceOptimism</th>\n",
       "      <th>...</th>\n",
       "      <th>Sum Depths_prod</th>\n",
       "      <th>Avg Depth_prod</th>\n",
       "      <th>Branching_prod</th>\n",
       "      <th>Dexterity_prod</th>\n",
       "      <th>No. Expressions_prod</th>\n",
       "      <th>No. Try_prod</th>\n",
       "      <th>No. Catch_prod</th>\n",
       "      <th>No. Loop_prod</th>\n",
       "      <th>No. Conditions_prod</th>\n",
       "      <th>No. Else_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>org.apache.commons.lang3.reflect.TypeLiteral</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>44</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2449.0</td>\n",
       "      <td>3.139744</td>\n",
       "      <td>1.524359</td>\n",
       "      <td>48.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>org.opengrok.suggest.query.SuggesterWildcardQuery</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>14</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>145.0</td>\n",
       "      <td>5.178571</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>org.apache.commons.math3.exception.TooManyEval...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.818182</td>\n",
       "      <td>4.272727</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>com.puppycrawl.tools.checkstyle.checks.imports...</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>22</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>171.0</td>\n",
       "      <td>4.275000</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>org.apache.commons.math3.random.RandomAdaptor</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>41</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>464.0</td>\n",
       "      <td>4.989247</td>\n",
       "      <td>5.387097</td>\n",
       "      <td>29.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667</th>\n",
       "      <td>org.jfree.data.xy.MatrixSeriesCollection</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>117</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1266.0</td>\n",
       "      <td>3.180905</td>\n",
       "      <td>2.120603</td>\n",
       "      <td>42.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>org.jsoup.parser.Tokeniser</td>\n",
       "      <td>0.381963</td>\n",
       "      <td>377</td>\n",
       "      <td>0.579618</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2579.0</td>\n",
       "      <td>3.332041</td>\n",
       "      <td>3.325581</td>\n",
       "      <td>42.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>com.google.debugging.sourcemap.Util</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>156</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>2.114286</td>\n",
       "      <td>37.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>io.reactivex.Observable</td>\n",
       "      <td>0.084152</td>\n",
       "      <td>4171</td>\n",
       "      <td>0.152627</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52986.0</td>\n",
       "      <td>5.226990</td>\n",
       "      <td>15.525106</td>\n",
       "      <td>49.0</td>\n",
       "      <td>18616.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682</th>\n",
       "      <td>org.opengrok.indexer.configuration.Configuration</td>\n",
       "      <td>0.051495</td>\n",
       "      <td>602</td>\n",
       "      <td>0.640227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6440.0</td>\n",
       "      <td>4.099300</td>\n",
       "      <td>19.502864</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>765 rows Ã 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             class_name  mutation  \\\n",
       "0          org.apache.commons.lang3.reflect.TypeLiteral  0.363636   \n",
       "2     org.opengrok.suggest.query.SuggesterWildcardQuery  0.357143   \n",
       "4     org.apache.commons.math3.exception.TooManyEval...  0.333333   \n",
       "8     com.puppycrawl.tools.checkstyle.checks.imports...  0.454545   \n",
       "9         org.apache.commons.math3.random.RandomAdaptor  0.365854   \n",
       "...                                                 ...       ...   \n",
       "2667           org.jfree.data.xy.MatrixSeriesCollection  0.179487   \n",
       "2671                         org.jsoup.parser.Tokeniser  0.381963   \n",
       "2675                com.google.debugging.sourcemap.Util  0.134615   \n",
       "2680                            io.reactivex.Observable  0.084152   \n",
       "2682   org.opengrok.indexer.configuration.Configuration  0.051495   \n",
       "\n",
       "      no_mutations  line_coverage  isAssertionRoulette  isEagerTest  \\\n",
       "0               44       0.750000                    1            1   \n",
       "2               14       0.500000                    0            0   \n",
       "4                3       1.000000                    0            0   \n",
       "8               22       1.000000                    0            0   \n",
       "9               41       0.695652                    1            1   \n",
       "...            ...            ...                  ...          ...   \n",
       "2667           117       0.316667                    1            1   \n",
       "2671           377       0.579618                    1            0   \n",
       "2675           156       0.215686                    1            1   \n",
       "2680          4171       0.152627                    1            1   \n",
       "2682           602       0.640227                    0            0   \n",
       "\n",
       "      isLazyTest  isMysteryGuest  isSensitiveEquality  isResourceOptimism  \\\n",
       "0              0               0                    0                   0   \n",
       "2              0               0                    0                   0   \n",
       "4              0               0                    0                   0   \n",
       "8              0               0                    0                   0   \n",
       "9              0               0                    0                   0   \n",
       "...          ...             ...                  ...                 ...   \n",
       "2667           0               0                    0                   0   \n",
       "2671           0               0                    0                   0   \n",
       "2675           0               0                    1                   0   \n",
       "2680           0               0                    0                   0   \n",
       "2682           0               0                    0                   0   \n",
       "\n",
       "      ...  Sum Depths_prod  Avg Depth_prod  Branching_prod  Dexterity_prod  \\\n",
       "0     ...           2449.0        3.139744        1.524359            48.0   \n",
       "2     ...            145.0        5.178571        3.428571            21.0   \n",
       "4     ...             64.0        5.818182        4.272727            18.0   \n",
       "8     ...            171.0        4.275000        2.650000            23.0   \n",
       "9     ...            464.0        4.989247        5.387097            29.0   \n",
       "...   ...              ...             ...             ...             ...   \n",
       "2667  ...           1266.0        3.180905        2.120603            42.0   \n",
       "2671  ...           2579.0        3.332041        3.325581            42.0   \n",
       "2675  ...           1200.0        3.428571        2.114286            37.0   \n",
       "2680  ...          52986.0        5.226990       15.525106            49.0   \n",
       "2682  ...           6440.0        4.099300       19.502864            46.0   \n",
       "\n",
       "      No. Expressions_prod  No. Try_prod  No. Catch_prod  No. Loop_prod  \\\n",
       "0                    623.0           0.0             0.0            3.0   \n",
       "2                     36.0           0.0             0.0            0.0   \n",
       "4                     16.0           0.0             0.0            0.0   \n",
       "8                     48.0           0.0             0.0            0.0   \n",
       "9                    116.0           0.0             0.0            0.0   \n",
       "...                    ...           ...             ...            ...   \n",
       "2667                 406.0           0.0             0.0            1.0   \n",
       "2671                 753.0           1.0             1.0            2.0   \n",
       "2675                 314.0           0.0             0.0            3.0   \n",
       "2680               18616.0           3.0             4.0            1.0   \n",
       "2682                1610.0           4.0             0.0            2.0   \n",
       "\n",
       "      No. Conditions_prod  No. Else_prod  \n",
       "0                    16.0            9.0  \n",
       "2                     1.0            0.0  \n",
       "4                     0.0            0.0  \n",
       "8                     1.0            1.0  \n",
       "9                     3.0            0.0  \n",
       "...                   ...            ...  \n",
       "2667                  7.0            0.0  \n",
       "2671                 28.0            9.0  \n",
       "2675                  8.0            0.0  \n",
       "2680                 54.0            6.0  \n",
       "2682                 21.0            0.0  \n",
       "\n",
       "[765 rows x 106 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame1 = pd.read_csv('bad_tests.csv', sep=\",\")\n",
    "frame1['TestClassName'] = frame1.apply(lambda row: label_rename1(row), axis=1)\n",
    "frame2 = load_frame() #pd.read_csv(CSV_MINER_PATH, sep=',')\n",
    "\n",
    "frame = frame2[frame2['TestClassName'].isin(frame1['TestClassName'].to_list())]\n",
    "frame = frame.drop(['TestClassName', 'ClassName', 'Project'], axis=1)\n",
    "\n",
    "\n",
    "frame.to_csv ('bad_tests_extended.csv', index = False, header=True)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2412 samples\n",
      "Epoch 1/500\n",
      "2412/2412 [==============================] - 1s 393us/sample - loss: 0.9012 - mae: 0.2946\n",
      "Epoch 2/500\n",
      "2412/2412 [==============================] - 0s 91us/sample - loss: 0.6057 - mae: 0.1584\n",
      "Epoch 3/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.4762 - mae: 0.1299\n",
      "Epoch 4/500\n",
      "2412/2412 [==============================] - 0s 91us/sample - loss: 0.3806 - mae: 0.1171\n",
      "Epoch 5/500\n",
      "2412/2412 [==============================] - 0s 85us/sample - loss: 0.3086 - mae: 0.1113\n",
      "Epoch 6/500\n",
      "2412/2412 [==============================] - 0s 85us/sample - loss: 0.2523 - mae: 0.1053\n",
      "Epoch 7/500\n",
      "2412/2412 [==============================] - 0s 87us/sample - loss: 0.2086 - mae: 0.1022\n",
      "Epoch 8/500\n",
      "2412/2412 [==============================] - 0s 85us/sample - loss: 0.1739 - mae: 0.0988\n",
      "Epoch 9/500\n",
      "2412/2412 [==============================] - 0s 89us/sample - loss: 0.1461 - mae: 0.0981\n",
      "Epoch 10/500\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.1238 - mae: 0.0975\n",
      "Epoch 11/500\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.1058 - mae: 0.0962\n",
      "Epoch 12/500\n",
      "2412/2412 [==============================] - 0s 85us/sample - loss: 0.0908 - mae: 0.0961\n",
      "Epoch 13/500\n",
      "2412/2412 [==============================] - 0s 85us/sample - loss: 0.0785 - mae: 0.0951\n",
      "Epoch 14/500\n",
      "2412/2412 [==============================] - 0s 85us/sample - loss: 0.0685 - mae: 0.0943\n",
      "Epoch 15/500\n",
      "2412/2412 [==============================] - 0s 85us/sample - loss: 0.0603 - mae: 0.0948\n",
      "Epoch 16/500\n",
      "2412/2412 [==============================] - 0s 89us/sample - loss: 0.0536 - mae: 0.0945\n",
      "Epoch 17/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0478 - mae: 0.0940\n",
      "Epoch 18/500\n",
      "2412/2412 [==============================] - 0s 90us/sample - loss: 0.0432 - mae: 0.0939\n",
      "Epoch 19/500\n",
      "2412/2412 [==============================] - 0s 85us/sample - loss: 0.0395 - mae: 0.0945\n",
      "Epoch 20/500\n",
      "2412/2412 [==============================] - 0s 86us/sample - loss: 0.0362 - mae: 0.0947\n",
      "Epoch 21/500\n",
      "2412/2412 [==============================] - 0s 88us/sample - loss: 0.0332 - mae: 0.0932\n",
      "Epoch 22/500\n",
      "2412/2412 [==============================] - 0s 88us/sample - loss: 0.0307 - mae: 0.0927\n",
      "Epoch 23/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0286 - mae: 0.0916\n",
      "Epoch 24/500\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0270 - mae: 0.0918\n",
      "Epoch 25/500\n",
      "2412/2412 [==============================] - 0s 86us/sample - loss: 0.0261 - mae: 0.0939\n",
      "Epoch 26/500\n",
      "2412/2412 [==============================] - 0s 87us/sample - loss: 0.0247 - mae: 0.0933\n",
      "Epoch 27/500\n",
      "2412/2412 [==============================] - 0s 85us/sample - loss: 0.0233 - mae: 0.0901\n",
      "Epoch 28/500\n",
      "2412/2412 [==============================] - 0s 91us/sample - loss: 0.0226 - mae: 0.0919\n",
      "Epoch 29/500\n",
      "2412/2412 [==============================] - 0s 86us/sample - loss: 0.0218 - mae: 0.0912\n",
      "Epoch 30/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0208 - mae: 0.0891\n",
      "Epoch 31/500\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0200 - mae: 0.0882\n",
      "Epoch 32/500\n",
      "2412/2412 [==============================] - 0s 88us/sample - loss: 0.0193 - mae: 0.0876\n",
      "Epoch 33/500\n",
      "2412/2412 [==============================] - 0s 90us/sample - loss: 0.0190 - mae: 0.0878\n",
      "Epoch 34/500\n",
      "2412/2412 [==============================] - 0s 87us/sample - loss: 0.0188 - mae: 0.0882\n",
      "Epoch 35/500\n",
      "2412/2412 [==============================] - 0s 87us/sample - loss: 0.0183 - mae: 0.0868\n",
      "Epoch 36/500\n",
      "2412/2412 [==============================] - 0s 89us/sample - loss: 0.0184 - mae: 0.0886\n",
      "Epoch 37/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0181 - mae: 0.0883\n",
      "Epoch 38/500\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0173 - mae: 0.0860\n",
      "Epoch 39/500\n",
      "2412/2412 [==============================] - 0s 90us/sample - loss: 0.0171 - mae: 0.0855\n",
      "Epoch 40/500\n",
      "2412/2412 [==============================] - 0s 87us/sample - loss: 0.0170 - mae: 0.0855\n",
      "Epoch 41/500\n",
      "2412/2412 [==============================] - 0s 86us/sample - loss: 0.0169 - mae: 0.0857\n",
      "Epoch 42/500\n",
      "2412/2412 [==============================] - 0s 87us/sample - loss: 0.0166 - mae: 0.0850\n",
      "Epoch 43/500\n",
      "2412/2412 [==============================] - 0s 89us/sample - loss: 0.0162 - mae: 0.0843\n",
      "Epoch 44/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0162 - mae: 0.0842\n",
      "Epoch 45/500\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0163 - mae: 0.0842\n",
      "Epoch 46/500\n",
      "2412/2412 [==============================] - 0s 87us/sample - loss: 0.0156 - mae: 0.0831\n",
      "Epoch 47/500\n",
      "2412/2412 [==============================] - 0s 87us/sample - loss: 0.0154 - mae: 0.0810\n",
      "Epoch 48/500\n",
      "2412/2412 [==============================] - 0s 86us/sample - loss: 0.0153 - mae: 0.0807\n",
      "Epoch 49/500\n",
      "2412/2412 [==============================] - 0s 87us/sample - loss: 0.0151 - mae: 0.0805\n",
      "Epoch 50/500\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0150 - mae: 0.0806\n",
      "Epoch 51/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0148 - mae: 0.0801\n",
      "Epoch 52/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0148 - mae: 0.0793\n",
      "Epoch 53/500\n",
      "2412/2412 [==============================] - 0s 91us/sample - loss: 0.0147 - mae: 0.0793\n",
      "Epoch 54/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0146 - mae: 0.0790\n",
      "Epoch 55/500\n",
      "2412/2412 [==============================] - 0s 88us/sample - loss: 0.0150 - mae: 0.0814\n",
      "Epoch 56/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0141 - mae: 0.0773\n",
      "Epoch 57/500\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 0.0138 - mae: 0.0758\n",
      "Epoch 58/500\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 0.0141 - mae: 0.0785\n",
      "Epoch 59/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0137 - mae: 0.0761\n",
      "Epoch 60/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0145 - mae: 0.0798\n",
      "Epoch 61/500\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0136 - mae: 0.0760\n",
      "Epoch 62/500\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0134 - mae: 0.0753\n",
      "Epoch 63/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0135 - mae: 0.0762\n",
      "Epoch 64/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0135 - mae: 0.0760\n",
      "Epoch 65/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0133 - mae: 0.0750\n",
      "Epoch 66/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0132 - mae: 0.0750\n",
      "Epoch 67/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0130 - mae: 0.0740\n",
      "Epoch 68/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0129 - mae: 0.0734\n",
      "Epoch 69/500\n",
      "2412/2412 [==============================] - 0s 89us/sample - loss: 0.0127 - mae: 0.0727\n",
      "Epoch 70/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0129 - mae: 0.0744\n",
      "Epoch 71/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0125 - mae: 0.0721\n",
      "Epoch 72/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0123 - mae: 0.0717\n",
      "Epoch 73/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0123 - mae: 0.0708\n",
      "Epoch 74/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0123 - mae: 0.0705\n",
      "Epoch 75/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0121 - mae: 0.0703\n",
      "Epoch 76/500\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 0.0123 - mae: 0.0717\n",
      "Epoch 77/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0121 - mae: 0.0707\n",
      "Epoch 78/500\n",
      "2412/2412 [==============================] - 0s 91us/sample - loss: 0.0120 - mae: 0.0696\n",
      "Epoch 79/500\n",
      "2412/2412 [==============================] - 0s 91us/sample - loss: 0.0117 - mae: 0.0689\n",
      "Epoch 80/500\n",
      "2412/2412 [==============================] - 0s 90us/sample - loss: 0.0121 - mae: 0.0705\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412/2412 [==============================] - 0s 91us/sample - loss: 0.0117 - mae: 0.0684\n",
      "Epoch 82/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0115 - mae: 0.0689\n",
      "Epoch 83/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0116 - mae: 0.0685\n",
      "Epoch 84/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0114 - mae: 0.0682\n",
      "Epoch 85/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0112 - mae: 0.0669\n",
      "Epoch 86/500\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0110 - mae: 0.0655\n",
      "Epoch 87/500\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0111 - mae: 0.0664\n",
      "Epoch 88/500\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0111 - mae: 0.0664\n",
      "Epoch 89/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0110 - mae: 0.0662\n",
      "Epoch 90/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0112 - mae: 0.0674\n",
      "Epoch 91/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0108 - mae: 0.0657\n",
      "Epoch 92/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0107 - mae: 0.0645\n",
      "Epoch 93/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0108 - mae: 0.0659\n",
      "Epoch 94/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0103 - mae: 0.0633\n",
      "Epoch 95/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0103 - mae: 0.0631\n",
      "Epoch 96/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0104 - mae: 0.0640\n",
      "Epoch 97/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0105 - mae: 0.0650\n",
      "Epoch 98/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0101 - mae: 0.0632\n",
      "Epoch 99/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0101 - mae: 0.0629\n",
      "Epoch 100/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0101 - mae: 0.0628\n",
      "Epoch 101/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0102 - mae: 0.0628\n",
      "Epoch 102/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0098 - mae: 0.0611\n",
      "Epoch 103/500\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0099 - mae: 0.0620\n",
      "Epoch 104/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0098 - mae: 0.0612\n",
      "Epoch 105/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0100 - mae: 0.0625\n",
      "Epoch 106/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0102 - mae: 0.0648\n",
      "Epoch 107/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0096 - mae: 0.0606\n",
      "Epoch 108/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0095 - mae: 0.0601\n",
      "Epoch 109/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0097 - mae: 0.0615\n",
      "Epoch 110/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0097 - mae: 0.0619\n",
      "Epoch 111/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0099 - mae: 0.0630\n",
      "Epoch 112/500\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0096 - mae: 0.0615\n",
      "Epoch 113/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0092 - mae: 0.0586\n",
      "Epoch 114/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0094 - mae: 0.0606\n",
      "Epoch 115/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0099 - mae: 0.0637\n",
      "Epoch 116/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0091 - mae: 0.0591\n",
      "Epoch 117/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0091 - mae: 0.0582\n",
      "Epoch 118/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0093 - mae: 0.0599\n",
      "Epoch 119/500\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 0.0091 - mae: 0.0592\n",
      "Epoch 120/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0089 - mae: 0.0573\n",
      "Epoch 121/500\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 0.0088 - mae: 0.0575\n",
      "Epoch 122/500\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 0.0087 - mae: 0.0567\n",
      "Epoch 123/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0088 - mae: 0.0575\n",
      "Epoch 124/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0089 - mae: 0.0578\n",
      "Epoch 125/500\n",
      "2412/2412 [==============================] - 0s 126us/sample - loss: 0.0090 - mae: 0.0587\n",
      "Epoch 126/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0086 - mae: 0.0571\n",
      "Epoch 127/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0088 - mae: 0.0585\n",
      "Epoch 128/500\n",
      "2412/2412 [==============================] - 0s 120us/sample - loss: 0.0088 - mae: 0.0582\n",
      "Epoch 129/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0089 - mae: 0.0585\n",
      "Epoch 130/500\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0087 - mae: 0.0578\n",
      "Epoch 131/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0083 - mae: 0.0557\n",
      "Epoch 132/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0082 - mae: 0.0547\n",
      "Epoch 133/500\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 0.0083 - mae: 0.0557\n",
      "Epoch 134/500\n",
      "2412/2412 [==============================] - 0s 115us/sample - loss: 0.0084 - mae: 0.0564\n",
      "Epoch 135/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0084 - mae: 0.0572\n",
      "Epoch 136/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0084 - mae: 0.0565\n",
      "Epoch 137/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0082 - mae: 0.0550\n",
      "Epoch 138/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0080 - mae: 0.0543\n",
      "Epoch 139/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0083 - mae: 0.0562\n",
      "Epoch 140/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0082 - mae: 0.0560\n",
      "Epoch 141/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0081 - mae: 0.0550\n",
      "Epoch 142/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0082 - mae: 0.0555\n",
      "Epoch 143/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0080 - mae: 0.0545\n",
      "Epoch 144/500\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0080 - mae: 0.0543\n",
      "Epoch 145/500\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0078 - mae: 0.0531\n",
      "Epoch 146/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0078 - mae: 0.0538\n",
      "Epoch 147/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0075 - mae: 0.0515\n",
      "Epoch 148/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0078 - mae: 0.0535\n",
      "Epoch 149/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0078 - mae: 0.0541\n",
      "Epoch 150/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0077 - mae: 0.0538\n",
      "Epoch 151/500\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0075 - mae: 0.0522\n",
      "Epoch 152/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0076 - mae: 0.0532\n",
      "Epoch 153/500\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0079 - mae: 0.0543\n",
      "Epoch 154/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0079 - mae: 0.0549\n",
      "Epoch 155/500\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0076 - mae: 0.0530\n",
      "Epoch 156/500\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0077 - mae: 0.0540\n",
      "Epoch 157/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0073 - mae: 0.0509\n",
      "Epoch 158/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0077 - mae: 0.0537\n",
      "Epoch 159/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0076 - mae: 0.0535\n",
      "Epoch 160/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0075 - mae: 0.0527\n",
      "Epoch 161/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0073 - mae: 0.0513\n",
      "Epoch 162/500\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0073 - mae: 0.0508\n",
      "Epoch 163/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0074 - mae: 0.0524\n",
      "Epoch 164/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0073 - mae: 0.0521\n",
      "Epoch 165/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0072 - mae: 0.0517\n",
      "Epoch 166/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0073 - mae: 0.0520\n",
      "Epoch 167/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0071 - mae: 0.0509\n",
      "Epoch 168/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0074 - mae: 0.0527\n",
      "Epoch 169/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0069 - mae: 0.0494\n",
      "Epoch 170/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0070 - mae: 0.0499\n",
      "Epoch 171/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0070 - mae: 0.0506\n",
      "Epoch 172/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0070 - mae: 0.0504\n",
      "Epoch 173/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0071 - mae: 0.0506\n",
      "Epoch 174/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0069 - mae: 0.0505\n",
      "Epoch 175/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0071 - mae: 0.0507\n",
      "Epoch 176/500\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 0.0071 - mae: 0.0515\n",
      "Epoch 177/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0068 - mae: 0.0487\n",
      "Epoch 178/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0066 - mae: 0.0478\n",
      "Epoch 179/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0068 - mae: 0.0491\n",
      "Epoch 180/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0068 - mae: 0.0488\n",
      "Epoch 181/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0067 - mae: 0.0484\n",
      "Epoch 182/500\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 0.0067 - mae: 0.0487\n",
      "Epoch 183/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0067 - mae: 0.0485\n",
      "Epoch 184/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0069 - mae: 0.0501\n",
      "Epoch 185/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0067 - mae: 0.0485\n",
      "Epoch 186/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0072 - mae: 0.0526\n",
      "Epoch 187/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0067 - mae: 0.0491\n",
      "Epoch 188/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0069 - mae: 0.0505\n",
      "Epoch 189/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0067 - mae: 0.0496\n",
      "Epoch 190/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0064 - mae: 0.0480\n",
      "Epoch 191/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0065 - mae: 0.0476\n",
      "Epoch 192/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0066 - mae: 0.0487\n",
      "Epoch 193/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0066 - mae: 0.0487\n",
      "Epoch 194/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0063 - mae: 0.0471\n",
      "Epoch 195/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0065 - mae: 0.0488\n",
      "Epoch 196/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0063 - mae: 0.0467\n",
      "Epoch 197/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0063 - mae: 0.0467\n",
      "Epoch 198/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0065 - mae: 0.0488\n",
      "Epoch 199/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0064 - mae: 0.0478\n",
      "Epoch 200/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0063 - mae: 0.0467\n",
      "Epoch 201/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0064 - mae: 0.0479\n",
      "Epoch 202/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0064 - mae: 0.0487\n",
      "Epoch 203/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0065 - mae: 0.0491\n",
      "Epoch 204/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0064 - mae: 0.0472\n",
      "Epoch 205/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0064 - mae: 0.0489\n",
      "Epoch 206/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0063 - mae: 0.0474\n",
      "Epoch 207/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0062 - mae: 0.0474\n",
      "Epoch 208/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0061 - mae: 0.0454\n",
      "Epoch 209/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0062 - mae: 0.0467\n",
      "Epoch 210/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0060 - mae: 0.0458\n",
      "Epoch 211/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0061 - mae: 0.0457\n",
      "Epoch 212/500\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0063 - mae: 0.0476\n",
      "Epoch 213/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0062 - mae: 0.0473\n",
      "Epoch 214/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0060 - mae: 0.0456\n",
      "Epoch 215/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0060 - mae: 0.0458\n",
      "Epoch 216/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0064 - mae: 0.0481\n",
      "Epoch 217/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0065 - mae: 0.0489\n",
      "Epoch 218/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0060 - mae: 0.0462\n",
      "Epoch 219/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0062 - mae: 0.0471\n",
      "Epoch 220/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0064 - mae: 0.0494\n",
      "Epoch 221/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0060 - mae: 0.0459\n",
      "Epoch 222/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0060 - mae: 0.0464\n",
      "Epoch 223/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0060 - mae: 0.0463\n",
      "Epoch 224/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0058 - mae: 0.0443\n",
      "Epoch 225/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0057 - mae: 0.0438\n",
      "Epoch 226/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0058 - mae: 0.0442\n",
      "Epoch 227/500\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 0.0058 - mae: 0.0448\n",
      "Epoch 228/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0057 - mae: 0.0435\n",
      "Epoch 229/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0058 - mae: 0.0457\n",
      "Epoch 230/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0056 - mae: 0.0434\n",
      "Epoch 231/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0057 - mae: 0.0443\n",
      "Epoch 232/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0058 - mae: 0.0457\n",
      "Epoch 233/500\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 0.0059 - mae: 0.0458\n",
      "Epoch 234/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0059 - mae: 0.0462\n",
      "Epoch 235/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0060 - mae: 0.0470\n",
      "Epoch 236/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0059 - mae: 0.0462\n",
      "Epoch 237/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0059 - mae: 0.0462\n",
      "Epoch 238/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0060 - mae: 0.0475\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0055 - mae: 0.0433\n",
      "Epoch 240/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0056 - mae: 0.0449\n",
      "Epoch 241/500\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0054 - mae: 0.0422\n",
      "Epoch 242/500\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0055 - mae: 0.0436\n",
      "Epoch 243/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0059 - mae: 0.0472\n",
      "Epoch 244/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0058 - mae: 0.0450\n",
      "Epoch 245/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0055 - mae: 0.0440\n",
      "Epoch 246/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0060 - mae: 0.0470\n",
      "Epoch 247/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0055 - mae: 0.0438\n",
      "Epoch 248/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0056 - mae: 0.0441\n",
      "Epoch 249/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0055 - mae: 0.0432\n",
      "Epoch 250/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0053 - mae: 0.0417\n",
      "Epoch 251/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0053 - mae: 0.0424\n",
      "Epoch 252/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0053 - mae: 0.0426\n",
      "Epoch 253/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0054 - mae: 0.0430\n",
      "Epoch 254/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0053 - mae: 0.0423\n",
      "Epoch 255/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0056 - mae: 0.0449\n",
      "Epoch 256/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0055 - mae: 0.0442\n",
      "Epoch 257/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0058 - mae: 0.0463\n",
      "Epoch 258/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0053 - mae: 0.0422\n",
      "Epoch 259/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0053 - mae: 0.0436\n",
      "Epoch 260/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0055 - mae: 0.0447\n",
      "Epoch 261/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0056 - mae: 0.0445\n",
      "Epoch 262/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0053 - mae: 0.0428\n",
      "Epoch 263/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0053 - mae: 0.0434\n",
      "Epoch 264/500\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0052 - mae: 0.0417\n",
      "Epoch 265/500\n",
      "2412/2412 [==============================] - 0s 115us/sample - loss: 0.0053 - mae: 0.0426\n",
      "Epoch 266/500\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 0.0053 - mae: 0.0426\n",
      "Epoch 267/500\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0053 - mae: 0.0427\n",
      "Epoch 268/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0050 - mae: 0.0404\n",
      "Epoch 269/500\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 0.0052 - mae: 0.0421\n",
      "Epoch 270/500\n",
      "2412/2412 [==============================] - 0s 140us/sample - loss: 0.0058 - mae: 0.0470\n",
      "Epoch 271/500\n",
      "2412/2412 [==============================] - 0s 123us/sample - loss: 0.0052 - mae: 0.0426\n",
      "Epoch 272/500\n",
      "2412/2412 [==============================] - 0s 136us/sample - loss: 0.0051 - mae: 0.0412\n",
      "Epoch 273/500\n",
      "2412/2412 [==============================] - 0s 142us/sample - loss: 0.0050 - mae: 0.0411\n",
      "Epoch 274/500\n",
      "2412/2412 [==============================] - 0s 124us/sample - loss: 0.0056 - mae: 0.0455\n",
      "Epoch 275/500\n",
      "2412/2412 [==============================] - 0s 126us/sample - loss: 0.0052 - mae: 0.0423\n",
      "Epoch 276/500\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 0.0050 - mae: 0.0407\n",
      "Epoch 277/500\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0051 - mae: 0.0417\n",
      "Epoch 278/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0052 - mae: 0.0426\n",
      "Epoch 279/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0050 - mae: 0.0410\n",
      "Epoch 280/500\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 0.0051 - mae: 0.0421\n",
      "Epoch 281/500\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 0.0049 - mae: 0.0408\n",
      "Epoch 282/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0055 - mae: 0.0444\n",
      "Epoch 283/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0056 - mae: 0.0446\n",
      "Epoch 284/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0053 - mae: 0.0436\n",
      "Epoch 285/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0049 - mae: 0.0402\n",
      "Epoch 286/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0047 - mae: 0.0385\n",
      "Epoch 287/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0054 - mae: 0.0447\n",
      "Epoch 288/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0051 - mae: 0.0422\n",
      "Epoch 289/500\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0050 - mae: 0.0414\n",
      "Epoch 290/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0054 - mae: 0.0447\n",
      "Epoch 291/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0052 - mae: 0.0430\n",
      "Epoch 292/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0049 - mae: 0.0406\n",
      "Epoch 293/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0047 - mae: 0.0396\n",
      "Epoch 294/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0050 - mae: 0.0414\n",
      "Epoch 295/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0048 - mae: 0.0400\n",
      "Epoch 296/500\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0048 - mae: 0.0402\n",
      "Epoch 297/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0049 - mae: 0.0405\n",
      "Epoch 298/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0048 - mae: 0.0401\n",
      "Epoch 299/500\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 0.0051 - mae: 0.0424\n",
      "Epoch 300/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0051 - mae: 0.0424\n",
      "Epoch 301/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0049 - mae: 0.0410\n",
      "Epoch 302/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0047 - mae: 0.0398\n",
      "Epoch 303/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0049 - mae: 0.0416\n",
      "Epoch 304/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0049 - mae: 0.0408\n",
      "Epoch 305/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0049 - mae: 0.0413\n",
      "Epoch 306/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0051 - mae: 0.0434\n",
      "Epoch 307/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0048 - mae: 0.0408\n",
      "Epoch 308/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0055 - mae: 0.0464\n",
      "Epoch 309/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0049 - mae: 0.0407\n",
      "Epoch 310/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0048 - mae: 0.0407\n",
      "Epoch 311/500\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0049 - mae: 0.0410\n",
      "Epoch 312/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0050 - mae: 0.0421\n",
      "Epoch 313/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0047 - mae: 0.0393\n",
      "Epoch 314/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0047 - mae: 0.0404\n",
      "Epoch 315/500\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0048 - mae: 0.0408\n",
      "Epoch 316/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0048 - mae: 0.0417\n",
      "Epoch 317/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0050 - mae: 0.0419\n",
      "Epoch 318/500\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 0.0044 - mae: 0.0381\n",
      "Epoch 319/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0048 - mae: 0.0409\n",
      "Epoch 320/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0051 - mae: 0.0436\n",
      "Epoch 321/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0052 - mae: 0.0439\n",
      "Epoch 322/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0051 - mae: 0.0423\n",
      "Epoch 323/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0048 - mae: 0.0403\n",
      "Epoch 324/500\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 0.0050 - mae: 0.0422\n",
      "Epoch 325/500\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 0.0049 - mae: 0.0422\n",
      "Epoch 326/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0049 - mae: 0.0421\n",
      "Epoch 327/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0049 - mae: 0.0421\n",
      "Epoch 328/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0049 - mae: 0.0417\n",
      "Epoch 329/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0045 - mae: 0.0388\n",
      "Epoch 330/500\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 0.0046 - mae: 0.0391\n",
      "Epoch 331/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0047 - mae: 0.0398\n",
      "Epoch 332/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0048 - mae: 0.0412\n",
      "Epoch 333/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0051 - mae: 0.0430\n",
      "Epoch 334/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0049 - mae: 0.0424\n",
      "Epoch 335/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0046 - mae: 0.0401\n",
      "Epoch 336/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0047 - mae: 0.0408\n",
      "Epoch 337/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0046 - mae: 0.0397\n",
      "Epoch 338/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0048 - mae: 0.0414\n",
      "Epoch 339/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0047 - mae: 0.0408\n",
      "Epoch 340/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0044 - mae: 0.0374\n",
      "Epoch 341/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0044 - mae: 0.0387\n",
      "Epoch 342/500\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 0.0046 - mae: 0.0396\n",
      "Epoch 343/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0046 - mae: 0.0397\n",
      "Epoch 344/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0047 - mae: 0.0404\n",
      "Epoch 345/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0049 - mae: 0.0422\n",
      "Epoch 346/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0043 - mae: 0.0375\n",
      "Epoch 347/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0044 - mae: 0.0386\n",
      "Epoch 348/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0046 - mae: 0.0396\n",
      "Epoch 349/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0044 - mae: 0.0395\n",
      "Epoch 350/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0044 - mae: 0.0386\n",
      "Epoch 351/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0044 - mae: 0.0380\n",
      "Epoch 352/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0047 - mae: 0.0410\n",
      "Epoch 353/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0047 - mae: 0.0409\n",
      "Epoch 354/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0044 - mae: 0.0387\n",
      "Epoch 355/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0047 - mae: 0.0415\n",
      "Epoch 356/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0045 - mae: 0.0393\n",
      "Epoch 357/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0046 - mae: 0.0408\n",
      "Epoch 358/500\n",
      "2412/2412 [==============================] - 0s 115us/sample - loss: 0.0045 - mae: 0.0394\n",
      "Epoch 359/500\n",
      "2412/2412 [==============================] - 0s 117us/sample - loss: 0.0045 - mae: 0.0393\n",
      "Epoch 360/500\n",
      "2412/2412 [==============================] - 0s 134us/sample - loss: 0.0045 - mae: 0.0397\n",
      "Epoch 361/500\n",
      "2412/2412 [==============================] - 0s 144us/sample - loss: 0.0046 - mae: 0.0412\n",
      "Epoch 362/500\n",
      "2412/2412 [==============================] - 0s 126us/sample - loss: 0.0043 - mae: 0.0384\n",
      "Epoch 363/500\n",
      "2412/2412 [==============================] - 0s 129us/sample - loss: 0.0045 - mae: 0.0393\n",
      "Epoch 364/500\n",
      "2412/2412 [==============================] - 0s 125us/sample - loss: 0.0044 - mae: 0.0385\n",
      "Epoch 365/500\n",
      "2412/2412 [==============================] - 0s 132us/sample - loss: 0.0046 - mae: 0.0400\n",
      "Epoch 366/500\n",
      "2412/2412 [==============================] - 0s 128us/sample - loss: 0.0047 - mae: 0.0419\n",
      "Epoch 367/500\n",
      "2412/2412 [==============================] - 0s 121us/sample - loss: 0.0046 - mae: 0.0407\n",
      "Epoch 368/500\n",
      "2412/2412 [==============================] - 0s 120us/sample - loss: 0.0042 - mae: 0.0371\n",
      "Epoch 369/500\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 0.0041 - mae: 0.0351\n",
      "Epoch 370/500\n",
      "2412/2412 [==============================] - 0s 117us/sample - loss: 0.0042 - mae: 0.0379\n",
      "Epoch 371/500\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 0.0045 - mae: 0.0402\n",
      "Epoch 372/500\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0043 - mae: 0.0379\n",
      "Epoch 373/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0044 - mae: 0.0392\n",
      "Epoch 374/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0042 - mae: 0.0373\n",
      "Epoch 375/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0044 - mae: 0.0396\n",
      "Epoch 376/500\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 0.0046 - mae: 0.0407\n",
      "Epoch 377/500\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 0.0044 - mae: 0.0387\n",
      "Epoch 378/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0047 - mae: 0.0403\n",
      "Epoch 379/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0047 - mae: 0.0412\n",
      "Epoch 380/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0043 - mae: 0.0377\n",
      "Epoch 381/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0042 - mae: 0.0377\n",
      "Epoch 382/500\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 0.0043 - mae: 0.0388\n",
      "Epoch 383/500\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 0.0042 - mae: 0.0371\n",
      "Epoch 384/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0044 - mae: 0.0395\n",
      "Epoch 385/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0045 - mae: 0.0400\n",
      "Epoch 386/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0047 - mae: 0.0417\n",
      "Epoch 387/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0044 - mae: 0.0396\n",
      "Epoch 388/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0044 - mae: 0.0391\n",
      "Epoch 389/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0043 - mae: 0.0387\n",
      "Epoch 390/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0044 - mae: 0.0399\n",
      "Epoch 391/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0042 - mae: 0.0382\n",
      "Epoch 392/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0043 - mae: 0.0391\n",
      "Epoch 393/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0043 - mae: 0.0384\n",
      "Epoch 394/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0044 - mae: 0.0394\n",
      "Epoch 395/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0041 - mae: 0.0372\n",
      "Epoch 396/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0041 - mae: 0.0372\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0044 - mae: 0.0393\n",
      "Epoch 398/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0043 - mae: 0.0389\n",
      "Epoch 399/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0046 - mae: 0.0414\n",
      "Epoch 400/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0044 - mae: 0.0393\n",
      "Epoch 401/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0046 - mae: 0.0402\n",
      "Epoch 402/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0043 - mae: 0.0380\n",
      "Epoch 403/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0040 - mae: 0.0366\n",
      "Epoch 404/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0038 - mae: 0.0344\n",
      "Epoch 405/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0044 - mae: 0.0398\n",
      "Epoch 406/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0041 - mae: 0.0372\n",
      "Epoch 407/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0040 - mae: 0.0370\n",
      "Epoch 408/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0041 - mae: 0.0373\n",
      "Epoch 409/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0042 - mae: 0.0380\n",
      "Epoch 410/500\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0040 - mae: 0.0366\n",
      "Epoch 411/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0041 - mae: 0.0373\n",
      "Epoch 412/500\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 0.0044 - mae: 0.0397\n",
      "Epoch 413/500\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 0.0047 - mae: 0.0432\n",
      "Epoch 414/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0039 - mae: 0.0351\n",
      "Epoch 415/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0039 - mae: 0.0354\n",
      "Epoch 416/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0045 - mae: 0.0403\n",
      "Epoch 417/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0041 - mae: 0.0381\n",
      "Epoch 418/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0039 - mae: 0.0355\n",
      "Epoch 419/500\n",
      "2412/2412 [==============================] - 0s 118us/sample - loss: 0.0041 - mae: 0.0370\n",
      "Epoch 420/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0042 - mae: 0.0380\n",
      "Epoch 421/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0049 - mae: 0.0441\n",
      "Epoch 422/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0044 - mae: 0.0396\n",
      "Epoch 423/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0043 - mae: 0.0391\n",
      "Epoch 424/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0041 - mae: 0.0368\n",
      "Epoch 425/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0039 - mae: 0.0356\n",
      "Epoch 426/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0037 - mae: 0.0345\n",
      "Epoch 427/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0038 - mae: 0.0354\n",
      "Epoch 428/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0041 - mae: 0.0385\n",
      "Epoch 429/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0038 - mae: 0.0351\n",
      "Epoch 430/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0041 - mae: 0.0385\n",
      "Epoch 431/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0038 - mae: 0.0355\n",
      "Epoch 432/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0042 - mae: 0.0393\n",
      "Epoch 433/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0038 - mae: 0.0354\n",
      "Epoch 434/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0040 - mae: 0.0369\n",
      "Epoch 435/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0041 - mae: 0.0386\n",
      "Epoch 436/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0040 - mae: 0.0373\n",
      "Epoch 437/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0040 - mae: 0.0375\n",
      "Epoch 438/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0039 - mae: 0.0363\n",
      "Epoch 439/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0038 - mae: 0.0354\n",
      "Epoch 440/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0039 - mae: 0.0364\n",
      "Epoch 441/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0043 - mae: 0.0398\n",
      "Epoch 442/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0044 - mae: 0.0406\n",
      "Epoch 443/500\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 0.0040 - mae: 0.0377\n",
      "Epoch 444/500\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 0.0039 - mae: 0.0359\n",
      "Epoch 445/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0046 - mae: 0.0422\n",
      "Epoch 446/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0042 - mae: 0.0380\n",
      "Epoch 447/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0040 - mae: 0.0369\n",
      "Epoch 448/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0039 - mae: 0.0365\n",
      "Epoch 449/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0043 - mae: 0.0398\n",
      "Epoch 450/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0040 - mae: 0.0379\n",
      "Epoch 451/500\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0038 - mae: 0.0356\n",
      "Epoch 452/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0037 - mae: 0.0347\n",
      "Epoch 453/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0039 - mae: 0.0360\n",
      "Epoch 454/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0049 - mae: 0.0445\n",
      "Epoch 455/500\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 0.0037 - mae: 0.0343\n",
      "Epoch 456/500\n",
      "2412/2412 [==============================] - 0s 117us/sample - loss: 0.0039 - mae: 0.0357\n",
      "Epoch 457/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0037 - mae: 0.0346\n",
      "Epoch 458/500\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 0.0039 - mae: 0.0374\n",
      "Epoch 459/500\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 0.0043 - mae: 0.0402\n",
      "Epoch 460/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0038 - mae: 0.0360\n",
      "Epoch 461/500\n",
      "2412/2412 [==============================] - 0s 115us/sample - loss: 0.0037 - mae: 0.0353\n",
      "Epoch 462/500\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 0.0039 - mae: 0.0365\n",
      "Epoch 463/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0037 - mae: 0.0348\n",
      "Epoch 464/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0040 - mae: 0.0364\n",
      "Epoch 465/500\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0040 - mae: 0.0377\n",
      "Epoch 466/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0039 - mae: 0.0363\n",
      "Epoch 467/500\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 0.0037 - mae: 0.0346\n",
      "Epoch 468/500\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 0.0040 - mae: 0.0375\n",
      "Epoch 469/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0038 - mae: 0.0365\n",
      "Epoch 470/500\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0036 - mae: 0.0347\n",
      "Epoch 471/500\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0036 - mae: 0.0340\n",
      "Epoch 472/500\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 0.0038 - mae: 0.0356\n",
      "Epoch 473/500\n",
      "2412/2412 [==============================] - 0s 119us/sample - loss: 0.0038 - mae: 0.0363\n",
      "Epoch 474/500\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 0.0041 - mae: 0.0381\n",
      "Epoch 475/500\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 0.0040 - mae: 0.0378\n",
      "Epoch 476/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412/2412 [==============================] - 0s 115us/sample - loss: 0.0038 - mae: 0.0353\n",
      "Epoch 477/500\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 0.0048 - mae: 0.0417\n",
      "Epoch 478/500\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 0.0039 - mae: 0.0373\n",
      "Epoch 479/500\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0035 - mae: 0.0330\n",
      "Epoch 480/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0037 - mae: 0.0354\n",
      "Epoch 481/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0041 - mae: 0.0379\n",
      "Epoch 482/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0037 - mae: 0.0354\n",
      "Epoch 483/500\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0041 - mae: 0.0385\n",
      "Epoch 484/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0037 - mae: 0.0342\n",
      "Epoch 485/500\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0039 - mae: 0.0371\n",
      "Epoch 486/500\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0036 - mae: 0.0341\n",
      "Epoch 487/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0036 - mae: 0.0340\n",
      "Epoch 488/500\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0038 - mae: 0.0363\n",
      "Epoch 489/500\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0040 - mae: 0.0372\n",
      "Epoch 490/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0039 - mae: 0.0363\n",
      "Epoch 491/500\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0039 - mae: 0.0378\n",
      "Epoch 492/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0038 - mae: 0.0364\n",
      "Epoch 493/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0036 - mae: 0.0349\n",
      "Epoch 494/500\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0036 - mae: 0.0339\n",
      "Epoch 495/500\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0035 - mae: 0.0332\n",
      "Epoch 496/500\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0034 - mae: 0.0332\n",
      "Epoch 497/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0039 - mae: 0.0376\n",
      "Epoch 498/500\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0040 - mae: 0.0385\n",
      "Epoch 499/500\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0040 - mae: 0.0385\n",
      "Epoch 500/500\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0036 - mae: 0.0352\n",
      "mae: 0.10433141887187958\n",
      "Overfit mae: 0.03105635568499565\n",
      "Train on 2413 samples\n",
      "Epoch 1/500\n",
      "2413/2413 [==============================] - 1s 411us/sample - loss: 0.8676 - mae: 0.2735\n",
      "Epoch 2/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.6044 - mae: 0.1613\n",
      "Epoch 3/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.4893 - mae: 0.1411\n",
      "Epoch 4/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.3996 - mae: 0.1276\n",
      "Epoch 5/500\n",
      "2413/2413 [==============================] - 0s 91us/sample - loss: 0.3268 - mae: 0.1160\n",
      "Epoch 6/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.2724 - mae: 0.1101\n",
      "Epoch 7/500\n",
      "2413/2413 [==============================] - 0s 91us/sample - loss: 0.2288 - mae: 0.1053\n",
      "Epoch 8/500\n",
      "2413/2413 [==============================] - 0s 91us/sample - loss: 0.1937 - mae: 0.1033\n",
      "Epoch 9/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.1647 - mae: 0.1000\n",
      "Epoch 10/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.1412 - mae: 0.0993\n",
      "Epoch 11/500\n",
      "2413/2413 [==============================] - 0s 91us/sample - loss: 0.1222 - mae: 0.0992\n",
      "Epoch 12/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.1058 - mae: 0.0972\n",
      "Epoch 13/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0921 - mae: 0.0968\n",
      "Epoch 14/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0808 - mae: 0.0957\n",
      "Epoch 15/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0716 - mae: 0.0957\n",
      "Epoch 16/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0637 - mae: 0.0959\n",
      "Epoch 17/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0570 - mae: 0.0949\n",
      "Epoch 18/500\n",
      "2413/2413 [==============================] - 0s 91us/sample - loss: 0.0507 - mae: 0.0926\n",
      "Epoch 19/500\n",
      "2413/2413 [==============================] - 0s 91us/sample - loss: 0.0458 - mae: 0.0927\n",
      "Epoch 20/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.0417 - mae: 0.0924\n",
      "Epoch 21/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.0382 - mae: 0.0919\n",
      "Epoch 22/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0352 - mae: 0.0914\n",
      "Epoch 23/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0328 - mae: 0.0918\n",
      "Epoch 24/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0307 - mae: 0.0914\n",
      "Epoch 25/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0288 - mae: 0.0909\n",
      "Epoch 26/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0274 - mae: 0.0912\n",
      "Epoch 27/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0253 - mae: 0.0886\n",
      "Epoch 28/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0245 - mae: 0.0893\n",
      "Epoch 29/500\n",
      "2413/2413 [==============================] - 0s 109us/sample - loss: 0.0233 - mae: 0.0887\n",
      "Epoch 30/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0225 - mae: 0.0885\n",
      "Epoch 31/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.0217 - mae: 0.0884\n",
      "Epoch 32/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0211 - mae: 0.0883\n",
      "Epoch 33/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0207 - mae: 0.0884\n",
      "Epoch 34/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0198 - mae: 0.0874\n",
      "Epoch 35/500\n",
      "2413/2413 [==============================] - 0s 112us/sample - loss: 0.0199 - mae: 0.0879\n",
      "Epoch 36/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0188 - mae: 0.0858\n",
      "Epoch 37/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0188 - mae: 0.0875\n",
      "Epoch 38/500\n",
      "2413/2413 [==============================] - 0s 109us/sample - loss: 0.0181 - mae: 0.0851\n",
      "Epoch 39/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0178 - mae: 0.0853\n",
      "Epoch 40/500\n",
      "2413/2413 [==============================] - 0s 111us/sample - loss: 0.0175 - mae: 0.0852\n",
      "Epoch 41/500\n",
      "2413/2413 [==============================] - 0s 119us/sample - loss: 0.0173 - mae: 0.0845\n",
      "Epoch 42/500\n",
      "2413/2413 [==============================] - 0s 115us/sample - loss: 0.0171 - mae: 0.0845\n",
      "Epoch 43/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0168 - mae: 0.0839\n",
      "Epoch 44/500\n",
      "2413/2413 [==============================] - 0s 109us/sample - loss: 0.0165 - mae: 0.0830\n",
      "Epoch 45/500\n",
      "2413/2413 [==============================] - 0s 115us/sample - loss: 0.0165 - mae: 0.0828\n",
      "Epoch 46/500\n",
      "2413/2413 [==============================] - 0s 122us/sample - loss: 0.0163 - mae: 0.0832\n",
      "Epoch 47/500\n",
      "2413/2413 [==============================] - 0s 116us/sample - loss: 0.0158 - mae: 0.0820\n",
      "Epoch 48/500\n",
      "2413/2413 [==============================] - 0s 119us/sample - loss: 0.0160 - mae: 0.0824\n",
      "Epoch 49/500\n",
      "2413/2413 [==============================] - 0s 120us/sample - loss: 0.0154 - mae: 0.0800\n",
      "Epoch 50/500\n",
      "2413/2413 [==============================] - 0s 121us/sample - loss: 0.0156 - mae: 0.0820\n",
      "Epoch 51/500\n",
      "2413/2413 [==============================] - 0s 132us/sample - loss: 0.0156 - mae: 0.0816\n",
      "Epoch 52/500\n",
      "2413/2413 [==============================] - 0s 129us/sample - loss: 0.0152 - mae: 0.0804\n",
      "Epoch 53/500\n",
      "2413/2413 [==============================] - 0s 122us/sample - loss: 0.0152 - mae: 0.0805\n",
      "Epoch 54/500\n",
      "2413/2413 [==============================] - 0s 113us/sample - loss: 0.0149 - mae: 0.0792\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2413/2413 [==============================] - 0s 122us/sample - loss: 0.0145 - mae: 0.0781\n",
      "Epoch 56/500\n",
      "2413/2413 [==============================] - 0s 131us/sample - loss: 0.0147 - mae: 0.0787\n",
      "Epoch 57/500\n",
      "2413/2413 [==============================] - 0s 122us/sample - loss: 0.0146 - mae: 0.0777\n",
      "Epoch 58/500\n",
      "2413/2413 [==============================] - 0s 115us/sample - loss: 0.0141 - mae: 0.0772\n",
      "Epoch 59/500\n",
      "2413/2413 [==============================] - 0s 119us/sample - loss: 0.0141 - mae: 0.0768\n",
      "Epoch 60/500\n",
      "2413/2413 [==============================] - 0s 123us/sample - loss: 0.0143 - mae: 0.0781\n",
      "Epoch 61/500\n",
      "2413/2413 [==============================] - 0s 128us/sample - loss: 0.0138 - mae: 0.0756\n",
      "Epoch 62/500\n",
      "2413/2413 [==============================] - 0s 140us/sample - loss: 0.0137 - mae: 0.0759\n",
      "Epoch 63/500\n",
      "2413/2413 [==============================] - 0s 125us/sample - loss: 0.0137 - mae: 0.0754\n",
      "Epoch 64/500\n",
      "2413/2413 [==============================] - 0s 128us/sample - loss: 0.0139 - mae: 0.0769\n",
      "Epoch 65/500\n",
      "2413/2413 [==============================] - 0s 132us/sample - loss: 0.0134 - mae: 0.0742\n",
      "Epoch 66/500\n",
      "2413/2413 [==============================] - 0s 139us/sample - loss: 0.0138 - mae: 0.0761\n",
      "Epoch 67/500\n",
      "2413/2413 [==============================] - 0s 142us/sample - loss: 0.0137 - mae: 0.0761\n",
      "Epoch 68/500\n",
      "2413/2413 [==============================] - 0s 126us/sample - loss: 0.0132 - mae: 0.0745\n",
      "Epoch 69/500\n",
      "2413/2413 [==============================] - 0s 130us/sample - loss: 0.0131 - mae: 0.0734\n",
      "Epoch 70/500\n",
      "2413/2413 [==============================] - 0s 122us/sample - loss: 0.0130 - mae: 0.0733\n",
      "Epoch 71/500\n",
      "2413/2413 [==============================] - 0s 131us/sample - loss: 0.0123 - mae: 0.0701\n",
      "Epoch 72/500\n",
      "2413/2413 [==============================] - 0s 123us/sample - loss: 0.0127 - mae: 0.0718\n",
      "Epoch 73/500\n",
      "2413/2413 [==============================] - 0s 117us/sample - loss: 0.0127 - mae: 0.0715\n",
      "Epoch 74/500\n",
      "2413/2413 [==============================] - 0s 119us/sample - loss: 0.0126 - mae: 0.0719\n",
      "Epoch 75/500\n",
      "2413/2413 [==============================] - 0s 117us/sample - loss: 0.0123 - mae: 0.0707\n",
      "Epoch 76/500\n",
      "2413/2413 [==============================] - 0s 123us/sample - loss: 0.0122 - mae: 0.0707\n",
      "Epoch 77/500\n",
      "2413/2413 [==============================] - 0s 126us/sample - loss: 0.0124 - mae: 0.0714\n",
      "Epoch 78/500\n",
      "2413/2413 [==============================] - 0s 114us/sample - loss: 0.0120 - mae: 0.0698\n",
      "Epoch 79/500\n",
      "2413/2413 [==============================] - 0s 117us/sample - loss: 0.0126 - mae: 0.0730\n",
      "Epoch 80/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0120 - mae: 0.0703\n",
      "Epoch 81/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0120 - mae: 0.0699\n",
      "Epoch 82/500\n",
      "2413/2413 [==============================] - 0s 114us/sample - loss: 0.0122 - mae: 0.0712\n",
      "Epoch 83/500\n",
      "2413/2413 [==============================] - 0s 110us/sample - loss: 0.0118 - mae: 0.0685\n",
      "Epoch 84/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0119 - mae: 0.0693\n",
      "Epoch 85/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0121 - mae: 0.0712\n",
      "Epoch 86/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0112 - mae: 0.0657\n",
      "Epoch 87/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0114 - mae: 0.0672\n",
      "Epoch 88/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0111 - mae: 0.0661\n",
      "Epoch 89/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0110 - mae: 0.0663\n",
      "Epoch 90/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0116 - mae: 0.0685\n",
      "Epoch 91/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0115 - mae: 0.0684\n",
      "Epoch 92/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0110 - mae: 0.0666\n",
      "Epoch 93/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0110 - mae: 0.0664\n",
      "Epoch 94/500\n",
      "2413/2413 [==============================] - 0s 109us/sample - loss: 0.0110 - mae: 0.0656\n",
      "Epoch 95/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0110 - mae: 0.0662\n",
      "Epoch 96/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.0105 - mae: 0.0641\n",
      "Epoch 97/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.0108 - mae: 0.0656\n",
      "Epoch 98/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0107 - mae: 0.0645\n",
      "Epoch 99/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0108 - mae: 0.0656\n",
      "Epoch 100/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0103 - mae: 0.0628\n",
      "Epoch 101/500\n",
      "2413/2413 [==============================] - 0s 114us/sample - loss: 0.0105 - mae: 0.0642\n",
      "Epoch 102/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0107 - mae: 0.0658\n",
      "Epoch 103/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0103 - mae: 0.0630\n",
      "Epoch 104/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0101 - mae: 0.0620\n",
      "Epoch 105/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0103 - mae: 0.0635\n",
      "Epoch 106/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0102 - mae: 0.0629\n",
      "Epoch 107/500\n",
      "2413/2413 [==============================] - 0s 113us/sample - loss: 0.0103 - mae: 0.0641\n",
      "Epoch 108/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0102 - mae: 0.0631\n",
      "Epoch 109/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0100 - mae: 0.0623\n",
      "Epoch 110/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0097 - mae: 0.0609\n",
      "Epoch 111/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0098 - mae: 0.0616\n",
      "Epoch 112/500\n",
      "2413/2413 [==============================] - 0s 114us/sample - loss: 0.0097 - mae: 0.0611\n",
      "Epoch 113/500\n",
      "2413/2413 [==============================] - 0s 115us/sample - loss: 0.0099 - mae: 0.0614\n",
      "Epoch 114/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0098 - mae: 0.0619\n",
      "Epoch 115/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0095 - mae: 0.0602\n",
      "Epoch 116/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0098 - mae: 0.0617\n",
      "Epoch 117/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0094 - mae: 0.0599\n",
      "Epoch 118/500\n",
      "2413/2413 [==============================] - 0s 112us/sample - loss: 0.0093 - mae: 0.0588\n",
      "Epoch 119/500\n",
      "2413/2413 [==============================] - 0s 111us/sample - loss: 0.0091 - mae: 0.0589\n",
      "Epoch 120/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0092 - mae: 0.0582\n",
      "Epoch 121/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0089 - mae: 0.0569\n",
      "Epoch 122/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0093 - mae: 0.0598\n",
      "Epoch 123/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.0093 - mae: 0.0593\n",
      "Epoch 124/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0091 - mae: 0.0586\n",
      "Epoch 125/500\n",
      "2413/2413 [==============================] - 0s 111us/sample - loss: 0.0089 - mae: 0.0574\n",
      "Epoch 126/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0095 - mae: 0.0605\n",
      "Epoch 127/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0094 - mae: 0.0600\n",
      "Epoch 128/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0090 - mae: 0.0581\n",
      "Epoch 129/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0087 - mae: 0.0570\n",
      "Epoch 130/500\n",
      "2413/2413 [==============================] - 0s 114us/sample - loss: 0.0091 - mae: 0.0585\n",
      "Epoch 131/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0090 - mae: 0.0588\n",
      "Epoch 132/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0087 - mae: 0.0572\n",
      "Epoch 133/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0085 - mae: 0.0555\n",
      "Epoch 134/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0085 - mae: 0.0556\n",
      "Epoch 135/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0083 - mae: 0.0543\n",
      "Epoch 136/500\n",
      "2413/2413 [==============================] - 0s 112us/sample - loss: 0.0087 - mae: 0.0572\n",
      "Epoch 137/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0083 - mae: 0.0545\n",
      "Epoch 138/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0086 - mae: 0.0567\n",
      "Epoch 139/500\n",
      "2413/2413 [==============================] - 0s 109us/sample - loss: 0.0089 - mae: 0.0581\n",
      "Epoch 140/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0082 - mae: 0.0548\n",
      "Epoch 141/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0081 - mae: 0.0551\n",
      "Epoch 142/500\n",
      "2413/2413 [==============================] - 0s 115us/sample - loss: 0.0085 - mae: 0.0568\n",
      "Epoch 143/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0083 - mae: 0.0558\n",
      "Epoch 144/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0087 - mae: 0.0582\n",
      "Epoch 145/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.0082 - mae: 0.0555\n",
      "Epoch 146/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0082 - mae: 0.0552\n",
      "Epoch 147/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0084 - mae: 0.0563\n",
      "Epoch 148/500\n",
      "2413/2413 [==============================] - 0s 114us/sample - loss: 0.0083 - mae: 0.0565\n",
      "Epoch 149/500\n",
      "2413/2413 [==============================] - 0s 113us/sample - loss: 0.0082 - mae: 0.0552\n",
      "Epoch 150/500\n",
      "2413/2413 [==============================] - 0s 110us/sample - loss: 0.0079 - mae: 0.0542\n",
      "Epoch 151/500\n",
      "2413/2413 [==============================] - 0s 112us/sample - loss: 0.0076 - mae: 0.0526\n",
      "Epoch 152/500\n",
      "2413/2413 [==============================] - 0s 109us/sample - loss: 0.0079 - mae: 0.0537\n",
      "Epoch 153/500\n",
      "2413/2413 [==============================] - 0s 116us/sample - loss: 0.0080 - mae: 0.0548\n",
      "Epoch 154/500\n",
      "2413/2413 [==============================] - 0s 117us/sample - loss: 0.0079 - mae: 0.0549\n",
      "Epoch 155/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0080 - mae: 0.0544\n",
      "Epoch 156/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0081 - mae: 0.0551\n",
      "Epoch 157/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0080 - mae: 0.0549\n",
      "Epoch 158/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0078 - mae: 0.0528\n",
      "Epoch 159/500\n",
      "2413/2413 [==============================] - 0s 114us/sample - loss: 0.0076 - mae: 0.0531\n",
      "Epoch 160/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0077 - mae: 0.0531\n",
      "Epoch 161/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0077 - mae: 0.0528\n",
      "Epoch 162/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0078 - mae: 0.0538\n",
      "Epoch 163/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0076 - mae: 0.0528\n",
      "Epoch 164/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0077 - mae: 0.0531\n",
      "Epoch 165/500\n",
      "2413/2413 [==============================] - 0s 111us/sample - loss: 0.0072 - mae: 0.0498\n",
      "Epoch 166/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0074 - mae: 0.0522\n",
      "Epoch 167/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0071 - mae: 0.0494\n",
      "Epoch 168/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0077 - mae: 0.0535\n",
      "Epoch 169/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0078 - mae: 0.0538\n",
      "Epoch 170/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0072 - mae: 0.0508\n",
      "Epoch 171/500\n",
      "2413/2413 [==============================] - 0s 112us/sample - loss: 0.0071 - mae: 0.0495\n",
      "Epoch 172/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0076 - mae: 0.0528\n",
      "Epoch 173/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0070 - mae: 0.0498\n",
      "Epoch 174/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0075 - mae: 0.0523\n",
      "Epoch 175/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0074 - mae: 0.0521\n",
      "Epoch 176/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0070 - mae: 0.0501\n",
      "Epoch 177/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0073 - mae: 0.0515\n",
      "Epoch 178/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0068 - mae: 0.0484\n",
      "Epoch 179/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0071 - mae: 0.0508\n",
      "Epoch 180/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0069 - mae: 0.0491\n",
      "Epoch 181/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0072 - mae: 0.0512\n",
      "Epoch 182/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.0073 - mae: 0.0517\n",
      "Epoch 183/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0071 - mae: 0.0506\n",
      "Epoch 184/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0067 - mae: 0.0478\n",
      "Epoch 185/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0066 - mae: 0.0474\n",
      "Epoch 186/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0070 - mae: 0.0500\n",
      "Epoch 187/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0069 - mae: 0.0500\n",
      "Epoch 188/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.0066 - mae: 0.0481\n",
      "Epoch 189/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0070 - mae: 0.0504\n",
      "Epoch 190/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0070 - mae: 0.0504\n",
      "Epoch 191/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0068 - mae: 0.0490\n",
      "Epoch 192/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0074 - mae: 0.0521\n",
      "Epoch 193/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0070 - mae: 0.0500\n",
      "Epoch 194/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0076 - mae: 0.0551\n",
      "Epoch 195/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.0067 - mae: 0.0490\n",
      "Epoch 196/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0067 - mae: 0.0498\n",
      "Epoch 197/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0066 - mae: 0.0483\n",
      "Epoch 198/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0069 - mae: 0.0508\n",
      "Epoch 199/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0069 - mae: 0.0507\n",
      "Epoch 200/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0064 - mae: 0.0469\n",
      "Epoch 201/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0065 - mae: 0.0478\n",
      "Epoch 202/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0068 - mae: 0.0498\n",
      "Epoch 203/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0064 - mae: 0.0473\n",
      "Epoch 204/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.0065 - mae: 0.0477\n",
      "Epoch 205/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0065 - mae: 0.0483\n",
      "Epoch 206/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0064 - mae: 0.0475\n",
      "Epoch 207/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0065 - mae: 0.0479\n",
      "Epoch 208/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0064 - mae: 0.0471\n",
      "Epoch 209/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0062 - mae: 0.0458\n",
      "Epoch 210/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0063 - mae: 0.0472\n",
      "Epoch 211/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0067 - mae: 0.0497\n",
      "Epoch 212/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0062 - mae: 0.0463\n",
      "Epoch 213/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0062 - mae: 0.0471\n",
      "Epoch 214/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0063 - mae: 0.0474\n",
      "Epoch 215/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0062 - mae: 0.0463\n",
      "Epoch 216/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0063 - mae: 0.0476\n",
      "Epoch 217/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0069 - mae: 0.0515\n",
      "Epoch 218/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.0064 - mae: 0.0484\n",
      "Epoch 219/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0061 - mae: 0.0459\n",
      "Epoch 220/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0062 - mae: 0.0471\n",
      "Epoch 221/500\n",
      "2413/2413 [==============================] - 0s 115us/sample - loss: 0.0064 - mae: 0.0482\n",
      "Epoch 222/500\n",
      "2413/2413 [==============================] - 0s 115us/sample - loss: 0.0063 - mae: 0.0479\n",
      "Epoch 223/500\n",
      "2413/2413 [==============================] - 0s 109us/sample - loss: 0.0063 - mae: 0.0479\n",
      "Epoch 224/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0062 - mae: 0.0467\n",
      "Epoch 225/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0058 - mae: 0.0444\n",
      "Epoch 226/500\n",
      "2413/2413 [==============================] - 0s 110us/sample - loss: 0.0058 - mae: 0.0440\n",
      "Epoch 227/500\n",
      "2413/2413 [==============================] - 0s 120us/sample - loss: 0.0059 - mae: 0.0451\n",
      "Epoch 228/500\n",
      "2413/2413 [==============================] - 0s 122us/sample - loss: 0.0059 - mae: 0.0444\n",
      "Epoch 229/500\n",
      "2413/2413 [==============================] - 0s 119us/sample - loss: 0.0058 - mae: 0.0447\n",
      "Epoch 230/500\n",
      "2413/2413 [==============================] - 0s 110us/sample - loss: 0.0059 - mae: 0.0444\n",
      "Epoch 231/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0059 - mae: 0.0449\n",
      "Epoch 232/500\n",
      "2413/2413 [==============================] - 0s 110us/sample - loss: 0.0058 - mae: 0.0447\n",
      "Epoch 233/500\n",
      "2413/2413 [==============================] - 0s 114us/sample - loss: 0.0059 - mae: 0.0452\n",
      "Epoch 234/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0058 - mae: 0.0447\n",
      "Epoch 235/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0058 - mae: 0.0451\n",
      "Epoch 236/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0061 - mae: 0.0465\n",
      "Epoch 237/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0062 - mae: 0.0460\n",
      "Epoch 238/500\n",
      "2413/2413 [==============================] - 0s 120us/sample - loss: 0.0058 - mae: 0.0448\n",
      "Epoch 239/500\n",
      "2413/2413 [==============================] - 0s 118us/sample - loss: 0.0061 - mae: 0.0464\n",
      "Epoch 240/500\n",
      "2413/2413 [==============================] - 0s 114us/sample - loss: 0.0061 - mae: 0.0466\n",
      "Epoch 241/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0066 - mae: 0.0506\n",
      "Epoch 242/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0061 - mae: 0.0469\n",
      "Epoch 243/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0060 - mae: 0.0462\n",
      "Epoch 244/500\n",
      "2413/2413 [==============================] - 0s 115us/sample - loss: 0.0058 - mae: 0.0444\n",
      "Epoch 245/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0060 - mae: 0.0461\n",
      "Epoch 246/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0060 - mae: 0.0467\n",
      "Epoch 247/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0057 - mae: 0.0443\n",
      "Epoch 248/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0058 - mae: 0.0451\n",
      "Epoch 249/500\n",
      "2413/2413 [==============================] - 0s 112us/sample - loss: 0.0056 - mae: 0.0440\n",
      "Epoch 250/500\n",
      "2413/2413 [==============================] - 0s 116us/sample - loss: 0.0058 - mae: 0.0451\n",
      "Epoch 251/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0055 - mae: 0.0430\n",
      "Epoch 252/500\n",
      "2413/2413 [==============================] - 0s 109us/sample - loss: 0.0057 - mae: 0.0450\n",
      "Epoch 253/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0055 - mae: 0.0429\n",
      "Epoch 254/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0055 - mae: 0.0429\n",
      "Epoch 255/500\n",
      "2413/2413 [==============================] - 0s 110us/sample - loss: 0.0054 - mae: 0.0425\n",
      "Epoch 256/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0054 - mae: 0.0420\n",
      "Epoch 257/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0054 - mae: 0.0430\n",
      "Epoch 258/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0058 - mae: 0.0459\n",
      "Epoch 259/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0054 - mae: 0.0424\n",
      "Epoch 260/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0056 - mae: 0.0441\n",
      "Epoch 261/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0055 - mae: 0.0434\n",
      "Epoch 262/500\n",
      "2413/2413 [==============================] - 0s 109us/sample - loss: 0.0052 - mae: 0.0404\n",
      "Epoch 263/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.0053 - mae: 0.0426\n",
      "Epoch 264/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0056 - mae: 0.0443\n",
      "Epoch 265/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0056 - mae: 0.0451\n",
      "Epoch 266/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0056 - mae: 0.0441\n",
      "Epoch 267/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0053 - mae: 0.0424\n",
      "Epoch 268/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0053 - mae: 0.0419\n",
      "Epoch 269/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0055 - mae: 0.0439\n",
      "Epoch 270/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0057 - mae: 0.0447\n",
      "Epoch 271/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0056 - mae: 0.0452\n",
      "Epoch 272/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0054 - mae: 0.0434\n",
      "Epoch 273/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0055 - mae: 0.0438\n",
      "Epoch 274/500\n",
      "2413/2413 [==============================] - 0s 109us/sample - loss: 0.0051 - mae: 0.0407\n",
      "Epoch 275/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0054 - mae: 0.0433\n",
      "Epoch 276/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0054 - mae: 0.0433\n",
      "Epoch 277/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0053 - mae: 0.0426\n",
      "Epoch 278/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0056 - mae: 0.0449\n",
      "Epoch 279/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0052 - mae: 0.0416\n",
      "Epoch 280/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0050 - mae: 0.0407\n",
      "Epoch 281/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0054 - mae: 0.0432\n",
      "Epoch 282/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0055 - mae: 0.0449\n",
      "Epoch 283/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0053 - mae: 0.0427\n",
      "Epoch 284/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0050 - mae: 0.0404\n",
      "Epoch 285/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.0049 - mae: 0.0400\n",
      "Epoch 286/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.0052 - mae: 0.0420\n",
      "Epoch 287/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0051 - mae: 0.0419\n",
      "Epoch 288/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0056 - mae: 0.0455\n",
      "Epoch 289/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0050 - mae: 0.0411\n",
      "Epoch 290/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0049 - mae: 0.0401\n",
      "Epoch 291/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0048 - mae: 0.0390\n",
      "Epoch 292/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0050 - mae: 0.0406\n",
      "Epoch 293/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0051 - mae: 0.0413\n",
      "Epoch 294/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0055 - mae: 0.0443\n",
      "Epoch 295/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0049 - mae: 0.0405\n",
      "Epoch 296/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0051 - mae: 0.0414\n",
      "Epoch 297/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0055 - mae: 0.0454\n",
      "Epoch 298/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0052 - mae: 0.0424\n",
      "Epoch 299/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0051 - mae: 0.0419\n",
      "Epoch 300/500\n",
      "2413/2413 [==============================] - 0s 110us/sample - loss: 0.0051 - mae: 0.0421\n",
      "Epoch 301/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0049 - mae: 0.0406\n",
      "Epoch 302/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.0047 - mae: 0.0391\n",
      "Epoch 303/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0051 - mae: 0.0416\n",
      "Epoch 304/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0056 - mae: 0.0454\n",
      "Epoch 305/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0051 - mae: 0.0420\n",
      "Epoch 306/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0055 - mae: 0.0458\n",
      "Epoch 307/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0051 - mae: 0.0419\n",
      "Epoch 308/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.0048 - mae: 0.0397\n",
      "Epoch 309/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0048 - mae: 0.0395\n",
      "Epoch 310/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0051 - mae: 0.0419\n",
      "Epoch 311/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0050 - mae: 0.0419\n",
      "Epoch 312/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0049 - mae: 0.0404\n",
      "Epoch 313/500\n",
      "2413/2413 [==============================] - 0s 123us/sample - loss: 0.0049 - mae: 0.0412\n",
      "Epoch 314/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0049 - mae: 0.0412\n",
      "Epoch 315/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0048 - mae: 0.0400\n",
      "Epoch 316/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0048 - mae: 0.0403\n",
      "Epoch 317/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0047 - mae: 0.0396\n",
      "Epoch 318/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0047 - mae: 0.0399\n",
      "Epoch 319/500\n",
      "2413/2413 [==============================] - 0s 114us/sample - loss: 0.0051 - mae: 0.0427\n",
      "Epoch 320/500\n",
      "2413/2413 [==============================] - 0s 113us/sample - loss: 0.0050 - mae: 0.0422\n",
      "Epoch 321/500\n",
      "2413/2413 [==============================] - 0s 109us/sample - loss: 0.0052 - mae: 0.0438\n",
      "Epoch 322/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0047 - mae: 0.0398\n",
      "Epoch 323/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0048 - mae: 0.0410\n",
      "Epoch 324/500\n",
      "2413/2413 [==============================] - 0s 112us/sample - loss: 0.0051 - mae: 0.0420\n",
      "Epoch 325/500\n",
      "2413/2413 [==============================] - 0s 111us/sample - loss: 0.0051 - mae: 0.0426\n",
      "Epoch 326/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0049 - mae: 0.0409\n",
      "Epoch 327/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0048 - mae: 0.0404\n",
      "Epoch 328/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0045 - mae: 0.0384\n",
      "Epoch 329/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0047 - mae: 0.0399\n",
      "Epoch 330/500\n",
      "2413/2413 [==============================] - 0s 114us/sample - loss: 0.0049 - mae: 0.0417\n",
      "Epoch 331/500\n",
      "2413/2413 [==============================] - 0s 113us/sample - loss: 0.0051 - mae: 0.0432\n",
      "Epoch 332/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0045 - mae: 0.0383\n",
      "Epoch 333/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0047 - mae: 0.0396\n",
      "Epoch 334/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0051 - mae: 0.0427\n",
      "Epoch 335/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0047 - mae: 0.0404\n",
      "Epoch 336/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0046 - mae: 0.0387\n",
      "Epoch 337/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0046 - mae: 0.0394\n",
      "Epoch 338/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0046 - mae: 0.0394\n",
      "Epoch 339/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0046 - mae: 0.0392\n",
      "Epoch 340/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0047 - mae: 0.0395\n",
      "Epoch 341/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0048 - mae: 0.0404\n",
      "Epoch 342/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0049 - mae: 0.0419\n",
      "Epoch 343/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0044 - mae: 0.0377\n",
      "Epoch 344/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0046 - mae: 0.0389\n",
      "Epoch 345/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0049 - mae: 0.0420\n",
      "Epoch 346/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0050 - mae: 0.0426\n",
      "Epoch 347/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.0046 - mae: 0.0399\n",
      "Epoch 348/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0045 - mae: 0.0385\n",
      "Epoch 349/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0046 - mae: 0.0401\n",
      "Epoch 350/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0043 - mae: 0.0372\n",
      "Epoch 351/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.0044 - mae: 0.0379\n",
      "Epoch 352/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0047 - mae: 0.0409\n",
      "Epoch 353/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0043 - mae: 0.0375\n",
      "Epoch 354/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0044 - mae: 0.0387\n",
      "Epoch 355/500\n",
      "2413/2413 [==============================] - 0s 115us/sample - loss: 0.0046 - mae: 0.0397\n",
      "Epoch 356/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0044 - mae: 0.0378\n",
      "Epoch 357/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0042 - mae: 0.0367\n",
      "Epoch 358/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0047 - mae: 0.0405\n",
      "Epoch 359/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0048 - mae: 0.0416\n",
      "Epoch 360/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0043 - mae: 0.0375\n",
      "Epoch 361/500\n",
      "2413/2413 [==============================] - 0s 114us/sample - loss: 0.0044 - mae: 0.0382\n",
      "Epoch 362/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0045 - mae: 0.0395\n",
      "Epoch 363/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.0044 - mae: 0.0382\n",
      "Epoch 364/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0044 - mae: 0.0383\n",
      "Epoch 365/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0043 - mae: 0.0373\n",
      "Epoch 366/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0049 - mae: 0.0429\n",
      "Epoch 367/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0046 - mae: 0.0407\n",
      "Epoch 368/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0043 - mae: 0.0375\n",
      "Epoch 369/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0044 - mae: 0.0382\n",
      "Epoch 370/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0044 - mae: 0.0383\n",
      "Epoch 371/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0044 - mae: 0.0388\n",
      "Epoch 372/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0043 - mae: 0.0378\n",
      "Epoch 373/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0042 - mae: 0.0373\n",
      "Epoch 374/500\n",
      "2413/2413 [==============================] - 0s 110us/sample - loss: 0.0043 - mae: 0.0370\n",
      "Epoch 375/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0044 - mae: 0.0390\n",
      "Epoch 376/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0045 - mae: 0.0390\n",
      "Epoch 377/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0047 - mae: 0.0408\n",
      "Epoch 378/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0043 - mae: 0.0382\n",
      "Epoch 379/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0042 - mae: 0.0370\n",
      "Epoch 380/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0042 - mae: 0.0367\n",
      "Epoch 381/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0041 - mae: 0.0371\n",
      "Epoch 382/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0045 - mae: 0.0397\n",
      "Epoch 383/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0043 - mae: 0.0378\n",
      "Epoch 384/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0043 - mae: 0.0381\n",
      "Epoch 385/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0046 - mae: 0.0404\n",
      "Epoch 386/500\n",
      "2413/2413 [==============================] - 0s 110us/sample - loss: 0.0042 - mae: 0.0365\n",
      "Epoch 387/500\n",
      "2413/2413 [==============================] - 0s 109us/sample - loss: 0.0041 - mae: 0.0365\n",
      "Epoch 388/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0041 - mae: 0.0361\n",
      "Epoch 389/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0042 - mae: 0.0376\n",
      "Epoch 390/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0040 - mae: 0.0358\n",
      "Epoch 391/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0042 - mae: 0.0375\n",
      "Epoch 392/500\n",
      "2413/2413 [==============================] - 0s 109us/sample - loss: 0.0041 - mae: 0.0364\n",
      "Epoch 393/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0041 - mae: 0.0368\n",
      "Epoch 394/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0042 - mae: 0.0377\n",
      "Epoch 395/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0042 - mae: 0.0382\n",
      "Epoch 396/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0042 - mae: 0.0380\n",
      "Epoch 397/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0041 - mae: 0.0368\n",
      "Epoch 398/500\n",
      "2413/2413 [==============================] - 0s 115us/sample - loss: 0.0042 - mae: 0.0374\n",
      "Epoch 399/500\n",
      "2413/2413 [==============================] - 0s 110us/sample - loss: 0.0042 - mae: 0.0372\n",
      "Epoch 400/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.0039 - mae: 0.0356\n",
      "Epoch 401/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0040 - mae: 0.0359\n",
      "Epoch 402/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0044 - mae: 0.0391\n",
      "Epoch 403/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0045 - mae: 0.0402\n",
      "Epoch 404/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0041 - mae: 0.0367\n",
      "Epoch 405/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0044 - mae: 0.0396\n",
      "Epoch 406/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0039 - mae: 0.0355\n",
      "Epoch 407/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0039 - mae: 0.0349\n",
      "Epoch 408/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0041 - mae: 0.0368\n",
      "Epoch 409/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0040 - mae: 0.0360\n",
      "Epoch 410/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0042 - mae: 0.0381\n",
      "Epoch 411/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0040 - mae: 0.0366\n",
      "Epoch 412/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0040 - mae: 0.0360\n",
      "Epoch 413/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0042 - mae: 0.0372\n",
      "Epoch 414/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0044 - mae: 0.0394\n",
      "Epoch 415/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0039 - mae: 0.0346\n",
      "Epoch 416/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0043 - mae: 0.0388\n",
      "Epoch 417/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0041 - mae: 0.0368\n",
      "Epoch 418/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0042 - mae: 0.0376\n",
      "Epoch 419/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0042 - mae: 0.0377\n",
      "Epoch 420/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.0039 - mae: 0.0355\n",
      "Epoch 421/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0040 - mae: 0.0364\n",
      "Epoch 422/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0043 - mae: 0.0386\n",
      "Epoch 423/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0042 - mae: 0.0381\n",
      "Epoch 424/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0039 - mae: 0.0355\n",
      "Epoch 425/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0041 - mae: 0.0376\n",
      "Epoch 426/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.0037 - mae: 0.0340\n",
      "Epoch 427/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0040 - mae: 0.0369\n",
      "Epoch 428/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0042 - mae: 0.0386\n",
      "Epoch 429/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0038 - mae: 0.0352\n",
      "Epoch 430/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0039 - mae: 0.0352\n",
      "Epoch 431/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0041 - mae: 0.0375\n",
      "Epoch 432/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0042 - mae: 0.0384\n",
      "Epoch 433/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0045 - mae: 0.0402\n",
      "Epoch 434/500\n",
      "2413/2413 [==============================] - 0s 111us/sample - loss: 0.0041 - mae: 0.0371\n",
      "Epoch 435/500\n",
      "2413/2413 [==============================] - 0s 114us/sample - loss: 0.0040 - mae: 0.0368\n",
      "Epoch 436/500\n",
      "2413/2413 [==============================] - 0s 115us/sample - loss: 0.0038 - mae: 0.0349\n",
      "Epoch 437/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0038 - mae: 0.0352\n",
      "Epoch 438/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0040 - mae: 0.0369\n",
      "Epoch 439/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0041 - mae: 0.0382\n",
      "Epoch 440/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0042 - mae: 0.0387\n",
      "Epoch 441/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0037 - mae: 0.0345\n",
      "Epoch 442/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0039 - mae: 0.0362\n",
      "Epoch 443/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0037 - mae: 0.0339\n",
      "Epoch 444/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0039 - mae: 0.0362\n",
      "Epoch 445/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.0041 - mae: 0.0383\n",
      "Epoch 446/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0049 - mae: 0.0432\n",
      "Epoch 447/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0043 - mae: 0.0392\n",
      "Epoch 448/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0038 - mae: 0.0351\n",
      "Epoch 449/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0037 - mae: 0.0339\n",
      "Epoch 450/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0036 - mae: 0.0333\n",
      "Epoch 451/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0035 - mae: 0.0328\n",
      "Epoch 452/500\n",
      "2413/2413 [==============================] - 0s 94us/sample - loss: 0.0035 - mae: 0.0323\n",
      "Epoch 453/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0037 - mae: 0.0344\n",
      "Epoch 454/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0037 - mae: 0.0338\n",
      "Epoch 455/500\n",
      "2413/2413 [==============================] - 0s 111us/sample - loss: 0.0038 - mae: 0.0354\n",
      "Epoch 456/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0038 - mae: 0.0358\n",
      "Epoch 457/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0038 - mae: 0.0359\n",
      "Epoch 458/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.0049 - mae: 0.0436\n",
      "Epoch 459/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.0039 - mae: 0.0366\n",
      "Epoch 460/500\n",
      "2413/2413 [==============================] - 0s 109us/sample - loss: 0.0037 - mae: 0.0349\n",
      "Epoch 461/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0038 - mae: 0.0352\n",
      "Epoch 462/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0045 - mae: 0.0411\n",
      "Epoch 463/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.0038 - mae: 0.0360\n",
      "Epoch 464/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0038 - mae: 0.0356\n",
      "Epoch 465/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0040 - mae: 0.0369\n",
      "Epoch 466/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.0037 - mae: 0.0340\n",
      "Epoch 467/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0038 - mae: 0.0359\n",
      "Epoch 468/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0038 - mae: 0.0358\n",
      "Epoch 469/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.0038 - mae: 0.0361\n",
      "Epoch 470/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0034 - mae: 0.0325\n",
      "Epoch 471/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0038 - mae: 0.0358\n",
      "Epoch 472/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0036 - mae: 0.0336\n",
      "Epoch 473/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0038 - mae: 0.0361\n",
      "Epoch 474/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0036 - mae: 0.0345\n",
      "Epoch 475/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0037 - mae: 0.0355\n",
      "Epoch 476/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.0037 - mae: 0.0354\n",
      "Epoch 477/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0038 - mae: 0.0361\n",
      "Epoch 478/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.0042 - mae: 0.0394\n",
      "Epoch 479/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0038 - mae: 0.0362\n",
      "Epoch 480/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0037 - mae: 0.0354\n",
      "Epoch 481/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0037 - mae: 0.0346\n",
      "Epoch 482/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0039 - mae: 0.0364\n",
      "Epoch 483/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0035 - mae: 0.0326\n",
      "Epoch 484/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0037 - mae: 0.0351\n",
      "Epoch 485/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0037 - mae: 0.0349\n",
      "Epoch 486/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0040 - mae: 0.0379\n",
      "Epoch 487/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0041 - mae: 0.0391\n",
      "Epoch 488/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0037 - mae: 0.0348\n",
      "Epoch 489/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0037 - mae: 0.0348\n",
      "Epoch 490/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0035 - mae: 0.0334\n",
      "Epoch 491/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.0036 - mae: 0.0341\n",
      "Epoch 492/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0038 - mae: 0.0367\n",
      "Epoch 493/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0037 - mae: 0.0353\n",
      "Epoch 494/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0035 - mae: 0.0335\n",
      "Epoch 495/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.0033 - mae: 0.0319\n",
      "Epoch 496/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.0036 - mae: 0.0344\n",
      "Epoch 497/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0038 - mae: 0.0365\n",
      "Epoch 498/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0036 - mae: 0.0347\n",
      "Epoch 499/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0035 - mae: 0.0333\n",
      "Epoch 500/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0036 - mae: 0.0346\n",
      "mae: 0.1003737822175026\n",
      "Overfit mae: 0.03336537629365921\n",
      "Train on 2413 samples\n",
      "Epoch 1/500\n",
      "2413/2413 [==============================] - 1s 395us/sample - loss: 0.8062 - mae: 0.2540\n",
      "Epoch 2/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.5493 - mae: 0.1512\n",
      "Epoch 3/500\n",
      "2413/2413 [==============================] - 0s 91us/sample - loss: 0.4216 - mae: 0.1377\n",
      "Epoch 4/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.3393 - mae: 0.1362\n",
      "Epoch 5/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.2609 - mae: 0.1174\n",
      "Epoch 6/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.2161 - mae: 0.1088\n",
      "Epoch 7/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.1845 - mae: 0.1098\n",
      "Epoch 8/500\n",
      "2413/2413 [==============================] - 0s 92us/sample - loss: 0.1559 - mae: 0.1044\n",
      "Epoch 9/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.1350 - mae: 0.1037\n",
      "Epoch 10/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.1175 - mae: 0.1015\n",
      "Epoch 11/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.1029 - mae: 0.1014\n",
      "Epoch 12/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0905 - mae: 0.0978\n",
      "Epoch 13/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0804 - mae: 0.0975\n",
      "Epoch 14/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0721 - mae: 0.0971\n",
      "Epoch 15/500\n",
      "2413/2413 [==============================] - 0s 93us/sample - loss: 0.0646 - mae: 0.0955\n",
      "Epoch 16/500\n",
      "2413/2413 [==============================] - 0s 95us/sample - loss: 0.0585 - mae: 0.0953\n",
      "Epoch 17/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0533 - mae: 0.0957\n",
      "Epoch 18/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0487 - mae: 0.0957\n",
      "Epoch 19/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0445 - mae: 0.0945\n",
      "Epoch 20/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0410 - mae: 0.0939\n",
      "Epoch 21/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0376 - mae: 0.0925\n",
      "Epoch 22/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0350 - mae: 0.0924\n",
      "Epoch 23/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.0328 - mae: 0.0927\n",
      "Epoch 24/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0309 - mae: 0.0925\n",
      "Epoch 25/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0289 - mae: 0.0911\n",
      "Epoch 26/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0277 - mae: 0.0920\n",
      "Epoch 27/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0257 - mae: 0.0892\n",
      "Epoch 28/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0249 - mae: 0.0899\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0236 - mae: 0.0891\n",
      "Epoch 30/500\n",
      "2413/2413 [==============================] - 0s 110us/sample - loss: 0.0225 - mae: 0.0877\n",
      "Epoch 31/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0217 - mae: 0.0880\n",
      "Epoch 32/500\n",
      "2413/2413 [==============================] - 0s 97us/sample - loss: 0.0210 - mae: 0.0872\n",
      "Epoch 33/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0206 - mae: 0.0876\n",
      "Epoch 34/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0202 - mae: 0.0874\n",
      "Epoch 35/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0199 - mae: 0.0880\n",
      "Epoch 36/500\n",
      "2413/2413 [==============================] - 0s 109us/sample - loss: 0.0189 - mae: 0.0864\n",
      "Epoch 37/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0190 - mae: 0.0881\n",
      "Epoch 38/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.0180 - mae: 0.0850\n",
      "Epoch 39/500\n",
      "2413/2413 [==============================] - 0s 96us/sample - loss: 0.0178 - mae: 0.0848\n",
      "Epoch 40/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0177 - mae: 0.0857\n",
      "Epoch 41/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0175 - mae: 0.0863\n",
      "Epoch 42/500\n",
      "2413/2413 [==============================] - 0s 114us/sample - loss: 0.0169 - mae: 0.0839\n",
      "Epoch 43/500\n",
      "2413/2413 [==============================] - 0s 112us/sample - loss: 0.0163 - mae: 0.0820\n",
      "Epoch 44/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0163 - mae: 0.0832\n",
      "Epoch 45/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0165 - mae: 0.0834\n",
      "Epoch 46/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0159 - mae: 0.0821\n",
      "Epoch 47/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0155 - mae: 0.0814\n",
      "Epoch 48/500\n",
      "2413/2413 [==============================] - 0s 115us/sample - loss: 0.0152 - mae: 0.0797\n",
      "Epoch 49/500\n",
      "2413/2413 [==============================] - 0s 114us/sample - loss: 0.0150 - mae: 0.0796\n",
      "Epoch 50/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0147 - mae: 0.0787\n",
      "Epoch 51/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0148 - mae: 0.0794\n",
      "Epoch 52/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0146 - mae: 0.0785\n",
      "Epoch 53/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0143 - mae: 0.0782\n",
      "Epoch 54/500\n",
      "2413/2413 [==============================] - 0s 119us/sample - loss: 0.0145 - mae: 0.0788\n",
      "Epoch 55/500\n",
      "2413/2413 [==============================] - 0s 119us/sample - loss: 0.0139 - mae: 0.0763\n",
      "Epoch 56/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0141 - mae: 0.0770\n",
      "Epoch 57/500\n",
      "2413/2413 [==============================] - 0s 109us/sample - loss: 0.0141 - mae: 0.0770\n",
      "Epoch 58/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0137 - mae: 0.0760\n",
      "Epoch 59/500\n",
      "2413/2413 [==============================] - 0s 116us/sample - loss: 0.0138 - mae: 0.0770\n",
      "Epoch 60/500\n",
      "2413/2413 [==============================] - 0s 119us/sample - loss: 0.0135 - mae: 0.0752\n",
      "Epoch 61/500\n",
      "2413/2413 [==============================] - 0s 114us/sample - loss: 0.0132 - mae: 0.0743\n",
      "Epoch 62/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0135 - mae: 0.0759\n",
      "Epoch 63/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0138 - mae: 0.0779\n",
      "Epoch 64/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0130 - mae: 0.0738\n",
      "Epoch 65/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0132 - mae: 0.0752\n",
      "Epoch 66/500\n",
      "2413/2413 [==============================] - 0s 112us/sample - loss: 0.0128 - mae: 0.0734\n",
      "Epoch 67/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0130 - mae: 0.0743\n",
      "Epoch 68/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0128 - mae: 0.0742\n",
      "Epoch 69/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0130 - mae: 0.0739\n",
      "Epoch 70/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0129 - mae: 0.0735\n",
      "Epoch 71/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0120 - mae: 0.0699\n",
      "Epoch 72/500\n",
      "2413/2413 [==============================] - 0s 112us/sample - loss: 0.0125 - mae: 0.0719\n",
      "Epoch 73/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0121 - mae: 0.0709\n",
      "Epoch 74/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0121 - mae: 0.0708\n",
      "Epoch 75/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0117 - mae: 0.0688\n",
      "Epoch 76/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0118 - mae: 0.0695\n",
      "Epoch 77/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0115 - mae: 0.0684\n",
      "Epoch 78/500\n",
      "2413/2413 [==============================] - 0s 111us/sample - loss: 0.0117 - mae: 0.0696\n",
      "Epoch 79/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0116 - mae: 0.0689\n",
      "Epoch 80/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0112 - mae: 0.0674\n",
      "Epoch 81/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0114 - mae: 0.0683\n",
      "Epoch 82/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0118 - mae: 0.0703\n",
      "Epoch 83/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0114 - mae: 0.0686\n",
      "Epoch 84/500\n",
      "2413/2413 [==============================] - 0s 110us/sample - loss: 0.0109 - mae: 0.0661\n",
      "Epoch 85/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0111 - mae: 0.0677\n",
      "Epoch 86/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0106 - mae: 0.0643\n",
      "Epoch 87/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0111 - mae: 0.0675\n",
      "Epoch 88/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0107 - mae: 0.0655\n",
      "Epoch 89/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0108 - mae: 0.0666\n",
      "Epoch 90/500\n",
      "2413/2413 [==============================] - 0s 109us/sample - loss: 0.0110 - mae: 0.0669\n",
      "Epoch 91/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0110 - mae: 0.0673\n",
      "Epoch 92/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0104 - mae: 0.0651\n",
      "Epoch 93/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0105 - mae: 0.0656\n",
      "Epoch 94/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0104 - mae: 0.0642\n",
      "Epoch 95/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0103 - mae: 0.0641\n",
      "Epoch 96/500\n",
      "2413/2413 [==============================] - 0s 112us/sample - loss: 0.0101 - mae: 0.0630\n",
      "Epoch 97/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0102 - mae: 0.0638\n",
      "Epoch 98/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0100 - mae: 0.0629\n",
      "Epoch 99/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0102 - mae: 0.0638\n",
      "Epoch 100/500\n",
      "2413/2413 [==============================] - 0s 102us/sample - loss: 0.0100 - mae: 0.0632\n",
      "Epoch 101/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0100 - mae: 0.0633\n",
      "Epoch 102/500\n",
      "2413/2413 [==============================] - 0s 112us/sample - loss: 0.0102 - mae: 0.0649\n",
      "Epoch 103/500\n",
      "2413/2413 [==============================] - 0s 107us/sample - loss: 0.0096 - mae: 0.0614\n",
      "Epoch 104/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0096 - mae: 0.0609\n",
      "Epoch 105/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0097 - mae: 0.0613\n",
      "Epoch 106/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0095 - mae: 0.0607\n",
      "Epoch 107/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0094 - mae: 0.0600\n",
      "Epoch 108/500\n",
      "2413/2413 [==============================] - 0s 112us/sample - loss: 0.0094 - mae: 0.0609\n",
      "Epoch 109/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0094 - mae: 0.0605\n",
      "Epoch 110/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0095 - mae: 0.0617\n",
      "Epoch 111/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0096 - mae: 0.0622\n",
      "Epoch 112/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0094 - mae: 0.0614\n",
      "Epoch 113/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0096 - mae: 0.0627\n",
      "Epoch 114/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0093 - mae: 0.0604\n",
      "Epoch 115/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0089 - mae: 0.0582\n",
      "Epoch 116/500\n",
      "2413/2413 [==============================] - 0s 98us/sample - loss: 0.0094 - mae: 0.0609\n",
      "Epoch 117/500\n",
      "2413/2413 [==============================] - 0s 99us/sample - loss: 0.0091 - mae: 0.0602\n",
      "Epoch 118/500\n",
      "2413/2413 [==============================] - 0s 100us/sample - loss: 0.0091 - mae: 0.0591\n",
      "Epoch 119/500\n",
      "2413/2413 [==============================] - 0s 101us/sample - loss: 0.0088 - mae: 0.0575\n",
      "Epoch 120/500\n",
      "2413/2413 [==============================] - 0s 108us/sample - loss: 0.0087 - mae: 0.0575\n",
      "Epoch 121/500\n",
      "2413/2413 [==============================] - 0s 116us/sample - loss: 0.0086 - mae: 0.0573\n",
      "Epoch 122/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0092 - mae: 0.0602\n",
      "Epoch 123/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0087 - mae: 0.0575\n",
      "Epoch 124/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0087 - mae: 0.0576\n",
      "Epoch 125/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0095 - mae: 0.0619\n",
      "Epoch 126/500\n",
      "2413/2413 [==============================] - 0s 117us/sample - loss: 0.0086 - mae: 0.0571\n",
      "Epoch 127/500\n",
      "2413/2413 [==============================] - 0s 113us/sample - loss: 0.0087 - mae: 0.0577\n",
      "Epoch 128/500\n",
      "2413/2413 [==============================] - 0s 105us/sample - loss: 0.0084 - mae: 0.0561\n",
      "Epoch 129/500\n",
      "2413/2413 [==============================] - 0s 104us/sample - loss: 0.0081 - mae: 0.0549\n",
      "Epoch 130/500\n",
      "2413/2413 [==============================] - 0s 106us/sample - loss: 0.0082 - mae: 0.0550\n",
      "Epoch 131/500\n",
      "2413/2413 [==============================] - 0s 103us/sample - loss: 0.0087 - mae: 0.0579\n",
      "Epoch 132/500\n",
      "2413/2413 [==============================] - 0s 114us/sample - loss: 0.0083 - mae: 0.0560\n",
      "Epoch 133/500\n",
      " 992/2413 [===========>..................] - ETA: 0s - loss: 0.0083 - mae: 0.0567"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-185-cac949334a02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m#early_stopping_monitor = keras.callbacks.EarlyStopping(patience=1,restore_best_weights=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                         \u001b[0;31m#validation_data=(x_validation, y_validation), callbacks=[early_stopping_monitor])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "\n",
    "frame = load_frame()\n",
    "data_x, data_y, number_of_features = load_all_data(frame) #load_meaningful_subset_static(frame)\n",
    "data_y = pd.concat([frame.mutation], axis = 1).round(2) #.mul(10)\n",
    "\n",
    "\n",
    "data_x = data_x.values\n",
    "data_y = data_y.values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_x)\n",
    "data_x = scaler.transform(data_x)\n",
    "    \n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = KFold(n_splits=10, shuffle=False, random_state=seed)\n",
    "cvscores = []\n",
    "overscores = []\n",
    "\n",
    "for train, test in kfold.split(data_x, data_y):\n",
    "\n",
    "    #x_validation, x_test, y_validation, y_test = train_test_split(data_x[validation_and_test], data_y[validation_and_test], test_size=.5, random_state=seed)\n",
    "\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(number_of_features, activation='relu', input_dim=number_of_features))\n",
    "    model.add(keras.layers.Dense(40, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(20, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mae'])\n",
    "\n",
    "\n",
    "    #early_stopping_monitor = keras.callbacks.EarlyStopping(patience=1,restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(data_x[train], data_y[train], epochs=500, verbose=1)#,\n",
    "                        #validation_data=(x_validation, y_validation), callbacks=[early_stopping_monitor])\n",
    "\n",
    "\n",
    "        \n",
    "    scores = model.evaluate(data_x[test], data_y[test], verbose=0)\n",
    "    overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "    print('{}: {}'.format(model.metrics_names[1], scores[1]))\n",
    "    print('Overfit {}: {}'.format(model.metrics_names[1], overfit[1]))\n",
    "    #print(\"-------------------------------------------\")\n",
    "\n",
    "    cvscores.append(scores[1])\n",
    "    overscores.append(overfit[1])\n",
    "    \n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Final results\")\n",
    "print('{} (+/- {})'.format(np.mean(cvscores), np.std(cvscores)))\n",
    "print('And overfit of {} (+/- {})'.format(np.mean(overscores), np.std(overscores)))\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      no_mutations  line_coverage  isAssertionRoulette  isEagerTest  \\\n",
       " 0              580           0.51                    1            1   \n",
       " 1              266           0.62                    1            1   \n",
       " 2              581           1.00                    0            0   \n",
       " 3              119           0.70                    0            1   \n",
       " 4               21           1.00                    1            1   \n",
       " ...            ...            ...                  ...          ...   \n",
       " 2678            85           0.88                    1            1   \n",
       " 2679           751           0.70                    1            1   \n",
       " 2680            95           0.85                    1            0   \n",
       " 2681            14           1.00                    1            0   \n",
       " 2682             2           0.50                    1            0   \n",
       " \n",
       "       isLazyTest  isMysteryGuest  isSensitiveEquality  isResourceOptimism  \\\n",
       " 0              0               0                    0                   0   \n",
       " 1              0               0                    0                   0   \n",
       " 2              0               1                    0                   1   \n",
       " 3              0               0                    0                   0   \n",
       " 4              0               0                    0                   0   \n",
       " ...          ...             ...                  ...                 ...   \n",
       " 2678           0               0                    1                   0   \n",
       " 2679           0               0                    0                   0   \n",
       " 2680           0               0                    0                   0   \n",
       " 2681           0               0                    0                   0   \n",
       " 2682           0               0                    0                   0   \n",
       " \n",
       "       isForTestersOnly  isIndirectTesting  ...  csm_CDSBP  csm_CC  csm_FD  \\\n",
       " 0                    0                  0  ...          0       1       0   \n",
       " 1                    0                  0  ...          0       0       0   \n",
       " 2                    0                  0  ...          0       0       0   \n",
       " 3                    0                  0  ...          0       0       0   \n",
       " 4                    0                  0  ...          0       0       0   \n",
       " ...                ...                ...  ...        ...     ...     ...   \n",
       " 2678                 0                  0  ...          0       0       0   \n",
       " 2679                 0                  1  ...          0       0       0   \n",
       " 2680                 0                  0  ...          0       0       0   \n",
       " 2681                 0                  1  ...          0       0       0   \n",
       " 2682                 1                  0  ...          0       0       0   \n",
       " \n",
       "       csm_Blob  csm_SC  csm_MC  csm_LM  csm_FE  prod_readability  \\\n",
       " 0            1       1       1       0       1              0.65   \n",
       " 1            0       0       0       0       1              0.89   \n",
       " 2            0       0       1       0       0              0.73   \n",
       " 3            0       0       0       0       0              0.78   \n",
       " 4            0       0       0       0       0              0.81   \n",
       " ...        ...     ...     ...     ...     ...               ...   \n",
       " 2678         0       0       0       0       0              0.94   \n",
       " 2679         0       0       0       0       0              0.75   \n",
       " 2680         0       0       0       0       0              0.86   \n",
       " 2681         0       0       1       0       0              0.62   \n",
       " 2682         0       0       0       0       0              0.93   \n",
       " \n",
       "       test_readability  \n",
       " 0                 0.65  \n",
       " 1                 0.85  \n",
       " 2                 0.66  \n",
       " 3                 0.77  \n",
       " 4                 0.70  \n",
       " ...                ...  \n",
       " 2678              0.65  \n",
       " 2679              0.66  \n",
       " 2680              0.87  \n",
       " 2681              0.64  \n",
       " 2682              0.67  \n",
       " \n",
       " [2681 rows x 68 columns],       mutation\n",
       " 0     0.432759\n",
       " 1     0.368421\n",
       " 2     0.500861\n",
       " 3     0.436975\n",
       " 4     0.857143\n",
       " ...        ...\n",
       " 2678  0.729412\n",
       " 2679  0.505992\n",
       " 2680  0.673684\n",
       " 2681  0.857143\n",
       " 2682  0.500000\n",
       " \n",
       " [2681 rows x 1 columns], 68)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      mutation  no_mutations  line_coverage  isAssertionRoulette  isEagerTest  \\\n",
      "0            1            63       0.911765                    1            0   \n",
      "1            0           235       0.430769                    1            1   \n",
      "2            0           198       0.876923                    0            1   \n",
      "3            1            24       0.866667                    0            0   \n",
      "4            1             3       1.000000                    1            0   \n",
      "...        ...           ...            ...                  ...          ...   \n",
      "1322         1             4       1.000000                    1            0   \n",
      "1323         0           269       0.466667                    1            1   \n",
      "1324         0           384       0.978022                    0            1   \n",
      "1325         0            44       0.750000                    1            1   \n",
      "1326         1            30       1.000000                    1            0   \n",
      "\n",
      "      isLazyTest  isMysteryGuest  isSensitiveEquality  isResourceOptimism  \\\n",
      "0              0               0                    0                   0   \n",
      "1              0               0                    0                   0   \n",
      "2              0               0                    1                   0   \n",
      "3              0               0                    0                   0   \n",
      "4              0               0                    0                   0   \n",
      "...          ...             ...                  ...                 ...   \n",
      "1322           0               0                    0                   0   \n",
      "1323           0               0                    0                   0   \n",
      "1324           0               1                    0                   0   \n",
      "1325           0               0                    0                   0   \n",
      "1326           0               0                    1                   0   \n",
      "\n",
      "      isForTestersOnly  ...  Sum Depths_prod  Avg Depth_prod  Branching_prod  \\\n",
      "0                    0  ...            671.0        3.241546        2.545894   \n",
      "1                    0  ...          11323.0        3.090338        2.464793   \n",
      "2                    0  ...           1261.0        3.552113        3.059155   \n",
      "3                    0  ...            351.0        4.228916        2.771084   \n",
      "4                    0  ...            731.0        4.626582        2.525316   \n",
      "...                ...  ...              ...             ...             ...   \n",
      "1322                 0  ...           1031.0        6.210843        3.560241   \n",
      "1323                 0  ...          19777.0        2.980259        1.908077   \n",
      "1324                 0  ...           1972.0        3.631676        3.804788   \n",
      "1325                 0  ...            411.0        4.110000        2.620000   \n",
      "1326                 0  ...           3116.0        3.293869        1.762156   \n",
      "\n",
      "      Dexterity_prod  No. Expressions_prod  No. Try_prod  No. Catch_prod  \\\n",
      "0               37.0                 170.0           0.0             0.0   \n",
      "1               58.0                3231.0           8.0             8.0   \n",
      "2               34.0                 367.0           0.0             0.0   \n",
      "3               29.0                  95.0           0.0             0.0   \n",
      "4               28.0                 170.0           1.0             1.0   \n",
      "...              ...                   ...           ...             ...   \n",
      "1322            28.0                 222.0           1.0             1.0   \n",
      "1323            58.0                5553.0           1.0             1.0   \n",
      "1324            34.0                 555.0           2.0             4.0   \n",
      "1325            37.0                 112.0           0.0             0.0   \n",
      "1326            47.0                 754.0           0.0             0.0   \n",
      "\n",
      "      No. Loop_prod  No. Conditions_prod  No. Else_prod  \n",
      "0               2.0                  3.0            0.0  \n",
      "1              25.0                 63.0           17.0  \n",
      "2               0.0                  7.0            2.0  \n",
      "3               1.0                  2.0            0.0  \n",
      "4               0.0                  5.0            1.0  \n",
      "...             ...                  ...            ...  \n",
      "1322            0.0                  2.0            0.0  \n",
      "1323           32.0                146.0           47.0  \n",
      "1324            0.0                 10.0            5.0  \n",
      "1325            0.0                  2.0            0.0  \n",
      "1326            5.0                 42.0            4.0  \n",
      "\n",
      "[1327 rows x 108 columns]\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam \n",
      "[CV]  activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam, total=   4.8s\n",
      "[CV] activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam, total=   2.3s\n",
      "[CV] activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam \n",
      "[CV]  activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam, total=   3.8s\n",
      "[CV] activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam \n",
      "[CV]  activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam, total=   4.9s\n",
      "[CV] activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam \n",
      "[CV]  activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam, total=   3.9s\n",
      "[CV] activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam \n",
      "[CV]  activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam, total=   4.0s\n",
      "[CV] activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam \n",
      "[CV]  activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam, total=   3.4s\n",
      "[CV] activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam \n",
      "[CV]  activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam, total=   4.7s\n",
      "[CV] activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam \n",
      "[CV]  activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam, total=   3.9s\n",
      "[CV] activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam \n",
      "[CV]  activation=relu, batch_size=100, dropout_rate=0.25, optimizer=Adam, total=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   41.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.807866 using {'activation': 'relu', 'batch_size': 100, 'dropout_rate': 0.25, 'optimizer': 'Adam'}\n",
      "0.807866 (0.034673) with: {'activation': 'relu', 'batch_size': 100, 'dropout_rate': 0.25, 'optimizer': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='adam', activation='linear', init_mode='uniform', dropout_rate=0.1):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dropout(dropout_rate, input_shape=(53,)))\n",
    "    model.add(keras.layers.Dense(40, kernel_initializer=init_mode, activation=activation))\n",
    "    model.add(keras.layers.Dense(20, kernel_initializer=init_mode, activation=activation))\n",
    "    model.add(keras.layers.Dense(2, kernel_initializer=init_mode, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# load dataset\n",
    "frame = load_frame()\n",
    "frame = load_quartile(frame)\n",
    "\n",
    "print(frame)\n",
    "\n",
    "data_x, data_y, number_of_features = load_all_test_data_dynamic(frame) #load_all_prod_data(frame) #load_all_test_data_dynamic(frame) #load_all_prod_data(frame) #load_all_test_data_dynamic(frame)\n",
    "\n",
    "data_x = data_x.values\n",
    "data_y = data_y.values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_x)\n",
    "data_x = scaler.transform(data_x)\n",
    "\n",
    "\n",
    "early_stopping_monitor = keras.callbacks.EarlyStopping(monitor='accuracy', min_delta=0.0003, patience=10, verbose=0, mode='max', restore_best_weights=True)\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0, epochs=2000)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [100]\n",
    "activation = ['relu']\n",
    "optimizer = ['Adam']\n",
    "dropout_rate = [0.25]\n",
    "param_grid = dict(batch_size=batch_size, optimizer=optimizer, activation=activation, dropout_rate=dropout_rate)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=kfold, verbose=2)\n",
    "grid_result = grid.fit(data_x, data_y, callbacks=[early_stopping_monitor])\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
