{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aux functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(train_x, train_y, training=0.8, validation=0.5):\n",
    "    train_size = training\n",
    "\n",
    "    train_cnt = math.floor(train_x.shape[0] * train_size)\n",
    "    x_train = train_x.iloc[0:train_cnt].values\n",
    "    y_train = train_y.iloc[0:train_cnt].values\n",
    "    x_test = train_x.iloc[train_cnt:]\n",
    "    y_test = train_y.iloc[train_cnt:]\n",
    "\n",
    "    division = validation\n",
    "\n",
    "    train_cnt = math.floor(x_test.shape[0] * division)\n",
    "    x_validate = x_test.iloc[0:train_cnt].values\n",
    "    y_validate = y_test.iloc[0:train_cnt].values\n",
    "    x_test = x_test.iloc[train_cnt:].values\n",
    "    y_test = y_test.iloc[train_cnt:].values\n",
    "\n",
    "    #Preprocess the data\n",
    "    #min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    #x_validate = min_max_scaler.fit_transform(x_validate)\n",
    "    #x_train = min_max_scaler.fit_transform(x_train)\n",
    "    #x_test = min_max_scaler.fit_transform(x_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, x_validate, y_validate\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_csv(\"complete-frame.csv\", sep=\",\")\n",
    "\"\"\"\n",
    "train_x = pd.concat([frame.no_mutations, frame.line_coverage, frame.isAssertionRoulette, frame.isEagerTest, frame.isLazyTest,\n",
    "frame.isMysteryGuest, frame.isSensitiveEquality, frame.isResourceOptimism, frame.isForTestersOnly,\n",
    "frame.isIndirectTesting, frame.LOC_prod, frame.HALSTEAD_prod, frame.RFC_prod, frame.CBO_prod, frame.MPC_prod, frame.IFC_prod, frame.DAC_prod,frame.DAC2_prod, frame.LCOM1_prod, frame.LCOM2_prod,\n",
    "frame.LCOM3_prod, frame.LCOM4_prod, frame.CONNECTIVITY_prod, frame.LCOM5_prod, frame.COH_prod, frame.TCC_prod,\n",
    "frame.LCC_prod, frame.ICH_prod, frame.WMC_prod, frame.NOA_prod, frame.NOPA_prod, frame.NOP_prod,\n",
    "frame.McCABE_prod, frame.BUSWEIMER_prod, frame.LOC_test, frame.HALSTEAD_test, frame.RFC_test, frame.CBO_test,\n",
    "frame.MPC_test, frame.IFC_test, frame.DAC_test, frame.DAC2_test, frame.LCOM1_test, frame.LCOM2_test,\n",
    "frame.LCOM3_test, frame.LCOM4_test, frame.CONNECTIVITY_test, frame.LCOM5_test, frame.COH_test, frame.TCC_test,\n",
    "frame.LCC_test, frame.ICH_test, frame.WMC_test, frame.NOA_test, frame.NOPA_test, frame.NOP_test, frame.McCABE_test,\n",
    "frame.BUSWEIMER_test, frame.csm_CDSBP, frame.csm_CC, frame.csm_FD, frame.csm_Blob, frame.csm_SC, frame.csm_MC,\n",
    "frame.csm_LM, frame.csm_FE, frame.prod_readability, frame.test_readability], axis=1).round(2)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "data_x = pd.concat([frame.no_mutations,\n",
    "                     frame.line_coverage,\n",
    "                     #frame.isEagerTest,\n",
    "                     frame.LOC_prod, frame.LOC_test, frame.WMC_prod,\n",
    "                     frame.LCOM1_prod, frame.LCOM2_prod,\n",
    "                     frame.LCOM4_prod, frame.McCABE_prod,\n",
    "                     frame.RFC_prod, frame.MPC_prod,\n",
    "                     frame.RFC_test, frame.MPC_test,\n",
    "                     frame.LCOM1_test, frame.LCOM2_test,\n",
    "                     frame.LCOM4_test, frame.LCC_test,\n",
    "                     frame.LCC_test, frame.WMC_test,\n",
    "                     frame.McCABE_test, frame.NOP_prod,\n",
    "                     frame.NOA_prod], axis = 1).round(2)\n",
    "\n",
    "data_y = pd.concat([frame.mutation], axis = 1)\n",
    "\n",
    "#labels = [1,2,3,4,5]\n",
    "#bins = [0,2,4,6,8,10]\n",
    "\n",
    "#frame['mutation_bins'] = pd.cut(frame.mutation.round(1).mul(10), bins=bins, labels = labels, include_lowest=True)\n",
    "#frame['mutation_bins'] = pd.cut(frame.mutation, bins=bins, labels = labels, include_lowest=True)\n",
    "#print(frame.mutation_bins)\n",
    "\n",
    "#train_y = pd.concat([frame.mutation_bins], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #1: Effective Vs. Non Effective\n",
    "    - 2 classes: effective tests and non-effective tests:\n",
    "        - Effective > median(mutation_score)\n",
    "        - Non Effective < media(mutation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 36.     0.93  95.   ...   6.     0.     0.  ]\n",
      " [ 28.     0.67 271.   ...  30.     0.     0.  ]\n",
      " [ 74.     0.97 375.   ...  24.     0.     0.  ]\n",
      " ...\n",
      " [  4.     1.    95.   ...   8.     0.     2.  ]\n",
      " [  4.     1.    95.   ...  21.     0.     2.  ]\n",
      " [  6.     1.    87.   ...   7.     0.     1.  ]]\n",
      "Train on 1928 samples, validate on 241 samples\n",
      "Epoch 1/1000\n",
      "1928/1928 [==============================] - 2s 934us/sample - loss: 2.0384 - accuracy: 0.0078 - val_loss: 21.5392 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "1928/1928 [==============================] - 0s 102us/sample - loss: 0.5565 - accuracy: 0.0099 - val_loss: 5.1906 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "1928/1928 [==============================] - 0s 95us/sample - loss: 0.2659 - accuracy: 0.0099 - val_loss: 2.0491 - val_accuracy: 0.0041\n",
      "Epoch 4/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.2110 - accuracy: 0.0099 - val_loss: 1.6984 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "1928/1928 [==============================] - 0s 90us/sample - loss: 0.1790 - accuracy: 0.0099 - val_loss: 1.7467 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "1928/1928 [==============================] - 0s 90us/sample - loss: 0.1649 - accuracy: 0.0099 - val_loss: 1.3840 - val_accuracy: 0.0041\n",
      "Epoch 7/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.1601 - accuracy: 0.0099 - val_loss: 1.0805 - val_accuracy: 0.0124\n",
      "Epoch 8/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.1484 - accuracy: 0.0104 - val_loss: 1.0200 - val_accuracy: 0.0581\n",
      "Epoch 9/1000\n",
      "1928/1928 [==============================] - 0s 97us/sample - loss: 0.1402 - accuracy: 0.0099 - val_loss: 0.9580 - val_accuracy: 0.0788\n",
      "Epoch 10/1000\n",
      "1928/1928 [==============================] - 0s 97us/sample - loss: 0.1344 - accuracy: 0.0109 - val_loss: 0.9075 - val_accuracy: 0.0954\n",
      "Epoch 11/1000\n",
      "1928/1928 [==============================] - 0s 94us/sample - loss: 0.1321 - accuracy: 0.0119 - val_loss: 0.9212 - val_accuracy: 0.0913\n",
      "Epoch 12/1000\n",
      "1928/1928 [==============================] - 0s 94us/sample - loss: 0.1291 - accuracy: 0.0119 - val_loss: 0.8642 - val_accuracy: 0.1120\n",
      "Epoch 13/1000\n",
      "1928/1928 [==============================] - 0s 95us/sample - loss: 0.1267 - accuracy: 0.0119 - val_loss: 0.8233 - val_accuracy: 0.1162\n",
      "Epoch 14/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.1234 - accuracy: 0.0150 - val_loss: 0.8009 - val_accuracy: 0.0747\n",
      "Epoch 15/1000\n",
      "1928/1928 [==============================] - 0s 92us/sample - loss: 0.1217 - accuracy: 0.0135 - val_loss: 0.7961 - val_accuracy: 0.2033\n",
      "Epoch 16/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.1190 - accuracy: 0.0150 - val_loss: 0.7955 - val_accuracy: 0.1826\n",
      "Epoch 17/1000\n",
      "1928/1928 [==============================] - 0s 98us/sample - loss: 0.1216 - accuracy: 0.0156 - val_loss: 0.7217 - val_accuracy: 0.2531\n",
      "Epoch 18/1000\n",
      "1928/1928 [==============================] - 0s 98us/sample - loss: 0.1183 - accuracy: 0.0156 - val_loss: 0.7818 - val_accuracy: 0.3029\n",
      "Epoch 19/1000\n",
      "1928/1928 [==============================] - 0s 96us/sample - loss: 0.1158 - accuracy: 0.0156 - val_loss: 0.9266 - val_accuracy: 0.2988\n",
      "Epoch 20/1000\n",
      "1928/1928 [==============================] - 0s 95us/sample - loss: 0.1141 - accuracy: 0.0171 - val_loss: 0.6984 - val_accuracy: 0.2656\n",
      "Epoch 21/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.1132 - accuracy: 0.0166 - val_loss: 0.7141 - val_accuracy: 0.2863\n",
      "Epoch 22/1000\n",
      "1928/1928 [==============================] - 0s 92us/sample - loss: 0.1107 - accuracy: 0.0171 - val_loss: 0.6997 - val_accuracy: 0.2656\n",
      "Epoch 23/1000\n",
      "1928/1928 [==============================] - 0s 95us/sample - loss: 0.1113 - accuracy: 0.0182 - val_loss: 0.6795 - val_accuracy: 0.2490\n",
      "Epoch 24/1000\n",
      "1928/1928 [==============================] - 0s 94us/sample - loss: 0.1112 - accuracy: 0.0192 - val_loss: 0.6796 - val_accuracy: 0.2656\n",
      "Epoch 25/1000\n",
      "1928/1928 [==============================] - 0s 98us/sample - loss: 0.1099 - accuracy: 0.0166 - val_loss: 0.6209 - val_accuracy: 0.3237\n",
      "Epoch 26/1000\n",
      "1928/1928 [==============================] - 0s 95us/sample - loss: 0.1083 - accuracy: 0.0202 - val_loss: 0.6297 - val_accuracy: 0.2822\n",
      "Epoch 27/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.1091 - accuracy: 0.0192 - val_loss: 0.6206 - val_accuracy: 0.2822\n",
      "Epoch 28/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.1070 - accuracy: 0.0171 - val_loss: 0.6113 - val_accuracy: 0.3693\n",
      "Epoch 29/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.1053 - accuracy: 0.0192 - val_loss: 0.6308 - val_accuracy: 0.3237\n",
      "Epoch 30/1000\n",
      "1928/1928 [==============================] - 0s 90us/sample - loss: 0.1063 - accuracy: 0.0202 - val_loss: 0.6233 - val_accuracy: 0.3610\n",
      "Epoch 31/1000\n",
      "1928/1928 [==============================] - 0s 97us/sample - loss: 0.1049 - accuracy: 0.0244 - val_loss: 0.6097 - val_accuracy: 0.3154\n",
      "Epoch 32/1000\n",
      "1928/1928 [==============================] - 0s 95us/sample - loss: 0.1044 - accuracy: 0.0207 - val_loss: 0.6307 - val_accuracy: 0.3527\n",
      "Epoch 33/1000\n",
      "1928/1928 [==============================] - 0s 98us/sample - loss: 0.1039 - accuracy: 0.0233 - val_loss: 0.6629 - val_accuracy: 0.3237\n",
      "Epoch 34/1000\n",
      "1928/1928 [==============================] - 0s 96us/sample - loss: 0.1054 - accuracy: 0.0239 - val_loss: 0.6431 - val_accuracy: 0.3361\n",
      "Epoch 35/1000\n",
      "1928/1928 [==============================] - 0s 93us/sample - loss: 0.1024 - accuracy: 0.0223 - val_loss: 0.6422 - val_accuracy: 0.3154\n",
      "Epoch 36/1000\n",
      "1928/1928 [==============================] - 0s 95us/sample - loss: 0.1043 - accuracy: 0.0249 - val_loss: 0.6370 - val_accuracy: 0.3402\n",
      "Epoch 37/1000\n",
      "1928/1928 [==============================] - 0s 98us/sample - loss: 0.1033 - accuracy: 0.0254 - val_loss: 1.0894 - val_accuracy: 0.3900\n",
      "Epoch 38/1000\n",
      "1928/1928 [==============================] - 0s 92us/sample - loss: 0.1016 - accuracy: 0.0254 - val_loss: 0.7133 - val_accuracy: 0.3154\n",
      "Epoch 39/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.1004 - accuracy: 0.0239 - val_loss: 0.7282 - val_accuracy: 0.4606\n",
      "Epoch 40/1000\n",
      "1928/1928 [==============================] - 0s 98us/sample - loss: 0.0980 - accuracy: 0.0270 - val_loss: 0.8999 - val_accuracy: 0.3942\n",
      "Epoch 41/1000\n",
      "1928/1928 [==============================] - 0s 104us/sample - loss: 0.0988 - accuracy: 0.0265 - val_loss: 0.6151 - val_accuracy: 0.4523\n",
      "242/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 55us/sample - loss: 0.3499 - accuracy: 0.0496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.049586777\n"
     ]
    }
   ],
   "source": [
    "#Edit the y axis data according to the description:\n",
    "labels = [1,2]\n",
    "bins = [0,frame.mutation.median(),1]\n",
    "frame['mutation_bins'] = pd.cut(frame.mutation, bins=bins, labels = labels, include_lowest=True)\n",
    "train_y = pd.concat([frame.mutation_bins], axis = 1)\n",
    "\n",
    "x_train, y_train, x_test, y_test, x_validate, y_validate = split_data(data_x, data_y)\n",
    "print(x_train)\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(22, input_dim=22, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(18, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(12, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(6, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(6, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping_monitor = keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1000, verbose=1,\n",
    "          validation_data=(x_validate, y_validate),\n",
    "          callbacks=[early_stopping_monitor])\n",
    "\n",
    "# Evaluate the model using test dataset.\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "#Check Overfeet\n",
    "#test_loss, test_acc = model.evaluate(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #1: Results\n",
    "\n",
    "| This | is   |\n",
    "|------|------|\n",
    "|   a  | table|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #2: Predicting Mutation Score\n",
    "    - 11 categories of mutation score: from 0, 0.1, 0.2, .... 1\n",
    "    - The goal: predict the mutation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1928 samples, validate on 241 samples\n",
      "Epoch 1/1000\n",
      "1928/1928 [==============================] - 1s 525us/sample - loss: 1.9150 - accuracy: 0.0342 - val_loss: 1.1318 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "1928/1928 [==============================] - 0s 90us/sample - loss: 0.5137 - accuracy: 0.0099 - val_loss: 1.9083 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "1928/1928 [==============================] - 0s 90us/sample - loss: 0.2251 - accuracy: 0.0099 - val_loss: 2.0746 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "1928/1928 [==============================] - 0s 90us/sample - loss: 0.2144 - accuracy: 0.0099 - val_loss: 1.9898 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "1928/1928 [==============================] - 0s 90us/sample - loss: 0.2043 - accuracy: 0.0099 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "1928/1928 [==============================] - 0s 97us/sample - loss: 0.1960 - accuracy: 0.0099 - val_loss: 1.9729 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "1928/1928 [==============================] - 0s 95us/sample - loss: 0.1881 - accuracy: 0.0099 - val_loss: 2.0962 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "1928/1928 [==============================] - 0s 101us/sample - loss: 0.1783 - accuracy: 0.0099 - val_loss: 2.3406 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "1928/1928 [==============================] - 0s 95us/sample - loss: 0.1691 - accuracy: 0.0099 - val_loss: 2.5955 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "1928/1928 [==============================] - 0s 90us/sample - loss: 0.1596 - accuracy: 0.0099 - val_loss: 2.6493 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "1928/1928 [==============================] - 0s 94us/sample - loss: 0.1520 - accuracy: 0.0099 - val_loss: 2.8933 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "1928/1928 [==============================] - 0s 90us/sample - loss: 0.1443 - accuracy: 0.0099 - val_loss: 2.9532 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.1380 - accuracy: 0.0099 - val_loss: 3.5048 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "1928/1928 [==============================] - 0s 95us/sample - loss: 0.1365 - accuracy: 0.0099 - val_loss: 3.6192 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "1928/1928 [==============================] - 0s 95us/sample - loss: 0.1321 - accuracy: 0.0099 - val_loss: 3.6601 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.1300 - accuracy: 0.0099 - val_loss: 4.1425 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "1928/1928 [==============================] - 0s 90us/sample - loss: 0.1319 - accuracy: 0.0099 - val_loss: 3.7271 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "1928/1928 [==============================] - 0s 89us/sample - loss: 0.1282 - accuracy: 0.0099 - val_loss: 3.7354 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.1283 - accuracy: 0.0099 - val_loss: 3.8995 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "1928/1928 [==============================] - 0s 94us/sample - loss: 0.1256 - accuracy: 0.0099 - val_loss: 3.8128 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "1928/1928 [==============================] - 0s 96us/sample - loss: 0.1246 - accuracy: 0.0099 - val_loss: 4.1009 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "1928/1928 [==============================] - 0s 98us/sample - loss: 0.1246 - accuracy: 0.0099 - val_loss: 4.0252 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "1928/1928 [==============================] - 0s 100us/sample - loss: 0.1221 - accuracy: 0.0099 - val_loss: 3.9252 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "1928/1928 [==============================] - 0s 96us/sample - loss: 0.1252 - accuracy: 0.0109 - val_loss: 3.7144 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "1928/1928 [==============================] - 0s 92us/sample - loss: 0.1212 - accuracy: 0.0114 - val_loss: 4.0889 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "1928/1928 [==============================] - 0s 97us/sample - loss: 0.1206 - accuracy: 0.0124 - val_loss: 3.9057 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "1928/1928 [==============================] - 0s 95us/sample - loss: 0.1185 - accuracy: 0.0213 - val_loss: 4.1510 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "1928/1928 [==============================] - 0s 90us/sample - loss: 0.1186 - accuracy: 0.0249 - val_loss: 4.7631 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "1928/1928 [==============================] - 0s 95us/sample - loss: 0.1221 - accuracy: 0.0161 - val_loss: 4.4088 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "1928/1928 [==============================] - 0s 104us/sample - loss: 0.1184 - accuracy: 0.0218 - val_loss: 4.5429 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "1928/1928 [==============================] - 0s 99us/sample - loss: 0.1207 - accuracy: 0.0254 - val_loss: 4.3106 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "1928/1928 [==============================] - 0s 99us/sample - loss: 0.1174 - accuracy: 0.0197 - val_loss: 3.9378 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "1928/1928 [==============================] - 0s 97us/sample - loss: 0.1180 - accuracy: 0.0249 - val_loss: 4.1232 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "1928/1928 [==============================] - 0s 97us/sample - loss: 0.1221 - accuracy: 0.0244 - val_loss: 4.7074 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "1928/1928 [==============================] - 0s 94us/sample - loss: 0.1164 - accuracy: 0.0254 - val_loss: 4.8117 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "1928/1928 [==============================] - 0s 96us/sample - loss: 0.1173 - accuracy: 0.0207 - val_loss: 4.3249 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "1928/1928 [==============================] - 0s 99us/sample - loss: 0.1158 - accuracy: 0.0207 - val_loss: 4.5766 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "1928/1928 [==============================] - 0s 103us/sample - loss: 0.1165 - accuracy: 0.0239 - val_loss: 3.9692 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "1928/1928 [==============================] - 0s 97us/sample - loss: 0.1145 - accuracy: 0.0275 - val_loss: 4.4804 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.1139 - accuracy: 0.0265 - val_loss: 4.6086 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.1130 - accuracy: 0.0233 - val_loss: 3.9913 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.1143 - accuracy: 0.0254 - val_loss: 4.4446 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "1928/1928 [==============================] - 0s 93us/sample - loss: 0.1162 - accuracy: 0.0239 - val_loss: 4.2613 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "1928/1928 [==============================] - 0s 89us/sample - loss: 0.1163 - accuracy: 0.0223 - val_loss: 4.1798 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "1928/1928 [==============================] - 0s 90us/sample - loss: 0.1146 - accuracy: 0.0228 - val_loss: 4.3280 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "1928/1928 [==============================] - 0s 106us/sample - loss: 0.1178 - accuracy: 0.0290 - val_loss: 4.0764 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "1928/1928 [==============================] - 0s 106us/sample - loss: 0.1130 - accuracy: 0.0249 - val_loss: 4.4821 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "1928/1928 [==============================] - 0s 100us/sample - loss: 0.1138 - accuracy: 0.0213 - val_loss: 4.2132 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "1928/1928 [==============================] - 0s 98us/sample - loss: 0.1134 - accuracy: 0.0228 - val_loss: 4.2861 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "1928/1928 [==============================] - 0s 98us/sample - loss: 0.1118 - accuracy: 0.0275 - val_loss: 4.2522 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "1928/1928 [==============================] - 0s 92us/sample - loss: 0.1117 - accuracy: 0.0270 - val_loss: 4.3917 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "1928/1928 [==============================] - 0s 94us/sample - loss: 0.1134 - accuracy: 0.0218 - val_loss: 4.4511 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "1928/1928 [==============================] - 0s 100us/sample - loss: 0.1107 - accuracy: 0.0275 - val_loss: 4.5429 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000\n",
      "1928/1928 [==============================] - 0s 102us/sample - loss: 0.1125 - accuracy: 0.0239 - val_loss: 4.2819 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "1928/1928 [==============================] - 0s 94us/sample - loss: 0.1127 - accuracy: 0.0239 - val_loss: 4.1300 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/1000\n",
      "1928/1928 [==============================] - 0s 89us/sample - loss: 0.1095 - accuracy: 0.0280 - val_loss: 4.2660 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "1928/1928 [==============================] - 0s 93us/sample - loss: 0.1101 - accuracy: 0.0265 - val_loss: 4.3169 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "1928/1928 [==============================] - 0s 105us/sample - loss: 0.1101 - accuracy: 0.0285 - val_loss: 4.3236 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "1928/1928 [==============================] - 0s 94us/sample - loss: 0.1101 - accuracy: 0.0233 - val_loss: 4.4014 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "1928/1928 [==============================] - 0s 95us/sample - loss: 0.1094 - accuracy: 0.0249 - val_loss: 3.9309 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "1928/1928 [==============================] - 0s 98us/sample - loss: 0.1167 - accuracy: 0.0301 - val_loss: 4.7556 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "1928/1928 [==============================] - 0s 98us/sample - loss: 0.1115 - accuracy: 0.0270 - val_loss: 4.4656 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.1148 - accuracy: 0.0249 - val_loss: 3.6763 - val_accuracy: 0.0041\n",
      "Epoch 64/1000\n",
      "1928/1928 [==============================] - 0s 93us/sample - loss: 0.1130 - accuracy: 0.0233 - val_loss: 4.6681 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "1928/1928 [==============================] - 0s 89us/sample - loss: 0.1104 - accuracy: 0.0244 - val_loss: 4.3275 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "1928/1928 [==============================] - 0s 90us/sample - loss: 0.1111 - accuracy: 0.0306 - val_loss: 4.4724 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.1093 - accuracy: 0.0249 - val_loss: 4.3719 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "1928/1928 [==============================] - 0s 88us/sample - loss: 0.1082 - accuracy: 0.0275 - val_loss: 4.4115 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "1928/1928 [==============================] - 0s 92us/sample - loss: 0.1085 - accuracy: 0.0270 - val_loss: 4.5053 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/1000\n",
      "1928/1928 [==============================] - 0s 93us/sample - loss: 0.1072 - accuracy: 0.0285 - val_loss: 4.2123 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/1000\n",
      "1928/1928 [==============================] - 0s 90us/sample - loss: 0.1076 - accuracy: 0.0259 - val_loss: 4.3177 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/1000\n",
      "1928/1928 [==============================] - 0s 87us/sample - loss: 0.1097 - accuracy: 0.0239 - val_loss: 4.6390 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/1000\n",
      "1928/1928 [==============================] - 0s 88us/sample - loss: 0.1064 - accuracy: 0.0311 - val_loss: 4.6265 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/1000\n",
      "1928/1928 [==============================] - 0s 89us/sample - loss: 0.1067 - accuracy: 0.0301 - val_loss: 4.6976 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/1000\n",
      "1928/1928 [==============================] - 0s 89us/sample - loss: 0.1070 - accuracy: 0.0280 - val_loss: 4.2513 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "1928/1928 [==============================] - 0s 87us/sample - loss: 0.1084 - accuracy: 0.0285 - val_loss: 4.8274 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/1000\n",
      "1928/1928 [==============================] - 0s 90us/sample - loss: 0.1075 - accuracy: 0.0265 - val_loss: 4.3806 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/1000\n",
      "1928/1928 [==============================] - 0s 100us/sample - loss: 0.1060 - accuracy: 0.0265 - val_loss: 4.9830 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/1000\n",
      "1928/1928 [==============================] - 0s 96us/sample - loss: 0.1057 - accuracy: 0.0306 - val_loss: 4.9254 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/1000\n",
      "1928/1928 [==============================] - 0s 95us/sample - loss: 0.1053 - accuracy: 0.0259 - val_loss: 4.8452 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/1000\n",
      "1928/1928 [==============================] - 0s 88us/sample - loss: 0.1077 - accuracy: 0.0265 - val_loss: 4.3970 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.1048 - accuracy: 0.0337 - val_loss: 4.8037 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/1000\n",
      "1928/1928 [==============================] - 0s 93us/sample - loss: 0.1059 - accuracy: 0.0290 - val_loss: 4.3840 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/1000\n",
      "1928/1928 [==============================] - 0s 88us/sample - loss: 0.1046 - accuracy: 0.0296 - val_loss: 4.4669 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/1000\n",
      "1928/1928 [==============================] - 0s 96us/sample - loss: 0.1061 - accuracy: 0.0306 - val_loss: 4.8894 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/1000\n",
      "1928/1928 [==============================] - 0s 96us/sample - loss: 0.1040 - accuracy: 0.0327 - val_loss: 4.9412 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "1928/1928 [==============================] - 0s 90us/sample - loss: 0.1051 - accuracy: 0.0280 - val_loss: 5.0588 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/1000\n",
      "1928/1928 [==============================] - 0s 90us/sample - loss: 0.1055 - accuracy: 0.0301 - val_loss: 4.8443 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/1000\n",
      "1928/1928 [==============================] - 0s 94us/sample - loss: 0.1045 - accuracy: 0.0316 - val_loss: 5.2292 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/1000\n",
      "1928/1928 [==============================] - 0s 88us/sample - loss: 0.1027 - accuracy: 0.0296 - val_loss: 4.7084 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/1000\n",
      "1928/1928 [==============================] - 0s 94us/sample - loss: 0.1032 - accuracy: 0.0306 - val_loss: 5.1425 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/1000\n",
      "1928/1928 [==============================] - 0s 97us/sample - loss: 0.1018 - accuracy: 0.0290 - val_loss: 4.5216 - val_accuracy: 0.0083\n",
      "Epoch 93/1000\n",
      "1928/1928 [==============================] - 0s 98us/sample - loss: 0.1050 - accuracy: 0.0358 - val_loss: 4.7701 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/1000\n",
      "1928/1928 [==============================] - 0s 99us/sample - loss: 0.1013 - accuracy: 0.0306 - val_loss: 5.2494 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/1000\n",
      "1928/1928 [==============================] - 0s 96us/sample - loss: 0.1008 - accuracy: 0.0280 - val_loss: 4.6904 - val_accuracy: 0.0249\n",
      "Epoch 96/1000\n",
      "1928/1928 [==============================] - 0s 96us/sample - loss: 0.1055 - accuracy: 0.0337 - val_loss: 5.5439 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/1000\n",
      "1928/1928 [==============================] - 0s 90us/sample - loss: 0.1028 - accuracy: 0.0296 - val_loss: 4.9571 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/1000\n",
      "1928/1928 [==============================] - 0s 89us/sample - loss: 0.1036 - accuracy: 0.0301 - val_loss: 5.0380 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "1928/1928 [==============================] - 0s 91us/sample - loss: 0.1014 - accuracy: 0.0296 - val_loss: 4.6935 - val_accuracy: 0.0249\n",
      "Epoch 100/1000\n",
      "1928/1928 [==============================] - 0s 92us/sample - loss: 0.1001 - accuracy: 0.0296 - val_loss: 4.5392 - val_accuracy: 0.0373\n",
      "Epoch 101/1000\n",
      "1928/1928 [==============================] - 0s 96us/sample - loss: 0.1030 - accuracy: 0.0311 - val_loss: 5.0982 - val_accuracy: 0.0000e+00\n",
      "242/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 48us/sample - loss: 1.1660 - accuracy: 0.0083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.008264462\n"
     ]
    }
   ],
   "source": [
    "train_y = pd.concat([frame.mutation], axis = 1).round(1).mul(10)\n",
    "\n",
    "x_train, y_train, x_test, y_test, x_validate, y_validate = split_data(data_x, data_y)\n",
    "\n",
    "# Define the model architecture\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(22, input_dim=22, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(18, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(12, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(6, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(11, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping_monitor = keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1000, verbose=1,\n",
    "          validation_data=(x_validate, y_validate),\n",
    "          callbacks=[early_stopping_monitor])\n",
    "\n",
    "# Evaluate the model using test dataset.\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
