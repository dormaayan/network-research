{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      mutation\n",
      "0     0.021978\n",
      "1     0.277372\n",
      "2     1.000000\n",
      "3     0.287879\n",
      "4     0.367816\n",
      "...        ...\n",
      "1202  0.919492\n",
      "1203  1.000000\n",
      "1204  1.000000\n",
      "1205  0.000000\n",
      "1206  0.302128\n",
      "\n",
      "[1207 rows x 1 columns]\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "2\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 844 samples\n",
      "Epoch 1/20\n",
      "844/844 [==============================] - 1s 688us/sample - loss: 2.1054 - accuracy: 0.8057\n",
      "Epoch 2/20\n",
      "844/844 [==============================] - 0s 149us/sample - loss: 0.9813 - accuracy: 0.8803\n",
      "Epoch 3/20\n",
      "844/844 [==============================] - 0s 136us/sample - loss: 0.9622 - accuracy: 0.8886\n",
      "Epoch 4/20\n",
      "844/844 [==============================] - 0s 148us/sample - loss: 1.0172 - accuracy: 0.8685\n",
      "Epoch 5/20\n",
      "844/844 [==============================] - 0s 141us/sample - loss: 1.1591 - accuracy: 0.8720\n",
      "Epoch 6/20\n",
      "844/844 [==============================] - 0s 137us/sample - loss: 1.3061 - accuracy: 0.8590\n",
      "Epoch 7/20\n",
      "844/844 [==============================] - 0s 136us/sample - loss: 0.8668 - accuracy: 0.8768\n",
      "Epoch 8/20\n",
      "844/844 [==============================] - 0s 136us/sample - loss: 0.7429 - accuracy: 0.8851\n",
      "Epoch 9/20\n",
      "844/844 [==============================] - 0s 138us/sample - loss: 0.7762 - accuracy: 0.8827\n",
      "Epoch 10/20\n",
      "844/844 [==============================] - 0s 141us/sample - loss: 0.8340 - accuracy: 0.8945\n",
      "Epoch 11/20\n",
      "844/844 [==============================] - 0s 141us/sample - loss: 0.9088 - accuracy: 0.8744\n",
      "Epoch 12/20\n",
      "844/844 [==============================] - 0s 150us/sample - loss: 0.7728 - accuracy: 0.8780\n",
      "Epoch 13/20\n",
      "844/844 [==============================] - 0s 147us/sample - loss: 0.5334 - accuracy: 0.9005\n",
      "Epoch 14/20\n",
      "844/844 [==============================] - 0s 148us/sample - loss: 0.6934 - accuracy: 0.8720\n",
      "Epoch 15/20\n",
      "844/844 [==============================] - 0s 140us/sample - loss: 0.6473 - accuracy: 0.8886\n",
      "Epoch 16/20\n",
      "844/844 [==============================] - 0s 138us/sample - loss: 0.6988 - accuracy: 0.8697\n",
      "Epoch 17/20\n",
      "844/844 [==============================] - 0s 135us/sample - loss: 0.8995 - accuracy: 0.8780\n",
      "Epoch 18/20\n",
      "844/844 [==============================] - 0s 145us/sample - loss: 0.4751 - accuracy: 0.9040\n",
      "Epoch 19/20\n",
      "844/844 [==============================] - 0s 139us/sample - loss: 0.5347 - accuracy: 0.9005\n",
      "Epoch 20/20\n",
      "844/844 [==============================] - 0s 144us/sample - loss: 0.5471 - accuracy: 0.9076\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Accuracy on training data: 0.899289071559906% \n",
      " Error on training data: 0.100710928440094\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Accuracy on test data: 0.8677685856819153% \n",
      " Error on test data: 0.13223141431808472\n"
     ]
    }
   ],
   "source": [
    "CSV_PATH = \"complete-frame.csv\"\n",
    "\n",
    "\n",
    "#frame = load_frame()\n",
    "#frame = load_quartile(frame)\n",
    "\n",
    "frame = pd.read_csv(CSV_PATH, sep=\",\")\n",
    "frame = frame.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "low, high = frame.mutation.quantile([0.25,0.75])\n",
    "frame_low = frame.query('mutation<{low}'.format(low=low))\n",
    "frame_high = frame.query('mutation>{high}'.format(high=high))\n",
    "\n",
    "frame_low.loc['mutation'] = 0\n",
    "frame_high.loc['mutation'] =1\n",
    "frame = pd.concat([frame_low, frame_high], ignore_index=True)\n",
    "frame = frame.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "columns = [frame.no_mutations,\n",
    "                         #frame.line_coverage,\n",
    "                         frame.csm_FE,\n",
    "                         frame.CONNECTIVITY_prod,\n",
    "                         frame.CONNECTIVITY_test,\n",
    "                         frame.isEagerTest,\n",
    "                         frame.LOC_prod, frame.LOC_test, frame.WMC_prod,\n",
    "                         frame.LCOM1_prod, frame.LCOM2_prod,\n",
    "                         frame.LCOM4_prod, frame.McCABE_prod,\n",
    "                         frame.RFC_prod, frame.MPC_prod,\n",
    "                         frame.RFC_test, frame.MPC_test,\n",
    "                         frame.LCOM1_test, frame.LCOM2_test,\n",
    "                         frame.LCOM4_test, frame.LCC_test,\n",
    "                         frame.LCC_test, frame.WMC_test,\n",
    "                         frame.McCABE_test, frame.NOP_prod]\n",
    "    \n",
    "data_x = pd.concat(columns, axis = 1).round(2)\n",
    "data_y = pd.concat([frame.mutation], axis = 1)#.round(2).mul(100)\n",
    "\n",
    "print(data_y)\n",
    "    \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.30, random_state=40)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "print(y_train)\n",
    "\n",
    "count_classes = y_test.shape[1]\n",
    "print(count_classes)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(500, activation='relu', input_dim=len(columns)))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20)\n",
    "\n",
    "pred_train= model.predict(x_train)\n",
    "scores = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n",
    " \n",
    "pred_test= model.predict(x_test)\n",
    "scores2 = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
