{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import sklearn\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"complete-frame.csv\"\n",
    "CSV_MINER_PATH = \"testminereffectiveness.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aux functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silent_evaluation(model, x_test, y_test):\n",
    "    f = open('/dev/null', 'w')\n",
    "    regular_stdout = sys.stdout\n",
    "    sys.stdout = f\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "    sys.stdout = regular_stdout\n",
    "    print('Model Accuracy: {}'.format(test_acc))\n",
    "    \n",
    "    \n",
    "def split_data(train_x, train_y, training=0.70, validation=0.5):\n",
    "    train_size = training\n",
    "\n",
    "    train_cnt = math.floor(train_x.shape[0] * train_size)\n",
    "    x_train = train_x.iloc[0:train_cnt].values\n",
    "    y_train = train_y.iloc[0:train_cnt].values\n",
    "    x_test = train_x.iloc[train_cnt:]\n",
    "    y_test = train_y.iloc[train_cnt:]\n",
    "\n",
    "    division = validation\n",
    "\n",
    "    train_cnt = math.floor(x_test.shape[0] * division)\n",
    "    x_validate = x_test.iloc[0:train_cnt].values\n",
    "    y_validate = y_test.iloc[0:train_cnt].values\n",
    "    x_test = x_test.iloc[train_cnt:].values\n",
    "    y_test = y_test.iloc[train_cnt:].values\n",
    "\n",
    "    return x_train, y_train, x_test, y_test, x_validate, y_validate\n",
    "\n",
    "\n",
    "def plot_graphs(history):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    #plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    #plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_rename (row):\n",
    "    return row['path_test'].split('/')[len(row['path_test'].split('/')) - 1].split('.')[0]\n",
    "\n",
    "def load_frame():\n",
    "    frame1 = pd.read_csv(CSV_PATH, sep=\",\")\n",
    "    frame1 = frame1.sample(frac=1).reset_index(drop=True)\n",
    "    frame1['TestClassName'] = frame1.apply(lambda row: label_rename(row), axis=1)\n",
    "    frame2 = pd.read_csv(CSV_MINER_PATH, sep=',')\n",
    "    frame = pd.merge(frame1, frame2, on='TestClassName')\n",
    "    frame = frame.drop(['project', 'module', 'path_test','test_name','path_src',\n",
    "                        'class_name','TestClassName','commit','Nº','Project'], axis=1)\n",
    "    frame = frame.sample(frac=1).reset_index(drop=True)\n",
    "    frame = frame.dropna()\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def load_static_frame():\n",
    "    frame1 = pd.read_csv(CSV_PATH, sep=\",\")\n",
    "    frame1 = frame1.sample(frac=1).reset_index(drop=True)\n",
    "    frame1['TestClassName'] = frame1.apply(lambda row: label_rename(row), axis=1)\n",
    "    frame2 = pd.read_csv(CSV_MINER_PATH, sep=',')\n",
    "    frame = pd.merge(frame1, frame2, on='TestClassName')\n",
    "    frame = frame.drop(['project', 'module', 'path_test','test_name','path_src',\n",
    "                        'class_name','TestClassName','commit','Nº','Project'], axis=1)\n",
    "    frame = frame.sample(frac=1).reset_index(drop=True)\n",
    "    frame = frame.dropna()\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def load_quartile(frame):\n",
    "    low, high = frame.mutation.quantile([0.25,0.75])\n",
    "    frame_low = frame.query('mutation<{low}'.format(low=low))\n",
    "    frame_high = frame.query('mutation>{high}'.format(high=high))\n",
    "    frame_low['mutation'] = 0\n",
    "    frame_high['mutation'] = 1\n",
    "    frame = pd.concat([frame_low, frame_high], ignore_index=True)\n",
    "    frame = frame.sample(frac=1).reset_index(drop=True)\n",
    "    return frame;\n",
    "\n",
    "def load_meaningful_subset(frame):\n",
    "    columns = [frame.no_mutations,\n",
    "                         frame.line_coverage,\n",
    "                         frame.csm_FE,\n",
    "                         frame.CONNECTIVITY_prod,\n",
    "                         frame.CONNECTIVITY_test,\n",
    "                         frame.isEagerTest,\n",
    "                         frame.LOC_prod, frame.LOC_test, frame.WMC_prod,\n",
    "                         frame.LCOM1_prod, frame.LCOM2_prod,\n",
    "                         frame.LCOM4_prod, frame.McCABE_prod,\n",
    "                         frame.RFC_prod, frame.MPC_prod,\n",
    "                         frame.RFC_test, frame.MPC_test,\n",
    "                         frame.LCOM1_test, frame.LCOM2_test,\n",
    "                         frame.LCOM4_test, frame.LCC_test,\n",
    "                         frame.LCC_test, frame.WMC_test,\n",
    "                         frame.McCABE_test, frame.NOP_prod]\n",
    "    \n",
    "    data_x = pd.concat(columns, axis = 1).round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "\n",
    "def load_meaningful_subset_static(frame):\n",
    "    columns = [frame.no_mutations,\n",
    "                         frame.csm_FE,\n",
    "                         frame.CONNECTIVITY_prod,\n",
    "                         frame.CONNECTIVITY_test,\n",
    "                         frame.isEagerTest,\n",
    "                         frame.LOC_prod, frame.LOC_test, frame.WMC_prod,\n",
    "                         frame.LCOM1_prod, frame.LCOM2_prod,\n",
    "                         frame.LCOM4_prod, frame.McCABE_prod,\n",
    "                         frame.RFC_prod, frame.MPC_prod,\n",
    "                         frame.RFC_test, frame.MPC_test,\n",
    "                         frame.LCOM1_test, frame.LCOM2_test,\n",
    "                         frame.LCOM4_test, frame.LCC_test,\n",
    "                         frame.LCC_test, frame.WMC_test,\n",
    "                         frame.McCABE_test, frame.NOP_prod]\n",
    "    \n",
    "    data_x = pd.concat(columns, axis = 1).round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "def load_meaningful_subset_2(frame):\n",
    "    #columns = [frame.line_coverage, frame.isAssertionRoulette, frame.isMysteryGuest,\n",
    "    #   frame.isResourceOptimism, frame.isForTestersOnly, frame.COH_prod, frame.BUSWEIMER_prod,\n",
    "    #   frame.BUSWEIMER_test, frame.csm_LM, frame.prod_readability]\n",
    "    \n",
    "    [frame.line_coverage,\n",
    "    frame.COH_prod, frame.BUSWEIMER_prod, frame.csm_MC,\n",
    "       frame.prod_readability, frame.prod_readability]\n",
    "    \n",
    "    data_x = pd.concat(columns, axis = 1).round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_all_data(frame):\n",
    "    columns = [frame.no_mutations, frame.line_coverage, frame.isAssertionRoulette, frame.isEagerTest, frame.isLazyTest,\n",
    "frame.isMysteryGuest, frame.isSensitiveEquality, frame.isResourceOptimism, frame.isForTestersOnly,\n",
    "frame.isIndirectTesting, frame.LOC_prod, frame.HALSTEAD_prod, frame.RFC_prod, frame.CBO_prod, frame.MPC_prod, frame.IFC_prod, frame.DAC_prod,frame.DAC2_prod, frame.LCOM1_prod, frame.LCOM2_prod,\n",
    "frame.LCOM3_prod, frame.LCOM4_prod, frame.CONNECTIVITY_prod, frame.LCOM5_prod, frame.COH_prod, frame.TCC_prod,\n",
    "frame.LCC_prod, frame.ICH_prod, frame.WMC_prod, frame.NOA_prod, frame.NOPA_prod, frame.NOP_prod,\n",
    "frame.McCABE_prod, frame.BUSWEIMER_prod, frame.LOC_test, frame.HALSTEAD_test, frame.RFC_test, frame.CBO_test,\n",
    "frame.MPC_test, frame.IFC_test, frame.DAC_test, frame.DAC2_test, frame.LCOM1_test, frame.LCOM2_test,\n",
    "frame.LCOM3_test, frame.LCOM4_test, frame.CONNECTIVITY_test, frame.LCOM5_test, frame.COH_test, frame.TCC_test,\n",
    "frame.LCC_test, frame.ICH_test, frame.WMC_test, frame.NOA_test, frame.NOPA_test, frame.NOP_test, frame.McCABE_test,\n",
    "frame.BUSWEIMER_test, frame.csm_CDSBP, frame.csm_CC, frame.csm_FD, frame.csm_Blob, frame.csm_SC, frame.csm_MC,\n",
    "frame.csm_LM, frame.csm_FE, frame.prod_readability, frame.test_readability]\n",
    "    data_x = pd.concat(columns, axis = 1).round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "    \n",
    "\n",
    "def load_all_data_with_mine(frame):\n",
    "    columns = [frame.no_mutations, frame.line_coverage, frame.isAssertionRoulette, frame.isEagerTest, frame.isLazyTest,\n",
    "frame.isMysteryGuest, frame.isSensitiveEquality, frame.isResourceOptimism, frame.isForTestersOnly,\n",
    "frame.isIndirectTesting, frame.LOC_prod, frame.HALSTEAD_prod, frame.RFC_prod, frame.CBO_prod, frame.MPC_prod, frame.IFC_prod, frame.DAC_prod,frame.DAC2_prod, frame.LCOM1_prod, frame.LCOM2_prod,\n",
    "frame.LCOM3_prod, frame.LCOM4_prod, frame.CONNECTIVITY_prod, frame.LCOM5_prod, frame.COH_prod, frame.TCC_prod,\n",
    "frame.LCC_prod, frame.ICH_prod, frame.WMC_prod, frame.NOA_prod, frame.NOPA_prod, frame.NOP_prod,\n",
    "frame.McCABE_prod, frame.BUSWEIMER_prod, frame.LOC_test, frame.HALSTEAD_test, frame.RFC_test, frame.CBO_test,\n",
    "frame.MPC_test, frame.IFC_test, frame.DAC_test, frame.DAC2_test, frame.LCOM1_test, frame.LCOM2_test,\n",
    "frame.LCOM3_test, frame.LCOM4_test, frame.CONNECTIVITY_test, frame.LCOM5_test, frame.COH_test, frame.TCC_test,\n",
    "frame.LCC_test, frame.ICH_test, frame.WMC_test, frame.NOA_test, frame.NOPA_test, frame.NOP_test, frame.McCABE_test,\n",
    "frame.BUSWEIMER_test, frame.csm_CDSBP, frame.csm_CC, frame.csm_FD, frame.csm_Blob, frame.csm_SC, frame.csm_MC,\n",
    "frame.csm_LM, frame.csm_FE, frame.prod_readability, frame.test_readability,frame.Assrtions, frame.Conditions,frame.TryCatch, frame.Loop,frame.Hamcrest,frame.Mockito,\n",
    "           frame.BadApi,frame.LOC,frame.Expressions, frame.Depth, frame.Vocabulary,\n",
    "           frame.Understandability,frame.BodySize, frame.Dexterity, frame.NonWhiteCharacters]\n",
    "    \n",
    "    data_x = pd.concat(columns, axis = 1).round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "\n",
    "def load_all_data_static(frame):\n",
    "    columns = [frame.no_mutations, frame.isAssertionRoulette, frame.isEagerTest, frame.isLazyTest,\n",
    "frame.isMysteryGuest, frame.isSensitiveEquality, frame.isResourceOptimism, frame.isForTestersOnly,\n",
    "frame.isIndirectTesting, frame.LOC_prod, frame.HALSTEAD_prod, frame.RFC_prod, frame.CBO_prod, frame.MPC_prod, frame.IFC_prod, frame.DAC_prod,frame.DAC2_prod, frame.LCOM1_prod, frame.LCOM2_prod,\n",
    "frame.LCOM3_prod, frame.LCOM4_prod, frame.CONNECTIVITY_prod, frame.LCOM5_prod, frame.COH_prod, frame.TCC_prod,\n",
    "frame.LCC_prod, frame.ICH_prod, frame.WMC_prod, frame.NOA_prod, frame.NOPA_prod, frame.NOP_prod,\n",
    "frame.McCABE_prod, frame.BUSWEIMER_prod, frame.LOC_test, frame.HALSTEAD_test, frame.RFC_test, frame.CBO_test,\n",
    "frame.MPC_test, frame.IFC_test, frame.DAC_test, frame.DAC2_test, frame.LCOM1_test, frame.LCOM2_test,\n",
    "frame.LCOM3_test, frame.LCOM4_test, frame.CONNECTIVITY_test, frame.LCOM5_test, frame.COH_test, frame.TCC_test,\n",
    "frame.LCC_test, frame.ICH_test, frame.WMC_test, frame.NOA_test, frame.NOPA_test, frame.NOP_test, frame.McCABE_test,\n",
    "frame.BUSWEIMER_test, frame.csm_CDSBP, frame.csm_CC, frame.csm_FD, frame.csm_Blob, frame.csm_SC, frame.csm_MC,\n",
    "frame.csm_LM, frame.csm_FE, frame.prod_readability, frame.test_readability]\n",
    "    data_x = pd.concat(columns, axis = 1).round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "    \n",
    "\n",
    "def load_all_data_with_mine_static(frame):\n",
    "    columns = [frame.no_mutations, frame.isAssertionRoulette, frame.isEagerTest, frame.isLazyTest,\n",
    "frame.isMysteryGuest, frame.isSensitiveEquality, frame.isResourceOptimism, frame.isForTestersOnly,\n",
    "frame.isIndirectTesting, frame.LOC_prod, frame.HALSTEAD_prod, frame.RFC_prod, frame.CBO_prod, frame.MPC_prod, frame.IFC_prod, frame.DAC_prod,frame.DAC2_prod, frame.LCOM1_prod, frame.LCOM2_prod,\n",
    "frame.LCOM3_prod, frame.LCOM4_prod, frame.CONNECTIVITY_prod, frame.LCOM5_prod, frame.COH_prod, frame.TCC_prod,\n",
    "frame.LCC_prod, frame.ICH_prod, frame.WMC_prod, frame.NOA_prod, frame.NOPA_prod, frame.NOP_prod,\n",
    "frame.McCABE_prod, frame.BUSWEIMER_prod, frame.LOC_test, frame.HALSTEAD_test, frame.RFC_test, frame.CBO_test,\n",
    "frame.MPC_test, frame.IFC_test, frame.DAC_test, frame.DAC2_test, frame.LCOM1_test, frame.LCOM2_test,\n",
    "frame.LCOM3_test, frame.LCOM4_test, frame.CONNECTIVITY_test, frame.LCOM5_test, frame.COH_test, frame.TCC_test,\n",
    "frame.LCC_test, frame.ICH_test, frame.WMC_test, frame.NOA_test, frame.NOPA_test, frame.NOP_test, frame.McCABE_test,\n",
    "frame.BUSWEIMER_test, frame.csm_CDSBP, frame.csm_CC, frame.csm_FD, frame.csm_Blob, frame.csm_SC, frame.csm_MC,\n",
    "frame.csm_LM, frame.csm_FE, frame.prod_readability, frame.test_readability,frame.Assrtions, frame.Conditions,frame.TryCatch, frame.Loop,frame.Hamcrest,frame.Mockito,\n",
    "           frame.BadApi,frame.LOC,frame.Expressions, frame.Depth, frame.Vocabulary,\n",
    "           frame.Understandability,frame.BodySize, frame.Dexterity, frame.NonWhiteCharacters]\n",
    "    \n",
    "    data_x = pd.concat(columns, axis = 1).round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "def load_mine(frame):\n",
    "    columns = [frame.Assrtions, frame.Conditions,frame.TryCatch, frame.Loop,frame.Hamcrest,frame.Mockito,\n",
    "           frame.BadApi,frame.LOC,frame.Expressions, frame.Depth, frame.Vocabulary,\n",
    "           frame.Understandability,frame.BodySize, frame.Dexterity, frame.NonWhiteCharacters, frame.mutation]\n",
    "    data_x = pd.concat(columns, axis = 1).round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Manipulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median(data_x, data_y, frame):\n",
    "    labels = [1,2]\n",
    "    bins = [0,frame.mutation.median(),1]\n",
    "    frame['mutation_bins'] = pd.cut(frame.mutation, bins=bins, labels = labels, include_lowest=True)\n",
    "    data_y = pd.concat([frame.mutation_bins], axis = 1)\n",
    "    return split_data(data_x, data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mutation</th>\n",
       "      <th>no_mutations</th>\n",
       "      <th>line_coverage</th>\n",
       "      <th>isAssertionRoulette</th>\n",
       "      <th>isEagerTest</th>\n",
       "      <th>isLazyTest</th>\n",
       "      <th>isMysteryGuest</th>\n",
       "      <th>isSensitiveEquality</th>\n",
       "      <th>isResourceOptimism</th>\n",
       "      <th>isForTestersOnly</th>\n",
       "      <th>...</th>\n",
       "      <th>Mockito</th>\n",
       "      <th>BadApi</th>\n",
       "      <th>LOC</th>\n",
       "      <th>Expressions</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Vocabulary</th>\n",
       "      <th>Understandability</th>\n",
       "      <th>BodySize</th>\n",
       "      <th>Dexterity</th>\n",
       "      <th>NonWhiteCharacters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>12</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3470.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2992.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.160000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2649.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1956.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5144.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>368.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mutation  no_mutations  line_coverage  isAssertionRoulette  isEagerTest  \\\n",
       "0  0.916667            12       0.900000                    1            1   \n",
       "1  0.160000            25       0.235294                    0            0   \n",
       "2  1.000000             3       1.000000                    0            0   \n",
       "3  0.833333             6       1.000000                    1            0   \n",
       "4  0.285714             7       1.000000                    1            0   \n",
       "\n",
       "   isLazyTest  isMysteryGuest  isSensitiveEquality  isResourceOptimism  \\\n",
       "0           0               0                    1                   0   \n",
       "1           0               0                    0                   0   \n",
       "2           0               0                    0                   0   \n",
       "3           0               0                    1                   0   \n",
       "4           0               0                    0                   0   \n",
       "\n",
       "   isForTestersOnly  ...  Mockito  BadApi    LOC  Expressions  Depth  \\\n",
       "0                 1  ...      0.0     4.0  144.0        406.0   11.0   \n",
       "1                 0  ...      0.0     0.0  106.0        258.0   13.0   \n",
       "2                 1  ...      0.0     0.0   10.0         21.0    8.0   \n",
       "3                 0  ...      0.0     0.0  168.0        316.0   22.0   \n",
       "4                 0  ...      0.0     0.0   23.0         34.0   16.0   \n",
       "\n",
       "   Vocabulary  Understandability  BodySize  Dexterity  NonWhiteCharacters  \n",
       "0        53.0             3470.0     483.0        3.0              2992.0  \n",
       "1        55.0             2649.0     319.0        2.0              1956.0  \n",
       "2         9.0              181.0      23.0        3.0               221.0  \n",
       "3        50.0             5144.0     463.0        2.0              2377.0  \n",
       "4        17.0              465.0      55.0        2.0               368.0  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = load_frame()\n",
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2243, 84)\n"
     ]
    }
   ],
   "source": [
    "print(frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 4968x4968 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Using Pearson Correlation\n",
    "plt.figure(figsize=(69,69))\n",
    "cor = frame.corr()\n",
    "sns.heatmap(cor, annot=False, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum number of features: 12\n",
      "Score with 12 features: 0.206163\n",
      "Index(['COH_prod', 'BUSWEIMER_prod', 'BUSWEIMER_test', 'csm_FD', 'csm_LM'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "x = frame.drop(['mutation','line_coverage'], axis=1)\n",
    "y = pd.concat([frame.mutation], axis = 1)\n",
    "\n",
    "x = x.fillna(0)\n",
    "y = column_or_1d(y, warn=False)\n",
    "\n",
    "#no of features\n",
    "nof_list=np.arange(1,13)            \n",
    "high_score=0\n",
    "#Variable to store the optimum features\n",
    "nof=0           \n",
    "score_list =[]\n",
    "for n in range(len(nof_list)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x,y, test_size = 0.3, random_state = 0)\n",
    "    model = LinearRegression()\n",
    "    rfe = RFE(model,nof_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    model.fit(X_train_rfe,y_train)\n",
    "    score = model.score(X_test_rfe,y_test)\n",
    "    score_list.append(score)\n",
    "    if(score>high_score):\n",
    "        high_score = score\n",
    "        nof = nof_list[n]\n",
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, high_score))\n",
    "\n",
    "cols = list(x.columns)\n",
    "model = LinearRegression()\n",
    "#Initializing RFE model\n",
    "rfe = RFE(model, 5)             \n",
    "#Transforming data using RFE\n",
    "X_rfe = rfe.fit_transform(x,y)  \n",
    "#Fitting the data to model\n",
    "model.fit(X_rfe,y)              \n",
    "temp = pd.Series(rfe.support_,index = cols)\n",
    "selected_features_rfe = temp[temp==True].index\n",
    "print(selected_features_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #1: Take all data and divide by the median - Dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Data from the paper + mine ------------------------------------\n",
      "(1570, 83)\n",
      "Train on 1570 samples, validate on 337 samples\n",
      "Epoch 1/2000\n",
      "1570/1570 [==============================] - 2s 1ms/sample - loss: 284.3230 - accuracy: 0.5083 - val_loss: 61.8167 - val_accuracy: 0.6261\n",
      "Epoch 2/2000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 25.6049 - accuracy: 0.6395 - val_loss: 77.9957 - val_accuracy: 0.5579\n",
      "Epoch 3/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 28.8822 - accuracy: 0.6490 - val_loss: 18.6102 - val_accuracy: 0.6350\n",
      "Epoch 4/2000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 15.7411 - accuracy: 0.6745 - val_loss: 15.5070 - val_accuracy: 0.6706\n",
      "Epoch 5/2000\n",
      "1570/1570 [==============================] - 0s 145us/sample - loss: 36.6679 - accuracy: 0.6497 - val_loss: 61.3987 - val_accuracy: 0.5964\n",
      "Epoch 6/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 33.1644 - accuracy: 0.6471 - val_loss: 17.5655 - val_accuracy: 0.6499\n",
      "Epoch 7/2000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 14.8870 - accuracy: 0.6828 - val_loss: 13.6521 - val_accuracy: 0.6706\n",
      "Epoch 8/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 15.6928 - accuracy: 0.6350 - val_loss: 16.8697 - val_accuracy: 0.6172\n",
      "Epoch 9/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 7.4641 - accuracy: 0.6930 - val_loss: 14.0112 - val_accuracy: 0.6469\n",
      "Epoch 10/2000\n",
      "1570/1570 [==============================] - 0s 145us/sample - loss: 5.9820 - accuracy: 0.7121 - val_loss: 8.0810 - val_accuracy: 0.6944\n",
      "Epoch 11/2000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 8.5460 - accuracy: 0.6739 - val_loss: 11.3308 - val_accuracy: 0.6973\n",
      "Epoch 12/2000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 5.9703 - accuracy: 0.6981 - val_loss: 15.8501 - val_accuracy: 0.6647\n",
      "Epoch 13/2000\n",
      "1570/1570 [==============================] - 0s 151us/sample - loss: 20.3428 - accuracy: 0.6535 - val_loss: 8.0785 - val_accuracy: 0.7211\n",
      "Epoch 14/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 10.8733 - accuracy: 0.6968 - val_loss: 12.8625 - val_accuracy: 0.6083\n",
      "Epoch 15/2000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 11.8046 - accuracy: 0.7127 - val_loss: 5.8512 - val_accuracy: 0.7033\n",
      "Epoch 16/2000\n",
      "1570/1570 [==============================] - 0s 152us/sample - loss: 6.1802 - accuracy: 0.6822 - val_loss: 7.6232 - val_accuracy: 0.6380\n",
      "Epoch 17/2000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 12.5420 - accuracy: 0.6395 - val_loss: 14.0536 - val_accuracy: 0.6973\n",
      "Epoch 18/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 21.8909 - accuracy: 0.6236 - val_loss: 7.4649 - val_accuracy: 0.6795\n",
      "Epoch 19/2000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 6.3225 - accuracy: 0.6274 - val_loss: 5.6617 - val_accuracy: 0.6528\n",
      "Epoch 20/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 5.1559 - accuracy: 0.6637 - val_loss: 17.1503 - val_accuracy: 0.6320\n",
      "Epoch 21/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 11.0133 - accuracy: 0.6624 - val_loss: 4.1887 - val_accuracy: 0.6558\n",
      "Epoch 22/2000\n",
      "1570/1570 [==============================] - 0s 145us/sample - loss: 2.5541 - accuracy: 0.6955 - val_loss: 3.1231 - val_accuracy: 0.6944\n",
      "Epoch 23/2000\n",
      "1570/1570 [==============================] - 0s 143us/sample - loss: 2.2698 - accuracy: 0.6930 - val_loss: 3.5381 - val_accuracy: 0.6884\n",
      "Epoch 24/2000\n",
      "1570/1570 [==============================] - 0s 146us/sample - loss: 3.8652 - accuracy: 0.6293 - val_loss: 4.0782 - val_accuracy: 0.7151\n",
      "Epoch 25/2000\n",
      "1570/1570 [==============================] - 0s 146us/sample - loss: 1.8879 - accuracy: 0.7166 - val_loss: 3.9713 - val_accuracy: 0.6261\n",
      "Epoch 26/2000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 2.0864 - accuracy: 0.7261 - val_loss: 4.0816 - val_accuracy: 0.6469\n",
      "Epoch 27/2000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 2.5165 - accuracy: 0.6904 - val_loss: 3.0196 - val_accuracy: 0.7033\n",
      "Epoch 28/2000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 1.5034 - accuracy: 0.7433 - val_loss: 2.9198 - val_accuracy: 0.6142\n",
      "Epoch 29/2000\n",
      "1570/1570 [==============================] - 0s 152us/sample - loss: 2.8424 - accuracy: 0.6822 - val_loss: 2.2880 - val_accuracy: 0.6944\n",
      "Epoch 30/2000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 1.7408 - accuracy: 0.7376 - val_loss: 4.1992 - val_accuracy: 0.6409\n",
      "Epoch 31/2000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 2.3227 - accuracy: 0.6917 - val_loss: 3.1702 - val_accuracy: 0.7062\n",
      "Epoch 32/2000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 1.4768 - accuracy: 0.7325 - val_loss: 4.2867 - val_accuracy: 0.7567\n",
      "Epoch 33/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 1.1747 - accuracy: 0.7204 - val_loss: 5.9449 - val_accuracy: 0.7329\n",
      "Epoch 34/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 1.4131 - accuracy: 0.7217 - val_loss: 8.9879 - val_accuracy: 0.6884\n",
      "Epoch 35/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 1.3351 - accuracy: 0.7166 - val_loss: 8.2655 - val_accuracy: 0.6973\n",
      "Epoch 36/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 1.4669 - accuracy: 0.7096 - val_loss: 6.8578 - val_accuracy: 0.7003\n",
      "Epoch 37/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 1.0556 - accuracy: 0.7420 - val_loss: 5.8095 - val_accuracy: 0.6973\n",
      "Epoch 38/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 1.8782 - accuracy: 0.6930 - val_loss: 6.8574 - val_accuracy: 0.7003\n",
      "Epoch 39/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 2.2737 - accuracy: 0.6981 - val_loss: 7.0365 - val_accuracy: 0.6944\n",
      "Epoch 40/2000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.9247 - accuracy: 0.7580 - val_loss: 4.9997 - val_accuracy: 0.7092\n",
      "Epoch 41/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 1.6596 - accuracy: 0.7057 - val_loss: 6.8166 - val_accuracy: 0.6291\n",
      "Epoch 42/2000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 1.2292 - accuracy: 0.7452 - val_loss: 6.1565 - val_accuracy: 0.6677\n",
      "Epoch 43/2000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.9540 - accuracy: 0.7573 - val_loss: 8.0965 - val_accuracy: 0.5430\n",
      "Epoch 44/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.9091 - accuracy: 0.7656 - val_loss: 6.7406 - val_accuracy: 0.7389\n",
      "Epoch 45/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.9668 - accuracy: 0.7452 - val_loss: 6.9812 - val_accuracy: 0.6855\n",
      "Epoch 46/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 1.4544 - accuracy: 0.7318 - val_loss: 5.5894 - val_accuracy: 0.7240\n",
      "Epoch 47/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.9401 - accuracy: 0.7554 - val_loss: 6.1686 - val_accuracy: 0.6884\n",
      "Epoch 48/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.9719 - accuracy: 0.7522 - val_loss: 6.1821 - val_accuracy: 0.7062\n",
      "Epoch 49/2000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.8707 - accuracy: 0.7790 - val_loss: 6.8128 - val_accuracy: 0.7389\n",
      "Epoch 50/2000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 1.0654 - accuracy: 0.7312 - val_loss: 7.1684 - val_accuracy: 0.7359\n",
      "Epoch 51/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 1.4281 - accuracy: 0.7204 - val_loss: 9.4254 - val_accuracy: 0.7507\n",
      "Epoch 52/2000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 1.3623 - accuracy: 0.7268 - val_loss: 8.5380 - val_accuracy: 0.7389\n",
      "Epoch 53/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 1.4403 - accuracy: 0.7127 - val_loss: 17.0474 - val_accuracy: 0.4777\n",
      "Epoch 54/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 4.2050 - accuracy: 0.6178 - val_loss: 11.4754 - val_accuracy: 0.6053\n",
      "Epoch 55/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 3.9301 - accuracy: 0.6675 - val_loss: 11.1687 - val_accuracy: 0.7300\n",
      "Epoch 56/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.9991 - accuracy: 0.7707 - val_loss: 17.4737 - val_accuracy: 0.5786\n",
      "Epoch 57/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 7.2380 - accuracy: 0.6197 - val_loss: 16.9704 - val_accuracy: 0.6825\n",
      "Epoch 58/2000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 2.0813 - accuracy: 0.7478 - val_loss: 11.7231 - val_accuracy: 0.6024\n",
      "Epoch 59/2000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 1.8952 - accuracy: 0.7070 - val_loss: 10.9678 - val_accuracy: 0.7122\n",
      "Epoch 60/2000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 2.3081 - accuracy: 0.7108 - val_loss: 8.0699 - val_accuracy: 0.6647\n",
      "Epoch 61/2000\n",
      "1570/1570 [==============================] - 0s 152us/sample - loss: 1.6439 - accuracy: 0.7293 - val_loss: 9.2734 - val_accuracy: 0.7507\n",
      "Epoch 62/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 1.0351 - accuracy: 0.7541 - val_loss: 9.7665 - val_accuracy: 0.7389\n",
      "Epoch 63/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.9537 - accuracy: 0.7535 - val_loss: 10.0032 - val_accuracy: 0.7418\n",
      "Epoch 64/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.9147 - accuracy: 0.7605 - val_loss: 8.2883 - val_accuracy: 0.7389\n",
      "Epoch 65/2000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.7506 - accuracy: 0.7828 - val_loss: 9.6677 - val_accuracy: 0.7774\n",
      "Epoch 66/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 1.1722 - accuracy: 0.7350 - val_loss: 8.5981 - val_accuracy: 0.7270\n",
      "Epoch 67/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 1.2430 - accuracy: 0.7299 - val_loss: 7.9412 - val_accuracy: 0.7478\n",
      "Epoch 68/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.7314 - accuracy: 0.7777 - val_loss: 8.6087 - val_accuracy: 0.7507\n",
      "Epoch 69/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.7549 - accuracy: 0.7732 - val_loss: 9.8082 - val_accuracy: 0.7240\n",
      "Epoch 70/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.7899 - accuracy: 0.7739 - val_loss: 8.1673 - val_accuracy: 0.6558\n",
      "Epoch 71/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 1.5913 - accuracy: 0.6854 - val_loss: 11.8749 - val_accuracy: 0.6617\n",
      "Epoch 72/2000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 1.2798 - accuracy: 0.7191 - val_loss: 11.8417 - val_accuracy: 0.7270\n",
      "Epoch 73/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.7615 - accuracy: 0.7662 - val_loss: 12.0881 - val_accuracy: 0.6677\n",
      "Epoch 74/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 1.2957 - accuracy: 0.6924 - val_loss: 10.4800 - val_accuracy: 0.7596\n",
      "Epoch 75/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 1.0874 - accuracy: 0.7510 - val_loss: 11.7335 - val_accuracy: 0.6617\n",
      "Epoch 76/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.9424 - accuracy: 0.7605 - val_loss: 12.1605 - val_accuracy: 0.6380\n",
      "Epoch 77/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 1.6279 - accuracy: 0.6898 - val_loss: 11.7213 - val_accuracy: 0.7181\n",
      "Epoch 78/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.9886 - accuracy: 0.7522 - val_loss: 11.3940 - val_accuracy: 0.6439\n",
      "Epoch 79/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.9578 - accuracy: 0.7586 - val_loss: 10.5474 - val_accuracy: 0.7389\n",
      "Epoch 80/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.9227 - accuracy: 0.7490 - val_loss: 10.8600 - val_accuracy: 0.7537\n",
      "Epoch 81/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.8963 - accuracy: 0.7631 - val_loss: 11.6781 - val_accuracy: 0.6884\n",
      "Epoch 82/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.6152 - accuracy: 0.7885 - val_loss: 9.8296 - val_accuracy: 0.7537\n",
      "Epoch 83/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.7575 - accuracy: 0.7726 - val_loss: 10.4976 - val_accuracy: 0.5193\n",
      "Epoch 84/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 2.9885 - accuracy: 0.6586 - val_loss: 21.8150 - val_accuracy: 0.6914\n",
      "Epoch 85/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 3.5413 - accuracy: 0.6732 - val_loss: 16.4811 - val_accuracy: 0.7003\n",
      "Epoch 86/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 1.5508 - accuracy: 0.7210 - val_loss: 14.1609 - val_accuracy: 0.7270\n",
      "Epoch 87/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 1.0708 - accuracy: 0.7242 - val_loss: 14.4877 - val_accuracy: 0.6350\n",
      "Epoch 88/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.9518 - accuracy: 0.7363 - val_loss: 12.9823 - val_accuracy: 0.6825\n",
      "Epoch 89/2000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.9001 - accuracy: 0.7535 - val_loss: 13.2533 - val_accuracy: 0.7300\n",
      "Epoch 90/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.7651 - accuracy: 0.7803 - val_loss: 13.4298 - val_accuracy: 0.6766\n",
      "Epoch 91/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 1.7507 - accuracy: 0.6752 - val_loss: 13.5210 - val_accuracy: 0.6973\n",
      "Epoch 92/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 1.6176 - accuracy: 0.7083 - val_loss: 13.0090 - val_accuracy: 0.7092\n",
      "Epoch 93/2000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 1.0933 - accuracy: 0.7720 - val_loss: 11.3504 - val_accuracy: 0.7329\n",
      "Epoch 94/2000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 1.0776 - accuracy: 0.7541 - val_loss: 12.3974 - val_accuracy: 0.7389\n",
      "Epoch 95/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.9662 - accuracy: 0.7312 - val_loss: 11.3881 - val_accuracy: 0.7062\n",
      "Epoch 96/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.9003 - accuracy: 0.7414 - val_loss: 11.7042 - val_accuracy: 0.7062\n",
      "Epoch 97/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.6992 - accuracy: 0.7561 - val_loss: 10.7278 - val_accuracy: 0.6677\n",
      "Epoch 98/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.8707 - accuracy: 0.7401 - val_loss: 10.7831 - val_accuracy: 0.6439\n",
      "Epoch 99/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.9139 - accuracy: 0.7255 - val_loss: 9.0831 - val_accuracy: 0.7329\n",
      "Epoch 100/2000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 1.0519 - accuracy: 0.7210 - val_loss: 10.1160 - val_accuracy: 0.5994\n",
      "Epoch 101/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 1.0380 - accuracy: 0.7541 - val_loss: 7.6135 - val_accuracy: 0.6855\n",
      "Epoch 102/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.7352 - accuracy: 0.7529 - val_loss: 7.2690 - val_accuracy: 0.6736\n",
      "Epoch 103/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.9716 - accuracy: 0.7280 - val_loss: 7.1254 - val_accuracy: 0.6914\n",
      "Epoch 104/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 1.7596 - accuracy: 0.6726 - val_loss: 8.3033 - val_accuracy: 0.6944\n",
      "Epoch 105/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 1.1491 - accuracy: 0.7312 - val_loss: 9.3356 - val_accuracy: 0.7270\n",
      "Epoch 106/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.9659 - accuracy: 0.7561 - val_loss: 7.9710 - val_accuracy: 0.5935\n",
      "Epoch 107/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.7422 - accuracy: 0.7497 - val_loss: 7.9040 - val_accuracy: 0.6499\n",
      "Epoch 108/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.6634 - accuracy: 0.7618 - val_loss: 5.3508 - val_accuracy: 0.6409\n",
      "Epoch 109/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.7085 - accuracy: 0.7420 - val_loss: 5.2007 - val_accuracy: 0.7033\n",
      "Epoch 110/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.8471 - accuracy: 0.7497 - val_loss: 9.3862 - val_accuracy: 0.7418\n",
      "Epoch 111/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 1.1235 - accuracy: 0.7873 - val_loss: 7.8108 - val_accuracy: 0.7300\n",
      "Epoch 112/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.8374 - accuracy: 0.7510 - val_loss: 9.3856 - val_accuracy: 0.7211\n",
      "Epoch 113/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.6668 - accuracy: 0.7503 - val_loss: 7.5779 - val_accuracy: 0.6855\n",
      "Epoch 114/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.5333 - accuracy: 0.7911 - val_loss: 8.7034 - val_accuracy: 0.6884\n",
      "Epoch 115/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.7630 - accuracy: 0.7516 - val_loss: 10.5320 - val_accuracy: 0.6528\n",
      "Epoch 116/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.6479 - accuracy: 0.7561 - val_loss: 10.6921 - val_accuracy: 0.7537\n",
      "Epoch 117/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.7044 - accuracy: 0.7414 - val_loss: 12.0520 - val_accuracy: 0.7003\n",
      "Epoch 118/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.6211 - accuracy: 0.7803 - val_loss: 11.2790 - val_accuracy: 0.7389\n",
      "Epoch 119/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.5901 - accuracy: 0.7873 - val_loss: 9.8428 - val_accuracy: 0.7418\n",
      "Epoch 120/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.5469 - accuracy: 0.7790 - val_loss: 8.5404 - val_accuracy: 0.7448\n",
      "Epoch 121/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.5335 - accuracy: 0.7707 - val_loss: 9.3663 - val_accuracy: 0.7567\n",
      "Epoch 122/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 1.0552 - accuracy: 0.7191 - val_loss: 10.7357 - val_accuracy: 0.5727\n",
      "Epoch 123/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.7247 - accuracy: 0.7331 - val_loss: 8.0331 - val_accuracy: 0.7359\n",
      "Epoch 124/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.6211 - accuracy: 0.7548 - val_loss: 8.9599 - val_accuracy: 0.6884\n",
      "Epoch 125/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.5449 - accuracy: 0.7777 - val_loss: 5.0011 - val_accuracy: 0.7329\n",
      "Epoch 126/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.6565 - accuracy: 0.7924 - val_loss: 7.6502 - val_accuracy: 0.7478\n",
      "Epoch 127/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.8100 - accuracy: 0.7299 - val_loss: 5.7846 - val_accuracy: 0.7389\n",
      "Epoch 128/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.8563 - accuracy: 0.7452 - val_loss: 6.0707 - val_accuracy: 0.7359\n",
      "Epoch 129/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.6478 - accuracy: 0.7631 - val_loss: 5.0618 - val_accuracy: 0.6706\n",
      "Epoch 130/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.8879 - accuracy: 0.7599 - val_loss: 7.0006 - val_accuracy: 0.7062\n",
      "Epoch 131/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 1.4234 - accuracy: 0.7287 - val_loss: 2.4578 - val_accuracy: 0.6499\n",
      "Epoch 132/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.9852 - accuracy: 0.7484 - val_loss: 6.3150 - val_accuracy: 0.7418\n",
      "Epoch 133/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.7125 - accuracy: 0.7732 - val_loss: 1.7179 - val_accuracy: 0.7181\n",
      "Epoch 134/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 1.0589 - accuracy: 0.7064 - val_loss: 2.0436 - val_accuracy: 0.6172\n",
      "Epoch 135/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.9515 - accuracy: 0.7344 - val_loss: 1.6295 - val_accuracy: 0.7181\n",
      "Epoch 136/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 1.2552 - accuracy: 0.7318 - val_loss: 2.9891 - val_accuracy: 0.4006\n",
      "Epoch 137/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 2.4638 - accuracy: 0.6121 - val_loss: 2.3648 - val_accuracy: 0.5223\n",
      "Epoch 138/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 1.6368 - accuracy: 0.6401 - val_loss: 5.4204 - val_accuracy: 0.5638\n",
      "Epoch 139/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 1.9142 - accuracy: 0.7038 - val_loss: 3.0048 - val_accuracy: 0.5846\n",
      "Epoch 140/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 2.0734 - accuracy: 0.6420 - val_loss: 2.4052 - val_accuracy: 0.6083\n",
      "Epoch 141/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.9088 - accuracy: 0.7146 - val_loss: 1.0040 - val_accuracy: 0.7537\n",
      "Epoch 142/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.6994 - accuracy: 0.7592 - val_loss: 2.0534 - val_accuracy: 0.7448\n",
      "Epoch 143/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.8079 - accuracy: 0.7459 - val_loss: 2.0679 - val_accuracy: 0.7122\n",
      "Epoch 144/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 1.9107 - accuracy: 0.6752 - val_loss: 2.4313 - val_accuracy: 0.6202\n",
      "Epoch 145/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 1.1612 - accuracy: 0.7197 - val_loss: 1.5569 - val_accuracy: 0.6825\n",
      "Epoch 146/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 1.1204 - accuracy: 0.7312 - val_loss: 1.0921 - val_accuracy: 0.6973\n",
      "Epoch 147/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.8844 - accuracy: 0.6879 - val_loss: 1.0313 - val_accuracy: 0.7122\n",
      "Epoch 148/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 1.1358 - accuracy: 0.6732 - val_loss: 1.8383 - val_accuracy: 0.6914\n",
      "Epoch 149/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 1.0832 - accuracy: 0.7376 - val_loss: 1.3624 - val_accuracy: 0.7122\n",
      "Epoch 150/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.7341 - accuracy: 0.7350 - val_loss: 17.0271 - val_accuracy: 0.7033\n",
      "Epoch 151/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.7294 - accuracy: 0.7408 - val_loss: 14.9719 - val_accuracy: 0.7270\n",
      "Epoch 152/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.6315 - accuracy: 0.7376 - val_loss: 13.2556 - val_accuracy: 0.7092\n",
      "Epoch 153/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.5344 - accuracy: 0.7586 - val_loss: 11.1253 - val_accuracy: 0.7359\n",
      "Epoch 154/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.5701 - accuracy: 0.7446 - val_loss: 11.5243 - val_accuracy: 0.7211\n",
      "Epoch 155/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.5208 - accuracy: 0.7669 - val_loss: 11.0657 - val_accuracy: 0.7537\n",
      "Epoch 156/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.5204 - accuracy: 0.7637 - val_loss: 11.6907 - val_accuracy: 0.7389\n",
      "Epoch 157/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.7057 - accuracy: 0.7541 - val_loss: 11.1048 - val_accuracy: 0.7092\n",
      "Epoch 158/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 1.1174 - accuracy: 0.6955 - val_loss: 1.4018 - val_accuracy: 0.6350\n",
      "Epoch 159/2000\n",
      "1570/1570 [==============================] - 0s 199us/sample - loss: 2.0090 - accuracy: 0.6624 - val_loss: 1.8240 - val_accuracy: 0.6528\n",
      "Epoch 160/2000\n",
      "1570/1570 [==============================] - 0s 198us/sample - loss: 0.9163 - accuracy: 0.7045 - val_loss: 3.3451 - val_accuracy: 0.6588\n",
      "Epoch 161/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 1.0409 - accuracy: 0.6847 - val_loss: 1.7099 - val_accuracy: 0.7092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.8468 - accuracy: 0.7535 - val_loss: 1.7610 - val_accuracy: 0.6884\n",
      "Epoch 163/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.7291 - accuracy: 0.7223 - val_loss: 1.9501 - val_accuracy: 0.6053\n",
      "Epoch 164/2000\n",
      "1570/1570 [==============================] - 0s 210us/sample - loss: 0.7876 - accuracy: 0.7427 - val_loss: 1.5590 - val_accuracy: 0.7062\n",
      "Epoch 165/2000\n",
      "1570/1570 [==============================] - 0s 204us/sample - loss: 0.5579 - accuracy: 0.7561 - val_loss: 1.9803 - val_accuracy: 0.7300\n",
      "Epoch 166/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.5193 - accuracy: 0.7611 - val_loss: 1.6712 - val_accuracy: 0.7300\n",
      "Epoch 167/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.5878 - accuracy: 0.7427 - val_loss: 2.0277 - val_accuracy: 0.7003\n",
      "Epoch 168/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.5904 - accuracy: 0.7280 - val_loss: 1.9017 - val_accuracy: 0.7181\n",
      "Epoch 169/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.5210 - accuracy: 0.7573 - val_loss: 2.1124 - val_accuracy: 0.7359\n",
      "Epoch 170/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.9325 - accuracy: 0.6803 - val_loss: 1.9218 - val_accuracy: 0.7329\n",
      "Epoch 171/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.7377 - accuracy: 0.7013 - val_loss: 1.8815 - val_accuracy: 0.7507\n",
      "Epoch 172/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.6690 - accuracy: 0.7484 - val_loss: 2.2389 - val_accuracy: 0.7151\n",
      "Epoch 173/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.5250 - accuracy: 0.7561 - val_loss: 2.1878 - val_accuracy: 0.7092\n",
      "Epoch 174/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.5273 - accuracy: 0.7478 - val_loss: 2.2125 - val_accuracy: 0.7092\n",
      "Epoch 175/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.5127 - accuracy: 0.7420 - val_loss: 2.3840 - val_accuracy: 0.7062\n",
      "Epoch 176/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.5284 - accuracy: 0.7529 - val_loss: 2.2292 - val_accuracy: 0.7062\n",
      "Epoch 177/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.4942 - accuracy: 0.7701 - val_loss: 2.1067 - val_accuracy: 0.7478\n",
      "Epoch 178/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.5565 - accuracy: 0.7484 - val_loss: 2.0838 - val_accuracy: 0.7300\n",
      "Epoch 179/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.5152 - accuracy: 0.7656 - val_loss: 2.1062 - val_accuracy: 0.7389\n",
      "Epoch 180/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.4933 - accuracy: 0.7726 - val_loss: 2.1761 - val_accuracy: 0.7270\n",
      "Epoch 181/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.5088 - accuracy: 0.7624 - val_loss: 2.1227 - val_accuracy: 0.7507\n",
      "Epoch 182/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.5165 - accuracy: 0.7643 - val_loss: 1.9836 - val_accuracy: 0.7567\n",
      "Epoch 183/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.5268 - accuracy: 0.7541 - val_loss: 2.1951 - val_accuracy: 0.7389\n",
      "Epoch 184/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.5117 - accuracy: 0.7669 - val_loss: 2.1362 - val_accuracy: 0.7240\n",
      "Epoch 185/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.4847 - accuracy: 0.7745 - val_loss: 2.1823 - val_accuracy: 0.7507\n",
      "Epoch 186/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.4806 - accuracy: 0.7803 - val_loss: 2.2773 - val_accuracy: 0.7626\n",
      "Epoch 187/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.4762 - accuracy: 0.7854 - val_loss: 2.2204 - val_accuracy: 0.7567\n",
      "Epoch 188/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.4624 - accuracy: 0.7771 - val_loss: 2.3023 - val_accuracy: 0.7507\n",
      "Epoch 189/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.5169 - accuracy: 0.7726 - val_loss: 2.5958 - val_accuracy: 0.7181\n",
      "Epoch 190/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.5266 - accuracy: 0.7510 - val_loss: 2.1899 - val_accuracy: 0.7359\n",
      "Epoch 191/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.4703 - accuracy: 0.7841 - val_loss: 2.2607 - val_accuracy: 0.7359\n",
      "Epoch 192/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.4819 - accuracy: 0.7764 - val_loss: 2.3420 - val_accuracy: 0.7389\n",
      "Epoch 193/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.4979 - accuracy: 0.7783 - val_loss: 2.4321 - val_accuracy: 0.7418\n",
      "Epoch 194/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.4906 - accuracy: 0.7726 - val_loss: 2.4599 - val_accuracy: 0.7300\n",
      "Epoch 195/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.4702 - accuracy: 0.7873 - val_loss: 2.3223 - val_accuracy: 0.7478\n",
      "Epoch 196/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.4671 - accuracy: 0.7834 - val_loss: 2.1150 - val_accuracy: 0.7418\n",
      "Epoch 197/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.4759 - accuracy: 0.7815 - val_loss: 2.4133 - val_accuracy: 0.7567\n",
      "Epoch 198/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.4655 - accuracy: 0.7962 - val_loss: 2.5109 - val_accuracy: 0.7329\n",
      "Epoch 199/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.5109 - accuracy: 0.7650 - val_loss: 2.4504 - val_accuracy: 0.7389\n",
      "Epoch 200/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.5519 - accuracy: 0.7599 - val_loss: 2.6993 - val_accuracy: 0.7270\n",
      "Epoch 201/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.4974 - accuracy: 0.7701 - val_loss: 1.7037 - val_accuracy: 0.7507\n",
      "Epoch 202/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.5273 - accuracy: 0.7752 - val_loss: 2.0680 - val_accuracy: 0.7329\n",
      "Epoch 203/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.4615 - accuracy: 0.7994 - val_loss: 2.1250 - val_accuracy: 0.7389\n",
      "Epoch 204/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.4753 - accuracy: 0.7847 - val_loss: 1.6686 - val_accuracy: 0.7211\n",
      "Epoch 205/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.4587 - accuracy: 0.7943 - val_loss: 1.7170 - val_accuracy: 0.7151\n",
      "Epoch 206/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.4492 - accuracy: 0.7994 - val_loss: 1.8729 - val_accuracy: 0.7478\n",
      "Epoch 207/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.4486 - accuracy: 0.8076 - val_loss: 2.0098 - val_accuracy: 0.7478\n",
      "Epoch 208/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 1.0020 - accuracy: 0.7287 - val_loss: 1.7490 - val_accuracy: 0.6795\n",
      "Epoch 209/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 1.1003 - accuracy: 0.6796 - val_loss: 1.7952 - val_accuracy: 0.7389\n",
      "Epoch 210/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 1.2012 - accuracy: 0.6962 - val_loss: 1.0611 - val_accuracy: 0.7062\n",
      "Epoch 211/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.9319 - accuracy: 0.7325 - val_loss: 1.2134 - val_accuracy: 0.7092\n",
      "Epoch 212/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.8124 - accuracy: 0.7529 - val_loss: 3.5192 - val_accuracy: 0.7240\n",
      "Epoch 213/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 1.7604 - accuracy: 0.7191 - val_loss: 3.0691 - val_accuracy: 0.7418\n",
      "Epoch 214/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 1.8071 - accuracy: 0.6771 - val_loss: 1.7094 - val_accuracy: 0.7003\n",
      "Epoch 215/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 1.9299 - accuracy: 0.7178 - val_loss: 2.5504 - val_accuracy: 0.6677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 1.0936 - accuracy: 0.6847 - val_loss: 1.3506 - val_accuracy: 0.6973\n",
      "Epoch 217/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.7916 - accuracy: 0.7325 - val_loss: 1.1497 - val_accuracy: 0.7092\n",
      "Epoch 218/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 1.1244 - accuracy: 0.6930 - val_loss: 1.7179 - val_accuracy: 0.7122\n",
      "Epoch 219/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.7125 - accuracy: 0.7478 - val_loss: 1.5857 - val_accuracy: 0.7240\n",
      "Epoch 220/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.8631 - accuracy: 0.7172 - val_loss: 2.2075 - val_accuracy: 0.7092\n",
      "Epoch 221/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.6403 - accuracy: 0.7567 - val_loss: 1.4553 - val_accuracy: 0.7418\n",
      "Epoch 222/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.6101 - accuracy: 0.7732 - val_loss: 1.3237 - val_accuracy: 0.7359\n",
      "Epoch 223/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.6399 - accuracy: 0.7618 - val_loss: 1.4651 - val_accuracy: 0.7418\n",
      "Epoch 224/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.5859 - accuracy: 0.7618 - val_loss: 1.5351 - val_accuracy: 0.7211\n",
      "Epoch 225/2000\n",
      "1570/1570 [==============================] - 0s 199us/sample - loss: 0.5745 - accuracy: 0.7548 - val_loss: 1.4819 - val_accuracy: 0.7033\n",
      "Epoch 226/2000\n",
      "1570/1570 [==============================] - 0s 196us/sample - loss: 0.6230 - accuracy: 0.7497 - val_loss: 1.5060 - val_accuracy: 0.7240\n",
      "Epoch 227/2000\n",
      "1570/1570 [==============================] - 0s 194us/sample - loss: 0.5365 - accuracy: 0.7726 - val_loss: 1.9205 - val_accuracy: 0.6855\n",
      "Epoch 228/2000\n",
      "1570/1570 [==============================] - 0s 212us/sample - loss: 0.5521 - accuracy: 0.7745 - val_loss: 1.4300 - val_accuracy: 0.7567\n",
      "Epoch 229/2000\n",
      "1570/1570 [==============================] - 0s 210us/sample - loss: 0.6006 - accuracy: 0.7631 - val_loss: 1.6733 - val_accuracy: 0.7181\n",
      "Epoch 230/2000\n",
      "1570/1570 [==============================] - 0s 228us/sample - loss: 0.5759 - accuracy: 0.7675 - val_loss: 2.0492 - val_accuracy: 0.6914\n",
      "Epoch 231/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.5711 - accuracy: 0.7548 - val_loss: 1.4661 - val_accuracy: 0.7389\n",
      "Epoch 232/2000\n",
      "1570/1570 [==============================] - 0s 198us/sample - loss: 0.4893 - accuracy: 0.7873 - val_loss: 1.3691 - val_accuracy: 0.7567\n",
      "Epoch 233/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.5011 - accuracy: 0.7841 - val_loss: 1.1360 - val_accuracy: 0.7359\n",
      "Epoch 234/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.5005 - accuracy: 0.7643 - val_loss: 1.1163 - val_accuracy: 0.7418\n",
      "Epoch 235/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.4860 - accuracy: 0.7879 - val_loss: 1.0507 - val_accuracy: 0.7567\n",
      "Epoch 236/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.4734 - accuracy: 0.7975 - val_loss: 1.2102 - val_accuracy: 0.7626\n",
      "Epoch 237/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.4776 - accuracy: 0.7854 - val_loss: 1.2573 - val_accuracy: 0.7240\n",
      "Epoch 238/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.4612 - accuracy: 0.7981 - val_loss: 1.2280 - val_accuracy: 0.7300\n",
      "Epoch 239/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.5922 - accuracy: 0.7822 - val_loss: 0.8887 - val_accuracy: 0.7240\n",
      "Epoch 240/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.5428 - accuracy: 0.7892 - val_loss: 0.9347 - val_accuracy: 0.7092\n",
      "Epoch 241/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.5736 - accuracy: 0.7847 - val_loss: 1.0677 - val_accuracy: 0.7567\n",
      "Epoch 242/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.4705 - accuracy: 0.7975 - val_loss: 1.2369 - val_accuracy: 0.7270\n",
      "Epoch 243/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.4550 - accuracy: 0.7866 - val_loss: 1.2099 - val_accuracy: 0.7448\n",
      "Epoch 244/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.5085 - accuracy: 0.7860 - val_loss: 1.4339 - val_accuracy: 0.7270\n",
      "Epoch 245/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.6332 - accuracy: 0.7930 - val_loss: 9.0991 - val_accuracy: 0.7329\n",
      "Epoch 246/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.9004 - accuracy: 0.7567 - val_loss: 1.8539 - val_accuracy: 0.7478\n",
      "Epoch 247/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.6385 - accuracy: 0.7739 - val_loss: 2.9944 - val_accuracy: 0.7270\n",
      "Epoch 248/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.6242 - accuracy: 0.7637 - val_loss: 2.1642 - val_accuracy: 0.7062\n",
      "Epoch 249/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.5633 - accuracy: 0.7764 - val_loss: 1.9737 - val_accuracy: 0.7507\n",
      "Epoch 250/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.5039 - accuracy: 0.8146 - val_loss: 1.8748 - val_accuracy: 0.7389\n",
      "Epoch 251/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.4863 - accuracy: 0.7987 - val_loss: 1.5009 - val_accuracy: 0.7181\n",
      "Epoch 252/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.4922 - accuracy: 0.7994 - val_loss: 1.4317 - val_accuracy: 0.7448\n",
      "Epoch 253/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.4816 - accuracy: 0.8064 - val_loss: 1.4385 - val_accuracy: 0.7626\n",
      "Epoch 254/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.5781 - accuracy: 0.7885 - val_loss: 1.4690 - val_accuracy: 0.7389\n",
      "Epoch 255/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.5296 - accuracy: 0.7783 - val_loss: 1.3970 - val_accuracy: 0.7329\n",
      "Epoch 256/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.4603 - accuracy: 0.8025 - val_loss: 1.2455 - val_accuracy: 0.7478\n",
      "Epoch 257/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.4337 - accuracy: 0.8096 - val_loss: 1.2820 - val_accuracy: 0.7596\n",
      "Epoch 258/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.4306 - accuracy: 0.8127 - val_loss: 1.2862 - val_accuracy: 0.7359\n",
      "Epoch 259/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.4232 - accuracy: 0.8153 - val_loss: 1.1506 - val_accuracy: 0.7448\n",
      "Epoch 260/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.4720 - accuracy: 0.8000 - val_loss: 1.1090 - val_accuracy: 0.7567\n",
      "Epoch 261/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.4489 - accuracy: 0.8153 - val_loss: 1.3249 - val_accuracy: 0.7418\n",
      "Epoch 262/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.4805 - accuracy: 0.8096 - val_loss: 1.2629 - val_accuracy: 0.7478\n",
      "Epoch 263/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.4237 - accuracy: 0.8121 - val_loss: 1.1816 - val_accuracy: 0.7507\n",
      "Epoch 264/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.5275 - accuracy: 0.7809 - val_loss: 1.2517 - val_accuracy: 0.7507\n",
      "Epoch 265/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.5216 - accuracy: 0.8000 - val_loss: 0.8918 - val_accuracy: 0.7507\n",
      "Epoch 266/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.4738 - accuracy: 0.7745 - val_loss: 0.9742 - val_accuracy: 0.7448\n",
      "Epoch 267/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.4630 - accuracy: 0.8032 - val_loss: 1.0809 - val_accuracy: 0.7151\n",
      "Epoch 268/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.5046 - accuracy: 0.7962 - val_loss: 1.0863 - val_accuracy: 0.7418\n",
      "Epoch 269/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.4386 - accuracy: 0.8089 - val_loss: 0.8937 - val_accuracy: 0.7478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.4128 - accuracy: 0.8178 - val_loss: 0.8576 - val_accuracy: 0.7448\n",
      "Epoch 271/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.4678 - accuracy: 0.7975 - val_loss: 1.0325 - val_accuracy: 0.7300\n",
      "Epoch 272/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.4172 - accuracy: 0.8127 - val_loss: 0.7905 - val_accuracy: 0.7448\n",
      "Epoch 273/2000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.4106 - accuracy: 0.8178 - val_loss: 0.9057 - val_accuracy: 0.7626\n",
      "Epoch 274/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.4148 - accuracy: 0.8223 - val_loss: 0.8876 - val_accuracy: 0.7329\n",
      "Epoch 275/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.3973 - accuracy: 0.8293 - val_loss: 0.8665 - val_accuracy: 0.7507\n",
      "Epoch 276/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.3925 - accuracy: 0.8255 - val_loss: 0.8506 - val_accuracy: 0.7567\n",
      "Epoch 277/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.4478 - accuracy: 0.8197 - val_loss: 1.0019 - val_accuracy: 0.7537\n",
      "Epoch 278/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.4616 - accuracy: 0.8089 - val_loss: 0.7721 - val_accuracy: 0.7448\n",
      "Epoch 279/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.4527 - accuracy: 0.8045 - val_loss: 0.8002 - val_accuracy: 0.7656\n",
      "Epoch 280/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.4456 - accuracy: 0.8204 - val_loss: 0.8059 - val_accuracy: 0.7418\n",
      "Epoch 281/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.4327 - accuracy: 0.8153 - val_loss: 1.1192 - val_accuracy: 0.7359\n",
      "Epoch 282/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.4362 - accuracy: 0.8248 - val_loss: 1.2876 - val_accuracy: 0.7478\n",
      "Epoch 283/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.4978 - accuracy: 0.7975 - val_loss: 1.1793 - val_accuracy: 0.7418\n",
      "Epoch 284/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.4286 - accuracy: 0.8045 - val_loss: 0.9095 - val_accuracy: 0.7596\n",
      "Epoch 285/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.4181 - accuracy: 0.8185 - val_loss: 0.9150 - val_accuracy: 0.7418\n",
      "Epoch 286/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.4065 - accuracy: 0.8191 - val_loss: 0.8397 - val_accuracy: 0.7656\n",
      "Epoch 287/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.4012 - accuracy: 0.8178 - val_loss: 0.8916 - val_accuracy: 0.7537\n",
      "Epoch 288/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.3968 - accuracy: 0.8204 - val_loss: 0.8807 - val_accuracy: 0.7626\n",
      "Epoch 289/2000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.4008 - accuracy: 0.8261 - val_loss: 0.9326 - val_accuracy: 0.7329\n",
      "Epoch 290/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.4036 - accuracy: 0.8261 - val_loss: 0.8131 - val_accuracy: 0.7448\n",
      "Epoch 291/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.4488 - accuracy: 0.8217 - val_loss: 0.9908 - val_accuracy: 0.7626\n",
      "Epoch 292/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.4857 - accuracy: 0.8051 - val_loss: 0.9350 - val_accuracy: 0.7240\n",
      "Epoch 293/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.4930 - accuracy: 0.7994 - val_loss: 0.8256 - val_accuracy: 0.7270\n",
      "Epoch 294/2000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.4092 - accuracy: 0.8210 - val_loss: 0.8773 - val_accuracy: 0.7596\n",
      "Epoch 295/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.4083 - accuracy: 0.8185 - val_loss: 0.6176 - val_accuracy: 0.7804\n",
      "Epoch 296/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.3873 - accuracy: 0.8255 - val_loss: 0.7289 - val_accuracy: 0.7507\n",
      "Epoch 297/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.4557 - accuracy: 0.8166 - val_loss: 0.7712 - val_accuracy: 0.7626\n",
      "Epoch 298/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.4184 - accuracy: 0.8255 - val_loss: 1.0699 - val_accuracy: 0.7478\n",
      "Epoch 299/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.4987 - accuracy: 0.8032 - val_loss: 1.0121 - val_accuracy: 0.7448\n",
      "Epoch 300/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.4516 - accuracy: 0.8146 - val_loss: 1.2794 - val_accuracy: 0.7389\n",
      "Epoch 301/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.4379 - accuracy: 0.8197 - val_loss: 0.9675 - val_accuracy: 0.7389\n",
      "Epoch 302/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.4552 - accuracy: 0.8210 - val_loss: 0.9426 - val_accuracy: 0.7537\n",
      "Epoch 303/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.4307 - accuracy: 0.8261 - val_loss: 0.8574 - val_accuracy: 0.7626\n",
      "Epoch 304/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.3962 - accuracy: 0.8363 - val_loss: 0.8633 - val_accuracy: 0.7537\n",
      "Epoch 305/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.3873 - accuracy: 0.8293 - val_loss: 0.9799 - val_accuracy: 0.7151\n",
      "Epoch 306/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.5117 - accuracy: 0.7758 - val_loss: 0.8749 - val_accuracy: 0.7300\n",
      "Epoch 307/2000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.4415 - accuracy: 0.8146 - val_loss: 0.8443 - val_accuracy: 0.7389\n",
      "Epoch 308/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.4634 - accuracy: 0.7911 - val_loss: 0.5592 - val_accuracy: 0.7537\n",
      "Epoch 309/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.4138 - accuracy: 0.8121 - val_loss: 0.5753 - val_accuracy: 0.7418\n",
      "Epoch 310/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.4385 - accuracy: 0.8268 - val_loss: 8.1949 - val_accuracy: 0.7596\n",
      "Epoch 311/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.4243 - accuracy: 0.8172 - val_loss: 6.1566 - val_accuracy: 0.7359\n",
      "Epoch 312/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.4255 - accuracy: 0.8274 - val_loss: 4.7736 - val_accuracy: 0.7389\n",
      "Epoch 313/2000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.4251 - accuracy: 0.8159 - val_loss: 1.7347 - val_accuracy: 0.7151\n",
      "Epoch 314/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.4806 - accuracy: 0.8096 - val_loss: 2.2051 - val_accuracy: 0.7240\n",
      "Epoch 315/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.5024 - accuracy: 0.7631 - val_loss: 5.0630 - val_accuracy: 0.7478\n",
      "Epoch 316/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.4077 - accuracy: 0.8242 - val_loss: 6.4864 - val_accuracy: 0.7656\n",
      "Epoch 317/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.3961 - accuracy: 0.8229 - val_loss: 4.4582 - val_accuracy: 0.7685\n",
      "Epoch 318/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.3951 - accuracy: 0.8268 - val_loss: 6.0748 - val_accuracy: 0.7507\n",
      "Epoch 319/2000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.4023 - accuracy: 0.8299 - val_loss: 8.2139 - val_accuracy: 0.7329\n",
      "Epoch 320/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.3988 - accuracy: 0.8236 - val_loss: 6.1772 - val_accuracy: 0.7537\n",
      "Epoch 321/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.5027 - accuracy: 0.7529 - val_loss: 9.0885 - val_accuracy: 0.7537\n",
      "Epoch 322/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.4406 - accuracy: 0.8121 - val_loss: 9.7208 - val_accuracy: 0.7359\n",
      "Epoch 323/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.4119 - accuracy: 0.8236 - val_loss: 6.6478 - val_accuracy: 0.7537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.3928 - accuracy: 0.8191 - val_loss: 8.6765 - val_accuracy: 0.7774\n",
      "Epoch 325/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.4005 - accuracy: 0.8299 - val_loss: 11.9651 - val_accuracy: 0.7359\n",
      "Epoch 326/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 1.0203 - accuracy: 0.8191 - val_loss: 1.0880 - val_accuracy: 0.7567\n",
      "Epoch 327/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.7037 - accuracy: 0.7815 - val_loss: 0.8958 - val_accuracy: 0.7478\n",
      "Epoch 328/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.5655 - accuracy: 0.7930 - val_loss: 1.5266 - val_accuracy: 0.7359\n",
      "Epoch 329/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 1.3358 - accuracy: 0.7312 - val_loss: 1.7626 - val_accuracy: 0.7211\n",
      "Epoch 330/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.7175 - accuracy: 0.7815 - val_loss: 1.8667 - val_accuracy: 0.7240\n",
      "Epoch 331/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.5070 - accuracy: 0.7981 - val_loss: 2.2934 - val_accuracy: 0.7745\n",
      "Epoch 332/2000\n",
      "1570/1570 [==============================] - 0s 196us/sample - loss: 0.4645 - accuracy: 0.8083 - val_loss: 3.1262 - val_accuracy: 0.7804\n",
      "Epoch 333/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.4564 - accuracy: 0.8268 - val_loss: 2.8101 - val_accuracy: 0.7448\n",
      "Epoch 334/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.4911 - accuracy: 0.8146 - val_loss: 5.9941 - val_accuracy: 0.7745\n",
      "Epoch 335/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.5050 - accuracy: 0.8166 - val_loss: 5.4416 - val_accuracy: 0.7715\n",
      "Epoch 336/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.4524 - accuracy: 0.8268 - val_loss: 5.6361 - val_accuracy: 0.7507\n",
      "Epoch 337/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.4338 - accuracy: 0.8268 - val_loss: 0.8500 - val_accuracy: 0.7804\n",
      "Epoch 338/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.4120 - accuracy: 0.8242 - val_loss: 0.7974 - val_accuracy: 0.7567\n",
      "Epoch 339/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.4249 - accuracy: 0.8217 - val_loss: 0.8117 - val_accuracy: 0.7329\n",
      "Epoch 340/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.6004 - accuracy: 0.6777 - val_loss: 2.1366 - val_accuracy: 0.6914\n",
      "Epoch 341/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.5178 - accuracy: 0.7389 - val_loss: 3.0680 - val_accuracy: 0.7211\n",
      "Epoch 342/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.5038 - accuracy: 0.7605 - val_loss: 3.8483 - val_accuracy: 0.7478\n",
      "Epoch 343/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.4566 - accuracy: 0.7701 - val_loss: 8.7665 - val_accuracy: 0.7596\n",
      "Epoch 344/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.4855 - accuracy: 0.7803 - val_loss: 9.1580 - val_accuracy: 0.7685\n",
      "Epoch 345/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.4558 - accuracy: 0.7949 - val_loss: 8.9934 - val_accuracy: 0.7656\n",
      "Epoch 346/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.4612 - accuracy: 0.7930 - val_loss: 7.0370 - val_accuracy: 0.7774\n",
      "Epoch 347/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.4316 - accuracy: 0.8038 - val_loss: 5.7732 - val_accuracy: 0.7953\n",
      "Epoch 348/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.4214 - accuracy: 0.8096 - val_loss: 5.9966 - val_accuracy: 0.7804\n",
      "Epoch 349/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.4290 - accuracy: 0.8108 - val_loss: 7.0657 - val_accuracy: 0.7656\n",
      "Epoch 350/2000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.4378 - accuracy: 0.8032 - val_loss: 9.3778 - val_accuracy: 0.7834\n",
      "Epoch 351/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.4589 - accuracy: 0.7987 - val_loss: 6.3478 - val_accuracy: 0.7685\n",
      "Epoch 352/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.4371 - accuracy: 0.8057 - val_loss: 4.1973 - val_accuracy: 0.7596\n",
      "Epoch 353/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.4145 - accuracy: 0.8172 - val_loss: 3.0169 - val_accuracy: 0.7567\n",
      "Epoch 354/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.4096 - accuracy: 0.8191 - val_loss: 3.5268 - val_accuracy: 0.7715\n",
      "Epoch 355/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.4182 - accuracy: 0.8229 - val_loss: 3.1243 - val_accuracy: 0.7715\n",
      "Epoch 356/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.3987 - accuracy: 0.8274 - val_loss: 3.1555 - val_accuracy: 0.7715\n",
      "Epoch 357/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.3998 - accuracy: 0.8287 - val_loss: 3.8737 - val_accuracy: 0.7685\n",
      "Epoch 358/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.3994 - accuracy: 0.8223 - val_loss: 3.0517 - val_accuracy: 0.7596\n",
      "Epoch 359/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.3932 - accuracy: 0.8287 - val_loss: 4.1109 - val_accuracy: 0.7893\n",
      "Epoch 360/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.4623 - accuracy: 0.7955 - val_loss: 0.5893 - val_accuracy: 0.7329\n",
      "Epoch 361/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.4552 - accuracy: 0.7943 - val_loss: 0.5612 - val_accuracy: 0.7626\n",
      "Epoch 362/2000\n",
      "1570/1570 [==============================] - 0s 204us/sample - loss: 0.4439 - accuracy: 0.8000 - val_loss: 0.5784 - val_accuracy: 0.7567\n",
      "Epoch 363/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.4114 - accuracy: 0.8268 - val_loss: 0.6736 - val_accuracy: 0.7537\n",
      "Epoch 364/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.4075 - accuracy: 0.8185 - val_loss: 0.7240 - val_accuracy: 0.7656\n",
      "Epoch 365/2000\n",
      "1570/1570 [==============================] - 0s 205us/sample - loss: 0.4145 - accuracy: 0.8204 - val_loss: 0.6950 - val_accuracy: 0.7418\n",
      "Epoch 366/2000\n",
      "1570/1570 [==============================] - 0s 203us/sample - loss: 0.4490 - accuracy: 0.8127 - val_loss: 0.5628 - val_accuracy: 0.7626\n",
      "Epoch 367/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.4155 - accuracy: 0.8121 - val_loss: 0.5196 - val_accuracy: 0.7418\n",
      "Epoch 368/2000\n",
      "1570/1570 [==============================] - 0s 252us/sample - loss: 0.4232 - accuracy: 0.8172 - val_loss: 0.4943 - val_accuracy: 0.7567\n",
      "Epoch 369/2000\n",
      "1570/1570 [==============================] - 0s 312us/sample - loss: 0.4131 - accuracy: 0.8185 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 370/2000\n",
      "1570/1570 [==============================] - 1s 345us/sample - loss: 0.4102 - accuracy: 0.8140 - val_loss: 0.5879 - val_accuracy: 0.7418\n",
      "Epoch 371/2000\n",
      "1570/1570 [==============================] - 0s 318us/sample - loss: 0.5122 - accuracy: 0.7752 - val_loss: 0.5997 - val_accuracy: 0.7537\n",
      "Epoch 372/2000\n",
      "1570/1570 [==============================] - 1s 438us/sample - loss: 0.4202 - accuracy: 0.8159 - val_loss: 0.6308 - val_accuracy: 0.7626\n",
      "Epoch 373/2000\n",
      "1570/1570 [==============================] - 1s 355us/sample - loss: 0.3957 - accuracy: 0.8274 - val_loss: 0.6965 - val_accuracy: 0.7211\n",
      "Epoch 374/2000\n",
      "1570/1570 [==============================] - 0s 240us/sample - loss: 0.4350 - accuracy: 0.7987 - val_loss: 0.7137 - val_accuracy: 0.7626\n",
      "Epoch 375/2000\n",
      "1570/1570 [==============================] - 0s 236us/sample - loss: 0.4086 - accuracy: 0.8121 - val_loss: 0.6396 - val_accuracy: 0.7537\n",
      "Epoch 376/2000\n",
      "1570/1570 [==============================] - 1s 376us/sample - loss: 0.3940 - accuracy: 0.8280 - val_loss: 0.6625 - val_accuracy: 0.7537\n",
      "Epoch 377/2000\n",
      "1570/1570 [==============================] - 0s 285us/sample - loss: 0.3943 - accuracy: 0.8287 - val_loss: 0.7145 - val_accuracy: 0.7626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378/2000\n",
      "1570/1570 [==============================] - 0s 202us/sample - loss: 0.4333 - accuracy: 0.8057 - val_loss: 0.7791 - val_accuracy: 0.7507\n",
      "Epoch 379/2000\n",
      "1570/1570 [==============================] - 0s 211us/sample - loss: 0.3923 - accuracy: 0.8299 - val_loss: 0.8137 - val_accuracy: 0.7507\n",
      "Epoch 380/2000\n",
      "1570/1570 [==============================] - 0s 224us/sample - loss: 0.3942 - accuracy: 0.8191 - val_loss: 0.8199 - val_accuracy: 0.7507\n",
      "Epoch 381/2000\n",
      "1570/1570 [==============================] - 0s 202us/sample - loss: 0.3914 - accuracy: 0.8268 - val_loss: 0.8719 - val_accuracy: 0.7567\n",
      "Epoch 382/2000\n",
      "1570/1570 [==============================] - 0s 200us/sample - loss: 0.3899 - accuracy: 0.8172 - val_loss: 0.9188 - val_accuracy: 0.7567\n",
      "Epoch 383/2000\n",
      "1570/1570 [==============================] - 0s 198us/sample - loss: 0.3867 - accuracy: 0.8268 - val_loss: 0.9306 - val_accuracy: 0.7537\n",
      "Epoch 384/2000\n",
      "1570/1570 [==============================] - 0s 208us/sample - loss: 0.3837 - accuracy: 0.8255 - val_loss: 1.0505 - val_accuracy: 0.7478\n",
      "Epoch 385/2000\n",
      "1570/1570 [==============================] - 0s 223us/sample - loss: 0.3900 - accuracy: 0.8197 - val_loss: 0.9238 - val_accuracy: 0.7507\n",
      "Epoch 386/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.3886 - accuracy: 0.8293 - val_loss: 1.1907 - val_accuracy: 0.7329\n",
      "Epoch 387/2000\n",
      "1570/1570 [==============================] - 0s 200us/sample - loss: 0.3880 - accuracy: 0.8331 - val_loss: 1.0081 - val_accuracy: 0.7567\n",
      "Epoch 388/2000\n",
      "1570/1570 [==============================] - 0s 227us/sample - loss: 0.3869 - accuracy: 0.8338 - val_loss: 1.0627 - val_accuracy: 0.7537\n",
      "Epoch 389/2000\n",
      "1570/1570 [==============================] - 0s 238us/sample - loss: 0.3741 - accuracy: 0.8306 - val_loss: 1.1430 - val_accuracy: 0.7507\n",
      "Epoch 390/2000\n",
      "1570/1570 [==============================] - 0s 220us/sample - loss: 0.3804 - accuracy: 0.8280 - val_loss: 1.1294 - val_accuracy: 0.7478\n",
      "Epoch 391/2000\n",
      "1570/1570 [==============================] - 0s 208us/sample - loss: 0.4041 - accuracy: 0.8261 - val_loss: 1.2619 - val_accuracy: 0.7567\n",
      "Epoch 392/2000\n",
      "1570/1570 [==============================] - 0s 214us/sample - loss: 0.3830 - accuracy: 0.8331 - val_loss: 1.0290 - val_accuracy: 0.7389\n",
      "Epoch 393/2000\n",
      "1570/1570 [==============================] - 0s 216us/sample - loss: 0.3694 - accuracy: 0.8401 - val_loss: 1.0496 - val_accuracy: 0.7567\n",
      "Epoch 394/2000\n",
      "1570/1570 [==============================] - 0s 244us/sample - loss: 0.3730 - accuracy: 0.8248 - val_loss: 1.0615 - val_accuracy: 0.7537\n",
      "Epoch 395/2000\n",
      "1570/1570 [==============================] - 0s 217us/sample - loss: 0.3674 - accuracy: 0.8382 - val_loss: 1.1711 - val_accuracy: 0.7507\n",
      "Epoch 396/2000\n",
      "1570/1570 [==============================] - 0s 206us/sample - loss: 0.3814 - accuracy: 0.8420 - val_loss: 1.0234 - val_accuracy: 0.7478\n",
      "Epoch 397/2000\n",
      "1570/1570 [==============================] - 0s 208us/sample - loss: 0.3922 - accuracy: 0.8357 - val_loss: 0.7926 - val_accuracy: 0.7448\n",
      "Epoch 398/2000\n",
      "1570/1570 [==============================] - 0s 207us/sample - loss: 0.4048 - accuracy: 0.8350 - val_loss: 0.9592 - val_accuracy: 0.7537\n",
      "Epoch 399/2000\n",
      "1570/1570 [==============================] - 0s 211us/sample - loss: 0.5219 - accuracy: 0.7962 - val_loss: 0.9094 - val_accuracy: 0.7418\n",
      "Epoch 400/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.3845 - accuracy: 0.8299 - val_loss: 0.8665 - val_accuracy: 0.7448\n",
      "Epoch 401/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.3858 - accuracy: 0.8318 - val_loss: 1.2438 - val_accuracy: 0.7418\n",
      "Epoch 402/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.3978 - accuracy: 0.8408 - val_loss: 1.1069 - val_accuracy: 0.7507\n",
      "Epoch 403/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.3900 - accuracy: 0.8306 - val_loss: 1.0138 - val_accuracy: 0.7478\n",
      "Epoch 404/2000\n",
      "1570/1570 [==============================] - 0s 200us/sample - loss: 0.3741 - accuracy: 0.8395 - val_loss: 0.9903 - val_accuracy: 0.7478\n",
      "Epoch 405/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.3676 - accuracy: 0.8369 - val_loss: 0.8791 - val_accuracy: 0.7507\n",
      "Epoch 406/2000\n",
      "1570/1570 [==============================] - 0s 194us/sample - loss: 0.3643 - accuracy: 0.8382 - val_loss: 0.9150 - val_accuracy: 0.7478\n",
      "Epoch 407/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.3676 - accuracy: 0.8427 - val_loss: 1.0118 - val_accuracy: 0.7448\n",
      "Epoch 408/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.3581 - accuracy: 0.8369 - val_loss: 0.9415 - val_accuracy: 0.7626\n",
      "Epoch 409/2000\n",
      "1570/1570 [==============================] - 0s 198us/sample - loss: 0.3876 - accuracy: 0.8274 - val_loss: 1.1479 - val_accuracy: 0.7567\n",
      "Epoch 410/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.3799 - accuracy: 0.8318 - val_loss: 1.1587 - val_accuracy: 0.7300\n",
      "Epoch 411/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.3826 - accuracy: 0.8299 - val_loss: 1.0257 - val_accuracy: 0.7537\n",
      "Epoch 412/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.3582 - accuracy: 0.8420 - val_loss: 1.2626 - val_accuracy: 0.7329\n",
      "Epoch 413/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.5788 - accuracy: 0.7089 - val_loss: 1.0154 - val_accuracy: 0.7329\n",
      "Epoch 414/2000\n",
      "1570/1570 [==============================] - 0s 198us/sample - loss: 0.4072 - accuracy: 0.8134 - val_loss: 1.1504 - val_accuracy: 0.7567\n",
      "Epoch 415/2000\n",
      "1570/1570 [==============================] - 0s 214us/sample - loss: 0.5028 - accuracy: 0.7981 - val_loss: 0.9903 - val_accuracy: 0.7240\n",
      "Epoch 416/2000\n",
      "1570/1570 [==============================] - 0s 197us/sample - loss: 0.4170 - accuracy: 0.8153 - val_loss: 0.9015 - val_accuracy: 0.7537\n",
      "Epoch 417/2000\n",
      "1570/1570 [==============================] - 0s 198us/sample - loss: 0.3922 - accuracy: 0.8331 - val_loss: 0.9137 - val_accuracy: 0.7567\n",
      "Epoch 418/2000\n",
      "1570/1570 [==============================] - 0s 198us/sample - loss: 0.3587 - accuracy: 0.8420 - val_loss: 0.9923 - val_accuracy: 0.7567\n",
      "Epoch 419/2000\n",
      "1570/1570 [==============================] - 0s 219us/sample - loss: 0.3631 - accuracy: 0.8459 - val_loss: 1.0333 - val_accuracy: 0.7656\n",
      "Epoch 420/2000\n",
      "1570/1570 [==============================] - 0s 238us/sample - loss: 0.3529 - accuracy: 0.8452 - val_loss: 0.9728 - val_accuracy: 0.7537\n",
      "Epoch 421/2000\n",
      "1570/1570 [==============================] - 0s 209us/sample - loss: 0.3632 - accuracy: 0.8446 - val_loss: 0.9572 - val_accuracy: 0.7448\n",
      "Epoch 422/2000\n",
      "1570/1570 [==============================] - 0s 208us/sample - loss: 0.3528 - accuracy: 0.8414 - val_loss: 1.1007 - val_accuracy: 0.7537\n",
      "Epoch 423/2000\n",
      "1570/1570 [==============================] - 0s 206us/sample - loss: 0.3526 - accuracy: 0.8510 - val_loss: 1.1018 - val_accuracy: 0.7745\n",
      "Epoch 424/2000\n",
      "1570/1570 [==============================] - 0s 227us/sample - loss: 0.3529 - accuracy: 0.8478 - val_loss: 1.0273 - val_accuracy: 0.7656\n",
      "Epoch 425/2000\n",
      "1570/1570 [==============================] - 0s 224us/sample - loss: 0.3532 - accuracy: 0.8490 - val_loss: 0.9368 - val_accuracy: 0.7626\n",
      "Epoch 426/2000\n",
      "1570/1570 [==============================] - 0s 203us/sample - loss: 0.3622 - accuracy: 0.8452 - val_loss: 1.0243 - val_accuracy: 0.7715\n",
      "Epoch 427/2000\n",
      "1570/1570 [==============================] - 0s 210us/sample - loss: 0.3440 - accuracy: 0.8561 - val_loss: 1.0783 - val_accuracy: 0.7329\n",
      "Epoch 428/2000\n",
      "1570/1570 [==============================] - 0s 218us/sample - loss: 0.3384 - accuracy: 0.8580 - val_loss: 0.9324 - val_accuracy: 0.7537\n",
      "Epoch 429/2000\n",
      "1570/1570 [==============================] - 0s 255us/sample - loss: 0.3801 - accuracy: 0.8217 - val_loss: 1.0056 - val_accuracy: 0.7567\n",
      "Epoch 430/2000\n",
      "1570/1570 [==============================] - 0s 240us/sample - loss: 0.4780 - accuracy: 0.8019 - val_loss: 0.7676 - val_accuracy: 0.7389\n",
      "Epoch 431/2000\n",
      "1570/1570 [==============================] - 0s 221us/sample - loss: 0.3717 - accuracy: 0.8408 - val_loss: 0.8437 - val_accuracy: 0.7537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 432/2000\n",
      "1570/1570 [==============================] - 0s 218us/sample - loss: 0.3529 - accuracy: 0.8433 - val_loss: 0.8239 - val_accuracy: 0.7418\n",
      "Epoch 433/2000\n",
      "1570/1570 [==============================] - 0s 228us/sample - loss: 0.3523 - accuracy: 0.8516 - val_loss: 0.8820 - val_accuracy: 0.7181\n",
      "Epoch 434/2000\n",
      "1570/1570 [==============================] - 0s 239us/sample - loss: 0.3447 - accuracy: 0.8516 - val_loss: 0.8462 - val_accuracy: 0.7389\n",
      "Epoch 435/2000\n",
      "1570/1570 [==============================] - 0s 221us/sample - loss: 0.3413 - accuracy: 0.8561 - val_loss: 0.6867 - val_accuracy: 0.7478\n",
      "Epoch 436/2000\n",
      "1570/1570 [==============================] - 0s 213us/sample - loss: 0.5927 - accuracy: 0.6650 - val_loss: 0.9895 - val_accuracy: 0.7211\n",
      "Epoch 437/2000\n",
      "1570/1570 [==============================] - 0s 212us/sample - loss: 0.4743 - accuracy: 0.7586 - val_loss: 0.8971 - val_accuracy: 0.7685\n",
      "Epoch 438/2000\n",
      "1570/1570 [==============================] - 0s 228us/sample - loss: 0.3807 - accuracy: 0.8248 - val_loss: 1.1187 - val_accuracy: 0.7567\n",
      "Epoch 439/2000\n",
      "1570/1570 [==============================] - 0s 213us/sample - loss: 0.3893 - accuracy: 0.8350 - val_loss: 0.9053 - val_accuracy: 0.7953\n",
      "Epoch 440/2000\n",
      "1570/1570 [==============================] - 0s 203us/sample - loss: 0.3627 - accuracy: 0.8471 - val_loss: 0.9180 - val_accuracy: 0.7596\n",
      "Epoch 441/2000\n",
      "1570/1570 [==============================] - 0s 209us/sample - loss: 0.3663 - accuracy: 0.8331 - val_loss: 0.7864 - val_accuracy: 0.7745\n",
      "Epoch 442/2000\n",
      "1570/1570 [==============================] - 0s 206us/sample - loss: 0.3448 - accuracy: 0.8490 - val_loss: 0.9163 - val_accuracy: 0.7537\n",
      "Epoch 443/2000\n",
      "1570/1570 [==============================] - 0s 237us/sample - loss: 0.3632 - accuracy: 0.8459 - val_loss: 0.8072 - val_accuracy: 0.7745\n",
      "Epoch 444/2000\n",
      "1570/1570 [==============================] - 0s 215us/sample - loss: 0.3675 - accuracy: 0.8357 - val_loss: 0.8894 - val_accuracy: 0.7745\n",
      "Epoch 445/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.3529 - accuracy: 0.8510 - val_loss: 0.7439 - val_accuracy: 0.7448\n",
      "Epoch 446/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.3490 - accuracy: 0.8427 - val_loss: 0.8643 - val_accuracy: 0.7745\n",
      "Epoch 447/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.3336 - accuracy: 0.8548 - val_loss: 0.9854 - val_accuracy: 0.7715\n",
      "Epoch 448/2000\n",
      "1570/1570 [==============================] - 0s 197us/sample - loss: 0.3340 - accuracy: 0.8516 - val_loss: 1.0046 - val_accuracy: 0.7774\n",
      "Epoch 449/2000\n",
      "1570/1570 [==============================] - 0s 207us/sample - loss: 0.3288 - accuracy: 0.8535 - val_loss: 0.9610 - val_accuracy: 0.7389\n",
      "Epoch 450/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.3340 - accuracy: 0.8529 - val_loss: 0.9718 - val_accuracy: 0.7656\n",
      "Epoch 451/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.3870 - accuracy: 0.8166 - val_loss: 0.9466 - val_accuracy: 0.7774\n",
      "Epoch 452/2000\n",
      "1570/1570 [==============================] - 0s 196us/sample - loss: 0.3417 - accuracy: 0.8503 - val_loss: 0.9878 - val_accuracy: 0.7804\n",
      "Epoch 453/2000\n",
      "1570/1570 [==============================] - 0s 234us/sample - loss: 0.3352 - accuracy: 0.8516 - val_loss: 1.0505 - val_accuracy: 0.7626\n",
      "Epoch 454/2000\n",
      "1570/1570 [==============================] - 0s 227us/sample - loss: 0.3364 - accuracy: 0.8478 - val_loss: 1.1205 - val_accuracy: 0.7478\n",
      "Epoch 455/2000\n",
      "1570/1570 [==============================] - 0s 212us/sample - loss: 0.3652 - accuracy: 0.8325 - val_loss: 1.1387 - val_accuracy: 0.7596\n",
      "Epoch 456/2000\n",
      "1570/1570 [==============================] - 0s 221us/sample - loss: 0.3435 - accuracy: 0.8465 - val_loss: 1.1865 - val_accuracy: 0.7567\n",
      "Epoch 457/2000\n",
      "1570/1570 [==============================] - 0s 240us/sample - loss: 0.3211 - accuracy: 0.8599 - val_loss: 1.0589 - val_accuracy: 0.7596\n",
      "Epoch 458/2000\n",
      "1570/1570 [==============================] - 0s 239us/sample - loss: 0.3495 - accuracy: 0.8573 - val_loss: 1.1665 - val_accuracy: 0.7418\n",
      "Epoch 459/2000\n",
      "1570/1570 [==============================] - 0s 227us/sample - loss: 0.3502 - accuracy: 0.8554 - val_loss: 0.9485 - val_accuracy: 0.7418\n",
      "Epoch 460/2000\n",
      "1570/1570 [==============================] - 0s 218us/sample - loss: 0.4220 - accuracy: 0.7911 - val_loss: 0.9714 - val_accuracy: 0.7596\n",
      "Epoch 461/2000\n",
      "1570/1570 [==============================] - 0s 218us/sample - loss: 0.3599 - accuracy: 0.8459 - val_loss: 1.0603 - val_accuracy: 0.7507\n",
      "Epoch 462/2000\n",
      "1570/1570 [==============================] - 0s 246us/sample - loss: 0.3374 - accuracy: 0.8516 - val_loss: 1.0481 - val_accuracy: 0.7656\n",
      "Epoch 463/2000\n",
      "1570/1570 [==============================] - 0s 231us/sample - loss: 0.3626 - accuracy: 0.8408 - val_loss: 1.0299 - val_accuracy: 0.7567\n",
      "Epoch 464/2000\n",
      "1570/1570 [==============================] - 0s 237us/sample - loss: 0.3462 - accuracy: 0.8503 - val_loss: 0.9508 - val_accuracy: 0.7537\n",
      "Epoch 465/2000\n",
      "1570/1570 [==============================] - 0s 235us/sample - loss: 0.3635 - accuracy: 0.8312 - val_loss: 1.0714 - val_accuracy: 0.7745\n",
      "Epoch 466/2000\n",
      "1570/1570 [==============================] - 0s 225us/sample - loss: 0.3342 - accuracy: 0.8554 - val_loss: 0.9322 - val_accuracy: 0.7685\n",
      "Epoch 467/2000\n",
      "1570/1570 [==============================] - 0s 225us/sample - loss: 0.3235 - accuracy: 0.8631 - val_loss: 0.9776 - val_accuracy: 0.7626\n",
      "Epoch 468/2000\n",
      "1570/1570 [==============================] - 0s 216us/sample - loss: 0.3354 - accuracy: 0.8503 - val_loss: 0.9947 - val_accuracy: 0.7567\n",
      "Epoch 469/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.3288 - accuracy: 0.8541 - val_loss: 1.1057 - val_accuracy: 0.7359\n",
      "Epoch 470/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.3121 - accuracy: 0.8611 - val_loss: 1.0121 - val_accuracy: 0.7685\n",
      "Epoch 471/2000\n",
      "1570/1570 [==============================] - 0s 198us/sample - loss: 0.3190 - accuracy: 0.8618 - val_loss: 0.9849 - val_accuracy: 0.7715\n",
      "Epoch 472/2000\n",
      "1570/1570 [==============================] - 0s 216us/sample - loss: 0.3142 - accuracy: 0.8669 - val_loss: 0.9321 - val_accuracy: 0.7596\n",
      "Epoch 473/2000\n",
      "1570/1570 [==============================] - 0s 197us/sample - loss: 0.3142 - accuracy: 0.8637 - val_loss: 1.0114 - val_accuracy: 0.7596\n",
      "Epoch 474/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.3614 - accuracy: 0.8510 - val_loss: 0.8879 - val_accuracy: 0.7656\n",
      "Epoch 475/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.3361 - accuracy: 0.8567 - val_loss: 0.9712 - val_accuracy: 0.7685\n",
      "Epoch 476/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.3237 - accuracy: 0.8624 - val_loss: 1.0001 - val_accuracy: 0.7626\n",
      "Epoch 477/2000\n",
      "1570/1570 [==============================] - 0s 197us/sample - loss: 0.3275 - accuracy: 0.8561 - val_loss: 1.0329 - val_accuracy: 0.7656\n",
      "Epoch 478/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.3099 - accuracy: 0.8611 - val_loss: 1.0455 - val_accuracy: 0.7418\n",
      "Epoch 479/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.3187 - accuracy: 0.8611 - val_loss: 1.0928 - val_accuracy: 0.7685\n",
      "Epoch 480/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.3143 - accuracy: 0.8592 - val_loss: 1.1020 - val_accuracy: 0.7715\n",
      "Epoch 481/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.3062 - accuracy: 0.8631 - val_loss: 1.2234 - val_accuracy: 0.7389\n",
      "Epoch 482/2000\n",
      "1570/1570 [==============================] - 0s 205us/sample - loss: 0.3392 - accuracy: 0.8516 - val_loss: 1.1011 - val_accuracy: 0.7507\n",
      "Epoch 483/2000\n",
      "1570/1570 [==============================] - 0s 209us/sample - loss: 0.3298 - accuracy: 0.8586 - val_loss: 1.0494 - val_accuracy: 0.7478\n",
      "Epoch 484/2000\n",
      "1570/1570 [==============================] - 0s 217us/sample - loss: 0.3884 - accuracy: 0.8446 - val_loss: 1.2458 - val_accuracy: 0.7240\n",
      "Epoch 485/2000\n",
      "1570/1570 [==============================] - 0s 216us/sample - loss: 0.4792 - accuracy: 0.7987 - val_loss: 1.3215 - val_accuracy: 0.7685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 486/2000\n",
      "1570/1570 [==============================] - 0s 196us/sample - loss: 0.5583 - accuracy: 0.8127 - val_loss: 2.6128 - val_accuracy: 0.7596\n",
      "Epoch 487/2000\n",
      "1570/1570 [==============================] - 0s 227us/sample - loss: 0.4841 - accuracy: 0.8083 - val_loss: 1.6609 - val_accuracy: 0.7685\n",
      "Epoch 488/2000\n",
      "1570/1570 [==============================] - 0s 205us/sample - loss: 0.4639 - accuracy: 0.8153 - val_loss: 2.1665 - val_accuracy: 0.7537\n",
      "Epoch 489/2000\n",
      "1570/1570 [==============================] - 0s 197us/sample - loss: 0.4276 - accuracy: 0.8261 - val_loss: 1.8523 - val_accuracy: 0.7745\n",
      "Epoch 490/2000\n",
      "1570/1570 [==============================] - 0s 196us/sample - loss: 0.4180 - accuracy: 0.8331 - val_loss: 1.8137 - val_accuracy: 0.7834\n",
      "Epoch 491/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.4038 - accuracy: 0.8401 - val_loss: 1.7463 - val_accuracy: 0.7685\n",
      "Epoch 492/2000\n",
      "1570/1570 [==============================] - 0s 202us/sample - loss: 0.3748 - accuracy: 0.8459 - val_loss: 2.2741 - val_accuracy: 0.7567\n",
      "Epoch 493/2000\n",
      "1570/1570 [==============================] - 0s 198us/sample - loss: 0.3850 - accuracy: 0.8420 - val_loss: 1.5814 - val_accuracy: 0.7656\n",
      "Epoch 494/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.3833 - accuracy: 0.8414 - val_loss: 1.7794 - val_accuracy: 0.7626\n",
      "Epoch 495/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.3747 - accuracy: 0.8439 - val_loss: 1.7772 - val_accuracy: 0.7596\n",
      "Epoch 496/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.3502 - accuracy: 0.8497 - val_loss: 1.5340 - val_accuracy: 0.7715\n",
      "Epoch 497/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.3493 - accuracy: 0.8567 - val_loss: 1.8991 - val_accuracy: 0.7567\n",
      "Epoch 498/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.3654 - accuracy: 0.8497 - val_loss: 1.5892 - val_accuracy: 0.7626\n",
      "Epoch 499/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.3771 - accuracy: 0.8389 - val_loss: 1.8281 - val_accuracy: 0.7537\n",
      "Epoch 500/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.3498 - accuracy: 0.8541 - val_loss: 1.8080 - val_accuracy: 0.7685\n",
      "Epoch 501/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.3400 - accuracy: 0.8599 - val_loss: 1.1837 - val_accuracy: 0.7834\n",
      "Epoch 502/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.3432 - accuracy: 0.8580 - val_loss: 1.0313 - val_accuracy: 0.7596\n",
      "Epoch 503/2000\n",
      "1570/1570 [==============================] - 0s 196us/sample - loss: 0.3325 - accuracy: 0.8675 - val_loss: 0.6962 - val_accuracy: 0.7715\n",
      "Epoch 504/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.3288 - accuracy: 0.8650 - val_loss: 1.8513 - val_accuracy: 0.7685\n",
      "Epoch 505/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.3305 - accuracy: 0.8643 - val_loss: 1.7095 - val_accuracy: 0.7596\n",
      "Epoch 506/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.3490 - accuracy: 0.8503 - val_loss: 1.6718 - val_accuracy: 0.7656\n",
      "Epoch 507/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.3369 - accuracy: 0.8535 - val_loss: 1.5418 - val_accuracy: 0.7745\n",
      "Epoch 508/2000\n",
      "1570/1570 [==============================] - 0s 204us/sample - loss: 0.3304 - accuracy: 0.8637 - val_loss: 1.8824 - val_accuracy: 0.7745\n",
      "Epoch 509/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.3261 - accuracy: 0.8643 - val_loss: 1.3894 - val_accuracy: 0.7774\n",
      "Epoch 510/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.3275 - accuracy: 0.8726 - val_loss: 1.8225 - val_accuracy: 0.7656\n",
      "Epoch 511/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.3539 - accuracy: 0.8484 - val_loss: 1.7784 - val_accuracy: 0.7715\n",
      "Epoch 512/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.3524 - accuracy: 0.8561 - val_loss: 1.2481 - val_accuracy: 0.7537\n",
      "Epoch 513/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.3355 - accuracy: 0.8656 - val_loss: 1.3011 - val_accuracy: 0.7596\n",
      "Epoch 514/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.3228 - accuracy: 0.8611 - val_loss: 1.1220 - val_accuracy: 0.7656\n",
      "Epoch 515/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.3208 - accuracy: 0.8682 - val_loss: 0.8502 - val_accuracy: 0.7270\n",
      "Epoch 516/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.3309 - accuracy: 0.8669 - val_loss: 0.6977 - val_accuracy: 0.7745\n",
      "Epoch 517/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.3331 - accuracy: 0.8624 - val_loss: 0.8766 - val_accuracy: 0.7685\n",
      "Epoch 518/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.5261 - accuracy: 0.7720 - val_loss: 1.2329 - val_accuracy: 0.7685\n",
      "Epoch 519/2000\n",
      "1570/1570 [==============================] - 0s 211us/sample - loss: 0.3735 - accuracy: 0.8420 - val_loss: 2.1446 - val_accuracy: 0.7685\n",
      "Epoch 520/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.3530 - accuracy: 0.8427 - val_loss: 1.8102 - val_accuracy: 0.7745\n",
      "Epoch 521/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.3270 - accuracy: 0.8586 - val_loss: 1.7580 - val_accuracy: 0.7537\n",
      "Epoch 522/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.3219 - accuracy: 0.8682 - val_loss: 0.6894 - val_accuracy: 0.7656\n",
      "Epoch 523/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.3278 - accuracy: 0.8561 - val_loss: 0.6894 - val_accuracy: 0.7715\n",
      "Epoch 524/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.3302 - accuracy: 0.8643 - val_loss: 0.7006 - val_accuracy: 0.7685\n",
      "Epoch 525/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.3176 - accuracy: 0.8637 - val_loss: 0.7562 - val_accuracy: 0.7596\n",
      "Epoch 526/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.3141 - accuracy: 0.8713 - val_loss: 0.6194 - val_accuracy: 0.7834\n",
      "Epoch 527/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.3129 - accuracy: 0.8739 - val_loss: 1.1749 - val_accuracy: 0.7685\n",
      "Epoch 528/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.3183 - accuracy: 0.8720 - val_loss: 0.6859 - val_accuracy: 0.7715\n",
      "Epoch 529/2000\n",
      "1570/1570 [==============================] - 0s 201us/sample - loss: 0.3420 - accuracy: 0.8637 - val_loss: 1.6792 - val_accuracy: 0.7774\n",
      "Epoch 530/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.3618 - accuracy: 0.8439 - val_loss: 1.7478 - val_accuracy: 0.7804\n",
      "Epoch 531/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.3593 - accuracy: 0.8490 - val_loss: 1.7934 - val_accuracy: 0.7923\n",
      "Epoch 532/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.3645 - accuracy: 0.8465 - val_loss: 0.5567 - val_accuracy: 0.7804\n",
      "Epoch 533/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.3291 - accuracy: 0.8631 - val_loss: 0.6823 - val_accuracy: 0.7567\n",
      "Epoch 534/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.3230 - accuracy: 0.8732 - val_loss: 1.9049 - val_accuracy: 0.7567\n",
      "Epoch 535/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.3266 - accuracy: 0.8650 - val_loss: 1.9799 - val_accuracy: 0.7834\n",
      "Epoch 536/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.4029 - accuracy: 0.8185 - val_loss: 1.6357 - val_accuracy: 0.7478\n",
      "Epoch 537/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.4059 - accuracy: 0.8369 - val_loss: 1.1024 - val_accuracy: 0.7567\n",
      "Epoch 538/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.3560 - accuracy: 0.8478 - val_loss: 1.1176 - val_accuracy: 0.7596\n",
      "Epoch 539/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.3345 - accuracy: 0.8592 - val_loss: 1.2834 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 540/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.3428 - accuracy: 0.8573 - val_loss: 1.4216 - val_accuracy: 0.7715\n",
      "Epoch 541/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.3371 - accuracy: 0.8605 - val_loss: 1.4495 - val_accuracy: 0.7715\n",
      "Epoch 542/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.3117 - accuracy: 0.8732 - val_loss: 1.8648 - val_accuracy: 0.7834\n",
      "Epoch 543/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.3191 - accuracy: 0.8701 - val_loss: 1.8491 - val_accuracy: 0.7507\n",
      "Epoch 544/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.3125 - accuracy: 0.8701 - val_loss: 1.5870 - val_accuracy: 0.7626\n",
      "Epoch 545/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.3142 - accuracy: 0.8701 - val_loss: 1.7834 - val_accuracy: 0.7329\n",
      "Epoch 546/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.3272 - accuracy: 0.8669 - val_loss: 1.8746 - val_accuracy: 0.7240\n",
      "Epoch 547/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.3213 - accuracy: 0.8688 - val_loss: 1.6093 - val_accuracy: 0.7864\n",
      "Epoch 548/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.3366 - accuracy: 0.8541 - val_loss: 1.4832 - val_accuracy: 0.7507\n",
      "Epoch 549/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.3299 - accuracy: 0.8624 - val_loss: 1.4204 - val_accuracy: 0.7596\n",
      "Epoch 550/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.3320 - accuracy: 0.8618 - val_loss: 1.6085 - val_accuracy: 0.7774\n",
      "Epoch 551/2000\n",
      "1570/1570 [==============================] - 0s 197us/sample - loss: 0.3061 - accuracy: 0.8739 - val_loss: 1.8242 - val_accuracy: 0.7567\n",
      "Epoch 552/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.3054 - accuracy: 0.8720 - val_loss: 1.8283 - val_accuracy: 0.7804\n",
      "Epoch 553/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.3033 - accuracy: 0.8739 - val_loss: 1.8356 - val_accuracy: 0.7715\n",
      "Epoch 554/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.3271 - accuracy: 0.8618 - val_loss: 1.7987 - val_accuracy: 0.7359\n",
      "Epoch 555/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.3219 - accuracy: 0.8758 - val_loss: 1.8452 - val_accuracy: 0.7685\n",
      "Epoch 556/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.3048 - accuracy: 0.8758 - val_loss: 1.8040 - val_accuracy: 0.7745\n",
      "Epoch 557/2000\n",
      "1570/1570 [==============================] - 0s 212us/sample - loss: 0.3019 - accuracy: 0.8854 - val_loss: 1.6715 - val_accuracy: 0.7270\n",
      "Epoch 558/2000\n",
      "1570/1570 [==============================] - 0s 204us/sample - loss: 0.3370 - accuracy: 0.8611 - val_loss: 1.0270 - val_accuracy: 0.7715\n",
      "Epoch 559/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.3593 - accuracy: 0.8484 - val_loss: 1.6482 - val_accuracy: 0.7715\n",
      "Epoch 560/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.3140 - accuracy: 0.8637 - val_loss: 1.6583 - val_accuracy: 0.7804\n",
      "Epoch 561/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.3742 - accuracy: 0.8490 - val_loss: 2.4493 - val_accuracy: 0.7923\n",
      "Epoch 562/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.3495 - accuracy: 0.8529 - val_loss: 1.7790 - val_accuracy: 0.7626\n",
      "Epoch 563/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.3282 - accuracy: 0.8605 - val_loss: 1.8479 - val_accuracy: 0.7715\n",
      "Epoch 564/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.3212 - accuracy: 0.8669 - val_loss: 2.0762 - val_accuracy: 0.7774\n",
      "Epoch 565/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.3232 - accuracy: 0.8599 - val_loss: 2.1794 - val_accuracy: 0.7745\n",
      "Epoch 566/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.3016 - accuracy: 0.8777 - val_loss: 2.0971 - val_accuracy: 0.7478\n",
      "Epoch 567/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.2975 - accuracy: 0.8783 - val_loss: 1.9191 - val_accuracy: 0.7389\n",
      "Epoch 568/2000\n",
      "1570/1570 [==============================] - 0s 199us/sample - loss: 0.3003 - accuracy: 0.8771 - val_loss: 1.7106 - val_accuracy: 0.7804\n",
      "Epoch 569/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.3224 - accuracy: 0.8675 - val_loss: 1.6884 - val_accuracy: 0.7537\n",
      "Epoch 570/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.3069 - accuracy: 0.8732 - val_loss: 2.0173 - val_accuracy: 0.7715\n",
      "Epoch 571/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.2950 - accuracy: 0.8777 - val_loss: 1.9417 - val_accuracy: 0.7596\n",
      "Epoch 572/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2974 - accuracy: 0.8758 - val_loss: 2.2531 - val_accuracy: 0.7567\n",
      "Epoch 573/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.4594 - accuracy: 0.8127 - val_loss: 1.6114 - val_accuracy: 0.7567\n",
      "Epoch 574/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.5236 - accuracy: 0.8293 - val_loss: 59.6420 - val_accuracy: 0.7211\n",
      "Epoch 575/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.3850 - accuracy: 0.8363 - val_loss: 33.5078 - val_accuracy: 0.7389\n",
      "Epoch 576/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.3891 - accuracy: 0.8376 - val_loss: 10.9642 - val_accuracy: 0.7567\n",
      "Epoch 577/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.3641 - accuracy: 0.8478 - val_loss: 12.5778 - val_accuracy: 0.7478\n",
      "Epoch 578/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.3678 - accuracy: 0.8427 - val_loss: 10.8926 - val_accuracy: 0.7240\n",
      "Epoch 579/2000\n",
      "1570/1570 [==============================] - 0s 194us/sample - loss: 0.3562 - accuracy: 0.8490 - val_loss: 8.1114 - val_accuracy: 0.7656\n",
      "Epoch 580/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.3326 - accuracy: 0.8561 - val_loss: 8.3893 - val_accuracy: 0.7804\n",
      "Epoch 581/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.3394 - accuracy: 0.8656 - val_loss: 9.1618 - val_accuracy: 0.7626\n",
      "Epoch 582/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.3334 - accuracy: 0.8529 - val_loss: 9.4367 - val_accuracy: 0.7745\n",
      "Epoch 583/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.3319 - accuracy: 0.8637 - val_loss: 11.3788 - val_accuracy: 0.7685\n",
      "Epoch 584/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.3243 - accuracy: 0.8548 - val_loss: 14.0173 - val_accuracy: 0.7537\n",
      "Epoch 585/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.3206 - accuracy: 0.8611 - val_loss: 13.4253 - val_accuracy: 0.7448\n",
      "Epoch 586/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.3506 - accuracy: 0.8522 - val_loss: 11.7571 - val_accuracy: 0.7715\n",
      "Epoch 587/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.3107 - accuracy: 0.8682 - val_loss: 15.6016 - val_accuracy: 0.7626\n",
      "Epoch 588/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.3236 - accuracy: 0.8611 - val_loss: 16.5578 - val_accuracy: 0.7715\n",
      "Epoch 589/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.3089 - accuracy: 0.8605 - val_loss: 18.2600 - val_accuracy: 0.7567\n",
      "Epoch 590/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.3373 - accuracy: 0.8701 - val_loss: 18.0359 - val_accuracy: 0.7626\n",
      "Epoch 591/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.3166 - accuracy: 0.8662 - val_loss: 19.5831 - val_accuracy: 0.7626\n",
      "Epoch 592/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.3230 - accuracy: 0.8599 - val_loss: 18.0708 - val_accuracy: 0.7567\n",
      "Epoch 593/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.3012 - accuracy: 0.8726 - val_loss: 17.2531 - val_accuracy: 0.7626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 594/2000\n",
      "1570/1570 [==============================] - 0s 197us/sample - loss: 0.3111 - accuracy: 0.8662 - val_loss: 16.7312 - val_accuracy: 0.7745\n",
      "Epoch 595/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.3108 - accuracy: 0.8713 - val_loss: 18.2141 - val_accuracy: 0.7774\n",
      "Epoch 596/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.3122 - accuracy: 0.8605 - val_loss: 17.0102 - val_accuracy: 0.7537\n",
      "Epoch 597/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.3321 - accuracy: 0.8541 - val_loss: 19.1577 - val_accuracy: 0.7804\n",
      "Epoch 598/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.3030 - accuracy: 0.8739 - val_loss: 18.8850 - val_accuracy: 0.7715\n",
      "Epoch 599/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.3483 - accuracy: 0.8631 - val_loss: 19.0790 - val_accuracy: 0.7893\n",
      "Epoch 600/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.3135 - accuracy: 0.8631 - val_loss: 18.3813 - val_accuracy: 0.7596\n",
      "Epoch 601/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.3762 - accuracy: 0.8516 - val_loss: 22.6127 - val_accuracy: 0.7537\n",
      "Epoch 602/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.3363 - accuracy: 0.8618 - val_loss: 23.5920 - val_accuracy: 0.7685\n",
      "Epoch 603/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.3843 - accuracy: 0.8338 - val_loss: 22.1796 - val_accuracy: 0.7715\n",
      "Epoch 604/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.3641 - accuracy: 0.8420 - val_loss: 19.5716 - val_accuracy: 0.7596\n",
      "Epoch 605/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.3377 - accuracy: 0.8675 - val_loss: 22.9276 - val_accuracy: 0.7418\n",
      "Epoch 606/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.3946 - accuracy: 0.8414 - val_loss: 14.2242 - val_accuracy: 0.7626\n",
      "Epoch 607/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.3407 - accuracy: 0.8567 - val_loss: 16.5915 - val_accuracy: 0.7626\n",
      "Epoch 608/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.3061 - accuracy: 0.8745 - val_loss: 16.0652 - val_accuracy: 0.7656\n",
      "Epoch 609/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.3011 - accuracy: 0.8720 - val_loss: 17.3254 - val_accuracy: 0.7567\n",
      "Epoch 610/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2951 - accuracy: 0.8809 - val_loss: 21.3463 - val_accuracy: 0.7567\n",
      "Epoch 611/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.2895 - accuracy: 0.8745 - val_loss: 20.5273 - val_accuracy: 0.7537\n",
      "Epoch 612/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.2829 - accuracy: 0.8783 - val_loss: 19.7964 - val_accuracy: 0.7418\n",
      "Epoch 613/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.3041 - accuracy: 0.8732 - val_loss: 21.8369 - val_accuracy: 0.7537\n",
      "Epoch 614/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.2964 - accuracy: 0.8732 - val_loss: 25.2645 - val_accuracy: 0.7507\n",
      "Epoch 615/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.3207 - accuracy: 0.8624 - val_loss: 24.8809 - val_accuracy: 0.7596\n",
      "Epoch 616/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.3053 - accuracy: 0.8650 - val_loss: 28.1522 - val_accuracy: 0.7626\n",
      "Epoch 617/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.2947 - accuracy: 0.8803 - val_loss: 25.8490 - val_accuracy: 0.7596\n",
      "Epoch 618/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.2767 - accuracy: 0.8841 - val_loss: 22.7716 - val_accuracy: 0.7596\n",
      "Epoch 619/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2978 - accuracy: 0.8707 - val_loss: 22.3887 - val_accuracy: 0.7537\n",
      "Epoch 620/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.2865 - accuracy: 0.8841 - val_loss: 24.2229 - val_accuracy: 0.7389\n",
      "Epoch 621/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2875 - accuracy: 0.8809 - val_loss: 23.1636 - val_accuracy: 0.7359\n",
      "Epoch 622/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.3057 - accuracy: 0.8777 - val_loss: 24.1730 - val_accuracy: 0.7567\n",
      "Epoch 623/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2950 - accuracy: 0.8694 - val_loss: 25.8670 - val_accuracy: 0.7715\n",
      "Epoch 624/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2879 - accuracy: 0.8783 - val_loss: 23.1360 - val_accuracy: 0.7626\n",
      "Epoch 625/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2767 - accuracy: 0.8879 - val_loss: 22.4623 - val_accuracy: 0.7567\n",
      "Epoch 626/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2940 - accuracy: 0.8745 - val_loss: 20.4537 - val_accuracy: 0.7567\n",
      "Epoch 627/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.2792 - accuracy: 0.8803 - val_loss: 25.9334 - val_accuracy: 0.7507\n",
      "Epoch 628/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2716 - accuracy: 0.8873 - val_loss: 23.7693 - val_accuracy: 0.7478\n",
      "Epoch 629/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.2898 - accuracy: 0.8815 - val_loss: 31.5509 - val_accuracy: 0.7656\n",
      "Epoch 630/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.2807 - accuracy: 0.8873 - val_loss: 23.0918 - val_accuracy: 0.7656\n",
      "Epoch 631/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.2691 - accuracy: 0.8854 - val_loss: 25.4642 - val_accuracy: 0.7537\n",
      "Epoch 632/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2908 - accuracy: 0.8803 - val_loss: 24.2194 - val_accuracy: 0.7567\n",
      "Epoch 633/2000\n",
      "1570/1570 [==============================] - 0s 197us/sample - loss: 0.2811 - accuracy: 0.8815 - val_loss: 20.5808 - val_accuracy: 0.7507\n",
      "Epoch 634/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.2767 - accuracy: 0.8828 - val_loss: 20.7440 - val_accuracy: 0.7389\n",
      "Epoch 635/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2806 - accuracy: 0.8898 - val_loss: 21.3921 - val_accuracy: 0.7596\n",
      "Epoch 636/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2677 - accuracy: 0.8815 - val_loss: 21.3469 - val_accuracy: 0.7567\n",
      "Epoch 637/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.2999 - accuracy: 0.8745 - val_loss: 20.4281 - val_accuracy: 0.7596\n",
      "Epoch 638/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.3043 - accuracy: 0.8777 - val_loss: 18.2772 - val_accuracy: 0.7478\n",
      "Epoch 639/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.2775 - accuracy: 0.8854 - val_loss: 20.2038 - val_accuracy: 0.7507\n",
      "Epoch 640/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.2658 - accuracy: 0.8860 - val_loss: 20.6731 - val_accuracy: 0.7626\n",
      "Epoch 641/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2743 - accuracy: 0.8841 - val_loss: 21.0709 - val_accuracy: 0.7448\n",
      "Epoch 642/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.3683 - accuracy: 0.8452 - val_loss: 20.5182 - val_accuracy: 0.7715\n",
      "Epoch 643/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2783 - accuracy: 0.8815 - val_loss: 21.8536 - val_accuracy: 0.7507\n",
      "Epoch 644/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.2723 - accuracy: 0.8892 - val_loss: 22.2338 - val_accuracy: 0.7478\n",
      "Epoch 645/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2762 - accuracy: 0.8847 - val_loss: 20.7334 - val_accuracy: 0.7596\n",
      "Epoch 646/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.2888 - accuracy: 0.8879 - val_loss: 6.3807 - val_accuracy: 0.7418\n",
      "Epoch 647/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.2908 - accuracy: 0.8790 - val_loss: 5.5468 - val_accuracy: 0.7567\n",
      "Epoch 648/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.4262 - accuracy: 0.8631 - val_loss: 2.1620 - val_accuracy: 0.7507\n",
      "Epoch 649/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.3668 - accuracy: 0.8497 - val_loss: 2.2606 - val_accuracy: 0.7389\n",
      "Epoch 650/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.4101 - accuracy: 0.8389 - val_loss: 1.6654 - val_accuracy: 0.7507\n",
      "Epoch 651/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.3568 - accuracy: 0.8548 - val_loss: 2.0569 - val_accuracy: 0.7626\n",
      "Epoch 652/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.3221 - accuracy: 0.8669 - val_loss: 1.9193 - val_accuracy: 0.7626\n",
      "Epoch 653/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.3286 - accuracy: 0.8611 - val_loss: 1.6816 - val_accuracy: 0.7448\n",
      "Epoch 654/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.3235 - accuracy: 0.8599 - val_loss: 2.0090 - val_accuracy: 0.7745\n",
      "Epoch 655/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.2949 - accuracy: 0.8790 - val_loss: 1.9457 - val_accuracy: 0.7626\n",
      "Epoch 656/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.2888 - accuracy: 0.8828 - val_loss: 1.9313 - val_accuracy: 0.7685\n",
      "Epoch 657/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.2742 - accuracy: 0.8924 - val_loss: 2.0193 - val_accuracy: 0.7507\n",
      "Epoch 658/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.2760 - accuracy: 0.8809 - val_loss: 2.3679 - val_accuracy: 0.7596\n",
      "Epoch 659/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.2832 - accuracy: 0.8771 - val_loss: 2.1757 - val_accuracy: 0.7715\n",
      "Epoch 660/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.2662 - accuracy: 0.8866 - val_loss: 2.4973 - val_accuracy: 0.7656\n",
      "Epoch 661/2000\n",
      "1570/1570 [==============================] - 0s 204us/sample - loss: 0.2718 - accuracy: 0.8822 - val_loss: 2.8305 - val_accuracy: 0.7626\n",
      "Epoch 662/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.2710 - accuracy: 0.8854 - val_loss: 2.6175 - val_accuracy: 0.7537\n",
      "Epoch 663/2000\n",
      "1570/1570 [==============================] - 0s 196us/sample - loss: 0.2667 - accuracy: 0.8955 - val_loss: 2.5594 - val_accuracy: 0.7537\n",
      "Epoch 664/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.2640 - accuracy: 0.8873 - val_loss: 2.7864 - val_accuracy: 0.7448\n",
      "Epoch 665/2000\n",
      "1570/1570 [==============================] - 1s 384us/sample - loss: 0.2727 - accuracy: 0.8828 - val_loss: 3.4191 - val_accuracy: 0.7567\n",
      "Epoch 666/2000\n",
      "1570/1570 [==============================] - 0s 241us/sample - loss: 0.2668 - accuracy: 0.8892 - val_loss: 2.7101 - val_accuracy: 0.7596\n",
      "Epoch 667/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.2730 - accuracy: 0.8892 - val_loss: 2.6081 - val_accuracy: 0.7567\n",
      "Epoch 668/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.2767 - accuracy: 0.8771 - val_loss: 2.8480 - val_accuracy: 0.7596\n",
      "Epoch 669/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.3004 - accuracy: 0.8694 - val_loss: 3.2636 - val_accuracy: 0.7656\n",
      "Epoch 670/2000\n",
      "1570/1570 [==============================] - 0s 199us/sample - loss: 0.2874 - accuracy: 0.8796 - val_loss: 2.5898 - val_accuracy: 0.7478\n",
      "Epoch 671/2000\n",
      "1570/1570 [==============================] - 0s 200us/sample - loss: 0.3602 - accuracy: 0.8522 - val_loss: 2.5058 - val_accuracy: 0.7507\n",
      "Epoch 672/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.2977 - accuracy: 0.8758 - val_loss: 2.9743 - val_accuracy: 0.7507\n",
      "Epoch 673/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.2715 - accuracy: 0.8841 - val_loss: 3.1701 - val_accuracy: 0.7715\n",
      "Epoch 674/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.2730 - accuracy: 0.8847 - val_loss: 3.7951 - val_accuracy: 0.7537\n",
      "Epoch 675/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.3678 - accuracy: 0.8414 - val_loss: 4.2112 - val_accuracy: 0.7685\n",
      "Epoch 676/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.2703 - accuracy: 0.8873 - val_loss: 3.7311 - val_accuracy: 0.7478\n",
      "Epoch 677/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.3062 - accuracy: 0.8726 - val_loss: 2.4749 - val_accuracy: 0.7448\n",
      "Epoch 678/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.2905 - accuracy: 0.8834 - val_loss: 2.6271 - val_accuracy: 0.7478\n",
      "Epoch 679/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2906 - accuracy: 0.8815 - val_loss: 3.4290 - val_accuracy: 0.7448\n",
      "Epoch 680/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.3104 - accuracy: 0.8726 - val_loss: 3.2428 - val_accuracy: 0.7448\n",
      "Epoch 681/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2748 - accuracy: 0.8866 - val_loss: 3.7196 - val_accuracy: 0.7507\n",
      "Epoch 682/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.2607 - accuracy: 0.8936 - val_loss: 3.8965 - val_accuracy: 0.7507\n",
      "Epoch 683/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2624 - accuracy: 0.8911 - val_loss: 4.0231 - val_accuracy: 0.7507\n",
      "Epoch 684/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2600 - accuracy: 0.8936 - val_loss: 3.8011 - val_accuracy: 0.7418\n",
      "Epoch 685/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.2702 - accuracy: 0.8885 - val_loss: 4.0487 - val_accuracy: 0.7626\n",
      "Epoch 686/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2646 - accuracy: 0.8936 - val_loss: 3.9319 - val_accuracy: 0.7596\n",
      "Epoch 687/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.2914 - accuracy: 0.8809 - val_loss: 4.6919 - val_accuracy: 0.7211\n",
      "Epoch 688/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.3048 - accuracy: 0.8732 - val_loss: 3.7505 - val_accuracy: 0.7359\n",
      "Epoch 689/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.2924 - accuracy: 0.8777 - val_loss: 3.5424 - val_accuracy: 0.7626\n",
      "Epoch 690/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.3321 - accuracy: 0.8675 - val_loss: 3.6020 - val_accuracy: 0.7418\n",
      "Epoch 691/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.3362 - accuracy: 0.8541 - val_loss: 2.8151 - val_accuracy: 0.7359\n",
      "Epoch 692/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.2730 - accuracy: 0.8898 - val_loss: 2.8166 - val_accuracy: 0.7596\n",
      "Epoch 693/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.2656 - accuracy: 0.8892 - val_loss: 3.5564 - val_accuracy: 0.7567\n",
      "Epoch 694/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.4649 - accuracy: 0.8478 - val_loss: 2.1461 - val_accuracy: 0.7300\n",
      "Epoch 695/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.3522 - accuracy: 0.8624 - val_loss: 1.9059 - val_accuracy: 0.7329\n",
      "Epoch 696/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.3352 - accuracy: 0.8637 - val_loss: 1.9581 - val_accuracy: 0.7270\n",
      "Epoch 697/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.3437 - accuracy: 0.8535 - val_loss: 2.0885 - val_accuracy: 0.7567\n",
      "Epoch 698/2000\n",
      "1570/1570 [==============================] - 0s 203us/sample - loss: 0.3165 - accuracy: 0.8618 - val_loss: 1.7166 - val_accuracy: 0.7448\n",
      "Epoch 699/2000\n",
      "1570/1570 [==============================] - 0s 194us/sample - loss: 0.3155 - accuracy: 0.8643 - val_loss: 1.9366 - val_accuracy: 0.7448\n",
      "Epoch 700/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.3026 - accuracy: 0.8777 - val_loss: 1.8198 - val_accuracy: 0.7507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 701/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.2850 - accuracy: 0.8809 - val_loss: 4.1584 - val_accuracy: 0.7478\n",
      "Epoch 702/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.3807 - accuracy: 0.8624 - val_loss: 0.9941 - val_accuracy: 0.7389\n",
      "Epoch 703/2000\n",
      "1570/1570 [==============================] - 0s 204us/sample - loss: 0.3418 - accuracy: 0.8554 - val_loss: 1.2210 - val_accuracy: 0.7596\n",
      "Epoch 704/2000\n",
      "1570/1570 [==============================] - 0s 208us/sample - loss: 0.3585 - accuracy: 0.8535 - val_loss: 1.1354 - val_accuracy: 0.7389\n",
      "Epoch 705/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.3246 - accuracy: 0.8586 - val_loss: 1.1113 - val_accuracy: 0.7418\n",
      "Epoch 706/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.3100 - accuracy: 0.8701 - val_loss: 1.7166 - val_accuracy: 0.7478\n",
      "Epoch 707/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.2909 - accuracy: 0.8803 - val_loss: 2.3191 - val_accuracy: 0.7774\n",
      "Epoch 708/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.2854 - accuracy: 0.8790 - val_loss: 2.3654 - val_accuracy: 0.7596\n",
      "Epoch 709/2000\n",
      "1570/1570 [==============================] - 0s 201us/sample - loss: 0.2680 - accuracy: 0.8898 - val_loss: 2.6752 - val_accuracy: 0.7478\n",
      "Epoch 710/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2709 - accuracy: 0.8892 - val_loss: 2.7141 - val_accuracy: 0.7656\n",
      "Epoch 711/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.2734 - accuracy: 0.8898 - val_loss: 2.9199 - val_accuracy: 0.7626\n",
      "Epoch 712/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2686 - accuracy: 0.8911 - val_loss: 2.9182 - val_accuracy: 0.7537\n",
      "Epoch 713/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.2672 - accuracy: 0.8917 - val_loss: 3.1905 - val_accuracy: 0.7478\n",
      "Epoch 714/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.2592 - accuracy: 0.8955 - val_loss: 3.1577 - val_accuracy: 0.7448\n",
      "Epoch 715/2000\n",
      "1570/1570 [==============================] - 0s 196us/sample - loss: 0.2615 - accuracy: 0.8943 - val_loss: 3.0537 - val_accuracy: 0.7567\n",
      "Epoch 716/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2557 - accuracy: 0.8955 - val_loss: 2.8214 - val_accuracy: 0.7656\n",
      "Epoch 717/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.3073 - accuracy: 0.8682 - val_loss: 3.3010 - val_accuracy: 0.7626\n",
      "Epoch 718/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.2548 - accuracy: 0.8962 - val_loss: 3.3630 - val_accuracy: 0.7567\n",
      "Epoch 719/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.2521 - accuracy: 0.8949 - val_loss: 3.0208 - val_accuracy: 0.7626\n",
      "Epoch 720/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.2531 - accuracy: 0.9013 - val_loss: 3.1797 - val_accuracy: 0.7478\n",
      "Epoch 721/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2592 - accuracy: 0.8904 - val_loss: 3.0770 - val_accuracy: 0.7596\n",
      "Epoch 722/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.2413 - accuracy: 0.9019 - val_loss: 3.5093 - val_accuracy: 0.7745\n",
      "Epoch 723/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2713 - accuracy: 0.8841 - val_loss: 3.2865 - val_accuracy: 0.7567\n",
      "Epoch 724/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.2553 - accuracy: 0.8987 - val_loss: 3.2915 - val_accuracy: 0.7685\n",
      "Epoch 725/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.3218 - accuracy: 0.8675 - val_loss: 3.7993 - val_accuracy: 0.7596\n",
      "Epoch 726/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.2754 - accuracy: 0.8911 - val_loss: 4.4928 - val_accuracy: 0.7567\n",
      "Epoch 727/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.2881 - accuracy: 0.8834 - val_loss: 4.1180 - val_accuracy: 0.7626\n",
      "Epoch 728/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2636 - accuracy: 0.8936 - val_loss: 4.0840 - val_accuracy: 0.7596\n",
      "Epoch 729/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.2677 - accuracy: 0.8841 - val_loss: 4.1742 - val_accuracy: 0.7596\n",
      "Epoch 730/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.2845 - accuracy: 0.8783 - val_loss: 4.5270 - val_accuracy: 0.7507\n",
      "Epoch 731/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.2707 - accuracy: 0.8949 - val_loss: 4.0494 - val_accuracy: 0.7359\n",
      "Epoch 732/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.2727 - accuracy: 0.8917 - val_loss: 4.9129 - val_accuracy: 0.7418\n",
      "Epoch 733/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2612 - accuracy: 0.8904 - val_loss: 4.7093 - val_accuracy: 0.7507\n",
      "Epoch 734/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2538 - accuracy: 0.8955 - val_loss: 5.1987 - val_accuracy: 0.7656\n",
      "Epoch 735/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.2465 - accuracy: 0.8975 - val_loss: 5.8331 - val_accuracy: 0.7626\n",
      "Epoch 736/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.3015 - accuracy: 0.8675 - val_loss: 5.7504 - val_accuracy: 0.7656\n",
      "Epoch 737/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.2796 - accuracy: 0.8854 - val_loss: 5.8010 - val_accuracy: 0.7448\n",
      "Epoch 738/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2570 - accuracy: 0.8917 - val_loss: 5.2494 - val_accuracy: 0.7507\n",
      "Epoch 739/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2862 - accuracy: 0.8752 - val_loss: 5.5309 - val_accuracy: 0.7596\n",
      "Epoch 740/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2368 - accuracy: 0.9076 - val_loss: 6.0836 - val_accuracy: 0.7596\n",
      "Epoch 741/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.2431 - accuracy: 0.9019 - val_loss: 6.4212 - val_accuracy: 0.7567\n",
      "Epoch 742/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.2954 - accuracy: 0.8815 - val_loss: 6.5431 - val_accuracy: 0.7389\n",
      "Epoch 743/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.2548 - accuracy: 0.8987 - val_loss: 6.6516 - val_accuracy: 0.7507\n",
      "Epoch 744/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.2412 - accuracy: 0.9006 - val_loss: 6.9123 - val_accuracy: 0.7567\n",
      "Epoch 745/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.2580 - accuracy: 0.8924 - val_loss: 6.8425 - val_accuracy: 0.7418\n",
      "Epoch 746/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.2415 - accuracy: 0.9025 - val_loss: 7.1194 - val_accuracy: 0.7537\n",
      "Epoch 747/2000\n",
      "1570/1570 [==============================] - 0s 200us/sample - loss: 0.2876 - accuracy: 0.8847 - val_loss: 5.7685 - val_accuracy: 0.7329\n",
      "Epoch 748/2000\n",
      "1570/1570 [==============================] - 0s 194us/sample - loss: 0.2646 - accuracy: 0.8949 - val_loss: 5.9129 - val_accuracy: 0.7537\n",
      "Epoch 749/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.2711 - accuracy: 0.8841 - val_loss: 1.9859 - val_accuracy: 0.7448\n",
      "Epoch 750/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.2705 - accuracy: 0.8904 - val_loss: 4.2447 - val_accuracy: 0.7389\n",
      "Epoch 751/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2504 - accuracy: 0.8955 - val_loss: 4.8520 - val_accuracy: 0.7507\n",
      "Epoch 752/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.2744 - accuracy: 0.8834 - val_loss: 5.3287 - val_accuracy: 0.7507\n",
      "Epoch 753/2000\n",
      "1570/1570 [==============================] - 0s 234us/sample - loss: 0.2789 - accuracy: 0.8898 - val_loss: 5.2498 - val_accuracy: 0.7507\n",
      "Epoch 754/2000\n",
      "1570/1570 [==============================] - 0s 219us/sample - loss: 0.2641 - accuracy: 0.8815 - val_loss: 5.4476 - val_accuracy: 0.7478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 755/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.2450 - accuracy: 0.9019 - val_loss: 5.5588 - val_accuracy: 0.7507\n",
      "Epoch 756/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.2446 - accuracy: 0.8975 - val_loss: 6.2265 - val_accuracy: 0.7567\n",
      "Epoch 757/2000\n",
      "1570/1570 [==============================] - 0s 196us/sample - loss: 0.2343 - accuracy: 0.9019 - val_loss: 6.6091 - val_accuracy: 0.7329\n",
      "Epoch 758/2000\n",
      "1570/1570 [==============================] - 0s 199us/sample - loss: 0.2726 - accuracy: 0.8815 - val_loss: 6.3887 - val_accuracy: 0.7389\n",
      "Epoch 759/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2459 - accuracy: 0.9000 - val_loss: 6.9673 - val_accuracy: 0.7478\n",
      "Epoch 760/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.2332 - accuracy: 0.8987 - val_loss: 7.6346 - val_accuracy: 0.7626\n",
      "Epoch 761/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2353 - accuracy: 0.9025 - val_loss: 8.9784 - val_accuracy: 0.7448\n",
      "Epoch 762/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.2538 - accuracy: 0.8924 - val_loss: 7.1083 - val_accuracy: 0.7596\n",
      "Epoch 763/2000\n",
      "1570/1570 [==============================] - 0s 197us/sample - loss: 0.2672 - accuracy: 0.8911 - val_loss: 4.6076 - val_accuracy: 0.7715\n",
      "Epoch 764/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.2763 - accuracy: 0.8732 - val_loss: 4.1852 - val_accuracy: 0.7567\n",
      "Epoch 765/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.2405 - accuracy: 0.9025 - val_loss: 5.2509 - val_accuracy: 0.7626\n",
      "Epoch 766/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.2425 - accuracy: 0.8994 - val_loss: 5.1718 - val_accuracy: 0.7418\n",
      "Epoch 767/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2854 - accuracy: 0.8803 - val_loss: 5.0779 - val_accuracy: 0.7537\n",
      "Epoch 768/2000\n",
      "1570/1570 [==============================] - 0s 200us/sample - loss: 0.2644 - accuracy: 0.8924 - val_loss: 4.8314 - val_accuracy: 0.7418\n",
      "Epoch 769/2000\n",
      "1570/1570 [==============================] - 0s 207us/sample - loss: 0.2573 - accuracy: 0.8924 - val_loss: 5.3448 - val_accuracy: 0.7626\n",
      "Epoch 770/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.2358 - accuracy: 0.9038 - val_loss: 4.9167 - val_accuracy: 0.7626\n",
      "Epoch 771/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.2589 - accuracy: 0.8949 - val_loss: 5.1126 - val_accuracy: 0.7537\n",
      "Epoch 772/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.2532 - accuracy: 0.8943 - val_loss: 4.0943 - val_accuracy: 0.7596\n",
      "Epoch 773/2000\n",
      "1570/1570 [==============================] - 0s 200us/sample - loss: 0.2643 - accuracy: 0.8866 - val_loss: 4.4393 - val_accuracy: 0.7626\n",
      "Epoch 774/2000\n",
      "1570/1570 [==============================] - 0s 206us/sample - loss: 0.2473 - accuracy: 0.8975 - val_loss: 3.7018 - val_accuracy: 0.7448\n",
      "Epoch 775/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.4128 - accuracy: 0.8178 - val_loss: 4.7689 - val_accuracy: 0.7359\n",
      "Epoch 776/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.3193 - accuracy: 0.8605 - val_loss: 5.8110 - val_accuracy: 0.7300\n",
      "Epoch 777/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.2712 - accuracy: 0.8854 - val_loss: 6.0789 - val_accuracy: 0.7537\n",
      "Epoch 778/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.4034 - accuracy: 0.8561 - val_loss: 3.3475 - val_accuracy: 0.7389\n",
      "Epoch 779/2000\n",
      "1570/1570 [==============================] - 0s 199us/sample - loss: 0.3751 - accuracy: 0.8497 - val_loss: 8.0621 - val_accuracy: 0.7418\n",
      "Epoch 780/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.3196 - accuracy: 0.8611 - val_loss: 6.6669 - val_accuracy: 0.7596\n",
      "Epoch 781/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2718 - accuracy: 0.8860 - val_loss: 8.0386 - val_accuracy: 0.7745\n",
      "Epoch 782/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2687 - accuracy: 0.8885 - val_loss: 8.9727 - val_accuracy: 0.7507\n",
      "Epoch 783/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.2469 - accuracy: 0.8994 - val_loss: 9.1396 - val_accuracy: 0.7656\n",
      "Epoch 784/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.2435 - accuracy: 0.8968 - val_loss: 9.7221 - val_accuracy: 0.7567\n",
      "Epoch 785/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.2633 - accuracy: 0.8860 - val_loss: 10.2250 - val_accuracy: 0.7656\n",
      "Epoch 786/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2622 - accuracy: 0.8943 - val_loss: 9.9043 - val_accuracy: 0.7715\n",
      "Epoch 787/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.2459 - accuracy: 0.8981 - val_loss: 10.4824 - val_accuracy: 0.7626\n",
      "Epoch 788/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.2397 - accuracy: 0.9045 - val_loss: 10.4222 - val_accuracy: 0.7745\n",
      "Epoch 789/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2868 - accuracy: 0.8777 - val_loss: 10.1443 - val_accuracy: 0.7656\n",
      "Epoch 790/2000\n",
      "1570/1570 [==============================] - 0s 197us/sample - loss: 0.2558 - accuracy: 0.9025 - val_loss: 10.4373 - val_accuracy: 0.7745\n",
      "Epoch 791/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.2399 - accuracy: 0.8962 - val_loss: 10.0011 - val_accuracy: 0.7537\n",
      "Epoch 792/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.2451 - accuracy: 0.9006 - val_loss: 11.1782 - val_accuracy: 0.7685\n",
      "Epoch 793/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.2498 - accuracy: 0.8943 - val_loss: 11.9573 - val_accuracy: 0.7537\n",
      "Epoch 794/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.2312 - accuracy: 0.9051 - val_loss: 12.1363 - val_accuracy: 0.7626\n",
      "Epoch 795/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.2253 - accuracy: 0.9134 - val_loss: 11.3570 - val_accuracy: 0.7537\n",
      "Epoch 796/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.2270 - accuracy: 0.9045 - val_loss: 10.8851 - val_accuracy: 0.7537\n",
      "Epoch 797/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.3234 - accuracy: 0.8605 - val_loss: 13.9386 - val_accuracy: 0.7626\n",
      "Epoch 798/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.2691 - accuracy: 0.8917 - val_loss: 20.5411 - val_accuracy: 0.7448\n",
      "Epoch 799/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2730 - accuracy: 0.8822 - val_loss: 20.7047 - val_accuracy: 0.7537\n",
      "Epoch 800/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.2446 - accuracy: 0.9032 - val_loss: 20.5531 - val_accuracy: 0.7685\n",
      "Epoch 801/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.2396 - accuracy: 0.9006 - val_loss: 21.8112 - val_accuracy: 0.7596\n",
      "Epoch 802/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.2221 - accuracy: 0.9089 - val_loss: 22.3089 - val_accuracy: 0.7389\n",
      "Epoch 803/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.2260 - accuracy: 0.9083 - val_loss: 22.4857 - val_accuracy: 0.7567\n",
      "Epoch 804/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2312 - accuracy: 0.9025 - val_loss: 23.1890 - val_accuracy: 0.7389\n",
      "Epoch 805/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2324 - accuracy: 0.8994 - val_loss: 23.0674 - val_accuracy: 0.7567\n",
      "Epoch 806/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.2225 - accuracy: 0.9070 - val_loss: 23.4633 - val_accuracy: 0.7211\n",
      "Epoch 807/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.4371 - accuracy: 0.8127 - val_loss: 20.6524 - val_accuracy: 0.7478\n",
      "Epoch 808/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.2899 - accuracy: 0.8873 - val_loss: 15.5661 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 809/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2428 - accuracy: 0.8975 - val_loss: 16.5207 - val_accuracy: 0.7745\n",
      "Epoch 810/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.2373 - accuracy: 0.9089 - val_loss: 17.9575 - val_accuracy: 0.7656\n",
      "Epoch 811/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.2246 - accuracy: 0.9108 - val_loss: 18.9608 - val_accuracy: 0.7715\n",
      "Epoch 812/2000\n",
      "1570/1570 [==============================] - 0s 201us/sample - loss: 0.2186 - accuracy: 0.9057 - val_loss: 19.1087 - val_accuracy: 0.7537\n",
      "Epoch 813/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.2322 - accuracy: 0.9083 - val_loss: 20.0142 - val_accuracy: 0.7537\n",
      "Epoch 814/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2200 - accuracy: 0.9096 - val_loss: 20.1491 - val_accuracy: 0.7418\n",
      "Epoch 815/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2252 - accuracy: 0.9070 - val_loss: 19.6442 - val_accuracy: 0.7656\n",
      "Epoch 816/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.2149 - accuracy: 0.9115 - val_loss: 20.0757 - val_accuracy: 0.7448\n",
      "Epoch 817/2000\n",
      "1570/1570 [==============================] - 0s 194us/sample - loss: 0.2178 - accuracy: 0.9115 - val_loss: 20.6237 - val_accuracy: 0.7389\n",
      "Epoch 818/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.2379 - accuracy: 0.9025 - val_loss: 20.0089 - val_accuracy: 0.7478\n",
      "Epoch 819/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.3237 - accuracy: 0.8669 - val_loss: 17.4817 - val_accuracy: 0.7537\n",
      "Epoch 820/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2336 - accuracy: 0.9045 - val_loss: 18.8678 - val_accuracy: 0.7537\n",
      "Epoch 821/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.2158 - accuracy: 0.9134 - val_loss: 20.5435 - val_accuracy: 0.7596\n",
      "Epoch 822/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2609 - accuracy: 0.8841 - val_loss: 22.0242 - val_accuracy: 0.7478\n",
      "Epoch 823/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.4375 - accuracy: 0.8248 - val_loss: 16.9641 - val_accuracy: 0.7567\n",
      "Epoch 824/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.2872 - accuracy: 0.8898 - val_loss: 18.5089 - val_accuracy: 0.7329\n",
      "Epoch 825/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2741 - accuracy: 0.8866 - val_loss: 16.9228 - val_accuracy: 0.7596\n",
      "Epoch 826/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2510 - accuracy: 0.9045 - val_loss: 20.1927 - val_accuracy: 0.7448\n",
      "Epoch 827/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2290 - accuracy: 0.9115 - val_loss: 19.8070 - val_accuracy: 0.7656\n",
      "Epoch 828/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.2269 - accuracy: 0.9038 - val_loss: 20.4908 - val_accuracy: 0.7329\n",
      "Epoch 829/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.2976 - accuracy: 0.8847 - val_loss: 21.3441 - val_accuracy: 0.7448\n",
      "Epoch 830/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2834 - accuracy: 0.8847 - val_loss: 20.0521 - val_accuracy: 0.7448\n",
      "Epoch 831/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2629 - accuracy: 0.8949 - val_loss: 21.9373 - val_accuracy: 0.7389\n",
      "Epoch 832/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.2377 - accuracy: 0.9070 - val_loss: 22.3022 - val_accuracy: 0.7448\n",
      "Epoch 833/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.2374 - accuracy: 0.9070 - val_loss: 23.5737 - val_accuracy: 0.7507\n",
      "Epoch 834/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.2335 - accuracy: 0.9127 - val_loss: 24.2958 - val_accuracy: 0.7300\n",
      "Epoch 835/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2327 - accuracy: 0.9051 - val_loss: 23.9996 - val_accuracy: 0.7567\n",
      "Epoch 836/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.2416 - accuracy: 0.8968 - val_loss: 23.6378 - val_accuracy: 0.7329\n",
      "Epoch 837/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.2272 - accuracy: 0.9134 - val_loss: 22.5311 - val_accuracy: 0.7685\n",
      "Epoch 838/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2124 - accuracy: 0.9185 - val_loss: 23.3240 - val_accuracy: 0.7596\n",
      "Epoch 839/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.2402 - accuracy: 0.9076 - val_loss: 23.4336 - val_accuracy: 0.7300\n",
      "Epoch 840/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.2295 - accuracy: 0.9076 - val_loss: 23.6247 - val_accuracy: 0.7537\n",
      "Epoch 841/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2232 - accuracy: 0.9134 - val_loss: 25.9077 - val_accuracy: 0.7478\n",
      "Epoch 842/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.2098 - accuracy: 0.9115 - val_loss: 24.5452 - val_accuracy: 0.7300\n",
      "Epoch 843/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2182 - accuracy: 0.9083 - val_loss: 25.3494 - val_accuracy: 0.7537\n",
      "Epoch 844/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2075 - accuracy: 0.9127 - val_loss: 25.0675 - val_accuracy: 0.7537\n",
      "Epoch 845/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2093 - accuracy: 0.9166 - val_loss: 25.0296 - val_accuracy: 0.7685\n",
      "Epoch 846/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.2192 - accuracy: 0.9070 - val_loss: 25.0316 - val_accuracy: 0.7418\n",
      "Epoch 847/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.2200 - accuracy: 0.9127 - val_loss: 26.2884 - val_accuracy: 0.7596\n",
      "Epoch 848/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.2234 - accuracy: 0.9102 - val_loss: 26.3127 - val_accuracy: 0.7596\n",
      "Epoch 849/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.2228 - accuracy: 0.9102 - val_loss: 22.8806 - val_accuracy: 0.7418\n",
      "Epoch 850/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.2274 - accuracy: 0.9121 - val_loss: 21.1056 - val_accuracy: 0.7626\n",
      "Epoch 851/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.6344 - accuracy: 0.7223 - val_loss: 11.9261 - val_accuracy: 0.7270\n",
      "Epoch 852/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.3889 - accuracy: 0.8287 - val_loss: 13.1125 - val_accuracy: 0.7507\n",
      "Epoch 853/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.3377 - accuracy: 0.8465 - val_loss: 13.7438 - val_accuracy: 0.7715\n",
      "Epoch 854/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.3283 - accuracy: 0.8567 - val_loss: 12.1894 - val_accuracy: 0.7478\n",
      "Epoch 855/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.3513 - accuracy: 0.8452 - val_loss: 11.8433 - val_accuracy: 0.7478\n",
      "Epoch 856/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.2979 - accuracy: 0.8631 - val_loss: 11.4029 - val_accuracy: 0.7596\n",
      "Epoch 857/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.3074 - accuracy: 0.8631 - val_loss: 1.7785 - val_accuracy: 0.7418\n",
      "Epoch 858/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.3134 - accuracy: 0.8599 - val_loss: 1.6396 - val_accuracy: 0.7507\n",
      "Epoch 859/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2847 - accuracy: 0.8771 - val_loss: 1.5867 - val_accuracy: 0.7359\n",
      "Epoch 860/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.2781 - accuracy: 0.8790 - val_loss: 1.5131 - val_accuracy: 0.7418\n",
      "Epoch 861/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.2855 - accuracy: 0.8713 - val_loss: 1.6661 - val_accuracy: 0.7478\n",
      "Epoch 862/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.2823 - accuracy: 0.8682 - val_loss: 1.7037 - val_accuracy: 0.7478\n",
      "Epoch 863/2000\n",
      "1570/1570 [==============================] - 0s 202us/sample - loss: 0.2798 - accuracy: 0.8764 - val_loss: 1.6547 - val_accuracy: 0.7418\n",
      "Epoch 864/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.2815 - accuracy: 0.8713 - val_loss: 1.6324 - val_accuracy: 0.7359\n",
      "Epoch 865/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2687 - accuracy: 0.8739 - val_loss: 1.6872 - val_accuracy: 0.7448\n",
      "Epoch 866/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.3564 - accuracy: 0.8439 - val_loss: 1.4746 - val_accuracy: 0.7300\n",
      "Epoch 867/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.2661 - accuracy: 0.8822 - val_loss: 1.9719 - val_accuracy: 0.7478\n",
      "Epoch 868/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2880 - accuracy: 0.8732 - val_loss: 2.2710 - val_accuracy: 0.7211\n",
      "Epoch 869/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.3213 - accuracy: 0.8592 - val_loss: 2.1978 - val_accuracy: 0.7240\n",
      "Epoch 870/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.2985 - accuracy: 0.8815 - val_loss: 5.8204 - val_accuracy: 0.7537\n",
      "Epoch 871/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.2711 - accuracy: 0.8892 - val_loss: 6.8199 - val_accuracy: 0.7478\n",
      "Epoch 872/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2500 - accuracy: 0.9045 - val_loss: 6.7579 - val_accuracy: 0.7804\n",
      "Epoch 873/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.2656 - accuracy: 0.8968 - val_loss: 7.2156 - val_accuracy: 0.7537\n",
      "Epoch 874/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2321 - accuracy: 0.9051 - val_loss: 6.7385 - val_accuracy: 0.7656\n",
      "Epoch 875/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2292 - accuracy: 0.9019 - val_loss: 7.6337 - val_accuracy: 0.7715\n",
      "Epoch 876/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.2343 - accuracy: 0.9019 - val_loss: 7.1595 - val_accuracy: 0.7478\n",
      "Epoch 877/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.2320 - accuracy: 0.9025 - val_loss: 7.7993 - val_accuracy: 0.7567\n",
      "Epoch 878/2000\n",
      "1570/1570 [==============================] - 0s 209us/sample - loss: 0.2378 - accuracy: 0.9025 - val_loss: 8.5476 - val_accuracy: 0.7507\n",
      "Epoch 879/2000\n",
      "1570/1570 [==============================] - 0s 202us/sample - loss: 0.2491 - accuracy: 0.8981 - val_loss: 10.5026 - val_accuracy: 0.7537\n",
      "Epoch 880/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2227 - accuracy: 0.9083 - val_loss: 10.9892 - val_accuracy: 0.7567\n",
      "Epoch 881/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.2062 - accuracy: 0.9159 - val_loss: 11.0858 - val_accuracy: 0.7596\n",
      "Epoch 882/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2231 - accuracy: 0.9159 - val_loss: 11.1160 - val_accuracy: 0.7745\n",
      "Epoch 883/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.2099 - accuracy: 0.9127 - val_loss: 12.4153 - val_accuracy: 0.7448\n",
      "Epoch 884/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.2194 - accuracy: 0.9083 - val_loss: 12.2771 - val_accuracy: 0.7596\n",
      "Epoch 885/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2005 - accuracy: 0.9204 - val_loss: 11.9020 - val_accuracy: 0.7626\n",
      "Epoch 886/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2097 - accuracy: 0.9172 - val_loss: 13.0838 - val_accuracy: 0.7626\n",
      "Epoch 887/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2108 - accuracy: 0.9096 - val_loss: 10.7105 - val_accuracy: 0.7685\n",
      "Epoch 888/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.2123 - accuracy: 0.9146 - val_loss: 11.8459 - val_accuracy: 0.7478\n",
      "Epoch 889/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.2414 - accuracy: 0.9038 - val_loss: 11.9787 - val_accuracy: 0.7537\n",
      "Epoch 890/2000\n",
      "1570/1570 [==============================] - 0s 198us/sample - loss: 0.2233 - accuracy: 0.9064 - val_loss: 12.3791 - val_accuracy: 0.7656\n",
      "Epoch 891/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.2032 - accuracy: 0.9191 - val_loss: 12.2382 - val_accuracy: 0.7596\n",
      "Epoch 892/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2157 - accuracy: 0.9197 - val_loss: 12.3796 - val_accuracy: 0.7567\n",
      "Epoch 893/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2015 - accuracy: 0.9236 - val_loss: 13.3973 - val_accuracy: 0.7448\n",
      "Epoch 894/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.3118 - accuracy: 0.8739 - val_loss: 10.3285 - val_accuracy: 0.7537\n",
      "Epoch 895/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.4764 - accuracy: 0.8516 - val_loss: 6.4831 - val_accuracy: 0.7329\n",
      "Epoch 896/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.3230 - accuracy: 0.8669 - val_loss: 7.1735 - val_accuracy: 0.7596\n",
      "Epoch 897/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.2526 - accuracy: 0.9000 - val_loss: 9.5789 - val_accuracy: 0.7745\n",
      "Epoch 898/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.2287 - accuracy: 0.9102 - val_loss: 11.2677 - val_accuracy: 0.7478\n",
      "Epoch 899/2000\n",
      "1570/1570 [==============================] - 0s 199us/sample - loss: 0.2355 - accuracy: 0.9057 - val_loss: 6.2143 - val_accuracy: 0.7626\n",
      "Epoch 900/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.2360 - accuracy: 0.8994 - val_loss: 7.8836 - val_accuracy: 0.7685\n",
      "Epoch 901/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.2101 - accuracy: 0.9146 - val_loss: 9.7776 - val_accuracy: 0.7804\n",
      "Epoch 902/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2164 - accuracy: 0.9127 - val_loss: 11.5858 - val_accuracy: 0.7537\n",
      "Epoch 903/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.2198 - accuracy: 0.9115 - val_loss: 12.3621 - val_accuracy: 0.7537\n",
      "Epoch 904/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.2152 - accuracy: 0.9178 - val_loss: 13.5323 - val_accuracy: 0.7537\n",
      "Epoch 905/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.2160 - accuracy: 0.9121 - val_loss: 12.1122 - val_accuracy: 0.7626\n",
      "Epoch 906/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.2015 - accuracy: 0.9197 - val_loss: 12.5662 - val_accuracy: 0.7685\n",
      "Epoch 907/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.2054 - accuracy: 0.9146 - val_loss: 13.1620 - val_accuracy: 0.7596\n",
      "Epoch 908/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.2175 - accuracy: 0.9108 - val_loss: 13.9918 - val_accuracy: 0.7389\n",
      "Epoch 909/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.2381 - accuracy: 0.8962 - val_loss: 12.6281 - val_accuracy: 0.7478\n",
      "Epoch 910/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.2069 - accuracy: 0.9153 - val_loss: 13.1140 - val_accuracy: 0.7626\n",
      "Epoch 911/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.2523 - accuracy: 0.8904 - val_loss: 14.4895 - val_accuracy: 0.7596\n",
      "Epoch 912/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.2206 - accuracy: 0.9115 - val_loss: 14.1386 - val_accuracy: 0.7211\n",
      "Epoch 913/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2631 - accuracy: 0.8885 - val_loss: 15.2969 - val_accuracy: 0.7596\n",
      "Epoch 914/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2309 - accuracy: 0.9045 - val_loss: 14.5700 - val_accuracy: 0.7626\n",
      "Epoch 915/2000\n",
      "1570/1570 [==============================] - 0s 194us/sample - loss: 0.2510 - accuracy: 0.8949 - val_loss: 12.6148 - val_accuracy: 0.7389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 916/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.2525 - accuracy: 0.8924 - val_loss: 13.8642 - val_accuracy: 0.7537\n",
      "Epoch 917/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2370 - accuracy: 0.9019 - val_loss: 15.1510 - val_accuracy: 0.7418\n",
      "Epoch 918/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2286 - accuracy: 0.9051 - val_loss: 12.9412 - val_accuracy: 0.7507\n",
      "Epoch 919/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.3240 - accuracy: 0.8847 - val_loss: 8.2851 - val_accuracy: 0.7596\n",
      "Epoch 920/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.2877 - accuracy: 0.8955 - val_loss: 8.0965 - val_accuracy: 0.7685\n",
      "Epoch 921/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.3733 - accuracy: 0.8331 - val_loss: 7.5360 - val_accuracy: 0.7418\n",
      "Epoch 922/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.2899 - accuracy: 0.8815 - val_loss: 7.8672 - val_accuracy: 0.7567\n",
      "Epoch 923/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2676 - accuracy: 0.8943 - val_loss: 8.5346 - val_accuracy: 0.7537\n",
      "Epoch 924/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.2463 - accuracy: 0.9013 - val_loss: 10.5357 - val_accuracy: 0.7389\n",
      "Epoch 925/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.2578 - accuracy: 0.8943 - val_loss: 11.0730 - val_accuracy: 0.7745\n",
      "Epoch 926/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.2322 - accuracy: 0.9115 - val_loss: 10.4495 - val_accuracy: 0.7478\n",
      "Epoch 927/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.2248 - accuracy: 0.9102 - val_loss: 11.8003 - val_accuracy: 0.7478\n",
      "Epoch 928/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.2313 - accuracy: 0.9102 - val_loss: 13.1495 - val_accuracy: 0.7478\n",
      "Epoch 929/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.2098 - accuracy: 0.9178 - val_loss: 13.2969 - val_accuracy: 0.7359\n",
      "Epoch 930/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2335 - accuracy: 0.9070 - val_loss: 15.1759 - val_accuracy: 0.7567\n",
      "Epoch 931/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2290 - accuracy: 0.9083 - val_loss: 16.9320 - val_accuracy: 0.7537\n",
      "Epoch 932/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.2102 - accuracy: 0.9166 - val_loss: 17.8908 - val_accuracy: 0.7567\n",
      "Epoch 933/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2212 - accuracy: 0.9121 - val_loss: 14.1072 - val_accuracy: 0.7507\n",
      "Epoch 934/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.2149 - accuracy: 0.9127 - val_loss: 14.5622 - val_accuracy: 0.7448\n",
      "Epoch 935/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2107 - accuracy: 0.9191 - val_loss: 15.7313 - val_accuracy: 0.7448\n",
      "Epoch 936/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2359 - accuracy: 0.9102 - val_loss: 12.2994 - val_accuracy: 0.7359\n",
      "Epoch 937/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2217 - accuracy: 0.9153 - val_loss: 14.2940 - val_accuracy: 0.7626\n",
      "Epoch 938/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2507 - accuracy: 0.8981 - val_loss: 14.9805 - val_accuracy: 0.7389\n",
      "Epoch 939/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2471 - accuracy: 0.8962 - val_loss: 15.4775 - val_accuracy: 0.7448\n",
      "Epoch 940/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2396 - accuracy: 0.9000 - val_loss: 13.4628 - val_accuracy: 0.7567\n",
      "Epoch 941/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2143 - accuracy: 0.9070 - val_loss: 14.2751 - val_accuracy: 0.7596\n",
      "Epoch 942/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1939 - accuracy: 0.9236 - val_loss: 16.6606 - val_accuracy: 0.7537\n",
      "Epoch 943/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2175 - accuracy: 0.9166 - val_loss: 16.8455 - val_accuracy: 0.7656\n",
      "Epoch 944/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.1950 - accuracy: 0.9255 - val_loss: 17.3419 - val_accuracy: 0.7507\n",
      "Epoch 945/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.1993 - accuracy: 0.9248 - val_loss: 17.5044 - val_accuracy: 0.7537\n",
      "Epoch 946/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1936 - accuracy: 0.9268 - val_loss: 18.2360 - val_accuracy: 0.7567\n",
      "Epoch 947/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1913 - accuracy: 0.9229 - val_loss: 18.6053 - val_accuracy: 0.7418\n",
      "Epoch 948/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1816 - accuracy: 0.9274 - val_loss: 18.0075 - val_accuracy: 0.7567\n",
      "Epoch 949/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.2092 - accuracy: 0.9102 - val_loss: 18.2416 - val_accuracy: 0.7567\n",
      "Epoch 950/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1944 - accuracy: 0.9146 - val_loss: 17.9413 - val_accuracy: 0.7507\n",
      "Epoch 951/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2026 - accuracy: 0.9172 - val_loss: 17.9674 - val_accuracy: 0.7507\n",
      "Epoch 952/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2377 - accuracy: 0.9076 - val_loss: 17.3105 - val_accuracy: 0.7181\n",
      "Epoch 953/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2872 - accuracy: 0.8822 - val_loss: 8.3834 - val_accuracy: 0.7448\n",
      "Epoch 954/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2149 - accuracy: 0.9089 - val_loss: 12.0198 - val_accuracy: 0.7715\n",
      "Epoch 955/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.2071 - accuracy: 0.9159 - val_loss: 13.5977 - val_accuracy: 0.7715\n",
      "Epoch 956/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2112 - accuracy: 0.9134 - val_loss: 14.7129 - val_accuracy: 0.7448\n",
      "Epoch 957/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2237 - accuracy: 0.9013 - val_loss: 13.3271 - val_accuracy: 0.7507\n",
      "Epoch 958/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.2139 - accuracy: 0.9115 - val_loss: 14.3883 - val_accuracy: 0.7656\n",
      "Epoch 959/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.1973 - accuracy: 0.9217 - val_loss: 15.3227 - val_accuracy: 0.7448\n",
      "Epoch 960/2000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.2176 - accuracy: 0.9096 - val_loss: 16.2215 - val_accuracy: 0.7567\n",
      "Epoch 961/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.2134 - accuracy: 0.9140 - val_loss: 16.9316 - val_accuracy: 0.7507\n",
      "Epoch 962/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.2010 - accuracy: 0.9178 - val_loss: 17.4908 - val_accuracy: 0.7567\n",
      "Epoch 963/2000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.1984 - accuracy: 0.9166 - val_loss: 18.0712 - val_accuracy: 0.7389\n",
      "Epoch 964/2000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.1900 - accuracy: 0.9293 - val_loss: 16.6147 - val_accuracy: 0.7418\n",
      "Epoch 965/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.1914 - accuracy: 0.9191 - val_loss: 16.2319 - val_accuracy: 0.7567\n",
      "Epoch 966/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1965 - accuracy: 0.9172 - val_loss: 17.1893 - val_accuracy: 0.7567\n",
      "Epoch 967/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1946 - accuracy: 0.9178 - val_loss: 16.7924 - val_accuracy: 0.7507\n",
      "Epoch 968/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.2690 - accuracy: 0.8930 - val_loss: 17.4201 - val_accuracy: 0.7448\n",
      "Epoch 969/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.2016 - accuracy: 0.9197 - val_loss: 17.3747 - val_accuracy: 0.7389\n",
      "Epoch 970/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1966 - accuracy: 0.9178 - val_loss: 17.7194 - val_accuracy: 0.7389\n",
      "Epoch 971/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.2025 - accuracy: 0.9153 - val_loss: 17.5195 - val_accuracy: 0.7626\n",
      "Epoch 972/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.2111 - accuracy: 0.9146 - val_loss: 15.6370 - val_accuracy: 0.7656\n",
      "Epoch 973/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2034 - accuracy: 0.9146 - val_loss: 18.6953 - val_accuracy: 0.7389\n",
      "Epoch 974/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.2098 - accuracy: 0.9121 - val_loss: 15.2731 - val_accuracy: 0.7596\n",
      "Epoch 975/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2340 - accuracy: 0.9051 - val_loss: 16.2280 - val_accuracy: 0.7240\n",
      "Epoch 976/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2692 - accuracy: 0.9000 - val_loss: 14.4856 - val_accuracy: 0.7507\n",
      "Epoch 977/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.2117 - accuracy: 0.9146 - val_loss: 13.9419 - val_accuracy: 0.7567\n",
      "Epoch 978/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.2430 - accuracy: 0.9057 - val_loss: 14.3404 - val_accuracy: 0.7240\n",
      "Epoch 979/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.2320 - accuracy: 0.9051 - val_loss: 15.9302 - val_accuracy: 0.7270\n",
      "Epoch 980/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2374 - accuracy: 0.9115 - val_loss: 16.0293 - val_accuracy: 0.7656\n",
      "Epoch 981/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.2206 - accuracy: 0.9127 - val_loss: 17.4981 - val_accuracy: 0.7537\n",
      "Epoch 982/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.2184 - accuracy: 0.9127 - val_loss: 17.7470 - val_accuracy: 0.7389\n",
      "Epoch 983/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.2138 - accuracy: 0.9089 - val_loss: 14.3455 - val_accuracy: 0.7626\n",
      "Epoch 984/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.4220 - accuracy: 0.8076 - val_loss: 13.6170 - val_accuracy: 0.7626\n",
      "Epoch 985/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2569 - accuracy: 0.8962 - val_loss: 15.4671 - val_accuracy: 0.7329\n",
      "Epoch 986/2000\n",
      "1570/1570 [==============================] - 0s 197us/sample - loss: 0.2262 - accuracy: 0.9127 - val_loss: 15.9059 - val_accuracy: 0.7537\n",
      "Epoch 987/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.2008 - accuracy: 0.9197 - val_loss: 16.3313 - val_accuracy: 0.7478\n",
      "Epoch 988/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1920 - accuracy: 0.9229 - val_loss: 16.7871 - val_accuracy: 0.7418\n",
      "Epoch 989/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1893 - accuracy: 0.9261 - val_loss: 17.4266 - val_accuracy: 0.7389\n",
      "Epoch 990/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.2384 - accuracy: 0.9064 - val_loss: 13.9827 - val_accuracy: 0.7389\n",
      "Epoch 991/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1936 - accuracy: 0.9236 - val_loss: 15.8475 - val_accuracy: 0.7507\n",
      "Epoch 992/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1814 - accuracy: 0.9261 - val_loss: 17.6177 - val_accuracy: 0.7448\n",
      "Epoch 993/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1794 - accuracy: 0.9248 - val_loss: 17.9891 - val_accuracy: 0.7389\n",
      "Epoch 994/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1814 - accuracy: 0.9287 - val_loss: 17.5929 - val_accuracy: 0.7359\n",
      "Epoch 995/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.2130 - accuracy: 0.9121 - val_loss: 15.5409 - val_accuracy: 0.7389\n",
      "Epoch 996/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1842 - accuracy: 0.9287 - val_loss: 15.6713 - val_accuracy: 0.7418\n",
      "Epoch 997/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1794 - accuracy: 0.9325 - val_loss: 18.6934 - val_accuracy: 0.7626\n",
      "Epoch 998/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.2187 - accuracy: 0.9115 - val_loss: 16.5180 - val_accuracy: 0.7389\n",
      "Epoch 999/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2412 - accuracy: 0.9006 - val_loss: 15.8227 - val_accuracy: 0.7685\n",
      "Epoch 1000/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.2015 - accuracy: 0.9153 - val_loss: 17.9926 - val_accuracy: 0.7478\n",
      "Epoch 1001/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1780 - accuracy: 0.9318 - val_loss: 18.5210 - val_accuracy: 0.7389\n",
      "Epoch 1002/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1802 - accuracy: 0.9248 - val_loss: 18.3274 - val_accuracy: 0.7181\n",
      "Epoch 1003/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.3016 - accuracy: 0.8752 - val_loss: 9.8225 - val_accuracy: 0.7478\n",
      "Epoch 1004/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.3135 - accuracy: 0.8745 - val_loss: 9.8194 - val_accuracy: 0.7478\n",
      "Epoch 1005/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.2585 - accuracy: 0.8943 - val_loss: 8.1328 - val_accuracy: 0.7478\n",
      "Epoch 1006/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.3675 - accuracy: 0.8567 - val_loss: 2.5908 - val_accuracy: 0.7685\n",
      "Epoch 1007/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2983 - accuracy: 0.8936 - val_loss: 3.3978 - val_accuracy: 0.7389\n",
      "Epoch 1008/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.2833 - accuracy: 0.8917 - val_loss: 5.2909 - val_accuracy: 0.7567\n",
      "Epoch 1009/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2563 - accuracy: 0.9038 - val_loss: 6.5288 - val_accuracy: 0.7448\n",
      "Epoch 1010/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.3175 - accuracy: 0.8669 - val_loss: 6.6588 - val_accuracy: 0.7389\n",
      "Epoch 1011/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.2385 - accuracy: 0.9121 - val_loss: 4.8150 - val_accuracy: 0.7478\n",
      "Epoch 1012/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.2273 - accuracy: 0.9096 - val_loss: 8.7039 - val_accuracy: 0.7211\n",
      "Epoch 1013/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.2177 - accuracy: 0.9096 - val_loss: 8.5595 - val_accuracy: 0.7567\n",
      "Epoch 1014/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2248 - accuracy: 0.9057 - val_loss: 7.8950 - val_accuracy: 0.7478\n",
      "Epoch 1015/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.3219 - accuracy: 0.8675 - val_loss: 6.9727 - val_accuracy: 0.7567\n",
      "Epoch 1016/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.2399 - accuracy: 0.9134 - val_loss: 9.9093 - val_accuracy: 0.7507\n",
      "Epoch 1017/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.2129 - accuracy: 0.9127 - val_loss: 11.0762 - val_accuracy: 0.7240\n",
      "Epoch 1018/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.1989 - accuracy: 0.9229 - val_loss: 11.1673 - val_accuracy: 0.7596\n",
      "Epoch 1019/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2053 - accuracy: 0.9210 - val_loss: 10.5337 - val_accuracy: 0.7448\n",
      "Epoch 1020/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.2100 - accuracy: 0.9166 - val_loss: 9.7004 - val_accuracy: 0.7537\n",
      "Epoch 1021/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2051 - accuracy: 0.9197 - val_loss: 8.6042 - val_accuracy: 0.7567\n",
      "Epoch 1022/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.1969 - accuracy: 0.9197 - val_loss: 10.4755 - val_accuracy: 0.7596\n",
      "Epoch 1023/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.1875 - accuracy: 0.9255 - val_loss: 11.7451 - val_accuracy: 0.7359\n",
      "Epoch 1024/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1797 - accuracy: 0.9287 - val_loss: 11.4403 - val_accuracy: 0.7448\n",
      "Epoch 1025/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1843 - accuracy: 0.9261 - val_loss: 10.9753 - val_accuracy: 0.7270\n",
      "Epoch 1026/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.2093 - accuracy: 0.9146 - val_loss: 12.5909 - val_accuracy: 0.7389\n",
      "Epoch 1027/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2213 - accuracy: 0.9083 - val_loss: 11.6676 - val_accuracy: 0.7507\n",
      "Epoch 1028/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.2730 - accuracy: 0.8892 - val_loss: 5.3678 - val_accuracy: 0.7389\n",
      "Epoch 1029/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.2409 - accuracy: 0.9032 - val_loss: 9.8861 - val_accuracy: 0.7507\n",
      "Epoch 1030/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1900 - accuracy: 0.9268 - val_loss: 10.8633 - val_accuracy: 0.7537\n",
      "Epoch 1031/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.1838 - accuracy: 0.9306 - val_loss: 12.4688 - val_accuracy: 0.7596\n",
      "Epoch 1032/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1915 - accuracy: 0.9287 - val_loss: 12.4837 - val_accuracy: 0.7359\n",
      "Epoch 1033/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1947 - accuracy: 0.9197 - val_loss: 17.7639 - val_accuracy: 0.7478\n",
      "Epoch 1034/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2239 - accuracy: 0.9108 - val_loss: 13.6268 - val_accuracy: 0.7418\n",
      "Epoch 1035/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2224 - accuracy: 0.9083 - val_loss: 12.4939 - val_accuracy: 0.7389\n",
      "Epoch 1036/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.2425 - accuracy: 0.8936 - val_loss: 12.1037 - val_accuracy: 0.7537\n",
      "Epoch 1037/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1914 - accuracy: 0.9191 - val_loss: 13.7650 - val_accuracy: 0.7685\n",
      "Epoch 1038/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1920 - accuracy: 0.9210 - val_loss: 13.3225 - val_accuracy: 0.7596\n",
      "Epoch 1039/2000\n",
      "1570/1570 [==============================] - 0s 198us/sample - loss: 0.1915 - accuracy: 0.9204 - val_loss: 13.0527 - val_accuracy: 0.7596\n",
      "Epoch 1040/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.2002 - accuracy: 0.9140 - val_loss: 15.0094 - val_accuracy: 0.7626\n",
      "Epoch 1041/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.2142 - accuracy: 0.9051 - val_loss: 15.0461 - val_accuracy: 0.7389\n",
      "Epoch 1042/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.1847 - accuracy: 0.9261 - val_loss: 16.9678 - val_accuracy: 0.7478\n",
      "Epoch 1043/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1816 - accuracy: 0.9293 - val_loss: 16.5315 - val_accuracy: 0.7240\n",
      "Epoch 1044/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.1740 - accuracy: 0.9338 - val_loss: 17.8118 - val_accuracy: 0.7418\n",
      "Epoch 1045/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.1832 - accuracy: 0.9261 - val_loss: 15.7339 - val_accuracy: 0.7418\n",
      "Epoch 1046/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.1874 - accuracy: 0.9312 - val_loss: 17.4630 - val_accuracy: 0.7389\n",
      "Epoch 1047/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1950 - accuracy: 0.9242 - val_loss: 18.9092 - val_accuracy: 0.7329\n",
      "Epoch 1048/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1954 - accuracy: 0.9217 - val_loss: 20.3385 - val_accuracy: 0.7537\n",
      "Epoch 1049/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.2182 - accuracy: 0.9159 - val_loss: 17.0721 - val_accuracy: 0.7270\n",
      "Epoch 1050/2000\n",
      "1570/1570 [==============================] - 0s 197us/sample - loss: 0.2183 - accuracy: 0.9096 - val_loss: 17.4838 - val_accuracy: 0.7478\n",
      "Epoch 1051/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.1856 - accuracy: 0.9223 - val_loss: 20.0408 - val_accuracy: 0.7448\n",
      "Epoch 1052/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1781 - accuracy: 0.9217 - val_loss: 21.3322 - val_accuracy: 0.7478\n",
      "Epoch 1053/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1736 - accuracy: 0.9325 - val_loss: 21.3548 - val_accuracy: 0.7359\n",
      "Epoch 1054/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1759 - accuracy: 0.9306 - val_loss: 22.8938 - val_accuracy: 0.7537\n",
      "Epoch 1055/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.2537 - accuracy: 0.9089 - val_loss: 17.6943 - val_accuracy: 0.7537\n",
      "Epoch 1056/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.2069 - accuracy: 0.9197 - val_loss: 18.9453 - val_accuracy: 0.7745\n",
      "Epoch 1057/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1921 - accuracy: 0.9248 - val_loss: 18.9523 - val_accuracy: 0.7478\n",
      "Epoch 1058/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.1844 - accuracy: 0.9261 - val_loss: 20.2493 - val_accuracy: 0.7359\n",
      "Epoch 1059/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1952 - accuracy: 0.9191 - val_loss: 18.5321 - val_accuracy: 0.7418\n",
      "Epoch 1060/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.1705 - accuracy: 0.9338 - val_loss: 20.5035 - val_accuracy: 0.7418\n",
      "Epoch 1061/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.1738 - accuracy: 0.9287 - val_loss: 20.1519 - val_accuracy: 0.7685\n",
      "Epoch 1062/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.1885 - accuracy: 0.9255 - val_loss: 22.5284 - val_accuracy: 0.7478\n",
      "Epoch 1063/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1755 - accuracy: 0.9325 - val_loss: 21.7951 - val_accuracy: 0.7715\n",
      "Epoch 1064/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1739 - accuracy: 0.9306 - val_loss: 21.1629 - val_accuracy: 0.7240\n",
      "Epoch 1065/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.1843 - accuracy: 0.9242 - val_loss: 22.6117 - val_accuracy: 0.7122\n",
      "Epoch 1066/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.2140 - accuracy: 0.9045 - val_loss: 27.0339 - val_accuracy: 0.7270\n",
      "Epoch 1067/2000\n",
      "1570/1570 [==============================] - 0s 194us/sample - loss: 0.4036 - accuracy: 0.8446 - val_loss: 12.8325 - val_accuracy: 0.7567\n",
      "Epoch 1068/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.2348 - accuracy: 0.9096 - val_loss: 13.1415 - val_accuracy: 0.7685\n",
      "Epoch 1069/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2183 - accuracy: 0.9191 - val_loss: 16.6956 - val_accuracy: 0.7596\n",
      "Epoch 1070/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.2044 - accuracy: 0.9197 - val_loss: 15.8422 - val_accuracy: 0.7359\n",
      "Epoch 1071/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1979 - accuracy: 0.9236 - val_loss: 16.3561 - val_accuracy: 0.7448\n",
      "Epoch 1072/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.1939 - accuracy: 0.9255 - val_loss: 20.4173 - val_accuracy: 0.7240\n",
      "Epoch 1073/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1821 - accuracy: 0.9318 - val_loss: 19.8108 - val_accuracy: 0.7567\n",
      "Epoch 1074/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1797 - accuracy: 0.9299 - val_loss: 19.9389 - val_accuracy: 0.7329\n",
      "Epoch 1075/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2247 - accuracy: 0.9121 - val_loss: 20.6840 - val_accuracy: 0.7329\n",
      "Epoch 1076/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2038 - accuracy: 0.9185 - val_loss: 20.6979 - val_accuracy: 0.7507\n",
      "Epoch 1077/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1801 - accuracy: 0.9312 - val_loss: 22.9717 - val_accuracy: 0.7359\n",
      "Epoch 1078/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.1696 - accuracy: 0.9350 - val_loss: 21.0132 - val_accuracy: 0.7300\n",
      "Epoch 1079/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.1666 - accuracy: 0.9376 - val_loss: 23.3492 - val_accuracy: 0.7300\n",
      "Epoch 1080/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.1761 - accuracy: 0.9363 - val_loss: 24.4290 - val_accuracy: 0.7329\n",
      "Epoch 1081/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1778 - accuracy: 0.9268 - val_loss: 24.6517 - val_accuracy: 0.7448\n",
      "Epoch 1082/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2701 - accuracy: 0.8930 - val_loss: 18.5189 - val_accuracy: 0.7359\n",
      "Epoch 1083/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.2081 - accuracy: 0.9140 - val_loss: 21.2734 - val_accuracy: 0.7448\n",
      "Epoch 1084/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.2068 - accuracy: 0.9191 - val_loss: 20.0027 - val_accuracy: 0.7507\n",
      "Epoch 1085/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1817 - accuracy: 0.9248 - val_loss: 22.5440 - val_accuracy: 0.7329\n",
      "Epoch 1086/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.1633 - accuracy: 0.9389 - val_loss: 21.7767 - val_accuracy: 0.7478\n",
      "Epoch 1087/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1643 - accuracy: 0.9325 - val_loss: 23.1406 - val_accuracy: 0.7507\n",
      "Epoch 1088/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.1678 - accuracy: 0.9363 - val_loss: 21.5569 - val_accuracy: 0.7418\n",
      "Epoch 1089/2000\n",
      "1570/1570 [==============================] - 0s 197us/sample - loss: 0.1851 - accuracy: 0.9280 - val_loss: 21.6385 - val_accuracy: 0.7359\n",
      "Epoch 1090/2000\n",
      "1570/1570 [==============================] - 0s 238us/sample - loss: 0.1871 - accuracy: 0.9274 - val_loss: 21.8160 - val_accuracy: 0.7567\n",
      "Epoch 1091/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.2014 - accuracy: 0.9236 - val_loss: 23.9834 - val_accuracy: 0.7507\n",
      "Epoch 1092/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1870 - accuracy: 0.9236 - val_loss: 22.0594 - val_accuracy: 0.7389\n",
      "Epoch 1093/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2075 - accuracy: 0.9274 - val_loss: 18.7274 - val_accuracy: 0.7715\n",
      "Epoch 1094/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.2499 - accuracy: 0.8981 - val_loss: 18.5536 - val_accuracy: 0.7300\n",
      "Epoch 1095/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.2150 - accuracy: 0.9172 - val_loss: 21.8452 - val_accuracy: 0.7448\n",
      "Epoch 1096/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.2800 - accuracy: 0.9013 - val_loss: 12.1543 - val_accuracy: 0.7389\n",
      "Epoch 1097/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2699 - accuracy: 0.9178 - val_loss: 12.6362 - val_accuracy: 0.7596\n",
      "Epoch 1098/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1850 - accuracy: 0.9274 - val_loss: 16.4300 - val_accuracy: 0.7537\n",
      "Epoch 1099/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.1803 - accuracy: 0.9287 - val_loss: 17.0481 - val_accuracy: 0.7359\n",
      "Epoch 1100/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.2040 - accuracy: 0.9153 - val_loss: 16.8257 - val_accuracy: 0.7567\n",
      "Epoch 1101/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.1743 - accuracy: 0.9293 - val_loss: 18.6924 - val_accuracy: 0.7507\n",
      "Epoch 1102/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.2191 - accuracy: 0.9134 - val_loss: 13.0270 - val_accuracy: 0.7329\n",
      "Epoch 1103/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2067 - accuracy: 0.9166 - val_loss: 14.3975 - val_accuracy: 0.7715\n",
      "Epoch 1104/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1694 - accuracy: 0.9382 - val_loss: 18.7946 - val_accuracy: 0.7567\n",
      "Epoch 1105/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.2362 - accuracy: 0.8987 - val_loss: 15.7956 - val_accuracy: 0.7300\n",
      "Epoch 1106/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.1991 - accuracy: 0.9172 - val_loss: 19.7759 - val_accuracy: 0.7567\n",
      "Epoch 1107/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1777 - accuracy: 0.9287 - val_loss: 23.0901 - val_accuracy: 0.7567\n",
      "Epoch 1108/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1817 - accuracy: 0.9306 - val_loss: 22.9125 - val_accuracy: 0.7537\n",
      "Epoch 1109/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1782 - accuracy: 0.9312 - val_loss: 23.1633 - val_accuracy: 0.7359\n",
      "Epoch 1110/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.2646 - accuracy: 0.9096 - val_loss: 12.6594 - val_accuracy: 0.7389\n",
      "Epoch 1111/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.2052 - accuracy: 0.9242 - val_loss: 19.9403 - val_accuracy: 0.7567\n",
      "Epoch 1112/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1847 - accuracy: 0.9236 - val_loss: 20.1893 - val_accuracy: 0.7418\n",
      "Epoch 1113/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1709 - accuracy: 0.9338 - val_loss: 20.8954 - val_accuracy: 0.7507\n",
      "Epoch 1114/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1638 - accuracy: 0.9344 - val_loss: 22.4405 - val_accuracy: 0.7270\n",
      "Epoch 1115/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1635 - accuracy: 0.9357 - val_loss: 22.2775 - val_accuracy: 0.7507\n",
      "Epoch 1116/2000\n",
      "1570/1570 [==============================] - 0s 207us/sample - loss: 0.1692 - accuracy: 0.9344 - val_loss: 23.3999 - val_accuracy: 0.7270\n",
      "Epoch 1117/2000\n",
      "1570/1570 [==============================] - 0s 209us/sample - loss: 0.1900 - accuracy: 0.9248 - val_loss: 20.9958 - val_accuracy: 0.7300\n",
      "Epoch 1118/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.1712 - accuracy: 0.9344 - val_loss: 22.0578 - val_accuracy: 0.7448\n",
      "Epoch 1119/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.1611 - accuracy: 0.9420 - val_loss: 24.3155 - val_accuracy: 0.7300\n",
      "Epoch 1120/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.1547 - accuracy: 0.9408 - val_loss: 26.3842 - val_accuracy: 0.7418\n",
      "Epoch 1121/2000\n",
      "1570/1570 [==============================] - 0s 212us/sample - loss: 0.1781 - accuracy: 0.9363 - val_loss: 21.9286 - val_accuracy: 0.7478\n",
      "Epoch 1122/2000\n",
      "1570/1570 [==============================] - 0s 196us/sample - loss: 0.1691 - accuracy: 0.9331 - val_loss: 25.2400 - val_accuracy: 0.7507\n",
      "Epoch 1123/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.1860 - accuracy: 0.9210 - val_loss: 21.9525 - val_accuracy: 0.7418\n",
      "Epoch 1124/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.1931 - accuracy: 0.9236 - val_loss: 22.9977 - val_accuracy: 0.7656\n",
      "Epoch 1125/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.1698 - accuracy: 0.9325 - val_loss: 18.1820 - val_accuracy: 0.7567\n",
      "Epoch 1126/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.2954 - accuracy: 0.8885 - val_loss: 21.9301 - val_accuracy: 0.7715\n",
      "Epoch 1127/2000\n",
      "1570/1570 [==============================] - 0s 199us/sample - loss: 0.2932 - accuracy: 0.8860 - val_loss: 20.3236 - val_accuracy: 0.7418\n",
      "Epoch 1128/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2133 - accuracy: 0.9140 - val_loss: 22.0036 - val_accuracy: 0.7537\n",
      "Epoch 1129/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1958 - accuracy: 0.9268 - val_loss: 24.4430 - val_accuracy: 0.7507\n",
      "Epoch 1130/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.1738 - accuracy: 0.9395 - val_loss: 24.8728 - val_accuracy: 0.7478\n",
      "Epoch 1131/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1640 - accuracy: 0.9363 - val_loss: 25.6822 - val_accuracy: 0.7478\n",
      "Epoch 1132/2000\n",
      "1570/1570 [==============================] - 0s 211us/sample - loss: 0.1520 - accuracy: 0.9459 - val_loss: 26.9706 - val_accuracy: 0.7300\n",
      "Epoch 1133/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.1543 - accuracy: 0.9395 - val_loss: 27.4490 - val_accuracy: 0.7418\n",
      "Epoch 1134/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.2116 - accuracy: 0.9140 - val_loss: 22.9968 - val_accuracy: 0.7537\n",
      "Epoch 1135/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.1840 - accuracy: 0.9287 - val_loss: 23.4622 - val_accuracy: 0.7448\n",
      "Epoch 1136/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1570 - accuracy: 0.9433 - val_loss: 24.7031 - val_accuracy: 0.7567\n",
      "Epoch 1137/2000\n",
      "1570/1570 [==============================] - 0s 199us/sample - loss: 0.1494 - accuracy: 0.9433 - val_loss: 25.1878 - val_accuracy: 0.7656\n",
      "Epoch 1138/2000\n",
      "1570/1570 [==============================] - 0s 200us/sample - loss: 0.1699 - accuracy: 0.9312 - val_loss: 27.8449 - val_accuracy: 0.7389\n",
      "Epoch 1139/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1588 - accuracy: 0.9401 - val_loss: 28.9238 - val_accuracy: 0.7656\n",
      "Epoch 1140/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1652 - accuracy: 0.9369 - val_loss: 22.6143 - val_accuracy: 0.7567\n",
      "Epoch 1141/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1512 - accuracy: 0.9433 - val_loss: 25.2217 - val_accuracy: 0.7448\n",
      "Epoch 1142/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.1577 - accuracy: 0.9350 - val_loss: 27.8924 - val_accuracy: 0.7359\n",
      "Epoch 1143/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.1459 - accuracy: 0.9452 - val_loss: 28.7092 - val_accuracy: 0.7478\n",
      "Epoch 1144/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2004 - accuracy: 0.9178 - val_loss: 27.1681 - val_accuracy: 0.7596\n",
      "Epoch 1145/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.2594 - accuracy: 0.8949 - val_loss: 17.5808 - val_accuracy: 0.7596\n",
      "Epoch 1146/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1858 - accuracy: 0.9268 - val_loss: 18.7852 - val_accuracy: 0.7537\n",
      "Epoch 1147/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1902 - accuracy: 0.9287 - val_loss: 21.6835 - val_accuracy: 0.7359\n",
      "Epoch 1148/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.1682 - accuracy: 0.9331 - val_loss: 21.4625 - val_accuracy: 0.7448\n",
      "Epoch 1149/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1634 - accuracy: 0.9357 - val_loss: 21.2729 - val_accuracy: 0.7300\n",
      "Epoch 1150/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1567 - accuracy: 0.9439 - val_loss: 21.4026 - val_accuracy: 0.7567\n",
      "Epoch 1151/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1663 - accuracy: 0.9306 - val_loss: 24.4051 - val_accuracy: 0.7240\n",
      "Epoch 1152/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.2080 - accuracy: 0.9191 - val_loss: 18.9480 - val_accuracy: 0.7507\n",
      "Epoch 1153/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2826 - accuracy: 0.8822 - val_loss: 14.2905 - val_accuracy: 0.7240\n",
      "Epoch 1154/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.2392 - accuracy: 0.9127 - val_loss: 15.3186 - val_accuracy: 0.7448\n",
      "Epoch 1155/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2004 - accuracy: 0.9274 - val_loss: 18.5487 - val_accuracy: 0.7389\n",
      "Epoch 1156/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1660 - accuracy: 0.9338 - val_loss: 19.6501 - val_accuracy: 0.7151\n",
      "Epoch 1157/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1725 - accuracy: 0.9306 - val_loss: 18.6213 - val_accuracy: 0.7151\n",
      "Epoch 1158/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.1791 - accuracy: 0.9344 - val_loss: 19.2926 - val_accuracy: 0.7389\n",
      "Epoch 1159/2000\n",
      "1570/1570 [==============================] - 0s 201us/sample - loss: 0.4263 - accuracy: 0.8293 - val_loss: 6.5164 - val_accuracy: 0.7626\n",
      "Epoch 1160/2000\n",
      "1570/1570 [==============================] - 0s 197us/sample - loss: 0.2646 - accuracy: 0.8904 - val_loss: 8.0495 - val_accuracy: 0.7656\n",
      "Epoch 1161/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.2073 - accuracy: 0.9191 - val_loss: 9.0527 - val_accuracy: 0.7567\n",
      "Epoch 1162/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.1863 - accuracy: 0.9261 - val_loss: 10.6431 - val_accuracy: 0.7418\n",
      "Epoch 1163/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1612 - accuracy: 0.9401 - val_loss: 12.1675 - val_accuracy: 0.7507\n",
      "Epoch 1164/2000\n",
      "1570/1570 [==============================] - 0s 200us/sample - loss: 0.1775 - accuracy: 0.9312 - val_loss: 11.8600 - val_accuracy: 0.7478\n",
      "Epoch 1165/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.2012 - accuracy: 0.9172 - val_loss: 13.1159 - val_accuracy: 0.7537\n",
      "Epoch 1166/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.1692 - accuracy: 0.9363 - val_loss: 14.3651 - val_accuracy: 0.7478\n",
      "Epoch 1167/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1537 - accuracy: 0.9414 - val_loss: 13.9420 - val_accuracy: 0.7329\n",
      "Epoch 1168/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1515 - accuracy: 0.9439 - val_loss: 13.6862 - val_accuracy: 0.7329\n",
      "Epoch 1169/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.1496 - accuracy: 0.9439 - val_loss: 14.6269 - val_accuracy: 0.7329\n",
      "Epoch 1170/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.1588 - accuracy: 0.9369 - val_loss: 15.3019 - val_accuracy: 0.7270\n",
      "Epoch 1171/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.1477 - accuracy: 0.9427 - val_loss: 15.7902 - val_accuracy: 0.7389\n",
      "Epoch 1172/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1421 - accuracy: 0.9452 - val_loss: 15.3199 - val_accuracy: 0.7507\n",
      "Epoch 1173/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1619 - accuracy: 0.9382 - val_loss: 16.7442 - val_accuracy: 0.7240\n",
      "Epoch 1174/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1438 - accuracy: 0.9459 - val_loss: 17.8510 - val_accuracy: 0.7270\n",
      "Epoch 1175/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.1490 - accuracy: 0.9401 - val_loss: 18.8388 - val_accuracy: 0.7359\n",
      "Epoch 1176/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.1585 - accuracy: 0.9427 - val_loss: 16.2840 - val_accuracy: 0.7389\n",
      "Epoch 1177/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1691 - accuracy: 0.9280 - val_loss: 17.9905 - val_accuracy: 0.7389\n",
      "Epoch 1178/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.2506 - accuracy: 0.9064 - val_loss: 11.3105 - val_accuracy: 0.7329\n",
      "Epoch 1179/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2007 - accuracy: 0.9146 - val_loss: 15.5213 - val_accuracy: 0.7537\n",
      "Epoch 1180/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1796 - accuracy: 0.9338 - val_loss: 13.8657 - val_accuracy: 0.7448\n",
      "Epoch 1181/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1601 - accuracy: 0.9420 - val_loss: 15.6492 - val_accuracy: 0.7389\n",
      "Epoch 1182/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1397 - accuracy: 0.9490 - val_loss: 18.1675 - val_accuracy: 0.7181\n",
      "Epoch 1183/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1568 - accuracy: 0.9382 - val_loss: 20.6580 - val_accuracy: 0.7685\n",
      "Epoch 1184/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.1528 - accuracy: 0.9414 - val_loss: 20.3161 - val_accuracy: 0.7359\n",
      "Epoch 1185/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1546 - accuracy: 0.9395 - val_loss: 22.8654 - val_accuracy: 0.7329\n",
      "Epoch 1186/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1451 - accuracy: 0.9465 - val_loss: 21.5077 - val_accuracy: 0.7329\n",
      "Epoch 1187/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1923 - accuracy: 0.9217 - val_loss: 20.2320 - val_accuracy: 0.7300\n",
      "Epoch 1188/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1773 - accuracy: 0.9306 - val_loss: 19.8029 - val_accuracy: 0.7448\n",
      "Epoch 1189/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1494 - accuracy: 0.9446 - val_loss: 20.9811 - val_accuracy: 0.7537\n",
      "Epoch 1190/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1447 - accuracy: 0.9459 - val_loss: 21.1437 - val_accuracy: 0.7300\n",
      "Epoch 1191/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1942 - accuracy: 0.9197 - val_loss: 20.4558 - val_accuracy: 0.7329\n",
      "Epoch 1192/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1832 - accuracy: 0.9350 - val_loss: 16.4108 - val_accuracy: 0.7537\n",
      "Epoch 1193/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1705 - accuracy: 0.9350 - val_loss: 19.1725 - val_accuracy: 0.7448\n",
      "Epoch 1194/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1658 - accuracy: 0.9363 - val_loss: 22.1377 - val_accuracy: 0.7418\n",
      "Epoch 1195/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1432 - accuracy: 0.9459 - val_loss: 20.3027 - val_accuracy: 0.7300\n",
      "Epoch 1196/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1391 - accuracy: 0.9510 - val_loss: 20.5348 - val_accuracy: 0.7181\n",
      "Epoch 1197/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1571 - accuracy: 0.9389 - val_loss: 21.4854 - val_accuracy: 0.7240\n",
      "Epoch 1198/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2224 - accuracy: 0.9121 - val_loss: 10.8817 - val_accuracy: 0.7567\n",
      "Epoch 1199/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2137 - accuracy: 0.9172 - val_loss: 12.4989 - val_accuracy: 0.7270\n",
      "Epoch 1200/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2357 - accuracy: 0.9064 - val_loss: 8.8982 - val_accuracy: 0.7389\n",
      "Epoch 1201/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1814 - accuracy: 0.9306 - val_loss: 10.2745 - val_accuracy: 0.7389\n",
      "Epoch 1202/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1723 - accuracy: 0.9439 - val_loss: 11.7553 - val_accuracy: 0.7537\n",
      "Epoch 1203/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1468 - accuracy: 0.9459 - val_loss: 12.5739 - val_accuracy: 0.7537\n",
      "Epoch 1204/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1391 - accuracy: 0.9465 - val_loss: 12.2816 - val_accuracy: 0.7418\n",
      "Epoch 1205/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1636 - accuracy: 0.9344 - val_loss: 11.1390 - val_accuracy: 0.7507\n",
      "Epoch 1206/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1590 - accuracy: 0.9369 - val_loss: 16.9331 - val_accuracy: 0.7389\n",
      "Epoch 1207/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.2639 - accuracy: 0.9019 - val_loss: 12.0995 - val_accuracy: 0.7448\n",
      "Epoch 1208/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.1798 - accuracy: 0.9268 - val_loss: 14.2292 - val_accuracy: 0.7359\n",
      "Epoch 1209/2000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.1518 - accuracy: 0.9433 - val_loss: 15.5433 - val_accuracy: 0.7240\n",
      "Epoch 1210/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2080 - accuracy: 0.9299 - val_loss: 10.5537 - val_accuracy: 0.7478\n",
      "Epoch 1211/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.2215 - accuracy: 0.9115 - val_loss: 10.1545 - val_accuracy: 0.7537\n",
      "Epoch 1212/2000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.1869 - accuracy: 0.9268 - val_loss: 12.0604 - val_accuracy: 0.7359\n",
      "Epoch 1213/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.2093 - accuracy: 0.9191 - val_loss: 8.1426 - val_accuracy: 0.7359\n",
      "Epoch 1214/2000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.2136 - accuracy: 0.9146 - val_loss: 8.9165 - val_accuracy: 0.7537\n",
      "Epoch 1215/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.2028 - accuracy: 0.9248 - val_loss: 13.2878 - val_accuracy: 0.7359\n",
      "Epoch 1216/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1972 - accuracy: 0.9210 - val_loss: 9.9871 - val_accuracy: 0.7300\n",
      "Epoch 1217/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1481 - accuracy: 0.9465 - val_loss: 10.9216 - val_accuracy: 0.7329\n",
      "Epoch 1218/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.1840 - accuracy: 0.9331 - val_loss: 10.1601 - val_accuracy: 0.7596\n",
      "Epoch 1219/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1877 - accuracy: 0.9331 - val_loss: 12.1300 - val_accuracy: 0.7507\n",
      "Epoch 1220/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.2206 - accuracy: 0.9191 - val_loss: 11.7910 - val_accuracy: 0.7448\n",
      "Epoch 1221/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1533 - accuracy: 0.9439 - val_loss: 13.6782 - val_accuracy: 0.7567\n",
      "Epoch 1222/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.1640 - accuracy: 0.9357 - val_loss: 12.4402 - val_accuracy: 0.7359\n",
      "Epoch 1223/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1554 - accuracy: 0.9389 - val_loss: 13.6637 - val_accuracy: 0.7300\n",
      "Epoch 1224/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2028 - accuracy: 0.9242 - val_loss: 10.6964 - val_accuracy: 0.7626\n",
      "Epoch 1225/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1674 - accuracy: 0.9325 - val_loss: 11.2467 - val_accuracy: 0.7181\n",
      "Epoch 1226/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1638 - accuracy: 0.9376 - val_loss: 12.4142 - val_accuracy: 0.7418\n",
      "Epoch 1227/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1718 - accuracy: 0.9357 - val_loss: 17.2291 - val_accuracy: 0.7359\n",
      "Epoch 1228/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.2714 - accuracy: 0.8885 - val_loss: 9.7363 - val_accuracy: 0.7240\n",
      "Epoch 1229/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.2140 - accuracy: 0.9108 - val_loss: 11.5786 - val_accuracy: 0.7507\n",
      "Epoch 1230/2000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.2092 - accuracy: 0.9191 - val_loss: 11.4917 - val_accuracy: 0.7448\n",
      "Epoch 1231/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.1697 - accuracy: 0.9369 - val_loss: 12.6542 - val_accuracy: 0.7685\n",
      "Epoch 1232/2000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.1726 - accuracy: 0.9312 - val_loss: 12.4602 - val_accuracy: 0.7478\n",
      "Epoch 1233/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1574 - accuracy: 0.9414 - val_loss: 13.0589 - val_accuracy: 0.7478\n",
      "Epoch 1234/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1486 - accuracy: 0.9459 - val_loss: 15.6204 - val_accuracy: 0.7240\n",
      "Epoch 1235/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1548 - accuracy: 0.9376 - val_loss: 13.4221 - val_accuracy: 0.7448\n",
      "Epoch 1236/2000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.1427 - accuracy: 0.9459 - val_loss: 15.2197 - val_accuracy: 0.7507\n",
      "Epoch 1237/2000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.1349 - accuracy: 0.9510 - val_loss: 16.5356 - val_accuracy: 0.7211\n",
      "Epoch 1238/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1384 - accuracy: 0.9516 - val_loss: 16.1920 - val_accuracy: 0.7359\n",
      "Epoch 1239/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1353 - accuracy: 0.9446 - val_loss: 15.7799 - val_accuracy: 0.7418\n",
      "Epoch 1240/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1599 - accuracy: 0.9389 - val_loss: 16.8388 - val_accuracy: 0.7329\n",
      "Epoch 1241/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1340 - accuracy: 0.9497 - val_loss: 17.2718 - val_accuracy: 0.7567\n",
      "Epoch 1242/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1612 - accuracy: 0.9350 - val_loss: 16.7496 - val_accuracy: 0.7122\n",
      "Epoch 1243/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.2092 - accuracy: 0.9217 - val_loss: 14.4087 - val_accuracy: 0.7478\n",
      "Epoch 1244/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1767 - accuracy: 0.9274 - val_loss: 13.9252 - val_accuracy: 0.7567\n",
      "Epoch 1245/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1709 - accuracy: 0.9312 - val_loss: 15.4866 - val_accuracy: 0.7211\n",
      "Epoch 1246/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1605 - accuracy: 0.9427 - val_loss: 16.2280 - val_accuracy: 0.7359\n",
      "Epoch 1247/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1846 - accuracy: 0.9280 - val_loss: 14.7282 - val_accuracy: 0.7418\n",
      "Epoch 1248/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1757 - accuracy: 0.9280 - val_loss: 13.8086 - val_accuracy: 0.7062\n",
      "Epoch 1249/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1450 - accuracy: 0.9408 - val_loss: 18.2132 - val_accuracy: 0.7478\n",
      "Epoch 1250/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1388 - accuracy: 0.9471 - val_loss: 19.1225 - val_accuracy: 0.7418\n",
      "Epoch 1251/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.1507 - accuracy: 0.9427 - val_loss: 18.7471 - val_accuracy: 0.7418\n",
      "Epoch 1252/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2552 - accuracy: 0.9185 - val_loss: 12.8283 - val_accuracy: 0.7359\n",
      "Epoch 1253/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1979 - accuracy: 0.9159 - val_loss: 13.4266 - val_accuracy: 0.7715\n",
      "Epoch 1254/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1534 - accuracy: 0.9439 - val_loss: 18.0306 - val_accuracy: 0.7329\n",
      "Epoch 1255/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1443 - accuracy: 0.9497 - val_loss: 19.9203 - val_accuracy: 0.7359\n",
      "Epoch 1256/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1470 - accuracy: 0.9427 - val_loss: 16.4289 - val_accuracy: 0.7418\n",
      "Epoch 1257/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.1445 - accuracy: 0.9414 - val_loss: 16.3673 - val_accuracy: 0.7507\n",
      "Epoch 1258/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.2385 - accuracy: 0.9064 - val_loss: 11.9592 - val_accuracy: 0.7507\n",
      "Epoch 1259/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1530 - accuracy: 0.9420 - val_loss: 12.5254 - val_accuracy: 0.7448\n",
      "Epoch 1260/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1391 - accuracy: 0.9452 - val_loss: 15.6468 - val_accuracy: 0.7537\n",
      "Epoch 1261/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1274 - accuracy: 0.9548 - val_loss: 17.9163 - val_accuracy: 0.7418\n",
      "Epoch 1262/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1373 - accuracy: 0.9452 - val_loss: 20.0516 - val_accuracy: 0.7270\n",
      "Epoch 1263/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1373 - accuracy: 0.9452 - val_loss: 19.6144 - val_accuracy: 0.7300\n",
      "Epoch 1264/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1281 - accuracy: 0.9503 - val_loss: 19.0046 - val_accuracy: 0.7359\n",
      "Epoch 1265/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1408 - accuracy: 0.9465 - val_loss: 20.8641 - val_accuracy: 0.7270\n",
      "Epoch 1266/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1405 - accuracy: 0.9484 - val_loss: 19.1904 - val_accuracy: 0.7478\n",
      "Epoch 1267/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.1553 - accuracy: 0.9382 - val_loss: 19.3477 - val_accuracy: 0.7448\n",
      "Epoch 1268/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.1465 - accuracy: 0.9427 - val_loss: 22.0485 - val_accuracy: 0.7507\n",
      "Epoch 1269/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1463 - accuracy: 0.9427 - val_loss: 21.4665 - val_accuracy: 0.7092\n",
      "Epoch 1270/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2030 - accuracy: 0.9204 - val_loss: 12.7475 - val_accuracy: 0.7626\n",
      "Epoch 1271/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2138 - accuracy: 0.9172 - val_loss: 12.5221 - val_accuracy: 0.7448\n",
      "Epoch 1272/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1902 - accuracy: 0.9350 - val_loss: 13.9106 - val_accuracy: 0.7567\n",
      "Epoch 1273/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.1679 - accuracy: 0.9357 - val_loss: 14.8526 - val_accuracy: 0.7329\n",
      "Epoch 1274/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.1407 - accuracy: 0.9522 - val_loss: 15.9030 - val_accuracy: 0.7389\n",
      "Epoch 1275/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1353 - accuracy: 0.9465 - val_loss: 19.3973 - val_accuracy: 0.7567\n",
      "Epoch 1276/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1499 - accuracy: 0.9420 - val_loss: 15.5086 - val_accuracy: 0.7478\n",
      "Epoch 1277/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.4541 - accuracy: 0.8261 - val_loss: 5.2962 - val_accuracy: 0.6588\n",
      "Epoch 1278/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.5029 - accuracy: 0.7803 - val_loss: 2.8289 - val_accuracy: 0.7567\n",
      "Epoch 1279/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.3444 - accuracy: 0.8497 - val_loss: 4.0361 - val_accuracy: 0.7656\n",
      "Epoch 1280/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.2312 - accuracy: 0.9083 - val_loss: 5.5245 - val_accuracy: 0.7418\n",
      "Epoch 1281/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1808 - accuracy: 0.9293 - val_loss: 7.2893 - val_accuracy: 0.7596\n",
      "Epoch 1282/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1571 - accuracy: 0.9369 - val_loss: 8.5098 - val_accuracy: 0.7329\n",
      "Epoch 1283/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1437 - accuracy: 0.9478 - val_loss: 9.5924 - val_accuracy: 0.7537\n",
      "Epoch 1284/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1422 - accuracy: 0.9490 - val_loss: 10.1943 - val_accuracy: 0.7418\n",
      "Epoch 1285/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.1375 - accuracy: 0.9490 - val_loss: 11.0456 - val_accuracy: 0.7418\n",
      "Epoch 1286/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1764 - accuracy: 0.9293 - val_loss: 8.4329 - val_accuracy: 0.7389\n",
      "Epoch 1287/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1553 - accuracy: 0.9389 - val_loss: 8.9603 - val_accuracy: 0.7537\n",
      "Epoch 1288/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1336 - accuracy: 0.9503 - val_loss: 10.3300 - val_accuracy: 0.7478\n",
      "Epoch 1289/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.1365 - accuracy: 0.9497 - val_loss: 12.4339 - val_accuracy: 0.7122\n",
      "Epoch 1290/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.1495 - accuracy: 0.9408 - val_loss: 12.5686 - val_accuracy: 0.7329\n",
      "Epoch 1291/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.1345 - accuracy: 0.9478 - val_loss: 14.0051 - val_accuracy: 0.7300\n",
      "Epoch 1292/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1582 - accuracy: 0.9395 - val_loss: 14.7298 - val_accuracy: 0.7092\n",
      "Epoch 1293/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1295 - accuracy: 0.9497 - val_loss: 15.9186 - val_accuracy: 0.7151\n",
      "Epoch 1294/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1470 - accuracy: 0.9414 - val_loss: 15.4040 - val_accuracy: 0.7389\n",
      "Epoch 1295/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.1396 - accuracy: 0.9478 - val_loss: 14.1560 - val_accuracy: 0.7537\n",
      "Epoch 1296/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.1555 - accuracy: 0.9439 - val_loss: 15.6143 - val_accuracy: 0.7359\n",
      "Epoch 1297/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.1333 - accuracy: 0.9561 - val_loss: 17.3025 - val_accuracy: 0.7329\n",
      "Epoch 1298/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1330 - accuracy: 0.9503 - val_loss: 19.8187 - val_accuracy: 0.7389\n",
      "Epoch 1299/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1975 - accuracy: 0.9242 - val_loss: 15.3363 - val_accuracy: 0.7389\n",
      "Epoch 1300/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1448 - accuracy: 0.9490 - val_loss: 16.6150 - val_accuracy: 0.7389\n",
      "Epoch 1301/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.1852 - accuracy: 0.9299 - val_loss: 12.4874 - val_accuracy: 0.7448\n",
      "Epoch 1302/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.2644 - accuracy: 0.8828 - val_loss: 4.8037 - val_accuracy: 0.7537\n",
      "Epoch 1303/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1970 - accuracy: 0.9197 - val_loss: 6.9402 - val_accuracy: 0.7596\n",
      "Epoch 1304/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1711 - accuracy: 0.9350 - val_loss: 9.0354 - val_accuracy: 0.7329\n",
      "Epoch 1305/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1374 - accuracy: 0.9459 - val_loss: 12.3537 - val_accuracy: 0.7300\n",
      "Epoch 1306/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1363 - accuracy: 0.9497 - val_loss: 16.5743 - val_accuracy: 0.7300\n",
      "Epoch 1307/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.1291 - accuracy: 0.9522 - val_loss: 17.5314 - val_accuracy: 0.7389\n",
      "Epoch 1308/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1373 - accuracy: 0.9459 - val_loss: 19.4062 - val_accuracy: 0.7300\n",
      "Epoch 1309/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1542 - accuracy: 0.9414 - val_loss: 18.1747 - val_accuracy: 0.7418\n",
      "Epoch 1310/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.2376 - accuracy: 0.9096 - val_loss: 16.5120 - val_accuracy: 0.7507\n",
      "Epoch 1311/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2803 - accuracy: 0.8917 - val_loss: 12.6235 - val_accuracy: 0.7507\n",
      "Epoch 1312/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2104 - accuracy: 0.9236 - val_loss: 14.0556 - val_accuracy: 0.7507\n",
      "Epoch 1313/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.1673 - accuracy: 0.9395 - val_loss: 15.7230 - val_accuracy: 0.7507\n",
      "Epoch 1314/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.1993 - accuracy: 0.9229 - val_loss: 15.1369 - val_accuracy: 0.7685\n",
      "Epoch 1315/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1454 - accuracy: 0.9433 - val_loss: 20.5156 - val_accuracy: 0.7596\n",
      "Epoch 1316/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1284 - accuracy: 0.9510 - val_loss: 19.3692 - val_accuracy: 0.7656\n",
      "Epoch 1317/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1548 - accuracy: 0.9452 - val_loss: 17.2593 - val_accuracy: 0.7507\n",
      "Epoch 1318/2000\n",
      "1570/1570 [==============================] - 0s 200us/sample - loss: 0.1285 - accuracy: 0.9548 - val_loss: 20.7505 - val_accuracy: 0.7537\n",
      "Epoch 1319/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.1214 - accuracy: 0.9567 - val_loss: 21.2196 - val_accuracy: 0.7448\n",
      "Epoch 1320/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1284 - accuracy: 0.9510 - val_loss: 22.3774 - val_accuracy: 0.7478\n",
      "Epoch 1321/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1253 - accuracy: 0.9561 - val_loss: 21.6346 - val_accuracy: 0.7418\n",
      "Epoch 1322/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1279 - accuracy: 0.9529 - val_loss: 23.3948 - val_accuracy: 0.7507\n",
      "Epoch 1323/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.2044 - accuracy: 0.9255 - val_loss: 12.9216 - val_accuracy: 0.7537\n",
      "Epoch 1324/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.1826 - accuracy: 0.9268 - val_loss: 13.7136 - val_accuracy: 0.7448\n",
      "Epoch 1325/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1573 - accuracy: 0.9414 - val_loss: 14.5603 - val_accuracy: 0.7389\n",
      "Epoch 1326/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1671 - accuracy: 0.9363 - val_loss: 16.2653 - val_accuracy: 0.7507\n",
      "Epoch 1327/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1385 - accuracy: 0.9484 - val_loss: 19.6414 - val_accuracy: 0.7389\n",
      "Epoch 1328/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1872 - accuracy: 0.9452 - val_loss: 20.2540 - val_accuracy: 0.7270\n",
      "Epoch 1329/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.2705 - accuracy: 0.9185 - val_loss: 9.7377 - val_accuracy: 0.7211\n",
      "Epoch 1330/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.3134 - accuracy: 0.8796 - val_loss: 7.9635 - val_accuracy: 0.7567\n",
      "Epoch 1331/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1837 - accuracy: 0.9299 - val_loss: 10.7921 - val_accuracy: 0.7596\n",
      "Epoch 1332/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1488 - accuracy: 0.9484 - val_loss: 13.3467 - val_accuracy: 0.7478\n",
      "Epoch 1333/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1681 - accuracy: 0.9376 - val_loss: 20.7505 - val_accuracy: 0.7537\n",
      "Epoch 1334/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1430 - accuracy: 0.9465 - val_loss: 21.2312 - val_accuracy: 0.7507\n",
      "Epoch 1335/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.2199 - accuracy: 0.9191 - val_loss: 24.5554 - val_accuracy: 0.7537\n",
      "Epoch 1336/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2090 - accuracy: 0.9280 - val_loss: 20.5103 - val_accuracy: 0.7685\n",
      "Epoch 1337/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1782 - accuracy: 0.9312 - val_loss: 21.5541 - val_accuracy: 0.7715\n",
      "Epoch 1338/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1814 - accuracy: 0.9293 - val_loss: 19.1233 - val_accuracy: 0.7656\n",
      "Epoch 1339/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1535 - accuracy: 0.9420 - val_loss: 21.7616 - val_accuracy: 0.7478\n",
      "Epoch 1340/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1378 - accuracy: 0.9503 - val_loss: 25.0560 - val_accuracy: 0.7537\n",
      "Epoch 1341/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1320 - accuracy: 0.9484 - val_loss: 25.8798 - val_accuracy: 0.7537\n",
      "Epoch 1342/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1274 - accuracy: 0.9567 - val_loss: 28.5104 - val_accuracy: 0.7507\n",
      "Epoch 1343/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1197 - accuracy: 0.9548 - val_loss: 30.3001 - val_accuracy: 0.7448\n",
      "Epoch 1344/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1215 - accuracy: 0.9554 - val_loss: 33.3378 - val_accuracy: 0.7359\n",
      "Epoch 1345/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1158 - accuracy: 0.9586 - val_loss: 34.3328 - val_accuracy: 0.7448\n",
      "Epoch 1346/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.1569 - accuracy: 0.9446 - val_loss: 32.0835 - val_accuracy: 0.7418\n",
      "Epoch 1347/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1661 - accuracy: 0.9376 - val_loss: 23.1184 - val_accuracy: 0.7359\n",
      "Epoch 1348/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2675 - accuracy: 0.8904 - val_loss: 20.3444 - val_accuracy: 0.7448\n",
      "Epoch 1349/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1680 - accuracy: 0.9427 - val_loss: 22.4822 - val_accuracy: 0.7329\n",
      "Epoch 1350/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.1328 - accuracy: 0.9541 - val_loss: 26.7751 - val_accuracy: 0.7596\n",
      "Epoch 1351/2000\n",
      "1570/1570 [==============================] - 0s 203us/sample - loss: 0.2496 - accuracy: 0.9140 - val_loss: 14.9735 - val_accuracy: 0.7151\n",
      "Epoch 1352/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.2230 - accuracy: 0.9153 - val_loss: 16.8762 - val_accuracy: 0.7567\n",
      "Epoch 1353/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1955 - accuracy: 0.9255 - val_loss: 19.3172 - val_accuracy: 0.7389\n",
      "Epoch 1354/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1478 - accuracy: 0.9478 - val_loss: 21.1460 - val_accuracy: 0.7478\n",
      "Epoch 1355/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1239 - accuracy: 0.9580 - val_loss: 24.6602 - val_accuracy: 0.7270\n",
      "Epoch 1356/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1187 - accuracy: 0.9605 - val_loss: 27.0473 - val_accuracy: 0.7448\n",
      "Epoch 1357/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.1182 - accuracy: 0.9586 - val_loss: 27.3345 - val_accuracy: 0.7418\n",
      "Epoch 1358/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1422 - accuracy: 0.9605 - val_loss: 31.7368 - val_accuracy: 0.7211\n",
      "Epoch 1359/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.2687 - accuracy: 0.9172 - val_loss: 32.0803 - val_accuracy: 0.7537\n",
      "Epoch 1360/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2465 - accuracy: 0.9025 - val_loss: 33.4434 - val_accuracy: 0.7715\n",
      "Epoch 1361/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2809 - accuracy: 0.8943 - val_loss: 30.8242 - val_accuracy: 0.7537\n",
      "Epoch 1362/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.2219 - accuracy: 0.9115 - val_loss: 38.6961 - val_accuracy: 0.7537\n",
      "Epoch 1363/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.2169 - accuracy: 0.9229 - val_loss: 36.5957 - val_accuracy: 0.7537\n",
      "Epoch 1364/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1827 - accuracy: 0.9274 - val_loss: 35.2633 - val_accuracy: 0.7448\n",
      "Epoch 1365/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.2021 - accuracy: 0.9229 - val_loss: 37.4764 - val_accuracy: 0.7359\n",
      "Epoch 1366/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1491 - accuracy: 0.9446 - val_loss: 32.6424 - val_accuracy: 0.7626\n",
      "Epoch 1367/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1355 - accuracy: 0.9497 - val_loss: 32.9965 - val_accuracy: 0.7478\n",
      "Epoch 1368/2000\n",
      "1570/1570 [==============================] - 0s 194us/sample - loss: 0.1802 - accuracy: 0.9299 - val_loss: 33.7235 - val_accuracy: 0.7715\n",
      "Epoch 1369/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.1568 - accuracy: 0.9420 - val_loss: 38.0912 - val_accuracy: 0.7448\n",
      "Epoch 1370/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1429 - accuracy: 0.9490 - val_loss: 40.1232 - val_accuracy: 0.7478\n",
      "Epoch 1371/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1618 - accuracy: 0.9363 - val_loss: 38.2796 - val_accuracy: 0.7596\n",
      "Epoch 1372/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1378 - accuracy: 0.9471 - val_loss: 37.0754 - val_accuracy: 0.7329\n",
      "Epoch 1373/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1202 - accuracy: 0.9611 - val_loss: 38.0793 - val_accuracy: 0.7537\n",
      "Epoch 1374/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.1228 - accuracy: 0.9580 - val_loss: 41.2935 - val_accuracy: 0.7389\n",
      "Epoch 1375/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.1273 - accuracy: 0.9510 - val_loss: 33.8504 - val_accuracy: 0.7448\n",
      "Epoch 1376/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1202 - accuracy: 0.9605 - val_loss: 34.7269 - val_accuracy: 0.7478\n",
      "Epoch 1377/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.3117 - accuracy: 0.8930 - val_loss: 28.6412 - val_accuracy: 0.7240\n",
      "Epoch 1378/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.2665 - accuracy: 0.8962 - val_loss: 28.8330 - val_accuracy: 0.7507\n",
      "Epoch 1379/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.1888 - accuracy: 0.9236 - val_loss: 28.7936 - val_accuracy: 0.7478\n",
      "Epoch 1380/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1459 - accuracy: 0.9420 - val_loss: 29.3043 - val_accuracy: 0.7418\n",
      "Epoch 1381/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1354 - accuracy: 0.9516 - val_loss: 31.5828 - val_accuracy: 0.7448\n",
      "Epoch 1382/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1275 - accuracy: 0.9541 - val_loss: 33.3229 - val_accuracy: 0.7270\n",
      "Epoch 1383/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1245 - accuracy: 0.9573 - val_loss: 33.2969 - val_accuracy: 0.7389\n",
      "Epoch 1384/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1363 - accuracy: 0.9478 - val_loss: 36.9041 - val_accuracy: 0.7270\n",
      "Epoch 1385/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2007 - accuracy: 0.9338 - val_loss: 27.2750 - val_accuracy: 0.7537\n",
      "Epoch 1386/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1571 - accuracy: 0.9446 - val_loss: 28.8874 - val_accuracy: 0.7507\n",
      "Epoch 1387/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1377 - accuracy: 0.9516 - val_loss: 30.1178 - val_accuracy: 0.7329\n",
      "Epoch 1388/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1566 - accuracy: 0.9382 - val_loss: 31.7995 - val_accuracy: 0.7300\n",
      "Epoch 1389/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1649 - accuracy: 0.9376 - val_loss: 32.7234 - val_accuracy: 0.7418\n",
      "Epoch 1390/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.2565 - accuracy: 0.9089 - val_loss: 19.2346 - val_accuracy: 0.7507\n",
      "Epoch 1391/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1838 - accuracy: 0.9287 - val_loss: 14.0317 - val_accuracy: 0.7507\n",
      "Epoch 1392/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1594 - accuracy: 0.9408 - val_loss: 15.4986 - val_accuracy: 0.7537\n",
      "Epoch 1393/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.1351 - accuracy: 0.9459 - val_loss: 17.3226 - val_accuracy: 0.7507\n",
      "Epoch 1394/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1590 - accuracy: 0.9395 - val_loss: 20.8885 - val_accuracy: 0.7567\n",
      "Epoch 1395/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1580 - accuracy: 0.9465 - val_loss: 17.1265 - val_accuracy: 0.7359\n",
      "Epoch 1396/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2016 - accuracy: 0.9395 - val_loss: 13.4415 - val_accuracy: 0.7567\n",
      "Epoch 1397/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1472 - accuracy: 0.9439 - val_loss: 12.8412 - val_accuracy: 0.7389\n",
      "Epoch 1398/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1202 - accuracy: 0.9580 - val_loss: 14.3657 - val_accuracy: 0.7418\n",
      "Epoch 1399/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1195 - accuracy: 0.9561 - val_loss: 15.2053 - val_accuracy: 0.7478\n",
      "Epoch 1400/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1155 - accuracy: 0.9605 - val_loss: 16.0678 - val_accuracy: 0.7300\n",
      "Epoch 1401/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1267 - accuracy: 0.9503 - val_loss: 15.1978 - val_accuracy: 0.7418\n",
      "Epoch 1402/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1203 - accuracy: 0.9561 - val_loss: 16.8610 - val_accuracy: 0.7507\n",
      "Epoch 1403/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1137 - accuracy: 0.9605 - val_loss: 17.1945 - val_accuracy: 0.7448\n",
      "Epoch 1404/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1171 - accuracy: 0.9567 - val_loss: 18.1630 - val_accuracy: 0.7448\n",
      "Epoch 1405/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1140 - accuracy: 0.9611 - val_loss: 19.1351 - val_accuracy: 0.7389\n",
      "Epoch 1406/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1213 - accuracy: 0.9554 - val_loss: 19.9468 - val_accuracy: 0.7537\n",
      "Epoch 1407/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1244 - accuracy: 0.9535 - val_loss: 20.6032 - val_accuracy: 0.7478\n",
      "Epoch 1408/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.1134 - accuracy: 0.9580 - val_loss: 20.6740 - val_accuracy: 0.7567\n",
      "Epoch 1409/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1210 - accuracy: 0.9580 - val_loss: 20.1142 - val_accuracy: 0.7389\n",
      "Epoch 1410/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1485 - accuracy: 0.9389 - val_loss: 18.2131 - val_accuracy: 0.7389\n",
      "Epoch 1411/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1272 - accuracy: 0.9516 - val_loss: 19.1459 - val_accuracy: 0.7329\n",
      "Epoch 1412/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1269 - accuracy: 0.9522 - val_loss: 20.4945 - val_accuracy: 0.7567\n",
      "Epoch 1413/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1267 - accuracy: 0.9580 - val_loss: 19.5419 - val_accuracy: 0.7418\n",
      "Epoch 1414/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1243 - accuracy: 0.9541 - val_loss: 19.7890 - val_accuracy: 0.7418\n",
      "Epoch 1415/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1365 - accuracy: 0.9465 - val_loss: 20.4059 - val_accuracy: 0.7478\n",
      "Epoch 1416/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1128 - accuracy: 0.9605 - val_loss: 22.0499 - val_accuracy: 0.7537\n",
      "Epoch 1417/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1263 - accuracy: 0.9510 - val_loss: 22.2428 - val_accuracy: 0.7418\n",
      "Epoch 1418/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1209 - accuracy: 0.9580 - val_loss: 22.7677 - val_accuracy: 0.7389\n",
      "Epoch 1419/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1246 - accuracy: 0.9580 - val_loss: 21.3535 - val_accuracy: 0.7567\n",
      "Epoch 1420/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.1288 - accuracy: 0.9497 - val_loss: 22.2372 - val_accuracy: 0.7359\n",
      "Epoch 1421/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1565 - accuracy: 0.9369 - val_loss: 18.5688 - val_accuracy: 0.7478\n",
      "Epoch 1422/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2976 - accuracy: 0.8930 - val_loss: 14.4267 - val_accuracy: 0.7685\n",
      "Epoch 1423/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2154 - accuracy: 0.9210 - val_loss: 13.9403 - val_accuracy: 0.7715\n",
      "Epoch 1424/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1836 - accuracy: 0.9217 - val_loss: 11.0470 - val_accuracy: 0.7211\n",
      "Epoch 1425/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1495 - accuracy: 0.9433 - val_loss: 13.2544 - val_accuracy: 0.7329\n",
      "Epoch 1426/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1313 - accuracy: 0.9522 - val_loss: 12.7258 - val_accuracy: 0.7537\n",
      "Epoch 1427/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1171 - accuracy: 0.9592 - val_loss: 15.1572 - val_accuracy: 0.7448\n",
      "Epoch 1428/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1418 - accuracy: 0.9478 - val_loss: 14.9279 - val_accuracy: 0.7359\n",
      "Epoch 1429/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1288 - accuracy: 0.9548 - val_loss: 15.2288 - val_accuracy: 0.7359\n",
      "Epoch 1430/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1180 - accuracy: 0.9573 - val_loss: 17.0753 - val_accuracy: 0.7300\n",
      "Epoch 1431/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.1249 - accuracy: 0.9567 - val_loss: 16.4247 - val_accuracy: 0.7389\n",
      "Epoch 1432/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1210 - accuracy: 0.9573 - val_loss: 16.7567 - val_accuracy: 0.7418\n",
      "Epoch 1433/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.3137 - accuracy: 0.8726 - val_loss: 10.2044 - val_accuracy: 0.7507\n",
      "Epoch 1434/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.3300 - accuracy: 0.8650 - val_loss: 10.3800 - val_accuracy: 0.7448\n",
      "Epoch 1435/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.4340 - accuracy: 0.8497 - val_loss: 3.5160 - val_accuracy: 0.7537\n",
      "Epoch 1436/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.3045 - accuracy: 0.8809 - val_loss: 4.2878 - val_accuracy: 0.7329\n",
      "Epoch 1437/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2496 - accuracy: 0.9051 - val_loss: 5.0681 - val_accuracy: 0.7389\n",
      "Epoch 1438/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.2342 - accuracy: 0.9083 - val_loss: 4.7515 - val_accuracy: 0.7596\n",
      "Epoch 1439/2000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.2228 - accuracy: 0.9172 - val_loss: 5.9989 - val_accuracy: 0.7596\n",
      "Epoch 1440/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.2010 - accuracy: 0.9325 - val_loss: 6.3189 - val_accuracy: 0.7478\n",
      "Epoch 1441/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1916 - accuracy: 0.9363 - val_loss: 6.8626 - val_accuracy: 0.7596\n",
      "Epoch 1442/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1812 - accuracy: 0.9376 - val_loss: 7.7644 - val_accuracy: 0.7448\n",
      "Epoch 1443/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.2041 - accuracy: 0.9318 - val_loss: 9.0281 - val_accuracy: 0.7448\n",
      "Epoch 1444/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.2049 - accuracy: 0.9217 - val_loss: 8.8197 - val_accuracy: 0.7507\n",
      "Epoch 1445/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1705 - accuracy: 0.9433 - val_loss: 9.6650 - val_accuracy: 0.7270\n",
      "Epoch 1446/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1725 - accuracy: 0.9408 - val_loss: 9.6928 - val_accuracy: 0.7567\n",
      "Epoch 1447/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1529 - accuracy: 0.9471 - val_loss: 10.6342 - val_accuracy: 0.7300\n",
      "Epoch 1448/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1700 - accuracy: 0.9363 - val_loss: 10.5108 - val_accuracy: 0.7537\n",
      "Epoch 1449/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1542 - accuracy: 0.9490 - val_loss: 11.0418 - val_accuracy: 0.7448\n",
      "Epoch 1450/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1527 - accuracy: 0.9471 - val_loss: 11.9596 - val_accuracy: 0.7151\n",
      "Epoch 1451/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1506 - accuracy: 0.9465 - val_loss: 12.0300 - val_accuracy: 0.7448\n",
      "Epoch 1452/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1597 - accuracy: 0.9446 - val_loss: 11.1449 - val_accuracy: 0.7300\n",
      "Epoch 1453/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1817 - accuracy: 0.9338 - val_loss: 10.5030 - val_accuracy: 0.7537\n",
      "Epoch 1454/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1878 - accuracy: 0.9363 - val_loss: 8.8172 - val_accuracy: 0.7448\n",
      "Epoch 1455/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1567 - accuracy: 0.9427 - val_loss: 9.3206 - val_accuracy: 0.7567\n",
      "Epoch 1456/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.1344 - accuracy: 0.9510 - val_loss: 11.8689 - val_accuracy: 0.7537\n",
      "Epoch 1457/2000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.1303 - accuracy: 0.9548 - val_loss: 11.9725 - val_accuracy: 0.7626\n",
      "Epoch 1458/2000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.1243 - accuracy: 0.9573 - val_loss: 12.7373 - val_accuracy: 0.7507\n",
      "Epoch 1459/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1436 - accuracy: 0.9459 - val_loss: 12.2845 - val_accuracy: 0.7685\n",
      "Epoch 1460/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1785 - accuracy: 0.9357 - val_loss: 12.7566 - val_accuracy: 0.7448\n",
      "Epoch 1461/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1401 - accuracy: 0.9516 - val_loss: 13.3720 - val_accuracy: 0.7448\n",
      "Epoch 1462/2000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.1272 - accuracy: 0.9567 - val_loss: 13.8379 - val_accuracy: 0.7567\n",
      "Epoch 1463/2000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.1222 - accuracy: 0.9599 - val_loss: 14.3019 - val_accuracy: 0.7448\n",
      "Epoch 1464/2000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.1987 - accuracy: 0.9306 - val_loss: 11.3915 - val_accuracy: 0.7418\n",
      "Epoch 1465/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.2398 - accuracy: 0.9070 - val_loss: 9.9057 - val_accuracy: 0.7537\n",
      "Epoch 1466/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1379 - accuracy: 0.9484 - val_loss: 10.7254 - val_accuracy: 0.7478\n",
      "Epoch 1467/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1203 - accuracy: 0.9567 - val_loss: 11.6729 - val_accuracy: 0.7389\n",
      "Epoch 1468/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1174 - accuracy: 0.9567 - val_loss: 11.7249 - val_accuracy: 0.7685\n",
      "Epoch 1469/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1433 - accuracy: 0.9433 - val_loss: 12.8992 - val_accuracy: 0.7448\n",
      "Epoch 1470/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.1871 - accuracy: 0.9280 - val_loss: 8.9920 - val_accuracy: 0.7240\n",
      "Epoch 1471/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1416 - accuracy: 0.9490 - val_loss: 9.7952 - val_accuracy: 0.7240\n",
      "Epoch 1472/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1458 - accuracy: 0.9478 - val_loss: 9.0224 - val_accuracy: 0.7448\n",
      "Epoch 1473/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1668 - accuracy: 0.9338 - val_loss: 12.1081 - val_accuracy: 0.7448\n",
      "Epoch 1474/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.2293 - accuracy: 0.9217 - val_loss: 7.3320 - val_accuracy: 0.7507\n",
      "Epoch 1475/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1894 - accuracy: 0.9293 - val_loss: 20.0813 - val_accuracy: 0.7567\n",
      "Epoch 1476/2000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.1744 - accuracy: 0.9363 - val_loss: 10.6227 - val_accuracy: 0.7567\n",
      "Epoch 1477/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1471 - accuracy: 0.9439 - val_loss: 13.1308 - val_accuracy: 0.7537\n",
      "Epoch 1478/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1184 - accuracy: 0.9592 - val_loss: 15.3489 - val_accuracy: 0.7240\n",
      "Epoch 1479/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1154 - accuracy: 0.9592 - val_loss: 16.8319 - val_accuracy: 0.7240\n",
      "Epoch 1480/2000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.1221 - accuracy: 0.9503 - val_loss: 15.0454 - val_accuracy: 0.7418\n",
      "Epoch 1481/2000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.1095 - accuracy: 0.9599 - val_loss: 18.6329 - val_accuracy: 0.7181\n",
      "Epoch 1482/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.1086 - accuracy: 0.9599 - val_loss: 18.4474 - val_accuracy: 0.7359\n",
      "Epoch 1483/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1104 - accuracy: 0.9580 - val_loss: 18.1850 - val_accuracy: 0.7270\n",
      "Epoch 1484/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1165 - accuracy: 0.9592 - val_loss: 20.4910 - val_accuracy: 0.7389\n",
      "Epoch 1485/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1565 - accuracy: 0.9414 - val_loss: 19.0994 - val_accuracy: 0.7211\n",
      "Epoch 1486/2000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.1434 - accuracy: 0.9433 - val_loss: 19.6074 - val_accuracy: 0.7418\n",
      "Epoch 1487/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1392 - accuracy: 0.9446 - val_loss: 18.8909 - val_accuracy: 0.7596\n",
      "Epoch 1488/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1556 - accuracy: 0.9503 - val_loss: 12.8760 - val_accuracy: 0.7507\n",
      "Epoch 1489/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.1217 - accuracy: 0.9561 - val_loss: 14.9673 - val_accuracy: 0.7359\n",
      "Epoch 1490/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1064 - accuracy: 0.9624 - val_loss: 16.5817 - val_accuracy: 0.7448\n",
      "Epoch 1491/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1142 - accuracy: 0.9554 - val_loss: 18.5072 - val_accuracy: 0.7448\n",
      "Epoch 1492/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1429 - accuracy: 0.9471 - val_loss: 13.3683 - val_accuracy: 0.7507\n",
      "Epoch 1493/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1383 - accuracy: 0.9497 - val_loss: 14.1831 - val_accuracy: 0.7418\n",
      "Epoch 1494/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1142 - accuracy: 0.9605 - val_loss: 21.0342 - val_accuracy: 0.7389\n",
      "Epoch 1495/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1225 - accuracy: 0.9548 - val_loss: 19.5985 - val_accuracy: 0.7211\n",
      "Epoch 1496/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1159 - accuracy: 0.9605 - val_loss: 19.2304 - val_accuracy: 0.7359\n",
      "Epoch 1497/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1137 - accuracy: 0.9618 - val_loss: 18.8075 - val_accuracy: 0.7092\n",
      "Epoch 1498/2000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.1510 - accuracy: 0.9490 - val_loss: 19.7336 - val_accuracy: 0.7122\n",
      "Epoch 1499/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.1462 - accuracy: 0.9433 - val_loss: 15.8873 - val_accuracy: 0.7359\n",
      "Epoch 1500/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.1421 - accuracy: 0.9478 - val_loss: 20.7745 - val_accuracy: 0.7240\n",
      "Epoch 1501/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1257 - accuracy: 0.9535 - val_loss: 19.5418 - val_accuracy: 0.7300\n",
      "Epoch 1502/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1145 - accuracy: 0.9643 - val_loss: 19.4165 - val_accuracy: 0.7359\n",
      "Epoch 1503/2000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.1274 - accuracy: 0.9535 - val_loss: 19.6676 - val_accuracy: 0.7329\n",
      "Epoch 1504/2000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.1021 - accuracy: 0.9650 - val_loss: 22.1759 - val_accuracy: 0.7270\n",
      "Epoch 1505/2000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.1018 - accuracy: 0.9669 - val_loss: 23.3580 - val_accuracy: 0.7359\n",
      "Epoch 1506/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.0938 - accuracy: 0.9662 - val_loss: 24.0811 - val_accuracy: 0.7122\n",
      "Epoch 1507/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1577 - accuracy: 0.9414 - val_loss: 19.2520 - val_accuracy: 0.7300\n",
      "Epoch 1508/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1783 - accuracy: 0.9401 - val_loss: 14.7830 - val_accuracy: 0.7507\n",
      "Epoch 1509/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2329 - accuracy: 0.9108 - val_loss: 9.6224 - val_accuracy: 0.7359\n",
      "Epoch 1510/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2991 - accuracy: 0.8866 - val_loss: 10.8215 - val_accuracy: 0.7656\n",
      "Epoch 1511/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1740 - accuracy: 0.9318 - val_loss: 15.7050 - val_accuracy: 0.7418\n",
      "Epoch 1512/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1582 - accuracy: 0.9401 - val_loss: 20.8855 - val_accuracy: 0.7300\n",
      "Epoch 1513/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.1333 - accuracy: 0.9554 - val_loss: 22.4698 - val_accuracy: 0.7507\n",
      "Epoch 1514/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1225 - accuracy: 0.9567 - val_loss: 21.8397 - val_accuracy: 0.7507\n",
      "Epoch 1515/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1183 - accuracy: 0.9561 - val_loss: 26.9471 - val_accuracy: 0.7537\n",
      "Epoch 1516/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1469 - accuracy: 0.9420 - val_loss: 23.4546 - val_accuracy: 0.7329\n",
      "Epoch 1517/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1267 - accuracy: 0.9535 - val_loss: 18.5390 - val_accuracy: 0.7537\n",
      "Epoch 1518/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.1325 - accuracy: 0.9484 - val_loss: 17.8115 - val_accuracy: 0.7448\n",
      "Epoch 1519/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.1281 - accuracy: 0.9490 - val_loss: 20.4766 - val_accuracy: 0.7300\n",
      "Epoch 1520/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1042 - accuracy: 0.9611 - val_loss: 21.7630 - val_accuracy: 0.7211\n",
      "Epoch 1521/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.0994 - accuracy: 0.9675 - val_loss: 24.0619 - val_accuracy: 0.7270\n",
      "Epoch 1522/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1328 - accuracy: 0.9535 - val_loss: 23.1853 - val_accuracy: 0.7418\n",
      "Epoch 1523/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1564 - accuracy: 0.9401 - val_loss: 21.6597 - val_accuracy: 0.7389\n",
      "Epoch 1524/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.1173 - accuracy: 0.9580 - val_loss: 22.6256 - val_accuracy: 0.7270\n",
      "Epoch 1525/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2019 - accuracy: 0.9274 - val_loss: 19.1013 - val_accuracy: 0.7270\n",
      "Epoch 1526/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2880 - accuracy: 0.8911 - val_loss: 11.0538 - val_accuracy: 0.7656\n",
      "Epoch 1527/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2349 - accuracy: 0.9006 - val_loss: 9.2347 - val_accuracy: 0.7567\n",
      "Epoch 1528/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1600 - accuracy: 0.9350 - val_loss: 15.8366 - val_accuracy: 0.7626\n",
      "Epoch 1529/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.2019 - accuracy: 0.9172 - val_loss: 15.0067 - val_accuracy: 0.7507\n",
      "Epoch 1530/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.1249 - accuracy: 0.9573 - val_loss: 17.7614 - val_accuracy: 0.7567\n",
      "Epoch 1531/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1165 - accuracy: 0.9586 - val_loss: 21.6440 - val_accuracy: 0.7596\n",
      "Epoch 1532/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1155 - accuracy: 0.9573 - val_loss: 22.4383 - val_accuracy: 0.7418\n",
      "Epoch 1533/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1039 - accuracy: 0.9611 - val_loss: 24.0672 - val_accuracy: 0.7418\n",
      "Epoch 1534/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1002 - accuracy: 0.9682 - val_loss: 25.9110 - val_accuracy: 0.7240\n",
      "Epoch 1535/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.1110 - accuracy: 0.9599 - val_loss: 25.0008 - val_accuracy: 0.7240\n",
      "Epoch 1536/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2062 - accuracy: 0.9261 - val_loss: 19.8984 - val_accuracy: 0.7270\n",
      "Epoch 1537/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1188 - accuracy: 0.9580 - val_loss: 20.4770 - val_accuracy: 0.7418\n",
      "Epoch 1538/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1126 - accuracy: 0.9624 - val_loss: 22.3108 - val_accuracy: 0.7389\n",
      "Epoch 1539/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.0992 - accuracy: 0.9675 - val_loss: 24.3029 - val_accuracy: 0.7418\n",
      "Epoch 1540/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.1859 - accuracy: 0.9293 - val_loss: 14.8531 - val_accuracy: 0.7389\n",
      "Epoch 1541/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.1488 - accuracy: 0.9465 - val_loss: 18.0079 - val_accuracy: 0.7537\n",
      "Epoch 1542/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1317 - accuracy: 0.9554 - val_loss: 19.6888 - val_accuracy: 0.7359\n",
      "Epoch 1543/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1141 - accuracy: 0.9637 - val_loss: 20.6668 - val_accuracy: 0.7478\n",
      "Epoch 1544/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1105 - accuracy: 0.9650 - val_loss: 21.8960 - val_accuracy: 0.7359\n",
      "Epoch 1545/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1084 - accuracy: 0.9650 - val_loss: 25.3524 - val_accuracy: 0.7418\n",
      "Epoch 1546/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.1071 - accuracy: 0.9624 - val_loss: 27.6551 - val_accuracy: 0.7329\n",
      "Epoch 1547/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.1047 - accuracy: 0.9643 - val_loss: 27.1204 - val_accuracy: 0.7389\n",
      "Epoch 1548/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1160 - accuracy: 0.9611 - val_loss: 26.2161 - val_accuracy: 0.7418\n",
      "Epoch 1549/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1222 - accuracy: 0.9573 - val_loss: 27.2073 - val_accuracy: 0.7507\n",
      "Epoch 1550/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.4439 - accuracy: 0.8465 - val_loss: 6.2015 - val_accuracy: 0.7181\n",
      "Epoch 1551/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.3375 - accuracy: 0.8529 - val_loss: 6.5118 - val_accuracy: 0.7478\n",
      "Epoch 1552/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.2663 - accuracy: 0.8879 - val_loss: 6.6797 - val_accuracy: 0.7567\n",
      "Epoch 1553/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2531 - accuracy: 0.8924 - val_loss: 6.5368 - val_accuracy: 0.7567\n",
      "Epoch 1554/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2541 - accuracy: 0.8885 - val_loss: 7.0992 - val_accuracy: 0.7478\n",
      "Epoch 1555/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.2354 - accuracy: 0.8936 - val_loss: 6.8834 - val_accuracy: 0.7448\n",
      "Epoch 1556/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.2293 - accuracy: 0.8930 - val_loss: 7.9682 - val_accuracy: 0.7537\n",
      "Epoch 1557/2000\n",
      "1570/1570 [==============================] - 0s 198us/sample - loss: 0.2244 - accuracy: 0.8981 - val_loss: 8.1046 - val_accuracy: 0.7567\n",
      "Epoch 1558/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2146 - accuracy: 0.9025 - val_loss: 9.3294 - val_accuracy: 0.7448\n",
      "Epoch 1559/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2107 - accuracy: 0.9013 - val_loss: 10.2046 - val_accuracy: 0.7359\n",
      "Epoch 1560/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.2425 - accuracy: 0.8892 - val_loss: 10.1366 - val_accuracy: 0.7418\n",
      "Epoch 1561/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.2468 - accuracy: 0.8885 - val_loss: 20.2796 - val_accuracy: 0.7359\n",
      "Epoch 1562/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.2284 - accuracy: 0.9000 - val_loss: 12.8186 - val_accuracy: 0.7300\n",
      "Epoch 1563/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.2582 - accuracy: 0.8866 - val_loss: 10.2539 - val_accuracy: 0.6884\n",
      "Epoch 1564/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.3504 - accuracy: 0.8796 - val_loss: 10.2502 - val_accuracy: 0.7448\n",
      "Epoch 1565/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.3148 - accuracy: 0.8694 - val_loss: 10.9154 - val_accuracy: 0.7478\n",
      "Epoch 1566/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2918 - accuracy: 0.8873 - val_loss: 16.7281 - val_accuracy: 0.7448\n",
      "Epoch 1567/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.2558 - accuracy: 0.8962 - val_loss: 17.7037 - val_accuracy: 0.7448\n",
      "Epoch 1568/2000\n",
      "1570/1570 [==============================] - 0s 197us/sample - loss: 0.2264 - accuracy: 0.9000 - val_loss: 20.0691 - val_accuracy: 0.7448\n",
      "Epoch 1569/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2035 - accuracy: 0.9076 - val_loss: 18.7539 - val_accuracy: 0.7567\n",
      "Epoch 1570/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.2224 - accuracy: 0.9070 - val_loss: 18.1858 - val_accuracy: 0.7418\n",
      "Epoch 1571/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2154 - accuracy: 0.9083 - val_loss: 19.2139 - val_accuracy: 0.7240\n",
      "Epoch 1572/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.1993 - accuracy: 0.9140 - val_loss: 20.9266 - val_accuracy: 0.7418\n",
      "Epoch 1573/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.1915 - accuracy: 0.9140 - val_loss: 20.9320 - val_accuracy: 0.7537\n",
      "Epoch 1574/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.2132 - accuracy: 0.9057 - val_loss: 21.9855 - val_accuracy: 0.7389\n",
      "Epoch 1575/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.2795 - accuracy: 0.8930 - val_loss: 13.2030 - val_accuracy: 0.7626\n",
      "Epoch 1576/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.2127 - accuracy: 0.9076 - val_loss: 13.7479 - val_accuracy: 0.7537\n",
      "Epoch 1577/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1902 - accuracy: 0.9140 - val_loss: 13.4778 - val_accuracy: 0.7507\n",
      "Epoch 1578/2000\n",
      "1570/1570 [==============================] - 0s 196us/sample - loss: 0.1790 - accuracy: 0.9210 - val_loss: 15.1110 - val_accuracy: 0.7567\n",
      "Epoch 1579/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1726 - accuracy: 0.9229 - val_loss: 16.3869 - val_accuracy: 0.7329\n",
      "Epoch 1580/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1804 - accuracy: 0.9229 - val_loss: 15.4384 - val_accuracy: 0.7418\n",
      "Epoch 1581/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1588 - accuracy: 0.9344 - val_loss: 17.7138 - val_accuracy: 0.7507\n",
      "Epoch 1582/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1546 - accuracy: 0.9325 - val_loss: 19.0088 - val_accuracy: 0.7626\n",
      "Epoch 1583/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.1555 - accuracy: 0.9318 - val_loss: 20.2653 - val_accuracy: 0.7359\n",
      "Epoch 1584/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.1811 - accuracy: 0.9280 - val_loss: 21.1332 - val_accuracy: 0.7507\n",
      "Epoch 1585/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2094 - accuracy: 0.9357 - val_loss: 22.1138 - val_accuracy: 0.7478\n",
      "Epoch 1586/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1974 - accuracy: 0.9223 - val_loss: 21.9830 - val_accuracy: 0.7567\n",
      "Epoch 1587/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1780 - accuracy: 0.9306 - val_loss: 22.3448 - val_accuracy: 0.7478\n",
      "Epoch 1588/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1579 - accuracy: 0.9395 - val_loss: 22.0237 - val_accuracy: 0.7478\n",
      "Epoch 1589/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1570 - accuracy: 0.9331 - val_loss: 22.8282 - val_accuracy: 0.7537\n",
      "Epoch 1590/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1679 - accuracy: 0.9287 - val_loss: 18.1938 - val_accuracy: 0.7596\n",
      "Epoch 1591/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1780 - accuracy: 0.9274 - val_loss: 16.6030 - val_accuracy: 0.7507\n",
      "Epoch 1592/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1576 - accuracy: 0.9325 - val_loss: 14.9488 - val_accuracy: 0.7478\n",
      "Epoch 1593/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1437 - accuracy: 0.9408 - val_loss: 20.1417 - val_accuracy: 0.7478\n",
      "Epoch 1594/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2120 - accuracy: 0.9408 - val_loss: 25.6638 - val_accuracy: 0.7389\n",
      "Epoch 1595/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.2314 - accuracy: 0.9070 - val_loss: 18.0414 - val_accuracy: 0.7359\n",
      "Epoch 1596/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1574 - accuracy: 0.9389 - val_loss: 19.0956 - val_accuracy: 0.7418\n",
      "Epoch 1597/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1333 - accuracy: 0.9446 - val_loss: 21.6958 - val_accuracy: 0.7448\n",
      "Epoch 1598/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.2088 - accuracy: 0.9280 - val_loss: 16.2630 - val_accuracy: 0.7329\n",
      "Epoch 1599/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1656 - accuracy: 0.9363 - val_loss: 18.8282 - val_accuracy: 0.7389\n",
      "Epoch 1600/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1522 - accuracy: 0.9465 - val_loss: 21.7360 - val_accuracy: 0.7329\n",
      "Epoch 1601/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1487 - accuracy: 0.9420 - val_loss: 24.5745 - val_accuracy: 0.7478\n",
      "Epoch 1602/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1600 - accuracy: 0.9459 - val_loss: 17.1516 - val_accuracy: 0.7270\n",
      "Epoch 1603/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1504 - accuracy: 0.9395 - val_loss: 19.5151 - val_accuracy: 0.7418\n",
      "Epoch 1604/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1223 - accuracy: 0.9478 - val_loss: 20.7371 - val_accuracy: 0.7418\n",
      "Epoch 1605/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1651 - accuracy: 0.9363 - val_loss: 21.3575 - val_accuracy: 0.7359\n",
      "Epoch 1606/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1760 - accuracy: 0.9299 - val_loss: 18.2495 - val_accuracy: 0.7626\n",
      "Epoch 1607/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1475 - accuracy: 0.9465 - val_loss: 19.3792 - val_accuracy: 0.7478\n",
      "Epoch 1608/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1243 - accuracy: 0.9573 - val_loss: 21.3691 - val_accuracy: 0.7596\n",
      "Epoch 1609/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1124 - accuracy: 0.9637 - val_loss: 24.3623 - val_accuracy: 0.7448\n",
      "Epoch 1610/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1373 - accuracy: 0.9490 - val_loss: 21.1464 - val_accuracy: 0.7329\n",
      "Epoch 1611/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1273 - accuracy: 0.9503 - val_loss: 22.9335 - val_accuracy: 0.7418\n",
      "Epoch 1612/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1057 - accuracy: 0.9650 - val_loss: 25.8322 - val_accuracy: 0.7448\n",
      "Epoch 1613/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1966 - accuracy: 0.9287 - val_loss: 18.6193 - val_accuracy: 0.7359\n",
      "Epoch 1614/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1708 - accuracy: 0.9363 - val_loss: 19.1112 - val_accuracy: 0.7567\n",
      "Epoch 1615/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1656 - accuracy: 0.9446 - val_loss: 14.9145 - val_accuracy: 0.7656\n",
      "Epoch 1616/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1241 - accuracy: 0.9554 - val_loss: 20.5257 - val_accuracy: 0.7567\n",
      "Epoch 1617/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1327 - accuracy: 0.9522 - val_loss: 20.0432 - val_accuracy: 0.7596\n",
      "Epoch 1618/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1152 - accuracy: 0.9561 - val_loss: 24.1306 - val_accuracy: 0.7448\n",
      "Epoch 1619/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1052 - accuracy: 0.9599 - val_loss: 25.0768 - val_accuracy: 0.7478\n",
      "Epoch 1620/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.0987 - accuracy: 0.9662 - val_loss: 25.1840 - val_accuracy: 0.7478\n",
      "Epoch 1621/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1179 - accuracy: 0.9567 - val_loss: 24.6364 - val_accuracy: 0.7685\n",
      "Epoch 1622/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2170 - accuracy: 0.9255 - val_loss: 19.1423 - val_accuracy: 0.7359\n",
      "Epoch 1623/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1149 - accuracy: 0.9592 - val_loss: 22.0038 - val_accuracy: 0.7478\n",
      "Epoch 1624/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1103 - accuracy: 0.9618 - val_loss: 23.7814 - val_accuracy: 0.7359\n",
      "Epoch 1625/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.0971 - accuracy: 0.9656 - val_loss: 24.4989 - val_accuracy: 0.7596\n",
      "Epoch 1626/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1869 - accuracy: 0.9318 - val_loss: 20.1645 - val_accuracy: 0.7507\n",
      "Epoch 1627/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1497 - accuracy: 0.9439 - val_loss: 24.3121 - val_accuracy: 0.7448\n",
      "Epoch 1628/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1307 - accuracy: 0.9510 - val_loss: 26.5718 - val_accuracy: 0.7448\n",
      "Epoch 1629/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1231 - accuracy: 0.9490 - val_loss: 22.7837 - val_accuracy: 0.7418\n",
      "Epoch 1630/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1780 - accuracy: 0.9255 - val_loss: 24.9920 - val_accuracy: 0.7507\n",
      "Epoch 1631/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1170 - accuracy: 0.9599 - val_loss: 25.8879 - val_accuracy: 0.7567\n",
      "Epoch 1632/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.0992 - accuracy: 0.9675 - val_loss: 27.4920 - val_accuracy: 0.7389\n",
      "Epoch 1633/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.0980 - accuracy: 0.9631 - val_loss: 29.5422 - val_accuracy: 0.7448\n",
      "Epoch 1634/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1288 - accuracy: 0.9490 - val_loss: 27.8824 - val_accuracy: 0.7418\n",
      "Epoch 1635/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1236 - accuracy: 0.9541 - val_loss: 28.3920 - val_accuracy: 0.7685\n",
      "Epoch 1636/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1439 - accuracy: 0.9535 - val_loss: 18.0035 - val_accuracy: 0.7389\n",
      "Epoch 1637/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2232 - accuracy: 0.9140 - val_loss: 9.0763 - val_accuracy: 0.7389\n",
      "Epoch 1638/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.4476 - accuracy: 0.8414 - val_loss: 2.8201 - val_accuracy: 0.7685\n",
      "Epoch 1639/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2979 - accuracy: 0.8783 - val_loss: 4.0940 - val_accuracy: 0.7537\n",
      "Epoch 1640/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2710 - accuracy: 0.8815 - val_loss: 4.5778 - val_accuracy: 0.7478\n",
      "Epoch 1641/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2492 - accuracy: 0.8936 - val_loss: 4.1242 - val_accuracy: 0.7656\n",
      "Epoch 1642/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.2381 - accuracy: 0.8955 - val_loss: 4.8577 - val_accuracy: 0.7507\n",
      "Epoch 1643/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.2233 - accuracy: 0.8981 - val_loss: 12.1747 - val_accuracy: 0.7448\n",
      "Epoch 1644/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.2272 - accuracy: 0.8949 - val_loss: 21.9974 - val_accuracy: 0.7448\n",
      "Epoch 1645/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2160 - accuracy: 0.9025 - val_loss: 10.9573 - val_accuracy: 0.7448\n",
      "Epoch 1646/2000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.2138 - accuracy: 0.9083 - val_loss: 9.4269 - val_accuracy: 0.7418\n",
      "Epoch 1647/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1928 - accuracy: 0.9108 - val_loss: 10.0656 - val_accuracy: 0.7507\n",
      "Epoch 1648/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1721 - accuracy: 0.9293 - val_loss: 9.4192 - val_accuracy: 0.7389\n",
      "Epoch 1649/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.1598 - accuracy: 0.9325 - val_loss: 11.7496 - val_accuracy: 0.7478\n",
      "Epoch 1650/2000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.1588 - accuracy: 0.9331 - val_loss: 13.0409 - val_accuracy: 0.7300\n",
      "Epoch 1651/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.1699 - accuracy: 0.9312 - val_loss: 13.7646 - val_accuracy: 0.7359\n",
      "Epoch 1652/2000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.1632 - accuracy: 0.9306 - val_loss: 13.3197 - val_accuracy: 0.7359\n",
      "Epoch 1653/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1469 - accuracy: 0.9420 - val_loss: 14.6574 - val_accuracy: 0.7240\n",
      "Epoch 1654/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1369 - accuracy: 0.9408 - val_loss: 15.7799 - val_accuracy: 0.7359\n",
      "Epoch 1655/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1447 - accuracy: 0.9382 - val_loss: 15.7064 - val_accuracy: 0.7270\n",
      "Epoch 1656/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1565 - accuracy: 0.9331 - val_loss: 17.1671 - val_accuracy: 0.7151\n",
      "Epoch 1657/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1884 - accuracy: 0.9312 - val_loss: 13.4626 - val_accuracy: 0.7389\n",
      "Epoch 1658/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1900 - accuracy: 0.9242 - val_loss: 7.3373 - val_accuracy: 0.7389\n",
      "Epoch 1659/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1538 - accuracy: 0.9382 - val_loss: 9.6434 - val_accuracy: 0.7270\n",
      "Epoch 1660/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1538 - accuracy: 0.9395 - val_loss: 9.7167 - val_accuracy: 0.7389\n",
      "Epoch 1661/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1747 - accuracy: 0.9274 - val_loss: 9.5442 - val_accuracy: 0.7359\n",
      "Epoch 1662/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1386 - accuracy: 0.9439 - val_loss: 10.8282 - val_accuracy: 0.7448\n",
      "Epoch 1663/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1343 - accuracy: 0.9408 - val_loss: 11.1930 - val_accuracy: 0.7389\n",
      "Epoch 1664/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1238 - accuracy: 0.9535 - val_loss: 12.8442 - val_accuracy: 0.7359\n",
      "Epoch 1665/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1438 - accuracy: 0.9433 - val_loss: 12.6728 - val_accuracy: 0.7092\n",
      "Epoch 1666/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.3781 - accuracy: 0.8688 - val_loss: 3.4518 - val_accuracy: 0.7389\n",
      "Epoch 1667/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.2290 - accuracy: 0.9089 - val_loss: 6.0217 - val_accuracy: 0.7478\n",
      "Epoch 1668/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1691 - accuracy: 0.9306 - val_loss: 7.8605 - val_accuracy: 0.7418\n",
      "Epoch 1669/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.1553 - accuracy: 0.9446 - val_loss: 7.9954 - val_accuracy: 0.7389\n",
      "Epoch 1670/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1518 - accuracy: 0.9433 - val_loss: 10.5153 - val_accuracy: 0.7300\n",
      "Epoch 1671/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.2909 - accuracy: 0.8720 - val_loss: 11.1897 - val_accuracy: 0.7151\n",
      "Epoch 1672/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.1880 - accuracy: 0.9287 - val_loss: 11.0087 - val_accuracy: 0.7418\n",
      "Epoch 1673/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1225 - accuracy: 0.9529 - val_loss: 12.6757 - val_accuracy: 0.7507\n",
      "Epoch 1674/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1087 - accuracy: 0.9573 - val_loss: 15.5899 - val_accuracy: 0.7359\n",
      "Epoch 1675/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1030 - accuracy: 0.9637 - val_loss: 17.5692 - val_accuracy: 0.7359\n",
      "Epoch 1676/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.1052 - accuracy: 0.9624 - val_loss: 18.5063 - val_accuracy: 0.7359\n",
      "Epoch 1677/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.1050 - accuracy: 0.9643 - val_loss: 19.3374 - val_accuracy: 0.7448\n",
      "Epoch 1678/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1035 - accuracy: 0.9611 - val_loss: 19.7626 - val_accuracy: 0.7359\n",
      "Epoch 1679/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.2176 - accuracy: 0.9248 - val_loss: 14.1203 - val_accuracy: 0.7537\n",
      "Epoch 1680/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1193 - accuracy: 0.9516 - val_loss: 16.8797 - val_accuracy: 0.7329\n",
      "Epoch 1681/2000\n",
      "1570/1570 [==============================] - 0s 201us/sample - loss: 0.0961 - accuracy: 0.9682 - val_loss: 19.3299 - val_accuracy: 0.7478\n",
      "Epoch 1682/2000\n",
      "1570/1570 [==============================] - 0s 196us/sample - loss: 0.0955 - accuracy: 0.9669 - val_loss: 23.3771 - val_accuracy: 0.7270\n",
      "Epoch 1683/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.0966 - accuracy: 0.9662 - val_loss: 24.0465 - val_accuracy: 0.7418\n",
      "Epoch 1684/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.0948 - accuracy: 0.9682 - val_loss: 23.6848 - val_accuracy: 0.7507\n",
      "Epoch 1685/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.0943 - accuracy: 0.9682 - val_loss: 26.6594 - val_accuracy: 0.7389\n",
      "Epoch 1686/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.1201 - accuracy: 0.9618 - val_loss: 27.9352 - val_accuracy: 0.7389\n",
      "Epoch 1687/2000\n",
      "1570/1570 [==============================] - 0s 205us/sample - loss: 0.2693 - accuracy: 0.9025 - val_loss: 16.6190 - val_accuracy: 0.7596\n",
      "Epoch 1688/2000\n",
      "1570/1570 [==============================] - 0s 196us/sample - loss: 0.1607 - accuracy: 0.9338 - val_loss: 19.9728 - val_accuracy: 0.7389\n",
      "Epoch 1689/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.1135 - accuracy: 0.9561 - val_loss: 23.6018 - val_accuracy: 0.7448\n",
      "Epoch 1690/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.1294 - accuracy: 0.9573 - val_loss: 18.8200 - val_accuracy: 0.7478\n",
      "Epoch 1691/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.0995 - accuracy: 0.9656 - val_loss: 20.2024 - val_accuracy: 0.7478\n",
      "Epoch 1692/2000\n",
      "1570/1570 [==============================] - 0s 196us/sample - loss: 0.0971 - accuracy: 0.9624 - val_loss: 21.1056 - val_accuracy: 0.7359\n",
      "Epoch 1693/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.0917 - accuracy: 0.9688 - val_loss: 22.4809 - val_accuracy: 0.7240\n",
      "Epoch 1694/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1024 - accuracy: 0.9592 - val_loss: 21.5293 - val_accuracy: 0.7478\n",
      "Epoch 1695/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1146 - accuracy: 0.9548 - val_loss: 14.7504 - val_accuracy: 0.7359\n",
      "Epoch 1696/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1769 - accuracy: 0.9293 - val_loss: 12.8759 - val_accuracy: 0.7389\n",
      "Epoch 1697/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1198 - accuracy: 0.9567 - val_loss: 16.6290 - val_accuracy: 0.7389\n",
      "Epoch 1698/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.2214 - accuracy: 0.9159 - val_loss: 13.2472 - val_accuracy: 0.7329\n",
      "Epoch 1699/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1351 - accuracy: 0.9541 - val_loss: 16.6428 - val_accuracy: 0.7329\n",
      "Epoch 1700/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1115 - accuracy: 0.9599 - val_loss: 17.5371 - val_accuracy: 0.7507\n",
      "Epoch 1701/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.0980 - accuracy: 0.9682 - val_loss: 19.2638 - val_accuracy: 0.7300\n",
      "Epoch 1702/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1774 - accuracy: 0.9548 - val_loss: 19.9018 - val_accuracy: 0.7507\n",
      "Epoch 1703/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.1034 - accuracy: 0.9631 - val_loss: 21.4949 - val_accuracy: 0.7478\n",
      "Epoch 1704/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1462 - accuracy: 0.9497 - val_loss: 21.9905 - val_accuracy: 0.7359\n",
      "Epoch 1705/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.2688 - accuracy: 0.9204 - val_loss: 10.4361 - val_accuracy: 0.7359\n",
      "Epoch 1706/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.4309 - accuracy: 0.8013 - val_loss: 6.4919 - val_accuracy: 0.7240\n",
      "Epoch 1707/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.3247 - accuracy: 0.8611 - val_loss: 5.1373 - val_accuracy: 0.7507\n",
      "Epoch 1708/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.2207 - accuracy: 0.9191 - val_loss: 7.7548 - val_accuracy: 0.7537\n",
      "Epoch 1709/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1623 - accuracy: 0.9420 - val_loss: 10.2345 - val_accuracy: 0.7537\n",
      "Epoch 1710/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1373 - accuracy: 0.9510 - val_loss: 12.6350 - val_accuracy: 0.7359\n",
      "Epoch 1711/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2606 - accuracy: 0.8943 - val_loss: 8.3953 - val_accuracy: 0.7507\n",
      "Epoch 1712/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2035 - accuracy: 0.9261 - val_loss: 10.5635 - val_accuracy: 0.7448\n",
      "Epoch 1713/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1620 - accuracy: 0.9465 - val_loss: 12.7441 - val_accuracy: 0.7448\n",
      "Epoch 1714/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1749 - accuracy: 0.9325 - val_loss: 11.5374 - val_accuracy: 0.7448\n",
      "Epoch 1715/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1439 - accuracy: 0.9446 - val_loss: 15.3508 - val_accuracy: 0.7448\n",
      "Epoch 1716/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1121 - accuracy: 0.9611 - val_loss: 16.0824 - val_accuracy: 0.7507\n",
      "Epoch 1717/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1298 - accuracy: 0.9535 - val_loss: 15.8021 - val_accuracy: 0.7448\n",
      "Epoch 1718/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1133 - accuracy: 0.9592 - val_loss: 19.7117 - val_accuracy: 0.7329\n",
      "Epoch 1719/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1073 - accuracy: 0.9637 - val_loss: 20.2428 - val_accuracy: 0.7329\n",
      "Epoch 1720/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1066 - accuracy: 0.9618 - val_loss: 20.3543 - val_accuracy: 0.7418\n",
      "Epoch 1721/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1275 - accuracy: 0.9567 - val_loss: 19.2374 - val_accuracy: 0.7181\n",
      "Epoch 1722/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1329 - accuracy: 0.9561 - val_loss: 17.5308 - val_accuracy: 0.7329\n",
      "Epoch 1723/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1187 - accuracy: 0.9573 - val_loss: 17.5368 - val_accuracy: 0.7359\n",
      "Epoch 1724/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1375 - accuracy: 0.9490 - val_loss: 18.6809 - val_accuracy: 0.7389\n",
      "Epoch 1725/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.2240 - accuracy: 0.9159 - val_loss: 13.2312 - val_accuracy: 0.7656\n",
      "Epoch 1726/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1385 - accuracy: 0.9459 - val_loss: 17.9990 - val_accuracy: 0.7507\n",
      "Epoch 1727/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1129 - accuracy: 0.9586 - val_loss: 19.2600 - val_accuracy: 0.7359\n",
      "Epoch 1728/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1139 - accuracy: 0.9631 - val_loss: 19.5001 - val_accuracy: 0.7359\n",
      "Epoch 1729/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1037 - accuracy: 0.9650 - val_loss: 20.7754 - val_accuracy: 0.7359\n",
      "Epoch 1730/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1049 - accuracy: 0.9631 - val_loss: 22.0050 - val_accuracy: 0.7329\n",
      "Epoch 1731/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.0998 - accuracy: 0.9650 - val_loss: 22.9592 - val_accuracy: 0.7448\n",
      "Epoch 1732/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.1207 - accuracy: 0.9592 - val_loss: 20.6694 - val_accuracy: 0.7448\n",
      "Epoch 1733/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.1084 - accuracy: 0.9618 - val_loss: 21.9674 - val_accuracy: 0.7507\n",
      "Epoch 1734/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.3013 - accuracy: 0.8841 - val_loss: 14.0531 - val_accuracy: 0.7389\n",
      "Epoch 1735/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1771 - accuracy: 0.9376 - val_loss: 17.9503 - val_accuracy: 0.7507\n",
      "Epoch 1736/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1310 - accuracy: 0.9522 - val_loss: 20.7396 - val_accuracy: 0.7478\n",
      "Epoch 1737/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1080 - accuracy: 0.9631 - val_loss: 23.3625 - val_accuracy: 0.7359\n",
      "Epoch 1738/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.1190 - accuracy: 0.9573 - val_loss: 22.3357 - val_accuracy: 0.7359\n",
      "Epoch 1739/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1243 - accuracy: 0.9554 - val_loss: 22.8751 - val_accuracy: 0.7537\n",
      "Epoch 1740/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1048 - accuracy: 0.9611 - val_loss: 22.8960 - val_accuracy: 0.7537\n",
      "Epoch 1741/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.1005 - accuracy: 0.9669 - val_loss: 26.5795 - val_accuracy: 0.7300\n",
      "Epoch 1742/2000\n",
      "1570/1570 [==============================] - 0s 316us/sample - loss: 0.1047 - accuracy: 0.9656 - val_loss: 25.3511 - val_accuracy: 0.7507\n",
      "Epoch 1743/2000\n",
      "1570/1570 [==============================] - 0s 268us/sample - loss: 0.0986 - accuracy: 0.9662 - val_loss: 27.8107 - val_accuracy: 0.7478\n",
      "Epoch 1744/2000\n",
      "1570/1570 [==============================] - 0s 209us/sample - loss: 0.1062 - accuracy: 0.9605 - val_loss: 25.2188 - val_accuracy: 0.7478\n",
      "Epoch 1745/2000\n",
      "1570/1570 [==============================] - 0s 207us/sample - loss: 0.1142 - accuracy: 0.9554 - val_loss: 26.5973 - val_accuracy: 0.7537\n",
      "Epoch 1746/2000\n",
      "1570/1570 [==============================] - 0s 222us/sample - loss: 0.1056 - accuracy: 0.9631 - val_loss: 27.4233 - val_accuracy: 0.7596\n",
      "Epoch 1747/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.1262 - accuracy: 0.9503 - val_loss: 24.4243 - val_accuracy: 0.7596\n",
      "Epoch 1748/2000\n",
      "1570/1570 [==============================] - 0s 217us/sample - loss: 0.1077 - accuracy: 0.9618 - val_loss: 26.8271 - val_accuracy: 0.7596\n",
      "Epoch 1749/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.2256 - accuracy: 0.9178 - val_loss: 7.0231 - val_accuracy: 0.7389\n",
      "Epoch 1750/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.6106 - accuracy: 0.7115 - val_loss: 4.3864 - val_accuracy: 0.6647\n",
      "Epoch 1751/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.5401 - accuracy: 0.7465 - val_loss: 5.9184 - val_accuracy: 0.7448\n",
      "Epoch 1752/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.4845 - accuracy: 0.7694 - val_loss: 4.2339 - val_accuracy: 0.7537\n",
      "Epoch 1753/2000\n",
      "1570/1570 [==============================] - 0s 197us/sample - loss: 0.3972 - accuracy: 0.8032 - val_loss: 3.9611 - val_accuracy: 0.7418\n",
      "Epoch 1754/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.4070 - accuracy: 0.8242 - val_loss: 5.3504 - val_accuracy: 0.7329\n",
      "Epoch 1755/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.3429 - accuracy: 0.8369 - val_loss: 4.3241 - val_accuracy: 0.7596\n",
      "Epoch 1756/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.3327 - accuracy: 0.8217 - val_loss: 5.9583 - val_accuracy: 0.7685\n",
      "Epoch 1757/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.2767 - accuracy: 0.8618 - val_loss: 5.6068 - val_accuracy: 0.7715\n",
      "Epoch 1758/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.2680 - accuracy: 0.8745 - val_loss: 4.5784 - val_accuracy: 0.7656\n",
      "Epoch 1759/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.2312 - accuracy: 0.8943 - val_loss: 5.3887 - val_accuracy: 0.7596\n",
      "Epoch 1760/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2212 - accuracy: 0.8975 - val_loss: 5.6011 - val_accuracy: 0.7507\n",
      "Epoch 1761/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1982 - accuracy: 0.9140 - val_loss: 7.0132 - val_accuracy: 0.7537\n",
      "Epoch 1762/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2121 - accuracy: 0.9153 - val_loss: 6.8481 - val_accuracy: 0.7685\n",
      "Epoch 1763/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.2355 - accuracy: 0.9025 - val_loss: 7.0982 - val_accuracy: 0.7656\n",
      "Epoch 1764/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.1709 - accuracy: 0.9242 - val_loss: 9.9278 - val_accuracy: 0.7389\n",
      "Epoch 1765/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1663 - accuracy: 0.9268 - val_loss: 9.3193 - val_accuracy: 0.7537\n",
      "Epoch 1766/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1710 - accuracy: 0.9299 - val_loss: 12.1680 - val_accuracy: 0.7418\n",
      "Epoch 1767/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1621 - accuracy: 0.9325 - val_loss: 11.4936 - val_accuracy: 0.7626\n",
      "Epoch 1768/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.1478 - accuracy: 0.9420 - val_loss: 11.7824 - val_accuracy: 0.7537\n",
      "Epoch 1769/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1916 - accuracy: 0.9261 - val_loss: 10.5512 - val_accuracy: 0.7478\n",
      "Epoch 1770/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1568 - accuracy: 0.9382 - val_loss: 12.2620 - val_accuracy: 0.7626\n",
      "Epoch 1771/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.1457 - accuracy: 0.9420 - val_loss: 13.9644 - val_accuracy: 0.7448\n",
      "Epoch 1772/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.1344 - accuracy: 0.9484 - val_loss: 14.5234 - val_accuracy: 0.7329\n",
      "Epoch 1773/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1406 - accuracy: 0.9459 - val_loss: 15.0775 - val_accuracy: 0.7507\n",
      "Epoch 1774/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1187 - accuracy: 0.9554 - val_loss: 16.0933 - val_accuracy: 0.7418\n",
      "Epoch 1775/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1624 - accuracy: 0.9408 - val_loss: 9.6160 - val_accuracy: 0.7389\n",
      "Epoch 1776/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1446 - accuracy: 0.9471 - val_loss: 10.5214 - val_accuracy: 0.7151\n",
      "Epoch 1777/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1235 - accuracy: 0.9535 - val_loss: 12.4231 - val_accuracy: 0.7418\n",
      "Epoch 1778/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1227 - accuracy: 0.9516 - val_loss: 12.6880 - val_accuracy: 0.7389\n",
      "Epoch 1779/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1246 - accuracy: 0.9497 - val_loss: 14.4294 - val_accuracy: 0.7240\n",
      "Epoch 1780/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1859 - accuracy: 0.9274 - val_loss: 12.9124 - val_accuracy: 0.7329\n",
      "Epoch 1781/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1428 - accuracy: 0.9503 - val_loss: 14.2400 - val_accuracy: 0.7329\n",
      "Epoch 1782/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1300 - accuracy: 0.9497 - val_loss: 13.5635 - val_accuracy: 0.7478\n",
      "Epoch 1783/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1120 - accuracy: 0.9599 - val_loss: 15.0900 - val_accuracy: 0.7626\n",
      "Epoch 1784/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1278 - accuracy: 0.9529 - val_loss: 17.0732 - val_accuracy: 0.7448\n",
      "Epoch 1785/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1217 - accuracy: 0.9541 - val_loss: 17.0429 - val_accuracy: 0.7448\n",
      "Epoch 1786/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1317 - accuracy: 0.9497 - val_loss: 17.1868 - val_accuracy: 0.7507\n",
      "Epoch 1787/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1196 - accuracy: 0.9561 - val_loss: 18.1540 - val_accuracy: 0.7478\n",
      "Epoch 1788/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.1372 - accuracy: 0.9503 - val_loss: 16.5953 - val_accuracy: 0.7418\n",
      "Epoch 1789/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.1065 - accuracy: 0.9580 - val_loss: 20.0668 - val_accuracy: 0.7389\n",
      "Epoch 1790/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1019 - accuracy: 0.9586 - val_loss: 19.6728 - val_accuracy: 0.7448\n",
      "Epoch 1791/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1149 - accuracy: 0.9548 - val_loss: 16.5895 - val_accuracy: 0.7448\n",
      "Epoch 1792/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1229 - accuracy: 0.9529 - val_loss: 19.4199 - val_accuracy: 0.7181\n",
      "Epoch 1793/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1033 - accuracy: 0.9611 - val_loss: 21.2435 - val_accuracy: 0.7418\n",
      "Epoch 1794/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1024 - accuracy: 0.9599 - val_loss: 21.6934 - val_accuracy: 0.7448\n",
      "Epoch 1795/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1636 - accuracy: 0.9331 - val_loss: 16.5360 - val_accuracy: 0.7537\n",
      "Epoch 1796/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.2072 - accuracy: 0.9115 - val_loss: 23.2973 - val_accuracy: 0.7596\n",
      "Epoch 1797/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1352 - accuracy: 0.9446 - val_loss: 22.2507 - val_accuracy: 0.7537\n",
      "Epoch 1798/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.1397 - accuracy: 0.9452 - val_loss: 20.9692 - val_accuracy: 0.7418\n",
      "Epoch 1799/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.1508 - accuracy: 0.9433 - val_loss: 15.2002 - val_accuracy: 0.7270\n",
      "Epoch 1800/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1253 - accuracy: 0.9554 - val_loss: 16.2207 - val_accuracy: 0.7270\n",
      "Epoch 1801/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1103 - accuracy: 0.9586 - val_loss: 18.5428 - val_accuracy: 0.7507\n",
      "Epoch 1802/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1204 - accuracy: 0.9529 - val_loss: 19.0426 - val_accuracy: 0.7448\n",
      "Epoch 1803/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1174 - accuracy: 0.9580 - val_loss: 19.0670 - val_accuracy: 0.7329\n",
      "Epoch 1804/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.1165 - accuracy: 0.9554 - val_loss: 19.0725 - val_accuracy: 0.7329\n",
      "Epoch 1805/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1094 - accuracy: 0.9586 - val_loss: 20.6608 - val_accuracy: 0.7507\n",
      "Epoch 1806/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1512 - accuracy: 0.9459 - val_loss: 18.1131 - val_accuracy: 0.7389\n",
      "Epoch 1807/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1524 - accuracy: 0.9427 - val_loss: 18.7514 - val_accuracy: 0.7181\n",
      "Epoch 1808/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1971 - accuracy: 0.9268 - val_loss: 14.8810 - val_accuracy: 0.7537\n",
      "Epoch 1809/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1393 - accuracy: 0.9471 - val_loss: 17.8062 - val_accuracy: 0.7329\n",
      "Epoch 1810/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1092 - accuracy: 0.9592 - val_loss: 18.7351 - val_accuracy: 0.7418\n",
      "Epoch 1811/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.0993 - accuracy: 0.9637 - val_loss: 20.1019 - val_accuracy: 0.7448\n",
      "Epoch 1812/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1248 - accuracy: 0.9541 - val_loss: 18.6387 - val_accuracy: 0.7567\n",
      "Epoch 1813/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1157 - accuracy: 0.9535 - val_loss: 18.4226 - val_accuracy: 0.7418\n",
      "Epoch 1814/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1022 - accuracy: 0.9599 - val_loss: 20.6611 - val_accuracy: 0.7300\n",
      "Epoch 1815/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.1059 - accuracy: 0.9618 - val_loss: 22.0078 - val_accuracy: 0.7418\n",
      "Epoch 1816/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.2646 - accuracy: 0.9172 - val_loss: 10.7756 - val_accuracy: 0.7389\n",
      "Epoch 1817/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.1956 - accuracy: 0.9318 - val_loss: 15.0894 - val_accuracy: 0.7181\n",
      "Epoch 1818/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.1315 - accuracy: 0.9503 - val_loss: 19.3378 - val_accuracy: 0.7389\n",
      "Epoch 1819/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.1672 - accuracy: 0.9344 - val_loss: 20.0647 - val_accuracy: 0.7478\n",
      "Epoch 1820/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.1583 - accuracy: 0.9408 - val_loss: 15.4394 - val_accuracy: 0.7448\n",
      "Epoch 1821/2000\n",
      "1570/1570 [==============================] - 0s 196us/sample - loss: 0.1490 - accuracy: 0.9408 - val_loss: 16.0784 - val_accuracy: 0.7507\n",
      "Epoch 1822/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.1152 - accuracy: 0.9554 - val_loss: 19.4329 - val_accuracy: 0.7537\n",
      "Epoch 1823/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.1442 - accuracy: 0.9465 - val_loss: 20.1937 - val_accuracy: 0.7329\n",
      "Epoch 1824/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1090 - accuracy: 0.9567 - val_loss: 22.1902 - val_accuracy: 0.7507\n",
      "Epoch 1825/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.0954 - accuracy: 0.9637 - val_loss: 22.3737 - val_accuracy: 0.7567\n",
      "Epoch 1826/2000\n",
      "1570/1570 [==============================] - 0s 205us/sample - loss: 0.0962 - accuracy: 0.9650 - val_loss: 23.0384 - val_accuracy: 0.7507\n",
      "Epoch 1827/2000\n",
      "1570/1570 [==============================] - 0s 190us/sample - loss: 0.0908 - accuracy: 0.9662 - val_loss: 25.1058 - val_accuracy: 0.7359\n",
      "Epoch 1828/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1104 - accuracy: 0.9586 - val_loss: 21.7927 - val_accuracy: 0.7537\n",
      "Epoch 1829/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.0947 - accuracy: 0.9643 - val_loss: 21.8187 - val_accuracy: 0.7507\n",
      "Epoch 1830/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.0903 - accuracy: 0.9650 - val_loss: 21.8380 - val_accuracy: 0.7418\n",
      "Epoch 1831/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.1358 - accuracy: 0.9478 - val_loss: 21.1861 - val_accuracy: 0.7478\n",
      "Epoch 1832/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.0956 - accuracy: 0.9637 - val_loss: 22.0035 - val_accuracy: 0.7448\n",
      "Epoch 1833/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.0893 - accuracy: 0.9631 - val_loss: 22.8038 - val_accuracy: 0.7537\n",
      "Epoch 1834/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1488 - accuracy: 0.9427 - val_loss: 20.6317 - val_accuracy: 0.7626\n",
      "Epoch 1835/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.2393 - accuracy: 0.9070 - val_loss: 13.8418 - val_accuracy: 0.7685\n",
      "Epoch 1836/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1556 - accuracy: 0.9401 - val_loss: 18.0435 - val_accuracy: 0.7448\n",
      "Epoch 1837/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.1174 - accuracy: 0.9561 - val_loss: 19.5720 - val_accuracy: 0.7359\n",
      "Epoch 1838/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.0956 - accuracy: 0.9669 - val_loss: 21.8555 - val_accuracy: 0.7507\n",
      "Epoch 1839/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.0846 - accuracy: 0.9682 - val_loss: 22.6183 - val_accuracy: 0.7329\n",
      "Epoch 1840/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.0953 - accuracy: 0.9631 - val_loss: 23.1215 - val_accuracy: 0.7478\n",
      "Epoch 1841/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1089 - accuracy: 0.9561 - val_loss: 25.3883 - val_accuracy: 0.7478\n",
      "Epoch 1842/2000\n",
      "1570/1570 [==============================] - 0s 198us/sample - loss: 0.0952 - accuracy: 0.9611 - val_loss: 22.5134 - val_accuracy: 0.7537\n",
      "Epoch 1843/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.1218 - accuracy: 0.9541 - val_loss: 18.6842 - val_accuracy: 0.7300\n",
      "Epoch 1844/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.0943 - accuracy: 0.9637 - val_loss: 20.5278 - val_accuracy: 0.7359\n",
      "Epoch 1845/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1233 - accuracy: 0.9592 - val_loss: 17.2333 - val_accuracy: 0.7389\n",
      "Epoch 1846/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.2124 - accuracy: 0.9261 - val_loss: 12.0033 - val_accuracy: 0.7300\n",
      "Epoch 1847/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1549 - accuracy: 0.9408 - val_loss: 11.6406 - val_accuracy: 0.7389\n",
      "Epoch 1848/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.1174 - accuracy: 0.9586 - val_loss: 10.6823 - val_accuracy: 0.7507\n",
      "Epoch 1849/2000\n",
      "1570/1570 [==============================] - 0s 194us/sample - loss: 0.1219 - accuracy: 0.9561 - val_loss: 12.9181 - val_accuracy: 0.7507\n",
      "Epoch 1850/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1667 - accuracy: 0.9535 - val_loss: 9.2843 - val_accuracy: 0.7300\n",
      "Epoch 1851/2000\n",
      "1570/1570 [==============================] - 0s 266us/sample - loss: 0.1220 - accuracy: 0.9573 - val_loss: 15.8955 - val_accuracy: 0.7418\n",
      "Epoch 1852/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.1315 - accuracy: 0.9516 - val_loss: 14.8619 - val_accuracy: 0.7418\n",
      "Epoch 1853/2000\n",
      "1570/1570 [==============================] - 0s 218us/sample - loss: 0.3210 - accuracy: 0.8764 - val_loss: 6.6738 - val_accuracy: 0.7715\n",
      "Epoch 1854/2000\n",
      "1570/1570 [==============================] - 0s 197us/sample - loss: 0.1669 - accuracy: 0.9389 - val_loss: 11.1646 - val_accuracy: 0.7359\n",
      "Epoch 1855/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.1256 - accuracy: 0.9573 - val_loss: 13.6540 - val_accuracy: 0.7448\n",
      "Epoch 1856/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.1270 - accuracy: 0.9548 - val_loss: 16.6460 - val_accuracy: 0.7211\n",
      "Epoch 1857/2000\n",
      "1570/1570 [==============================] - 0s 196us/sample - loss: 0.1278 - accuracy: 0.9561 - val_loss: 16.5904 - val_accuracy: 0.7567\n",
      "Epoch 1858/2000\n",
      "1570/1570 [==============================] - 0s 197us/sample - loss: 0.1011 - accuracy: 0.9631 - val_loss: 18.8997 - val_accuracy: 0.7329\n",
      "Epoch 1859/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1211 - accuracy: 0.9580 - val_loss: 15.6068 - val_accuracy: 0.7359\n",
      "Epoch 1860/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.2337 - accuracy: 0.9127 - val_loss: 10.3957 - val_accuracy: 0.7418\n",
      "Epoch 1861/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1253 - accuracy: 0.9561 - val_loss: 14.5909 - val_accuracy: 0.7359\n",
      "Epoch 1862/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1190 - accuracy: 0.9567 - val_loss: 16.5728 - val_accuracy: 0.7418\n",
      "Epoch 1863/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.1018 - accuracy: 0.9637 - val_loss: 17.2692 - val_accuracy: 0.7300\n",
      "Epoch 1864/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.1133 - accuracy: 0.9611 - val_loss: 15.7533 - val_accuracy: 0.7478\n",
      "Epoch 1865/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.0900 - accuracy: 0.9682 - val_loss: 18.4241 - val_accuracy: 0.7418\n",
      "Epoch 1866/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.0961 - accuracy: 0.9650 - val_loss: 18.0784 - val_accuracy: 0.7389\n",
      "Epoch 1867/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.0978 - accuracy: 0.9656 - val_loss: 18.2844 - val_accuracy: 0.7359\n",
      "Epoch 1868/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.0886 - accuracy: 0.9675 - val_loss: 20.6691 - val_accuracy: 0.7300\n",
      "Epoch 1869/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.0884 - accuracy: 0.9656 - val_loss: 20.4299 - val_accuracy: 0.7300\n",
      "Epoch 1870/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.1113 - accuracy: 0.9567 - val_loss: 18.7174 - val_accuracy: 0.7448\n",
      "Epoch 1871/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1093 - accuracy: 0.9592 - val_loss: 20.2174 - val_accuracy: 0.7240\n",
      "Epoch 1872/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.0945 - accuracy: 0.9631 - val_loss: 21.0380 - val_accuracy: 0.7329\n",
      "Epoch 1873/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1069 - accuracy: 0.9605 - val_loss: 17.3349 - val_accuracy: 0.7359\n",
      "Epoch 1874/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1472 - accuracy: 0.9433 - val_loss: 16.1242 - val_accuracy: 0.7478\n",
      "Epoch 1875/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1094 - accuracy: 0.9573 - val_loss: 15.9967 - val_accuracy: 0.7300\n",
      "Epoch 1876/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.0865 - accuracy: 0.9682 - val_loss: 18.6403 - val_accuracy: 0.7359\n",
      "Epoch 1877/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1244 - accuracy: 0.9586 - val_loss: 18.1355 - val_accuracy: 0.7418\n",
      "Epoch 1878/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.5398 - accuracy: 0.8166 - val_loss: 2.6068 - val_accuracy: 0.6944\n",
      "Epoch 1879/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.4013 - accuracy: 0.8166 - val_loss: 3.9311 - val_accuracy: 0.7329\n",
      "Epoch 1880/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.3112 - accuracy: 0.8764 - val_loss: 6.2086 - val_accuracy: 0.7507\n",
      "Epoch 1881/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2800 - accuracy: 0.8911 - val_loss: 4.6255 - val_accuracy: 0.7359\n",
      "Epoch 1882/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2532 - accuracy: 0.9038 - val_loss: 6.3741 - val_accuracy: 0.7478\n",
      "Epoch 1883/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2389 - accuracy: 0.9076 - val_loss: 7.1987 - val_accuracy: 0.7507\n",
      "Epoch 1884/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.2595 - accuracy: 0.9025 - val_loss: 6.3028 - val_accuracy: 0.7567\n",
      "Epoch 1885/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.2347 - accuracy: 0.9096 - val_loss: 8.0796 - val_accuracy: 0.7537\n",
      "Epoch 1886/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.2164 - accuracy: 0.9204 - val_loss: 9.2761 - val_accuracy: 0.7478\n",
      "Epoch 1887/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.2182 - accuracy: 0.9172 - val_loss: 14.6175 - val_accuracy: 0.7596\n",
      "Epoch 1888/2000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1997 - accuracy: 0.9274 - val_loss: 17.0330 - val_accuracy: 0.7389\n",
      "Epoch 1889/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2606 - accuracy: 0.9051 - val_loss: 12.0935 - val_accuracy: 0.7389\n",
      "Epoch 1890/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1972 - accuracy: 0.9312 - val_loss: 14.1545 - val_accuracy: 0.7418\n",
      "Epoch 1891/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1846 - accuracy: 0.9338 - val_loss: 13.3926 - val_accuracy: 0.7448\n",
      "Epoch 1892/2000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.1775 - accuracy: 0.9395 - val_loss: 15.3718 - val_accuracy: 0.7389\n",
      "Epoch 1893/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1605 - accuracy: 0.9465 - val_loss: 18.0951 - val_accuracy: 0.7329\n",
      "Epoch 1894/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1951 - accuracy: 0.9338 - val_loss: 16.5806 - val_accuracy: 0.7507\n",
      "Epoch 1895/2000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1829 - accuracy: 0.9331 - val_loss: 16.2004 - val_accuracy: 0.7448\n",
      "Epoch 1896/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1415 - accuracy: 0.9490 - val_loss: 17.4353 - val_accuracy: 0.7478\n",
      "Epoch 1897/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1254 - accuracy: 0.9554 - val_loss: 21.1643 - val_accuracy: 0.7240\n",
      "Epoch 1898/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1285 - accuracy: 0.9535 - val_loss: 22.2818 - val_accuracy: 0.7507\n",
      "Epoch 1899/2000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.3916 - accuracy: 0.9153 - val_loss: 11.0893 - val_accuracy: 0.7181\n",
      "Epoch 1900/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2793 - accuracy: 0.8968 - val_loss: 13.3886 - val_accuracy: 0.7507\n",
      "Epoch 1901/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.2511 - accuracy: 0.9038 - val_loss: 6.3850 - val_accuracy: 0.7270\n",
      "Epoch 1902/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.1935 - accuracy: 0.9255 - val_loss: 8.0050 - val_accuracy: 0.7389\n",
      "Epoch 1903/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2177 - accuracy: 0.9287 - val_loss: 7.5392 - val_accuracy: 0.7626\n",
      "Epoch 1904/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1404 - accuracy: 0.9535 - val_loss: 9.7523 - val_accuracy: 0.7359\n",
      "Epoch 1905/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.1453 - accuracy: 0.9535 - val_loss: 10.1236 - val_accuracy: 0.7507\n",
      "Epoch 1906/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.1388 - accuracy: 0.9510 - val_loss: 10.2388 - val_accuracy: 0.7567\n",
      "Epoch 1907/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1418 - accuracy: 0.9510 - val_loss: 9.7850 - val_accuracy: 0.7389\n",
      "Epoch 1908/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.1707 - accuracy: 0.9338 - val_loss: 10.3393 - val_accuracy: 0.7389\n",
      "Epoch 1909/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1411 - accuracy: 0.9503 - val_loss: 12.7663 - val_accuracy: 0.7418\n",
      "Epoch 1910/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1161 - accuracy: 0.9586 - val_loss: 14.2012 - val_accuracy: 0.7359\n",
      "Epoch 1911/2000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.1162 - accuracy: 0.9618 - val_loss: 14.6951 - val_accuracy: 0.7151\n",
      "Epoch 1912/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.1426 - accuracy: 0.9497 - val_loss: 13.4468 - val_accuracy: 0.7507\n",
      "Epoch 1913/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1341 - accuracy: 0.9510 - val_loss: 13.7938 - val_accuracy: 0.7329\n",
      "Epoch 1914/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.1102 - accuracy: 0.9611 - val_loss: 15.3101 - val_accuracy: 0.7270\n",
      "Epoch 1915/2000\n",
      "1570/1570 [==============================] - 0s 203us/sample - loss: 0.1140 - accuracy: 0.9605 - val_loss: 16.2030 - val_accuracy: 0.7389\n",
      "Epoch 1916/2000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.1150 - accuracy: 0.9580 - val_loss: 15.0720 - val_accuracy: 0.7359\n",
      "Epoch 1917/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1107 - accuracy: 0.9586 - val_loss: 15.2210 - val_accuracy: 0.7448\n",
      "Epoch 1918/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1101 - accuracy: 0.9631 - val_loss: 14.3723 - val_accuracy: 0.7329\n",
      "Epoch 1919/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.0999 - accuracy: 0.9656 - val_loss: 14.8086 - val_accuracy: 0.7418\n",
      "Epoch 1920/2000\n",
      "1570/1570 [==============================] - 0s 198us/sample - loss: 0.0987 - accuracy: 0.9675 - val_loss: 16.4054 - val_accuracy: 0.7300\n",
      "Epoch 1921/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.0982 - accuracy: 0.9682 - val_loss: 16.8538 - val_accuracy: 0.7389\n",
      "Epoch 1922/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.4786 - accuracy: 0.8707 - val_loss: 3.7417 - val_accuracy: 0.7478\n",
      "Epoch 1923/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.4430 - accuracy: 0.8541 - val_loss: 6.8804 - val_accuracy: 0.7478\n",
      "Epoch 1924/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.3211 - accuracy: 0.8752 - val_loss: 6.2175 - val_accuracy: 0.7715\n",
      "Epoch 1925/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.2861 - accuracy: 0.8936 - val_loss: 7.2512 - val_accuracy: 0.7537\n",
      "Epoch 1926/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.2640 - accuracy: 0.8949 - val_loss: 8.3031 - val_accuracy: 0.7834\n",
      "Epoch 1927/2000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2355 - accuracy: 0.9051 - val_loss: 9.4643 - val_accuracy: 0.7774\n",
      "Epoch 1928/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.2208 - accuracy: 0.9102 - val_loss: 11.4137 - val_accuracy: 0.7685\n",
      "Epoch 1929/2000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.2124 - accuracy: 0.9146 - val_loss: 10.0231 - val_accuracy: 0.7774\n",
      "Epoch 1930/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1986 - accuracy: 0.9178 - val_loss: 10.8160 - val_accuracy: 0.7685\n",
      "Epoch 1931/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1956 - accuracy: 0.9159 - val_loss: 11.2876 - val_accuracy: 0.7537\n",
      "Epoch 1932/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2277 - accuracy: 0.9038 - val_loss: 9.9833 - val_accuracy: 0.7685\n",
      "Epoch 1933/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2070 - accuracy: 0.9223 - val_loss: 9.5595 - val_accuracy: 0.7389\n",
      "Epoch 1934/2000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1981 - accuracy: 0.9261 - val_loss: 10.5417 - val_accuracy: 0.7567\n",
      "Epoch 1935/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2003 - accuracy: 0.9159 - val_loss: 9.9887 - val_accuracy: 0.7626\n",
      "Epoch 1936/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.2451 - accuracy: 0.9013 - val_loss: 10.6954 - val_accuracy: 0.7478\n",
      "Epoch 1937/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.1822 - accuracy: 0.9261 - val_loss: 10.6119 - val_accuracy: 0.7507\n",
      "Epoch 1938/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1746 - accuracy: 0.9331 - val_loss: 12.2152 - val_accuracy: 0.7685\n",
      "Epoch 1939/2000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.4080 - accuracy: 0.9223 - val_loss: 8.3292 - val_accuracy: 0.7804\n",
      "Epoch 1940/2000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.3470 - accuracy: 0.8662 - val_loss: 3.8672 - val_accuracy: 0.7626\n",
      "Epoch 1941/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.2538 - accuracy: 0.9025 - val_loss: 5.1290 - val_accuracy: 0.7567\n",
      "Epoch 1942/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2221 - accuracy: 0.9140 - val_loss: 6.8155 - val_accuracy: 0.7567\n",
      "Epoch 1943/2000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.2130 - accuracy: 0.9172 - val_loss: 6.3477 - val_accuracy: 0.7537\n",
      "Epoch 1944/2000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.2466 - accuracy: 0.9096 - val_loss: 7.1812 - val_accuracy: 0.7537\n",
      "Epoch 1945/2000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.3676 - accuracy: 0.8439 - val_loss: 5.5566 - val_accuracy: 0.7418\n",
      "Epoch 1946/2000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.2188 - accuracy: 0.9115 - val_loss: 6.2498 - val_accuracy: 0.7507\n",
      "Epoch 1947/2000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.1897 - accuracy: 0.9255 - val_loss: 8.8632 - val_accuracy: 0.7359\n",
      "Epoch 1948/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1855 - accuracy: 0.9261 - val_loss: 8.4882 - val_accuracy: 0.7478\n",
      "Epoch 1949/2000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.1781 - accuracy: 0.9344 - val_loss: 9.3135 - val_accuracy: 0.7567\n",
      "Epoch 1950/2000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1678 - accuracy: 0.9408 - val_loss: 9.1558 - val_accuracy: 0.7418\n",
      "Epoch 1951/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.2017 - accuracy: 0.9197 - val_loss: 10.1732 - val_accuracy: 0.7418\n",
      "Epoch 1952/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1910 - accuracy: 0.9287 - val_loss: 9.1160 - val_accuracy: 0.7300\n",
      "Epoch 1953/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1749 - accuracy: 0.9274 - val_loss: 9.4418 - val_accuracy: 0.7448\n",
      "Epoch 1954/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.1645 - accuracy: 0.9382 - val_loss: 9.9172 - val_accuracy: 0.7329\n",
      "Epoch 1955/2000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1727 - accuracy: 0.9338 - val_loss: 10.1483 - val_accuracy: 0.7359\n",
      "Epoch 1956/2000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1766 - accuracy: 0.9357 - val_loss: 8.6381 - val_accuracy: 0.7418\n",
      "Epoch 1957/2000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1768 - accuracy: 0.9376 - val_loss: 9.8712 - val_accuracy: 0.7270\n",
      "Epoch 1958/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1647 - accuracy: 0.9408 - val_loss: 13.1815 - val_accuracy: 0.7448\n",
      "Epoch 1959/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.1556 - accuracy: 0.9369 - val_loss: 13.7015 - val_accuracy: 0.7418\n",
      "Epoch 1960/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.1555 - accuracy: 0.9484 - val_loss: 13.0874 - val_accuracy: 0.7181\n",
      "Epoch 1961/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1471 - accuracy: 0.9471 - val_loss: 13.5540 - val_accuracy: 0.7478\n",
      "Epoch 1962/2000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.1385 - accuracy: 0.9459 - val_loss: 14.6650 - val_accuracy: 0.7389\n",
      "Epoch 1963/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1447 - accuracy: 0.9471 - val_loss: 14.1274 - val_accuracy: 0.7181\n",
      "Epoch 1964/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1431 - accuracy: 0.9465 - val_loss: 14.6252 - val_accuracy: 0.7359\n",
      "Epoch 1965/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.1488 - accuracy: 0.9408 - val_loss: 17.1601 - val_accuracy: 0.7359\n",
      "Epoch 1966/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.1383 - accuracy: 0.9459 - val_loss: 16.3616 - val_accuracy: 0.7389\n",
      "Epoch 1967/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.1397 - accuracy: 0.9427 - val_loss: 16.6213 - val_accuracy: 0.7389\n",
      "Epoch 1968/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.1362 - accuracy: 0.9497 - val_loss: 16.2161 - val_accuracy: 0.7507\n",
      "Epoch 1969/2000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.1573 - accuracy: 0.9369 - val_loss: 16.7388 - val_accuracy: 0.7359\n",
      "Epoch 1970/2000\n",
      "1570/1570 [==============================] - 0s 201us/sample - loss: 0.1400 - accuracy: 0.9471 - val_loss: 18.6925 - val_accuracy: 0.7270\n",
      "Epoch 1971/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.1735 - accuracy: 0.9401 - val_loss: 16.9658 - val_accuracy: 0.7596\n",
      "Epoch 1972/2000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.1778 - accuracy: 0.9306 - val_loss: 17.6207 - val_accuracy: 0.7359\n",
      "Epoch 1973/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1562 - accuracy: 0.9459 - val_loss: 17.2083 - val_accuracy: 0.7359\n",
      "Epoch 1974/2000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1286 - accuracy: 0.9567 - val_loss: 18.1461 - val_accuracy: 0.7359\n",
      "Epoch 1975/2000\n",
      "1570/1570 [==============================] - 0s 194us/sample - loss: 0.1187 - accuracy: 0.9561 - val_loss: 19.3485 - val_accuracy: 0.7448\n",
      "Epoch 1976/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570/1570 [==============================] - 0s 188us/sample - loss: 0.1965 - accuracy: 0.9287 - val_loss: 15.1871 - val_accuracy: 0.7507\n",
      "Epoch 1977/2000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.1494 - accuracy: 0.9490 - val_loss: 16.3357 - val_accuracy: 0.7507\n",
      "Epoch 1978/2000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.1267 - accuracy: 0.9548 - val_loss: 20.3154 - val_accuracy: 0.7300\n",
      "Epoch 1979/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.1160 - accuracy: 0.9605 - val_loss: 19.2770 - val_accuracy: 0.7448\n",
      "Epoch 1980/2000\n",
      "1570/1570 [==============================] - 0s 208us/sample - loss: 0.1185 - accuracy: 0.9567 - val_loss: 19.3452 - val_accuracy: 0.7448\n",
      "Epoch 1981/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.2314 - accuracy: 0.9191 - val_loss: 11.6570 - val_accuracy: 0.7478\n",
      "Epoch 1982/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.1782 - accuracy: 0.9376 - val_loss: 12.7653 - val_accuracy: 0.7567\n",
      "Epoch 1983/2000\n",
      "1570/1570 [==============================] - 0s 187us/sample - loss: 0.1554 - accuracy: 0.9459 - val_loss: 13.3891 - val_accuracy: 0.7448\n",
      "Epoch 1984/2000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 0.1625 - accuracy: 0.9350 - val_loss: 16.2570 - val_accuracy: 0.7448\n",
      "Epoch 1985/2000\n",
      "1570/1570 [==============================] - 0s 196us/sample - loss: 0.1343 - accuracy: 0.9497 - val_loss: 16.0853 - val_accuracy: 0.7240\n",
      "Epoch 1986/2000\n",
      "1570/1570 [==============================] - 0s 211us/sample - loss: 0.1186 - accuracy: 0.9567 - val_loss: 17.7569 - val_accuracy: 0.7300\n",
      "Epoch 1987/2000\n",
      "1570/1570 [==============================] - 0s 199us/sample - loss: 0.1026 - accuracy: 0.9605 - val_loss: 17.8548 - val_accuracy: 0.7300\n",
      "Epoch 1988/2000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 0.1577 - accuracy: 0.9363 - val_loss: 19.6112 - val_accuracy: 0.7181\n",
      "Epoch 1989/2000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.1300 - accuracy: 0.9497 - val_loss: 17.4663 - val_accuracy: 0.7300\n",
      "Epoch 1990/2000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.1294 - accuracy: 0.9567 - val_loss: 15.4775 - val_accuracy: 0.7359\n",
      "Epoch 1991/2000\n",
      "1570/1570 [==============================] - 0s 242us/sample - loss: 0.1220 - accuracy: 0.9554 - val_loss: 17.7924 - val_accuracy: 0.7329\n",
      "Epoch 1992/2000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.1137 - accuracy: 0.9592 - val_loss: 19.6843 - val_accuracy: 0.7211\n",
      "Epoch 1993/2000\n",
      "1570/1570 [==============================] - 0s 196us/sample - loss: 0.1322 - accuracy: 0.9503 - val_loss: 16.4096 - val_accuracy: 0.7478\n",
      "Epoch 1994/2000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.1470 - accuracy: 0.9452 - val_loss: 17.3734 - val_accuracy: 0.7300\n",
      "Epoch 1995/2000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 0.1118 - accuracy: 0.9611 - val_loss: 18.9887 - val_accuracy: 0.7329\n",
      "Epoch 1996/2000\n",
      "1570/1570 [==============================] - 0s 201us/sample - loss: 0.1095 - accuracy: 0.9599 - val_loss: 21.2128 - val_accuracy: 0.7181\n",
      "Epoch 1997/2000\n",
      "1570/1570 [==============================] - 0s 195us/sample - loss: 0.1400 - accuracy: 0.9471 - val_loss: 19.2667 - val_accuracy: 0.7211\n",
      "Epoch 1998/2000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.1306 - accuracy: 0.9503 - val_loss: 18.3312 - val_accuracy: 0.7240\n",
      "Epoch 1999/2000\n",
      "1570/1570 [==============================] - 0s 198us/sample - loss: 0.1181 - accuracy: 0.9567 - val_loss: 21.9336 - val_accuracy: 0.7122\n",
      "Epoch 2000/2000\n",
      "1570/1570 [==============================] - 0s 194us/sample - loss: 0.1106 - accuracy: 0.9573 - val_loss: 21.2116 - val_accuracy: 0.7359\n",
      "Model Accuracy: 0.7359050512313843\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfit checks:\n",
      "Model Accuracy: 0.9656050801277161\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(\"-------------------------- Data from the paper ------------------------------------\")\n",
    "frame = load_frame()\n",
    "data_x, data_y, number_of_features = load_all_data(frame)\n",
    "x_train, y_train, x_test, y_test, x_validate, y_validate = median(data_x, data_y, frame)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dense(number_of_features, activation='relu', input_dim=number_of_features))\n",
    "model.add(keras.layers.Dense(40, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "model.add(keras.layers.Dense(20, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping_monitor = keras.callbacks.EarlyStopping(patience=40,restore_best_weights=True)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=1000, verbose=0,\n",
    "          validation_data=(x_validate, y_validate), callbacks=[early_stopping_monitor])\n",
    "\n",
    "silent_evaluation(model, x_test, y_test)\n",
    "plot_graphs(history)\n",
    "print(\"Overfit checks:\")\n",
    "silent_evaluation(model, x_train, y_train)\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"-------------------------- Data from the paper + mine ------------------------------------\")\n",
    "\n",
    "frame = load_frame()\n",
    "data_x, data_y, number_of_features = load_all_data_with_mine(frame)\n",
    "x_train, y_train, x_test, y_test, x_validate, y_validate = median(data_x, data_y, frame)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dense(number_of_features, activation='relu', input_dim=number_of_features))\n",
    "model.add(keras.layers.Dense(40, activation='relu'))\n",
    "model.add(keras.layers.Dense(20, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping_monitor = keras.callbacks.EarlyStopping(patience=40,restore_best_weights=True)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=2000, verbose=1,\n",
    "          validation_data=(x_test, y_test))#, callbacks=[early_stopping_monitor])\n",
    "\n",
    "silent_evaluation(model, x_test, y_test)\n",
    "plot_graphs(history)\n",
    "print(\"Overfit checks:\")\n",
    "silent_evaluation(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Data from the paper + mine ------------------------------------\n",
      "(1570, 83)\n",
      "Model Accuracy: 0.7982195615768433\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZxcZZ3v8c+vt+z7QgJJSMImASGGFkFgABUERNGRUXJFEdEMM3p1Bp0RRmdARhz0ioDLgFECqBhBFkXkgphRGe6wdTDEkBASIEsnTbrTWTqk00tV/e4f51R1VXV1eqmqru463/frVa+u85ztOXWS+tWznOcxd0dERASgotQZEBGRoUNBQUREUhQUREQkRUFBRERSFBRERCRFQUFERFIUFET6yczmmpmbWVUftv2kmT2V73FEBouCgpQ1M9tkZh1mNjUrfVX4hTy3NDkTGZoUFCQKXgcWJxfM7K3AqNJlR2ToUlCQKPgp8Im05cuAn6RvYGYTzOwnZtZkZpvN7KtmVhGuqzSzb5vZTjN7DXhfjn3vMLMGM9tmZl83s8r+ZtLMDjWzh81sl5ltNLPPpK072czqzKzFzHaY2XfC9JFm9jMzazazPWb2vJkd0t9ziyQpKEgUPAOMN7Njwy/rjwI/y9rme8AEYD5wJkEQuTxc9xngQuBtQC1wcda+dwMx4Mhwm3OBTw8gn8uBeuDQ8BzfMLN3h+tuBW519/HAEcB9YfplYb5nA1OAK4EDAzi3CKCgINGRLC2cA7wMbEuuSAsU17j7PnffBNwEfDzc5CPALe6+1d13Af+Rtu8hwPnAP7j7fndvBG4GLulP5sxsNnA68GV3b3P3VcCP0/LQCRxpZlPd/U13fyYtfQpwpLvH3X2lu7f059wi6RQUJCp+Cvwv4JNkVR0BU4EaYHNa2mbgsPD9ocDWrHVJhwPVQENYfbMH+CEwvZ/5OxTY5e77esjDFcDRwMthFdGFadf1OPALM9tuZt8ys+p+nlskRUFBIsHdNxM0OF8APJi1eifBL+7D09Lm0FWaaCConklfl7QVaAemuvvE8DXe3Y/rZxa3A5PNbFyuPLj7BndfTBBsvgncb2Zj3L3T3b/m7guAdxJUc30CkQFSUJAouQJ4l7vvT0909zhBHf0NZjbOzA4HrqKr3eE+4PNmNsvMJgFXp+3bAPwOuMnMxptZhZkdYWZn9idj7r4V+B/gP8LG4xPC/N4DYGaXmtk0d08Ae8Ld4mZ2tpm9NawCayEIbvH+nFsknYKCRIa7v+rudT2s/t/AfuA14Cng58CycN2PCKpoXgReoHtJ4xME1U9rgd3A/cDMAWRxMTCXoNTwEHCtuz8RrjsPeMnM3iRodL7E3duAGeH5WoB1wJ/o3ogu0memSXZERCRJJQUREUlRUBARkRQFBRERSVFQEBGRlGE9ZO/UqVN97ty5pc6GiMiwsnLlyp3uPi3XumEdFObOnUtdXU89DEVEJBcz29zTOlUfiYhIioKCiIikFC0omNkyM2s0szVpafeGM16tCmfEWhWmzzWzA2nrbi9WvkREpGfFbFO4C/g+aSNSuvtHk+/N7CZgb9r2r7r7wnxP2tnZSX19PW1tbfkeatgYOXIks2bNorpag2OKSH6KFhTc/cme5r81MyMYo/5dhT5vfX0948aNY+7cuQSnKW/uTnNzM/X19cybN6/U2RGRYa5UbQpnADvcfUNa2jwz+7OZ/cnMzhjogdva2pgyZUokAgKAmTFlypRIlYxEpHhK1SV1McHUg0kNwBx3bzazk4BfmdlxuWaQMrMlwBKAOXPmZK9OblP4HA9hUbteESmeQS8pmFkV8NfAvck0d2939+bw/UrgVYJZprpx96XuXuvutdOm5Xz2oledsQRv7G2jrVPDzouIpCtF9dF7gJfdvT6ZYGbTwklCMLP5wFEE49oXRWciQeO+NjpiiYIfu7m5mYULF7Jw4UJmzJjBYYcdllru6Ojo0zEuv/xy1q9fX/C8iYj0pmjVR2a2HDgLmGpm9QQThtxBMKH58qzN/wq43sxiBLNGXRlOkD7sTJkyhVWrVgFw3XXXMXbsWL70pS9lbOPuuDsVFblj8p133ln0fIqI5FK0koK7L3b3me5e7e6zwoCAu3/S3W/P2vYBdz/O3U9090Xu/pti5atUNm7cyPHHH8+VV17JokWLaGhoYMmSJdTW1nLcccdx/fXXp7Y9/fTTWbVqFbFYjIkTJ3L11Vdz4okncuqpp9LY2FjCqxCRcjesxz7qzdd+8xJrt3drqybhzoGOOCOrK6ms6F8j7YJDx3Pt+/s7J3tg7dq13Hnnndx+exATb7zxRiZPnkwsFuPss8/m4osvZsGCBRn77N27lzPPPJMbb7yRq666imXLlnH11VfnOryISN40zMUgOuKII3j729+eWl6+fDmLFi1i0aJFrFu3jrVr13bbZ9SoUZx//vkAnHTSSWzatGmwsisiEVTWJYWeftG3dsTY2Pgmc6eMYfyowXsKeMyYMan3GzZs4NZbb+W5555j4sSJXHrppTmfNaipqUm9r6ysJBaLDUpeRSSaIllSGAq9+ltaWhg3bhzjx4+noaGBxx9/vNRZEhEp75JCb7yE5160aBELFizg+OOPZ/78+Zx22mklzI2ISMDcS/nVmJ/a2lrPnmRn3bp1HHvssQfd70BHjA2Nb3L4lDFMGMTqo2Lqy3WLiACY2Up3r821LpLVRyIikpuCgoiIpJRlUOi9SmwoNDUXznCuAhSRoaXsgsLIkSNpbm7u4xfl8P8yTc6nMHLkyFJnRUTKQNn1Ppo1axb19fU0NTX1uE1nPMGOlnZizTWMqqkcxNwVR3LmNRGRfJVdUKiuru51BrJ1DS185mf/zW0fW8T5x84cpJyJiAx9ZVd91Beak0ZEJLdIBoWk4d+iICJSWJEMClZmvY9ERAolkkEhST05RUQyRTIoqE1BRCS3SAaFJFergohIhkgGBRUURERyi2RQSFKbgohIpqIFBTNbZmaNZrYmLe06M9tmZqvC1wVp664xs41mtt7M3lusfAXnKubRRUSGr2KWFO4CzsuRfrO7LwxfjwKY2QLgEuC4cJ//NLOijz+hgoKISKaiBQV3fxLY1cfNLwJ+4e7t7v46sBE4uVh5U6uCiEhupWhT+JyZrQ6rlyaFaYcBW9O2qQ/TujGzJWZWZ2Z1Bxv0ri805LSISKbBDgq3AUcAC4EG4KYwPddP95zf2O6+1N1r3b122rRpA8qE2hRERHIb1KDg7jvcPe7uCeBHdFUR1QOz0zadBWwvVj4UE0REchvUoGBm6eNUfwhI9kx6GLjEzEaY2TzgKOC5YudHtUciIpmKNp+CmS0HzgKmmlk9cC1wlpktJKga2gT8LYC7v2Rm9wFrgRjwWXePFzFvxTq0iMiwVrSg4O6LcyTfcZDtbwBuKFZ+cp5TnVJFRDJE8olmlRNERHKLZFBIUpuCiEimSAYFNSmIiOQWyaCQpJKCiEimSAYFTccpIpJbJINCkgoKIiKZIhkU1KYgIpJbJINCkgbEExHJFOmgICIimSIdFFROEBHJFMmgoDYFEZHcIhkUUlRUEBHJEMmgkBwlVQPiiYhkimZQKHUGRESGqEgGhST1SBURyRTJoKCGZhGR3CIZFJJUUBARyRTJoKAB8UREcotkUEhSm4KISKZIBgW1KYiI5Fa0oGBmy8ys0czWpKX9HzN72cxWm9lDZjYxTJ9rZgfMbFX4ur1Y+Uqn5xRERDIVs6RwF3BeVtoTwPHufgLwCnBN2rpX3X1h+LqyiPlSi4KISA+KFhTc/UlgV1ba79w9Fi4+A8wq1vn7Qm0KIiKZStmm8Cng/6YtzzOzP5vZn8zsjJ52MrMlZlZnZnVNTU0DO7OKCiIiOZUkKJjZV4AYcE+Y1ADMcfe3AVcBPzez8bn2dfel7l7r7rXTpk3LKx8qKIiIZBr0oGBmlwEXAh/zcOozd2939+bw/UrgVeDoouVBRQURkZwGNSiY2XnAl4EPuHtrWvo0M6sM388HjgJeK3qG1KggIpKhqlgHNrPlwFnAVDOrB64l6G00AngiHL76mbCn0V8B15tZDIgDV7r7rpwHLkjeinVkEZHhrWhBwd0X50i+o4dtHwAeKFZeeqJygohIpmg+0VzqDIiIDFGRDApJalIQEckUyaCQmo5TUUFEJEM0g0KpMyAiMkRFMigkqZwgIpIpkkFBXVJFRHKLZFBIUpOCiEimSAYFDXMhIpJbJINCkgoKIiKZohkUVFAQEckpmkEhpOcUREQyRTIoqPeRiEhukQwKIiKSWySDggoKIiK5RTIoJKlJQUQkUySDgqlRQUQkp0gGhSTXkwoiIhkiGRRUThARyS2SQSFJbQoiIpkiGRSSTQqKCSIimYoaFMxsmZk1mtmatLTJZvaEmW0I/04K083MvmtmG81stZktKlq+VIEkIpJTsUsKdwHnZaVdDaxw96OAFeEywPnAUeFrCXBbkfOm6iMRkSxFDQru/iSwKyv5IuDu8P3dwAfT0n/igWeAiWY2sxj5Uo9UEZHcStGmcIi7NwCEf6eH6YcBW9O2qw/TMpjZEjOrM7O6pqamvDKiLqkiIpmGUkNzrt/v3b613X2pu9e6e+20adMGIVsiItFRiqCwI1ktFP5tDNPrgdlp280CthczI2pTEBHJVIqg8DBwWfj+MuDXaemfCHshnQLsTVYzFZraFEREcqsq5sHNbDlwFjDVzOqBa4EbgfvM7ApgC/A34eaPAhcAG4FW4PJi5k1ERLoralBw98U9rHp3jm0d+Gwx85Ok5xRERHIbSg3Ng07TcYqIZOpTUDCzI8xsRPj+LDP7vJlNLG7WikdtCiIiufW1pPAAEDezI4E7gHnAz4uWq0GigoKISKa+BoWEu8eADwG3uPs/AkV52ngwqKAgIpJbX4NCp5ktJuhC+kiYVl2cLA0eFRRERDL1NShcDpwK3ODur5vZPOBnxctWcWk6ThGR3PrUJdXd1wKfBwiHuh7n7jcWM2ODQW0KIiKZ+tr76I9mNt7MJgMvAnea2XeKm7XiSZYTCjEgXltnnJ8/u0XdW0WkLPS1+miCu7cAfw3c6e4nAe8pXraGj28/vp5/eegv/G7tjlJnRUQkb30NClXh4HUfoauhedhKTcdZgB/3zfs7ANjfHsv/YCIiJdbXoHA98Djwqrs/b2bzgQ3Fy1ZxqaFZRCS3vjY0/xL4Zdrya8CHi5WpwaJWABGRTH1taJ5lZg+ZWaOZ7TCzB8xsVrEzJyIig6uv1Ud3Esx3cCjBFJm/CdOGtwL2GFLnIxEpB30NCtPc/U53j4Wvu4BhPRdmoZoV1DohIuWkr0Fhp5ldamaV4etSoLmYGRsM+nEvIpKpr0HhUwTdUd8AGoCLGeYzo+kXvohId30KCu6+xd0/4O7T3H26u3+Q4EG2YU3tACIimfKZee2qguWiBPSsgohId/nM0Tygb1UzOwa4Ny1pPvBvwETgM0BTmP4v7v5oHvnrVSHGPuo6lojI8JdPUBjQ96C7rwcWAphZJbANeIigjeJmd/92Hnnqs4KVE1TgEJEyctCgYGb7yP3lb8CoApz/3QRDZ2wuRXWO2hRERDIdtE3B3ce5+/gcr3Hunk8pI+kSYHna8ufMbLWZLQvnbejGzJaYWZ2Z1TU1NeXapE/UpCAi0l0+Dc15MbMa4AN0jal0G3AEQdVSA3BTrv3cfam717p77bRp+T0/p4KCiEimkgUF4HzgBXffAeDuO9w97u4J4EfAycU8uakxQESkm1IGhcWkVR2F8zUkfQhYU+wMqE1BRCRTIdoF+s3MRgPnAH+blvwtM1tIUKuzKWtdETJR4C6pijAiUgZKEhTcvRWYkpX28cHMQ6Eqj1QNJSLlpJTVR6WnH/ciIhkiGxTUJVVEpLvIBgVQQUFEJFtkg4LaAkREuotsUAD1GBIRyRbZoFDoNgWFFxEpB5ENClCYh9fUYC0i5SSyQUHf5SIi3UU2KICqfEREskU2KGg6ThGR7iIbFKAwbQrqwCQi5SSyQUHlBBGR7iIbFCAYJfU//7iR7XsODPgYqoUSkXIS3aBgsLm5lW89tp4lP60rdW5ERIaE6AYFIJ4IGgT2t8dLnBMRkaEhskHBUJdUEZFskQ0KIiLSXWSDgplpQDwRkSwRDgoFPqDii4iUgcgGhUJRj1QRKSdVpTqxmW0C9gFxIObutWY2GbgXmAtsAj7i7ruLcv5iHFREZJgrdUnhbHdf6O614fLVwAp3PwpYES4XndoWREQCpQ4K2S4C7g7f3w18sFgnChqag/cKCSIigVIGBQd+Z2YrzWxJmHaIuzcAhH+nZ+9kZkvMrM7M6pqamvLKQEIlBBGRDCVrUwBOc/ftZjYdeMLMXu7LTu6+FFgKUFtbO+BvdaOwQcFV3hCRMlCykoK7bw//NgIPAScDO8xsJkD4t7GYeUgk8j+GBsQTkXJSkqBgZmPMbFzyPXAusAZ4GLgs3Owy4NfFy0NmSaGtM54aC0lEJKpKVVI4BHjKzF4EngN+6+6PATcC55jZBuCccLlo4mlB4S3/+hh/f8/KYp5ORGTIK0mbgru/BpyYI70ZePfg5MLILhg8/tKOwTm1iMgQNdS6pA4aM4iHjQrqhCQiEohsUKiuMDpjigYiIukiGxQqK43OeFBSKETXVJU2RKQcRDYoVFVU0BEGhXx6HZlGURKRMhLZoFBZ0VVSiA2hrqgPvlDPn17J70ltEZGBKuUTzSVVVWF0xoNgkBhCQeGq+14EYNON7ytxTkQkiiJbUqiqNDpjhSspDJ2wIiIycJENCpVpbQqxeP7jXaihWUTKQWSDQlWB2xQ0IJ6IlIPIBoXKiq4nmgsx5pFKCiJSDiIbFKoqurqS5lNSSI6SqpggIuUgskFhd2tnYQ+oooKIlIHIBoV1DS0FPZ5CgoiUg8g+p9CTRMKpqOj/U8r5FhT2t8d46M/b8juIiEieFBSyxBJOzYCCQn5R4d8fWcsvnt+a1zFERPIV2eqjnvQ2OJ67s2bb3u7peZ5355sdeR5BRCR/CgpZeuue+utV27nwe0/x2JoGIK33kRoVRKQMKChk6a17auO+NgCee313RrpigoiUAwWFLL+sO3i9/iHjRwLwRsuBjPRkm8LeA52pwNEfphG4RWQIiGxQePTzZ+RM//pv1/H6zv097ldTGXxk+9vjOdef/s3/4uQbVqSWX9iymw98/ynaOnNvLyIylAx6UDCz2Wb2BzNbZ2YvmdkXwvTrzGybma0KXxcUMx8LDh3P/Gljcq7b3x7rcb9k9VJ2dVGyTWFfW+a+1z38Eqvr97L+jX0HzY8KCiIyFJSiS2oM+KK7v2Bm44CVZvZEuO5md//2YGWkqoeupx0HGTU12Ttp2+5W5l79W0ZVVxYlbyIipTDoQcHdG4CG8P0+M1sHHDbY+YBgSs5ckvMs5BILJ+Z5tSmoYjoQVgv1NkpqfxuiB/oQnYhIPkrapmBmc4G3Ac+GSZ8zs9VmtszMJvWwzxIzqzOzuqam/KatrKrM/aWbnJEtl3gPfU976pI60K/19oMEJhGRYilZUDCzscADwD+4ewtwG3AEsJCgJHFTrv3cfam717p77bRp0/LKQ09VPwdrFP7n+1fnTM+3S2p27yM1TItIKZQkKJhZNUFAuMfdHwRw9x3uHnf3BPAj4ORi5+OWSxbymTPmdUtv7eELedNBeiX99OnNOdOzg8Ube9u4+3829Zq3tpiCgogMvlL0PjLgDmCdu38nLX1m2mYfAtYUOy8zJ4ziK+9b0C39QEdmD6J1DS3s2t9B4772Ho+1bc+BHtel+9uf1nHtwy+xPWt7y6poOtChoCAig68UJYXTgI8D78rqfvotM/uLma0Gzgb+cbAydM+n30Ht4V1NGNlfyOff+t+8/3tPHbSrak+y2xT2HAjmcejsZV7otk61KYjI4CtF76OnyN3++uhg5yXptCOnMnXsCN57y5NA7uqjbXsOsL+j/0EhKfnEc0XYeNDbGEuqPhKRUojsE83Zxo3sio8HOuJ8+/H1fGLZc2xu7mpH6E9JIZH1pZ9IBYVgubfeRW2qPhKREtB8CqH0oPC9/9qYen/RD/5f6v2XH/hLn4/XmUgwoqIy1a0oWVtUGUaF7N5F3XofqaQgIiWgkkJoTE3u+LhngHM5Z1cPxRJBVEhWH/XWZtAR07irIjL4FBRChXh6OH32tewH4MKYgCWDQi8lgYMNtSEiUiwKCgWU3k6QXVKIZ7cp9FJ91KEnmkWkBBQUCujNtIboZHVRUrLhuatNobfqIwUFERl8CgoF9P20BupYVvVRsuSQqj7qZRiL3p5jEBEpBgWFNOcfP4Mzjx74eEpbdrWm3ndvaA5LCmE1UW9BQSUFESkFBYU0t116End/quchl35/1ZkH3X9fW1dPpfashuTkcwrJGdvasr70s4e5yKeh+Z5nN7P8uS0D3l9EoktBoR+OnD6WX332tB7Xp8+69ucte3jwhfrUV3084RzoiPNKYzADWyFKCrF4gvvqthLLCiBfeWgN1zzY92cqRESSFBRyWP6ZU7qlffbsIwBYOHsiZxw1Ned+L6dNuflP96/mqvteTI2SmnCnpa0zNe9Ct4bm7N5HfSgp/PDJ1/jn+1fz8Ivbe91WRKQvFBRyOPWIKRwyfkRq+YvnHM2Xzj0mtdzThDq5JIeriMU9Y5iM15reZPHSZ3h+066c+/WlpJDct7pSt1FECkPDXPTgmx8+gZff2Mcn3zmXkVmT8fzrhQtSg+f1JtlNNe6eak8AeOa1ZlraYix98jXmTx3Db1c3ZOzXt+qjIDpld38VERkoBYUenHXMdM46ZnrOdcfMGMeYmkr292HQuuQ8Cz/4w0Y2N3f1TmoJ2x/c4a4ck+6kN1r3JPnAW6sGzxORAlG9wwBNHz8y9f6dR0zpdfv0gJCtIvtxZmDnmx29HjO5X2u7goKIFIaCwgD95FMn89X3Hcsfv3QWP76stl/7zp48KvX+9+t2cOuKDRnrp48bwXOv7+Kq+1bREUvQ1hnn589uofnNzJnfKnopKWQP3y0i0hsFhQGaPXk0nz5jPnOnjmF02girm258H9+6+AQg6MKa7SO1s3jfWw896LHfMnM8HfEED76wjdX1e/jab17iXx76Cyd9/fcZ2yV7KLX2MPnPm3lMCnQw//TLFzOGFBeR8qE2hQK5d8kpjKoJGqQ/Ujubj9TOBuCNvW3c/MQr3Fu3FYCzj5nOkdPHcvufXu3xWOcuOIQnX2kC4OLbn+5xu2S31vqw3WJ/e4y7n96UWv+X+r2cdmTQffbfH1nLQ3/exgv/es7ALjDNL1fWA8GosJaj6ktEhi+VFArkHfOncMKsid3SZ0wYyb+9fwFL/mo+AIdOHMVRh4zj/SceytgRmTH5whNm8vQ17+Kjb5/NxSfNynme5ENve1o7UtVGq7bsobGljVtXbOBbj61PbXvlz1YCQUnijqdeZ9f+DlrCBuzGlrZeH6Drzfa9bXntLyJDj3l/Ot0PAjM7D7gVqAR+7O439rRtbW2t19XVDVre8tW4r43p47oaqN2dJ9bu4Ku/WkPjvnZe/cYFqVFUATY27uM93wm6vr7/xEP5zQAeUrvm/LewqXk/y58LSir3X3kqDvzN7U9z6ISR/P3ZR/LClt1840NvZWR1JRsb32TMiEpmThiVcZzGljYSHgS5uVf/FgjaPr754RNYNGcSE0ZX9ztvPYknnEuWPs1FCw/j0lMOL9hxRSRgZivdPWdj6JAKCmZWCbwCnAPUA88Di919ba7th1tQ6MmBjji7Wjs4bOKobutaO2KMrqkiFk/wm9Xb2dzcyi2/72qY/uI5R3PTE6+klmsqK+iIJ5g6tqZPPZh68p5jD2HymGo6Ygk6E556jmLO5NEZA/8BTBlTww0feivb9hzgsIkjcYd767YybewIjpkxjq27WpkydgQ1VRW8Y95kdrS0MXnMCNa/0cLeA5088MI2bvjg8UwZO4IJo6q5r24r3wmv6fqLjuO0I6cyZUwNDXvbmD15NJ2xBK/tfJPZk0fT1pFgwqhqxo+q6rEq60BHnIQ7o2sqM7YpdPVX0752bvvjq3zx3KPpjCcYVVOZ6hk2cXR1r+dyd1o74rS0dTJ+ZDVjRuRXu7untYOJo2vyOka+3J0nN+zkHfMmd3veJ1+JhLPzzXYmjK6mprKi6FWZ8YTT1hnP+74MBcMpKJwKXOfu7w2XrwFw9//ItX25BIX+auuMU7+7lSOnjwOCB9064gm2NLcydVwNf3i5kYtPms0zrzXzqbue55gZ4/j+4kWs3raHq+59kY54gq9/8Hhe2t6Sc+C8MTWVTBxdQ8PeA4wdUZV6pgJg8pgadu0feLAZDGbBqCFmwTCDcXfcobrSqK6s6OrK2xGjpqoC96B7b8KdCjMqKwyzIM3dU0OVVFYYFdY1dGEyPfl/aHfW1K0VBukdwEbXVDKqurLbhEpJ7Z0J9oUPO46oqmD8qGoqLBgsMZZwEu4Zs/tVWJBPMyOecFo7YowdEezTGU+wu7WTKWNqCvrEe/JzCQZ8NCrC5cqKzM8q+fnvTqvmnD5uROoz7E3yOrs+4/BvmOIOLW2dqXa1mqoKxo2ooqKiK0/Jzyd4H9yLRPhvIftcHh4z/fieOm+wz/6OGJ1xz/njLdcl5brKXIEr56fRh+Odfcx0vnrhglx792o4BYWLgfPc/dPh8seBd7j759K2WQIsAZgzZ85JmzdvLkleh7P2WJwRVV2/2hIJp7Uzzqjqyozqq6T63a3sae3kmBnjqDBj7fYWjp4xlq27DgDOxsb91O9upaaqgkmja+iMJ5gxfiTHzBjHpuZW9rV10rivnU0793PYpFHsb48xa9JoZk4YSf3uA+xvjzGyupL9HTHcg5LHW2aOpzOeYHX93lS33Dda2pg4Oii9bGlu5ZgZ45g4uprGlnZiifC/c9Z/cHcYUVVJTVUFLW2dxOIJ4glSJYdYwjELPoOKCiORcBIe/CrMLkkk3FOj3SYlQ0Rys+c37ebkuZPYvKuV8SOrae2IMaK6kjlhCedAD+04Ht6HlrZORtdUYUBVZQUenrOyooKqiq5zJa8v4ckvUGNEVVBKdHfiCWf9G/t4y4zxA/tH0lK+l+YAAAcCSURBVIOEO3H31K/+5Lniia5gnLye5Ee1rqGFhXMm4u7E4sH2WPeRgZOSn6V1W878rM1g4ugaRlVXsr89xr724N9P8jNLDwLxhAfBosJSx3Ecw9J+RJBa7jpP1/oDnXGa9rUzdWzXEDjJzyBbrm/VXF+1ubfr2/EWzZnEFafPy7GmdwcLCkOtHJTrX0nG5+HuS4GlEJQUBiNT5SY9IEDwHyW70TvdrEmjmTWpa/mtsyYAXV1ukyWWXKZk/QfK9rY5kw66/uhDej62iBTeUOt9VA/MTlueBWgIUBGRQTLUgsLzwFFmNs/MaoBLgIdLnCcRkcgYUtVH7h4zs88BjxN0SV3m7i+VOFsiIpExpIICgLs/Cjxa6nyIiETRUKs+EhGRElJQEBGRFAUFERFJUVAQEZGUIfVEc3+ZWROQzyPNU4GdBcrOcBC16wVdc1TomvvncHeflmvFsA4K+TKzup4e9S5HUbte0DVHha65cFR9JCIiKQoKIiKSEvWgsLTUGRhkUbte0DVHha65QCLdpiAiIpmiXlIQEZE0CgoiIpISyaBgZueZ2Xoz22hmV5c6P4ViZrPN7A9mts7MXjKzL4Tpk83sCTPbEP6dFKabmX03/BxWm9mi0l7BwJhZpZn92cweCZfnmdmz4fXeGw7DjpmNCJc3huvnljLf+TCziWZ2v5m9HN7vUyNwn/8x/He9xsyWm9nIcrvXZrbMzBrNbE1aWr/vq5ldFm6/wcwu608eIhcUzKwS+AFwPrAAWGxmA5vodOiJAV9092OBU4DPhtd2NbDC3Y8CVoTLEHwGR4WvJcBtg5/lgvgCsC5t+ZvAzeH17gauCNOvAHa7+5HAzeF2w9WtwGPu/hbgRILrL9v7bGaHAZ8Hat39eIKh9S+h/O71XcB5WWn9uq9mNhm4FngHcDJwbTKQ9ImHk4FH5QWcCjyetnwNcE2p81Wka/01cA6wHpgZps0E1ofvfwgsTts+td1weRHMzrcCeBfwCMGUrjuBquz7TTBPx6nh+6pwOyv1NQzgmscDr2fnvczv82HAVmByeO8eAd5bjvcamAusGeh9BRYDP0xLz9iut1fkSgp0/eNKqg/TykpYXH4b8CxwiLs3AIR/p4eblcNncQvwz0AiXJ4C7HH3WLicfk2p6w3X7w23H27mA03AnWG12Y/NbAxlfJ/dfRvwbWAL0EBw71ZS/vca+n9f87rfUQwKliOtrPrlmtlY4AHgH9y95WCb5kgbNp+FmV0INLr7yvTkHJt6H9YNJ1XAIuA2d38bsJ+uKoVchv11h9UfFwHzgEOBMQTVJ9nK7V4fTE/XmNe1RzEo1AOz05ZnAdtLlJeCM7NqgoBwj7s/GCbvMLOZ4fqZQGOYPtw/i9OAD5jZJuAXBFVItwATzSw5q2D6NaWuN1w/Adg1mBkukHqg3t2fDZfvJwgS5XqfAd4DvO7uTe7eCTwIvJPyv9fQ//ua1/2OYlB4Hjgq7LVQQ9BY9XCJ81QQZmbAHcA6d/9O2qqHgWQPhMsI2hqS6Z8IezGcAuxNFlOHA3e/xt1nuftcgvv4X+7+MeAPwMXhZtnXm/wcLg63H3a/Ht39DWCrmR0TJr0bWEuZ3ufQFuAUMxsd/jtPXnNZ3+tQf+/r48C5ZjYpLGGdG6b1TakbVUrUkHMB8ArwKvCVUuengNd1OkExcTWwKnxdQFCXugLYEP6dHG5vBD2xXgX+QtCzo+TXMcBrPwt4JHw/H3gO2Aj8EhgRpo8MlzeG6+eXOt95XO9CoC68178CJpX7fQa+BrwMrAF+Cowot3sNLCdoM+kk+MV/xUDuK/Cp8No3Apf3Jw8a5kJERFKiWH0kIiI9UFAQEZEUBQUREUlRUBARkRQFBRERSVFQEOmFmcXNbFXaq2Aj65rZ3PQRMUVKrar3TUQi74C7Lyx1JkQGg0oKIgNkZpvM7Jtm9lz4OjJMP9zMVoRj3K8wszlh+iFm9pCZvRi+3hkeqtLMfhTOFfA7MxtVsouSyFNQEOndqKzqo4+mrWtx95OB7xOMu0T4/ifufgJwD/DdMP27wJ/c/USCsYpeCtOPAn7g7scBe4APF/l6RHqkJ5pFemFmb7r72Bzpm4B3uftr4UCEb7j7FDPbSTD+fWeY3uDuU82sCZjl7u1px5gLPOHBBCqY2ZeBanf/evGvTKQ7lRRE8uM9vO9pm1za097HUVuflJCCgkh+Ppr29+nw/f8QjNoK8DHgqfD9CuDvIDWv9PjByqRIX+kXiUjvRpnZqrTlx9w92S11hJk9S/ADa3GY9nlgmZn9E8EMaZeH6V8AlprZFQQlgr8jGBFTZMhQm4LIAIVtCrXuvrPUeREpFFUfiYhIikoKIiKSopKCiIikKCiIiEiKgoKIiKQoKIiISIqCgoiIpPx/MpE3TMGGL7EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfit checks:\n",
      "Model Accuracy: 0.8203821778297424\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------- Data from the paper + mine ------------------------------------\")\n",
    "\n",
    "frame = load_frame()\n",
    "data_x, data_y, number_of_features = load_all_data_with_mine(frame)\n",
    "x_train, y_train, x_test, y_test, x_validate, y_validate = median(data_x, data_y, frame)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dropout(0.05, input_shape=(number_of_features,)))\n",
    "model.add(keras.layers.Dense(40, activation='relu'))\n",
    "model.add(keras.layers.Dense(20, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping_monitor = keras.callbacks.EarlyStopping(patience=40,restore_best_weights=True)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=2000, verbose=1,\n",
    "          validation_data=(x_validate, y_validate))#, callbacks=[early_stopping_monitor])\n",
    "\n",
    "silent_evaluation(model, x_test, y_test)\n",
    "plot_graphs(history)\n",
    "print(\"Overfit checks:\")\n",
    "silent_evaluation(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #2: Take half of the data - Dynamic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Data from the paper ------------------------------------\n",
      "(782, 68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.8392857313156128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfit checks:\n",
      "Model Accuracy: 0.8823529481887817\n",
      "-------------------------- Data from the paper + mine ------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(782, 83)\n",
      "Model Accuracy: 0.9345238208770752\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZxU1Zn/8c/T1Rt0N3uzow2CkUVsCOKaKGoSNTEu40ZiosaEiToxGbOMycz8NJk4MYlxy2KiUdRoNEZjNI7RKEEjUVRQRFbZGmgaodl6o9eq5/fHvV1UdxfI0kUD9/t+vep1b527nVM09dQ5595zzN0REREByOrqDIiIyIFDQUFERJIUFEREJElBQUREkhQUREQkSUFBRESSFBRE9pCZlZiZm1n2bux7hZnN2tfziOwvCgpySDOzMjNrMrN+7dLnhV/IJV2TM5EDk4KCRMEqYGrrGzM7GujWddkROXApKEgU/A74Ysr7y4GHUncws55m9pCZVZrZajP7LzPLCrfFzOxWM9tkZiuBT6c59j4zW29m68zsh2YW29NMmtlgM3vGzLaY2XIz+0rKtslmNsfMqs1sg5ndFqbnm9nDZrbZzLaZ2VtmNmBPry3SSkFBomA20MPMRodf1pcAD7fb5+dAT2AEcApBELky3PYV4DPABGAScGG7Yx8EWoCR4T6fBL68F/l8FCgHBofX+F8zOz3cdidwp7v3AI4AHg/TLw/zPQzoC3wVqN+La4sACgoSHa21hU8AS4B1rRtSAsV33b3G3cuAnwFfCHe5GLjD3de6+xbgRynHDgDOAr7h7nXuvhG4Hbh0TzJnZsOAk4H/cPcGd58H/DYlD83ASDPr5+617j47Jb0vMNLd4+4+192r9+TaIqkUFCQqfgd8DriCdk1HQD8gF1idkrYaGBKuDwbWttvW6nAgB1gfNt9sA34D9N/D/A0Gtrh7zU7ycBVwJLAkbCL6TEq5XgAeM7MKM/uJmeXs4bVFkhQUJBLcfTVBh/PZwJ/abd5E8Iv78JS0w9hRm1hP0DyTuq3VWqAR6OfuvcJXD3cfu4dZrAD6mFlRujy4+zJ3n0oQbH4MPGFmBe7e7O7fd/cxwIkEzVxfRGQvKShIlFwFnObudamJ7h4naKO/2cyKzOxw4Hp29Ds8DlxnZkPNrDdwQ8qx64G/AT8zsx5mlmVmR5jZKXuSMXdfC7wG/CjsPB4f5vcRADO7zMyK3T0BbAsPi5vZFDM7OmwCqyYIbvE9ubZIKgUFiQx3X+Huc3ay+WtAHbASmAX8Hrg/3HYvQRPNu8DbdKxpfJGg+WkRsBV4Ahi0F1mcCpQQ1BqeAm509xfDbWcCC82slqDT+VJ3bwAGhterBhYDr9CxE11kt5km2RERkVaqKYiISJKCgoiIJCkoiIhIkoKCiIgkHdRD9vbr189LSkq6OhsiIgeVuXPnbnL34nTbDuqgUFJSwpw5O7vDUERE0jGz1TvbpuYjERFJUlAQEZGkjAWF8FH9N83sXTNbaGbfD9OHm9kbZrbMzP5gZrlhel74fnm4vSRTeRMRkfQy2afQSDDOTG04auMsM/srwZgyt7v7Y2b2a4LxXe4Ol1vdfaSZXUow6Ncle3rR5uZmysvLaWho6LySCPn5+QwdOpScHA3AKXIoy1hQ8GD8jNrwbU74cuA0giGMIZic5CaCoHBuuA7BWC6/MDPzPRyHo7y8nKKiIkpKSjCzfSqDBNydzZs3U15ezvDhw7s6OyKSQRntUwinMZwHbAReBFYA29y9JdylnB3jxQ8hHLM+3F5FMHlI+3NOC6clnFNZWdnhmg0NDfTt21cBoROZGX379lXtSyQCMhoUwpmgSoGhwGRgdLrdwmW6b/EOtQR3v8fdJ7n7pOLitLfZKiBkgD5TkWjYL3cfufs24GXgeKCXmbU2Ww0lGCYYglrDMIBwe09gSyby09Ac54OqBprjiUycXkTkoJXJu4+KzaxXuN4NOINgvPeZ7Jj4/HLg6XD9mfA94fa/72l/wu5qaI6zsaaBeKLzT79582ZKS0spLS1l4MCBDBkyJPm+qalpt85x5ZVXsnTp0k7Pm4jIh8nk3UeDgAfDGaGygMfd/VkzW0Qwn+wPgXeA+8L97wN+Z2bLCWoIezTx+YGib9++zJs3D4CbbrqJwsJCvvWtb7XZx91xd7Ky0sfk6dOnZzyfIiLpZKym4O7z3X2Cu49393Hu/oMwfaW7T3b3ke5+kbs3hukN4fuR4faVmcpba+v4/pxeaPny5YwbN46vfvWrTJw4kfXr1zNt2jQmTZrE2LFj+cEPfpDc9+STT2bevHm0tLTQq1cvbrjhBo455hhOOOEENm7cuB9zLSJRc1CPffRhvv+XhSyqqO6QHk84Dc1xuuXGyNrDDtQxg3tw4zl7Oid7YNGiRUyfPp1f//rXANxyyy306dOHlpYWpkyZwoUXXsiYMWPaHFNVVcUpp5zCLbfcwvXXX8/999/PDTfckO70IiL7TMNc7EdHHHEExx57bPL9o48+ysSJE5k4cSKLFy9m0aJFHY7p1q0bZ511FgAf/ehHKSsr21/ZFZEIOqRrCjv7RV9V38zqzXWM6l9It9z99xEUFBQk15ctW8add97Jm2++Sa9evbjsssvSPgeQm5ubXI/FYrS0tHTYR0Sks6im0EWqq6spKiqiR48erF+/nhdeeKGrsyQicmjXFA5kEydOZMyYMYwbN44RI0Zw0kkndXWWRESwDD0KsF9MmjTJ20+ys3jxYkaPTvfg9A7V9c2Uba5jZP9Cuu/H5qOD3e58tiJy4DOzue4+Kd02NR+JiEiSgoKIiCQpKIiISFK0g8LB250iIpIR0QwK4UPMigkiIm1FMihoZgARkfQiGRQy6dRTT+3wINodd9zBNddcs9NjCgsLAaioqODCCy9Mu8+pp55K+9tv27vjjjvYvn178v3ZZ5/Ntm3bdjfrIiIKCp1t6tSpPPbYY23SHnvsMaZOnfqhxw4ePJgnnnhir6/dPig899xz9OrVa6/PJyLRo6DQyS688EKeffZZGhsbASgrK6OiooLS0lJOP/10Jk6cyNFHH83TTz/d4diysjLGjRsHQH19PZdeeinjx4/nkksuob6+Prnf1VdfnRxy+8YbbwTgrrvuoqKigilTpjBlyhQASkpK2LRpEwC33XYb48aNY9y4cdxxxx3J640ePZqvfOUrjB07lk9+8pNtriMi0XNoP8771xvgg/c6JHdLJBjRnCA/NwZ7OvfwwKPhrFt2urlv375MnjyZ559/nnPPPZfHHnuMSy65hG7duvHUU0/Ro0cPNm3axPHHH89nP/vZnc59fPfdd9O9e3fmz5/P/PnzmThxYnLbzTffTJ8+fYjH45x++unMnz+f6667jttuu42ZM2fSr1+/NueaO3cu06dP54033sDdOe644zjllFPo3bs3y5Yt49FHH+Xee+/l4osv5sknn+Syyy7bs89ERA4ZkawpZLqjObUJqbXpyN353ve+x/jx4znjjDNYt24dGzZs2Ok5/vGPfyS/nMePH8/48eOT2x5//HEmTpzIhAkTWLhwYdoht1PNmjWL888/n4KCAgoLC7ngggt49dVXARg+fDilpaWAhuYWkUO9prCTX/T1Dc2s3FTHiOJCCvM6/yM477zzuP7663n77bepr69n4sSJPPDAA1RWVjJ37lxycnIoKSlJO1R2qnS1iFWrVnHrrbfy1ltv0bt3b6644ooPPc+uxrfKy8tLrsdiMTUfiURcJGsKSRl6UKGwsJBTTz2VL33pS8kO5qqqKvr3709OTg4zZ85k9erVuzzHxz/+cR555BEAFixYwPz584FgyO2CggJ69uzJhg0b+Otf/5o8pqioiJqamrTn+vOf/8z27dupq6vjqaee4mMf+1hnFVdEDiGHdk1hpzI/S/PUqVO54IILks1In//85znnnHOYNGkSpaWlHHXUUbs8/uqrr+bKK69k/PjxlJaWMnnyZACOOeYYJkyYwNixYzsMuT1t2jTOOussBg0axMyZM5PpEydO5Iorrkie48tf/jITJkxQU5GIdBDJobNrG1tYWVnLiH4FFObnZDKLhxQNnS1yaNDQ2SIislsiGRQy33gkInJwOiSDwsHcJHag0mcqEg2HXFDIz89n8+bN+hLrRO7O5s2byc/P7+qsiEiGZezuIzMbBjwEDAQSwD3ufqeZ3QR8BagMd/2euz8XHvNd4CogDlzn7i90OPGHGDp0KOXl5VRWVu50n6aWBBtrGolvySU/J7anl4ik/Px8hg4d2tXZEJEMy+QtqS3AN939bTMrAuaa2Yvhttvd/dbUnc1sDHApMBYYDLxkZke6e3xPLpqTk8Pw4cN3uc/c1Vv5yiOv8cCVxzLhI/335PQiIoe0jDUfuft6d387XK8BFgNDdnHIucBj7t7o7quA5cDkTOTNNMmOiEha+6VPwcxKgAnAG2HSv5nZfDO738x6h2lDgLUph5WTJoiY2TQzm2Nmc3bVRLTL/LSuKCqIiLSR8aBgZoXAk8A33L0auBs4AigF1gM/a901zeEdvrbd/R53n+Tuk4qLi/c2T+HJFRVERFJlNCiYWQ5BQHjE3f8E4O4b3D3u7gngXnY0EZUDw1IOHwpUZCRf4VI3KImItJWxoGDBz/H7gMXufltK+qCU3c4HFoTrzwCXmlmemQ0HRgFvZiZvwVJBQUSkrUzefXQS8AXgPTObF6Z9D5hqZqUETUNlwL8CuPtCM3scWERw59K1e3rn0e4yWpuPREQkVcaCgrvPIn0/wXO7OOZm4OZM5anVjpqCwoKISKpD7onmPaGQICLSViSDgvoURETSi2ZQ0DipIiJpRTMoqKYgIpJWtINC12ZDROSAE82g0HpLqqKCiEgb0QwKyZqCooKISKpoBoVwqZqCiEhb0QwK6lMQEUkrkkGBZJ+CwoKISKpIBgVLN/iGiIhENCiES1UURETaimZQ0CQ7IiJpRTMohEvVFERE2opmUNAwFyIiaUUzKGiSHRGRtKIZFDTJjohIWpEMCq0UEkRE2opkUDBNpyAiklZEg4JuSRURSSeaQSFcqktBRKStaAYFDYgnIpJWNIOCJtkREUkrmkFBk+yIiKSVsaBgZsPMbKaZLTazhWb29TC9j5m9aGbLwmXvMN3M7C4zW25m881sYsbyFi5VUxARaSuTNYUW4JvuPho4HrjWzMYANwAz3H0UMCN8D3AWMCp8TQPuzljO1KcgIpJWxoKCu69397fD9RpgMTAEOBd4MNztQeC8cP1c4CEPzAZ6mdmgTOTN0OBHIiLp7Jc+BTMrASYAbwAD3H09BIED6B/uNgRYm3JYeZjW/lzTzGyOmc2prKzcy/wES4UEEZG2Mh4UzKwQeBL4hrtX72rXNGkdvrfd/R53n+Tuk4qLi/cuT8lz7dXhIiKHrIwGBTPLIQgIj7j7n8LkDa3NQuFyY5heDgxLOXwoUJGhfAEaEE9EpL1M3n1kwH3AYne/LWXTM8Dl4frlwNMp6V8M70I6HqhqbWbq9LyFS4UEEZG2sjN47pOALwDvmdm8MO17wC3A42Z2FbAGuCjc9hxwNrAc2A5cmamMaZIdEZH0MhYU3H0W6fsJAE5Ps78D12YqP6k0yY6ISHqRfKIZTbIjIpJWJIOC7az+IiIScdEMCuFSFQURkbaiGRQ0yY6ISFrRDArhUjUFEZG2ohkUNMyFiEha0QwKmmRHRCStaAYFTbIjIpJWJINCK9UURETaimRQ0HMKIiLpRTMooFFSRUTSiWZQ0IB4IiJpRTMohEvFBBGRtqIZFEy3pIqIpBPNoBAudUuqiEhb0QwK6lMQEUkrokFBk+yIiKQTyaCQpKqCiEgbkQ0KZqopiIi0F92ggCoKIiLtRTcomOnuIxGRdnYrKJjZEWaWF66fambXmVmvzGYts1RTEBHpaHdrCk8CcTMbCdwHDAd+n7Fc7QfqUxAR6Wh3g0LC3VuA84E73P3fgUGZy1bmGaaagohIO7sbFJrNbCpwOfBsmJaTmSztJ6YnmkVE2tvdoHAlcAJws7uvMrPhwMO7OsDM7jezjWa2ICXtJjNbZ2bzwtfZKdu+a2bLzWypmX1qbwqzJwzUfiQi0k727uzk7ouA6wDMrDdQ5O63fMhhDwC/AB5ql367u9+ammBmY4BLgbHAYOAlMzvS3eO7k7+9oT4FEZGOdvfuo5fNrIeZ9QHeBaab2W27Osbd/wFs2c18nAs85u6N7r4KWA5M3s1j90rQp6CwICKSanebj3q6ezVwATDd3T8KnLGX1/w3M5sfNi/1DtOGAGtT9ikP0zows2lmNsfM5lRWVu5lFsKagmKCiEgbuxsUss1sEHAxOzqa98bdwBFAKbAe+FmYnm7W5LRf2e5+j7tPcvdJxcXFe50R29kFREQibHeDwg+AF4AV7v6WmY0Alu3pxdx9g7vH3T0B3MuOJqJyYFjKrkOBij09/54w0y2pIiLt7VZQcPc/uvt4d786fL/S3f9lTy8W1jZanQ+03pn0DHCpmeWFdzaNAt7c0/PvUV7QLakiIu3t1t1HZjYU+DlwEkGryyzg6+5evotjHgVOBfqZWTlwI3CqmZWG5ygD/hXA3Rea2ePAIqAFuDaTdx4FGVSfgohIe7sVFIDpBMNaXBS+vyxM+8TODnD3qWmS79vF/jcDN+9mfvZZuk4MEZGo290+hWJ3n+7uLeHrAWDve3kPAEGfgqoKIiKpdjcobDKzy8wsFr4uAzZnMmOZpofXREQ62t2g8CWC21E/ILiV9EKCoS8OWho6W0Sko929+2iNu3/W3Yvdvb+7n0fwINtBS5PsiIh0tC8zr13fabnoAqopiIh0tC9B4aC+gUd9CiIiHe1LUDjIv1P1RLOISHu7fE7BzGpI/+VvQLeM5Gg/MU2oICLSwS6DgrsX7a+M7G/qUxAR6Whfmo8Oaho6W0Sko+gGBXRLqohIe9ENCqopiIh0EN2ggLqZRUTai25Q0CQ7IiIdRDYogCbZERFpL7JBwdR+JCLSQaSDgmKCiEhb0Q0KaJIdEZH2ohsUVFMQEekgukEBPacgItJedIOCmWoKIiLtRDcogPoURETaiWxQQH0KIiIdRDYoaDoFEZGOMhYUzOx+M9toZgtS0vqY2Ytmtixc9g7TzczuMrPlZjbfzCZmKl8pedETzSIi7WSypvAAcGa7tBuAGe4+CpgRvgc4CxgVvqYBd2cwX4DuPhIRSSdjQcHd/wFsaZd8LvBguP4gcF5K+kMemA30MrNBmcobaOhsEZF09nefwgB3Xw8QLvuH6UOAtSn7lYdpHZjZNDObY2ZzKisr9zojmmRHRKSjA6Wj2dKkpf3Gdvd73H2Su08qLi7e+wuqpiAi0sH+DgobWpuFwuXGML0cGJay31CgItOZUUwQEWlrfweFZ4DLw/XLgadT0r8Y3oV0PFDV2syUKZpkR0Sko+xMndjMHgVOBfqZWTlwI3AL8LiZXQWsAS4Kd38OOBtYDmwHrsxUvpL5A1RXEBFpK2NBwd2n7mTT6Wn2deDaTOUlHfUpiIh0dKB0NO93GjpbRKSj6AYFTbIjItJBdIOCagoiIh1ENyigPgURkfYiGxTQJDsiIh1ENihokh0RkY6iGxTSDawhIhJx0Q0KqE9BRKS96AYFTbIjItJBdIMCqimIiLQX3aCgYS5ERDqIblDQJDsiIh1ENiigmoKISAeRDQqGhrkQEWkvukFBUUFEpIPoBgX1KYiIdBDdoKA+BRGRDqIdFLo6EyIiB5joBgVNsiMi0kF0g4JqCiIiHUQ2KID6FERE2otsUMiNZdEcT3R1NkREDiiRDQr5OTEamuNdnQ0RkQNKZINCXnYWjS2qKYiIpIpuUMiJ0dCsoCAikiq7Ky5qZmVADRAHWtx9kpn1Af4AlABlwMXuvjVTeQhqCmo+EhFJ1ZU1hSnuXuruk8L3NwAz3H0UMCN8nzH5OTEaVVMQEWnjQGo+Ohd4MFx/EDgvkxfLz8miKZ4gkdB9qSIirboqKDjwNzOba2bTwrQB7r4eIFz2T3egmU0zszlmNqeysnKvM5CXHQNQZ7OISIou6VMATnL3CjPrD7xoZkt290B3vwe4B2DSpEl7/TM/PyeIh40tcbrlxvb2NCIih5QuqSm4e0W43Ag8BUwGNpjZIIBwuTGTeWitKegOJBGRHfZ7UDCzAjMral0HPgksAJ4BLg93uxx4OpP5SK0piIhIoCuajwYAT5lZ6/V/7+7Pm9lbwONmdhWwBrgok5lQTUFEpKP9HhTcfSVwTJr0zcDp+ysfqimIiHR0IN2Sul/l56imICLSXmSDQl62agoiIu1FNiiopiAi0lFkg0JrTUHDZ4uI7BDZoNBaU9ATzSIiO0Q2KBTkBTde1TQ0d3FOREQOHF01zEXXaqyhZ205edbMptpGEgknK8u6OlciIl0umjWFZX8jdvfxjM3fwi9nrmDa7+Z2dY5ERA4I0QwKeT0AGJgfNB29tHjDhx8TbwbvvGG26xpb+NFzi9ne1NJp5xQR2VfRDAq5hQCUtKziotjLH75//Vb4n37c/F/X0BzvnI7pP7y1lt/8YyW/fnlFp5yvq22qbeTi37xOxbb6rs6KiOyDaAaFvCIAvtN8Nz/NuYdcPqSzuW4TAJ+PzaCqvnM6povyg+6cFZvqOuV8Xe3h2at5c9UWfjd7dVdnRUT2QaSDQqtCPuTXbSJo4sm15k4LComwKap866Hxy3pDdQMAA3vkd3FORGRfKCgARbZ9p8NdjP7v57l3xgIAcmlh2/bOCQq1jcH1DpXmlvVVDV2dhUPGwooqTRMrXUZBAShiOxf9+vUOuzXHE9Q3x/n7e6uCw2imqr6pU7KwvTGofWzb3oR3Ygd2V/kgDAp16jjfJ+9vqOHTd83ithff7+qsSERFMyjEciB7RzNHkdUzv7yK2158n8feXJNM31jTCEB3gi+8PJo6r6YQfnk2x73TztmVtjcFNZ/tjRo2ZF+0Pkw5Y0lGJx4U2aloPrwGQW2hJfiyL2I7AHfNWAbAcSP6MrxfQbKdvDtBcMi1OFs76Qu8rnHHL+p12+rpXZDbKeftKq3lqW1UTWFftA67sqm2sYtzIlEVzZoCtGlC+vrJA9psmnLryzwxt5wNYZNIN9vxH7Rqe+c0H9Wl/KI+FPoVasJgoOcu9k1rTauyRkFBuoaCAlCcs+M/4CgrB5y/vFvBB+1qCgBV2zunQ7WusYXiojwA1h7kdyA1tsRpCn/h1qn5aJ+oT0a6WnSDQu6OoNAnu5GC3Bg/P66KF/O+w49HzGfu6q2s3VJPbiyL0gE5yX1XrF7dKXeGbG9s4ryCBQztlc9ryzft8/m6Umog0JfavkltfqtTU5x0gegGhT7Dk6vZzTUs+P6nOGdwDQAn5K6gtrGF37+5miMHFHD6EYXJfbd+sIZXllXy4+eX8NMXluzyzqGHZ6/m3/8wL+22yVUv8J/bbuRbA+Ywa/mmTm12cXfO+fksTrv15f0yCmxdYwsltp7+bNUX2T6qa2xhlJVjJJJ9WiL7U3SDwoQv7FjfvgUzg4ZqAAYW5pCdZVyUeJ4ntl1KUXxrcteBtoUrp7/F3S+v4JczV3D3KyuIJ5wn5pazenNdm2Ew/uvPC3jqnXVpH3graA5qB8d230BjS4JZyzqvtrC+qoFF67ZQtPldFqyr7rTz7kxNQwsv532TN/OvZbuGIt8n+VuW8mLed7g29jQbqtWvIPtfdIPCYcfBNbNh1Cdh5cuQSMDWMgByFzzK50uquTr7GfITdfD2Q8nDzjp8xymOG96Hnzy/lDH/73m+9cd3OeOnL3HV9Nm4e5sZ3eat3caqTXXEw2anDdUN1IV9E4NyGyjKz+aFhRv45czlXPCrf/K/zy1uk9XtPxrJjB+cxaX3vL5bzzSsqKzllux7eTrv/7Fu1eIP3X93baxpYO7qLR3SU5s8em6czSW/eZ1X3q/stOtGSXbdBwCcEnuXjTWqKcj+F91bUgH6j4axF8Cyv8HCPyWDAsCN9lvqe/SEmtQvQeO8I4xPfOGTbCmbz2G9c/nGy/k8+245U2Mz+VHOfTy1+iSue+xmJgzrxediMzg2awlfeySL6sYERWzncyd9hCWry/lh1isAZG1dxWfGD+LRN9cmr/L2mm3MWLyBb3/qKAYWxShtrOR0Krlq5RbeKtvKoJ75VDc0M3Zwz+Qx7s7CimpG9i9kxYYarsj+BwA15YuAk9uWe8MiqNvIqq1N5HbvwZDRxwMwc+lG/jhnLTedM5b+aYaruOmZhbywcANPXXMi44f2AuDVZZU88fpSJof7HGnlPLBqC0s3vMOr35lCUX5Oh/Okcnfc6ZT5LBqa49z0zEK+/LHhjOxf1HGH8rmQnQcDx+31NbY3tdDQnKBPhm4hzm4IaowFNCYfCBTZn6IdFADGng+zfwlPXhW8P/JMqFxC1rq3KAD4+LfhHz8NthUOIHvTEnrWvE/Pp8+HxipuPfsO/nf9LymqDp5xOD/2T/793Qr+8m4FZfn3BWn8kxP4Oa/nf40n3zyZM7I2M8zCX9Lr3+XKM4e0CQoAKyrruO7h2Qy1Sv4e3KTEmNwNzJ9+HVObLiZOjEuPHcYZowfQFE8w+/8eIKemnPviZzOYTVwRfqeXLVvAlFtf5vZLStlS18jHRxWTffcJALT2qnxz9CssWjyfxQ19Acgy4ycXjmdzbRPD+nRnfVU9v3llJTPfK2OIVfHTX90NI6bwvxeM59r7ZnKUrYEwj98YXcu5Jx/H+b9+g9tfXMZ/f2Z00DQXWr6xlqG9uwUBrLiQf314DrNXbmFySR/uvXwSPbvlhPleyLxFi3h2Wwl3XjqB7rnB9Kmp52pvTtlWHntrLYvWV/PUNScRax9ofntasLypqsOx5Vu3c8tfl3DiEf0455hBzF65hSkfKSY71rYy/bPHX+SNhcv59pWXcsqRxW22xRPe9pru8NJN+OjPYkUDYPNyGHEqAFuWz+H55ds5/7ST6BaWDSC/Pvi7GGqVvLGikrPGDeKwvt1TLtICZpC145j9raklwf88u4jRg3rwueMO67J8SGbYgTbEgpmdCdwJxIDfuvstO9t30qRJPmfOnH2/aP02ePMeKJsFFz8EjdVw14RgILzLnrIwZsIAABAoSURBVIQ+I6C5AeY/Bv+8MzgmKzs5UF57K4++nseXxbmh4c7du/6nb+OV/Cks2wbHHd6T/777YS4fk8V5K2+kIbcP3RrbNsX8sdvFvFtdwMPxM4DgS6gs/3MAXNtvOiMSZXxzy/cBeD4xma82fZ3LYi/Rhxp+n38Jc+IXtTnfTc1f5Kach7is+b9YnF/K5rodz2Kcc8xgVm+uY0TF/3FH7q+S6d9ouoaVPojbc37FEVnr25Zn0peYvqaY29aMoobuDO3djW6JesqqWhhvK1jqwzjK1lCatYLfxj+dPGxwz3wumDiU7Jhx9asnkmfNHNUwnTGHDWD5xlqqG1o45chivnHGKGYt28SSDTV8UNXARwYWUZSXzV/ereCC2kc5IWsRSz7xIF/62Eia4gmaWhLEG+vodXvQ9lfzHxtpThibaxvZVNvExpoG7n11ZbL/pX9RHhtrGjlqYBENzXEGJdbz1RMHM+ro4+hx+3AKrZ6Li5/moWkf44Yn57OwopqrTz2C2196n3GDe3LtlJFsqm3kxN415P5qIgCVOYMpbq7g7f7n8wumcv/GiwH484lPccpJJzNr+Sbmrt7Kyct+whk1fwbg1y2f4ZaWz/GDs4eTP+9Bxp93PUOe+DRrW3oy6/h7GNW/iAE98hkzuEebj39VZS2FOU5xr6C2tHxjLf0Kc+nVfde1m8aWOHnZHYONu7cJxn9b+EFyYqo/XXMi989axfkThnD66OB5n1fer6S+qYUzRg/oEFQpmwUzfwSffxxyC3aZn301p2wLYwf3bBN0JWBmc919UtptB1JQMLMY8D7wCaAceAuY6u6L0u3faUEhnXVvQ2MNjDhlR1q8GV7/RZB+/DWw6M/w5m9h7HlQ8Q68/zzkFEBzynDYYy+Apc8ln55OshhM+R68dhc0VAXH5feAprogKAHk9YTG8FdtmiAULxpCVeEIum9ZRH7j5iCxcADUhpMG9fsIbFpKs+WQ40EH8NZYX3rHN7c5T31WId0StXhuEVXDz+L2xUWUeAU53sTsxBg+krWWr2X/eY8/wjVFE3mgagKj++dz1paH6J6oJQtniR/OURYMsT1/6FRmN5RwTOMc3thawNuJURyftZivZj8LwHuJEuYlRjLc1lNPHs1k83T8JMq9mB6FhYzZ/iZnx96giO0s9sM5N/YaAP/dfAVLskaxOVFAQaKWb2b/kVNj7wLwhaYb6M82YhYnnyY+HXuD8baSLT2O4qXqw5iTOJLPfKSAvy7azDmx1zk99g4AVzZ9m+m5Qa3x4ZbTOTxrI80eo9J7scBLmJU4mlJbzsmxBfwtPonDbAP/mfP7Dp/LRu9Ff9sGwNzEKF6OH8NmevJM/AR+nvNzSnPWUFRQwNa6Rn7WeC7HZi3lX2KvssUL6WO1ALwUn0CcGDMTpWT1GMKxhRuZ1/1Eajyf01bdytFZZdwz+H+ojfVk1Yr3qc/ry8dH9qWP1bKlKcaoIcVsrWtg8LZ3GFf5LNuyi3l1ay/WDjiNMycMx5ubWFexlqL3n+KRltM4duQgJowvpTaexRuvvkjTplV0sybOj81ig/fm283/yjmlwxha4Cx9/S8cl7WY93OOonnwJLZmD6BnrJF+vYr49nufJae5mueKr2LdgNOJxWLEegxiZK8EQxbfx7KPXM3AAQMp29JAdWMLw3p3p2b2g0xY+yCJgcdQPvm/GTBwCLHqtVjDNirzS3h9TR09u+VgTbUcPbQX2UueocwH8M/XXqWi/yl8peg1fN07zBx9E2eXlvDaojKGDRvGEf0KaXbjz2+XM7RXLlPGDKEgL0ZTS9A8WF+5mpxegynsno87VNU309Acp0e3HLbWNTG0d7dk0NtUXQcWY+nKVdRn9+akUcWYBeOn5cSyqK5vprK2kVH9i6htbOHVZZX06p7LccP7sKm2kfycGH0LcmlJOPGEk5edlQzEqzbVkWVwWJ/uJDzo26tvijOiuLDD39buOpiCwgnATe7+qfD9dwHc/Ufp9s9oUNhTrZ+jWTApz+YVwS+h4qOgugKq10FBMSx5Nnhw7qNXBPtvWwurX4M1rweBI9ESNDGsexuOOhv6HQmNtVD8EZh9NzRsC47fvgXWzIbtm6BoUBA0Jn4R3n4QmuthwNjgGu/+IQhYtRuC23C3rAxqRvVb4Mizgut6AsZdEJxv8wpINOPZ3SDRjLWvDfUYEuZvLlQu2REEcwpg6u+h7J+wOnzty8dZNBjLzsO3rcF89x6Ii8e6UTXyXHqt+j+ymmr26fq7o9HyiOf1pHvDrscpaiw6nLyadvNMDDuO9YM/waA3fthh/62HfYrepZ+BZ77WmdntFE0eI9fS/3s0eYxsEmRZ2++UhFuHtPbHxYnRzZqo91zyaKaBXBrIIU4WxbbjDrp6zyWHFrJtx11+67wv2cTpQw057fLW6Nnk2Y6/4da81HsucbJoIpt8mulujTR5jAbyqCcXxxhoW2nwHJrIwQHHcIxEuASIE+S9P1uIk0WetdDo2YDRWuLW49q/D9aBlPXUbZjhviPdkvsExywedikf//JPdvq57srBFBQuBM509y+H778AHOfu/5ayzzRgGsBhhx320dWrNanLXmlpDDpd22vaDts3Q4/BQY1l80rofXhQS8rvCbkp7dstTWBZQVBpqQ+2t0okgoBVvS641rDjgoCWSATLLaug74jg+IbqIGCufQO69Q6CXu8S6N4nCH6bV0DRQNi4CAZPDNrmt60OAmHPYTBsMiTiwbmysmDDwiAINtYE5cnKhkHHQNVaiOUGgTGne7BvTvcg8NZVBstEHMpeDfLj8aDZcODRQS1u+UvBNY76TBDIiwZBzyFQMS8oa10l9DosuEbVuuBzPPxE6D8muMNt2ORgKtjm7TueqF/ybHBMbSWsnwd9j4BRnwoGbVz61+DY2g+Cz6VmffDQpVnwPtES/OBItOBZOdjWlcG/U3Ye9B8b3DixbQ30PQJvrCGRSJCVk4e7s622gbpmZ8iAYhI9hpLdcxA01xNf9iLlNQm653ej0fLoOWgERZXv0OTZbNq0kVhTFT179CD/sEnBv+PgicEPi21r8EQLnkiQVdgP+o6EeDOJmg1Y3UYsvwfN9bWUN3ajV/9h5LZUE8vtTm4MGta9R+22Smqz+1AQr6Iuuw9FWQ3kW5y6hkYKC4vI7jWE6oYW4pvL2NqSS/dENW7Z0K03AxMbSMTyaM7rxda6Jlpi3enu28ntdzi5W5ZRXXAYQ4aNoH7jSipWv0/PwgK2N8Uxb6ElnmBQ355s8wKqqqqgpZ68RCOJpjoSeT1pIofmljhZJMjLNrIMmlvi5MaM2oZmSLRgiRa8oB+5lqB7jz7EEo1UVjeQZUH/XDyRIMuge06M6oYm8mJG34I86ptbqK5vpntujHg8TkNzPHlMczxOPJ7ADHJjRm52FvVNcWJZRl7MaEkkyD3yDI6c8vm9+u9/MAWFi4BPtQsKk9097U+mA6qmICJykNhVUDjQnlMoB4alvB8KVHRRXkREIudACwpvAaPMbLiZ5QKXAs90cZ5ERCLjgHpOwd1bzOzfgBcIbkm9390XdnG2REQi44AKCgDu/hzwXFfnQ0Qkig605iMREelCCgoiIpKkoCAiIkkKCiIiknRAPby2p8ysEtjbR5r7AQf3PJh7J4rlVpmjIYplhr0r9+HuXpxuw0EdFPaFmc3Z2RN9h7IolltljoYolhk6v9xqPhIRkSQFBRERSYpyULinqzPQRaJYbpU5GqJYZujkcke2T0FERDqKck1BRETaUVAQEZGkSAYFMzvTzJaa2XIzu6Gr89NZzOx+M9toZgtS0vqY2Ytmtixc9g7TzczuCj+D+WY2setyvvfMbJiZzTSzxWa20My+HqYfsuU2s3wze9PM3g3L/P0wfbiZvRGW+Q/h8POYWV74fnm4vaQr878vzCxmZu+Y2bPh+yiUuczM3jOzeWY2J0zL2N935IKCmcWAXwJnAWOAqWY2pmtz1WkeAM5sl3YDMMPdRwEzwvcQlH9U+JoG3L2f8tjZWoBvuvto4Hjg2vDf81AudyNwmrsfA5QCZ5rZ8cCPgdvDMm8Frgr3vwrY6u4jgdvD/Q5WXwcWp7yPQpkBprh7acrzCJn7+3b3SL2AE4AXUt5/F/huV+erE8tXAixIeb8UGBSuDwKWhuu/Aaam2+9gfgFPA5+ISrmB7sDbwHEET7Vmh+nJv3OC+UlOCNezw/2sq/O+F2UdGn4BngY8SzDj/SFd5jD/ZUC/dmkZ+/uOXE0BGAKsTXlfHqYdqga4+3qAcNk/TD/kPoewiWAC8AaHeLnDZpR5wEbgRWAFsM3dW8JdUsuVLHO4vQrou39z3CnuAL4DJML3fTn0ywzgwN/MbK6ZTQvTMvb3fcBNsrMfWJq0KN6Xe0h9DmZWCDwJfMPdq83SFS/YNU3aQVdud48DpWbWC3gKGJ1ut3B50JfZzD4DbHT3uWZ2amtyml0PmTKnOMndK8ysP/CimS3Zxb77XO4o1hTKgWEp74cCFV2Ul/1hg5kNAgiXG8P0Q+ZzMLMcgoDwiLv/KUw+5MsN4O7bgJcJ+lN6mVnrD73UciXLHG7vCWzZvzndZycBnzWzMuAxgiakOzi0ywyAu1eEy40EPwAmk8G/7ygGhbeAUeFdC7nApcAzXZynTHoGuDxcv5ygzb01/Yvh3QrHA1Wt1dGDiQVVgvuAxe5+W8qmQ7bcZlYc1hAws27AGQSdrzOBC8Pd2pe59bO4EPi7hw3OBwt3/667D3X3EoL/s393989zCJcZwMwKzKyodR34JLCATP59d3UnShd13JwNvE/QDvufXZ2fTizXo8B6oJngF8NVBO2oM4Bl4bJPuK8R3IW1AngPmNTV+d/LMp9MUD2eD8wLX2cfyuUGxgPvhGVeAPy/MH0E8CawHPgjkBem54fvl4fbR3R1Gfax/KcCz0ahzGH53g1fC1u/rzL5961hLkREJCmKzUciIrITCgoiIpKkoCAiIkkKCiIikqSgICIiSQoKIrtgZvFwdMrWV6eNqmtmJZYyoq3IgSCKw1yI7Il6dy/t6kyI7C+qKYjshXCM+x+H8xq8aWYjw/TDzWxGOJb9DDM7LEwfYGZPhXMgvGtmJ4anipnZveG8CH8Ln1AW6TIKCiK71q1d89ElKduq3X0y8AuCcXgI1x9y9/HAI8BdYfpdwCsezIEwkeDpVAjGvf+lu48FtgH/kuHyiOySnmgW2QUzq3X3wjTpZQQT3awMB+T7wN37mtkmgvHrm8P09e7ez8wqgaHu3phyjhLgRQ8mSsHM/gPIcfcfZr5kIumppiCy93wn6zvbJ53GlPU46ueTLqagILL3LklZvh6uv0YwiifA54FZ4foM4GpITpDTY39lUmRP6FeJyK51C2c4a/W8u7felppnZm8Q/LiaGqZdB9xvZt8GKoErw/SvA/eY2VUENYKrCUa0FTmgqE9BZC+EfQqT3H1TV+dFpDOp+UhERJJUUxARkSTVFEREJElBQUREkhQUREQkSUFBRESSFBRERCTp/wNDDAqIhIWNuwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfit checks:\n",
      "Model Accuracy: 0.877237856388092\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------- Data from the paper ------------------------------------\")\n",
    "frame = load_frame()\n",
    "frame = load_quartile(frame)\n",
    "data_x, data_y, number_of_features = load_all_data(frame)\n",
    "x_train, y_train, x_test, y_test, x_validate, y_validate = split_data(data_x, data_y)\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dropout(0.2, input_shape=(number_of_features,)))\n",
    "model.add(keras.layers.Dense(40, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "model.add(keras.layers.Dense(20, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping_monitor = keras.callbacks.EarlyStopping(patience=100,restore_best_weights=True)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=1000, verbose=0,\n",
    "          validation_data=(x_validate, y_validate), callbacks=[early_stopping_monitor])\n",
    "\n",
    "silent_evaluation(model, x_test, y_test)\n",
    "plot_graphs(history)\n",
    "print(\"Overfit checks:\")\n",
    "silent_evaluation(model, x_train, y_train)\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "print(\"-------------------------- Data from the paper + mine ------------------------------------\")\n",
    "\n",
    "frame = load_frame()\n",
    "frame = load_quartile(frame)\n",
    "data_x, data_y, number_of_features = load_all_data_with_mine(frame)\n",
    "x_train, y_train, x_test, y_test, x_validate, y_validate = split_data(data_x, data_y)\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dropout(0.2, input_shape=(number_of_features,)))\n",
    "model.add(keras.layers.Dense(40, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "model.add(keras.layers.Dense(20, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping_monitor = keras.callbacks.EarlyStopping(patience=100,restore_best_weights=True)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=1000, verbose=0,\n",
    "          validation_data=(x_validate, y_validate), callbacks=[early_stopping_monitor])\n",
    "\n",
    "silent_evaluation(model, x_test, y_test)\n",
    "plot_graphs(history)\n",
    "print(\"Overfit checks:\")\n",
    "silent_evaluation(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #3: Take all data and divide by the median - Static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Data from the paper ------------------------------------\n",
      "(1570, 67)\n",
      "Model Accuracy: 0.7744807004928589\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfit checks:\n",
      "Model Accuracy: 0.8452229499816895\n",
      "-------------------------- Data from the paper + mine ------------------------------------\n",
      "(1570, 83)\n",
      "Model Accuracy: 0.780415415763855\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd5xcVf3/8ddn6va+2WzqppFKyib0klBEA1KESBGQjmLhq6hfUfz+xA4WBGwoUgVBihTpBIMUIaQQ0nvd7GZ7b9PO7497ZzJJtiXZyc7OfJ6PRx4zc2fmztlheM+Zzzn3XDHGoJRSKnk4BroBSimljiwNfqWUSjIa/EoplWQ0+JVSKslo8CulVJLR4FdKqSSjwa9UN0SkRESMiLj68NirReS9w92PUkeCBr9KCCKyXUR8IlKw3/YVduiWDEzLlIo/GvwqkWwDLgvfEJGjgdSBa45S8UmDXyWSvwFfjLp9FfBo9ANEJFtEHhWRahHZISI/EBGHfZ9TRH4tIjUishU4p4vnPiAiFSKyW0R+KiLOg22kiAwTkRdFpE5ENovIDVH3HSsiS0WkSUQqReQue3uKiDwmIrUi0iAiS0Sk6GBfWynQ4FeJ5UMgS0Qm24F8CfDYfo/5HZANjAXmYn1RXGPfdwPwWWAWMAdYsN9zHwECwHj7MWcB1x9CO58AyoBh9mv8XETOsO+7B7jHGJMFjAOesrdfZbd7JJAPfBloP4TXVkqDXyWccK//U8B6YHf4jqgvg+8ZY5qNMduB3wBX2g+5GLjbGLPLGFMH/CLquUXAfOAbxphWY0wV8Fvg0oNpnIiMBE4GvmuM6TDGrAD+GtUGPzBeRAqMMS3GmA+jtucD440xQWPMMmNM08G8tlJhGvwq0fwN+AJwNfuVeYACwAPsiNq2AxhuXx8G7NrvvrDRgBuosEstDcCfgSEH2b5hQJ0xprmbNlwHHAWst8s5n436u14HnhSRchH5pYi4D/K1lQI0+FWCMcbswBrkPRv4535312D1nEdHbRvF3l8FFVillOj7wnYBnUCBMSbH/pdljJl6kE0sB/JEJLOrNhhjNhljLsP6QrkTeEZE0o0xfmPMj4wxU4ATsUpSX0SpQ6DBrxLRdcDpxpjW6I3GmCBWzfxnIpIpIqOBW9g7DvAUcLOIjBCRXODWqOdWAG8AvxGRLBFxiMg4EZl7MA0zxuwC/gv8wh6wnW6393EAEblCRAqNMSGgwX5aUEROE5Gj7XJVE9YXWPBgXlupMA1+lXCMMVuMMUu7ufvrQCuwFXgP+DvwoH3f/VjllE+A5Rz4i+GLWKWitUA98AxQfAhNvAwower9Pwf80Bjzpn3fZ4A1ItKCNdB7qTGmAxhqv14TsA74DwcOXCvVJ6InYlFKqeSiPX6llEoyGvxKKZVkNPiVUirJaPArpVSSGRTLxBYUFJiSkpKBboZSSg0qy5YtqzHGFO6/fVAEf0lJCUuXdjc7TymlVFdEZEdX27XUo5RSSUaDXymlkowGv1JKJZlBUePvit/vp6ysjI6OjoFuSsJISUlhxIgRuN266KNSiWzQBn9ZWRmZmZmUlJQgIgPdnEHPGENtbS1lZWWMGTNmoJujlIqhQVvq6ejoID8/X0O/n4gI+fn5+gtKqSQwaIMf0NDvZ/p+KpUcBnXw96a+zUdtS+dAN0MppeJKQgd/Y5ufulZfTPZdW1vLzJkzmTlzJkOHDmX48OGR2z5f317zmmuuYcOGDTFpn1JKdWfQDu72VazONpCfn8+KFSsAuP3228nIyODb3/72vq9tDMYYHI6uv18feuihGLVOKaW6l9A9fhFil/zd2Lx5M9OmTePLX/4ypaWlVFRUcOONNzJnzhymTp3Kj3/848hjTz75ZFasWEEgECAnJ4dbb72VGTNmcMIJJ1BVVXVkG66UShoJ0eP/0b/WsLa86YDtnYEQoZAh1eM86H1OGZbFD8892PNoW9auXctDDz3EfffdB8Add9xBXl4egUCA0047jQULFjBlypR9ntPY2MjcuXO54447uOWWW3jwwQe59dZbu9q9UkodloTu8cMR7/ADMG7cOI455pjI7SeeeILS0lJKS0tZt24da9euPeA5qampzJ8/H4DZs2ezffv2I9VcpVSSSYgef3c987K6Npo7A0wuzjqi7UlPT49c37RpE/fccw8fffQROTk5XHHFFV3Olfd4PJHrTqeTQCBwRNqqlEo+Me3xi8g3RWSNiKwWkSdEJEVExojIYhHZJCL/EBFP73s61AbAQJ9LvqmpiczMTLKysqioqOD1118f2AYppZJezIJfRIYDNwNzjDHTACdwKXAn8FtjzASgHrguhm3ADEixZ6/S0lKmTJnCtGnTuOGGGzjppJMGtD1KKSUmRl1iO/g/BGYATcDzwO+Ax4GhxpiAiJwA3G6M+XRP+5ozZ47Z/0Qs69atY/LkyT22obyhnfpWH1OHZx/6H5Jk+vK+KqUGBxFZZoyZs//2mPX4jTG7gV8DO4EKoBFYBjQYY8IF7DJgeFfPF5EbRWSpiCytrq4+pDaIDMzgrlJKxbNYlnpygfOBMcAwIB2Y38VDu8xmY8xfjDFzjDFzCgsPOGVk39rAwNf4lVIq3sRycPdMYJsxptoY4wf+CZwI5IhIeDbRCKA8Vg0I1/hjVc5SSqnBKJbBvxM4XkTSxFr28QxgLbAIWGA/5irghRi2QSml1H5iWeNfDDwDLAdW2a/1F+C7wC0ishnIBx6IVRvCqwxrh18ppfaK6QFcxpgfAj/cb/NW4NhYvm6YYCW/NaVT15pXSilI8CUbYtnjnzdv3gEHY91999185Stf6fY5GRkZAJSXl7NgwYIuHzNv3jz2n7q6v7vvvpu2trbI7bPPPpuGhoa+Nl0pleQSO/jty1hUei677DKefPLJfbY9+eSTXHbZZb0+d9iwYTzzzDOH/Nr7B/8rr7xCTk7OIe9PKZVcEjv4Y9jjX7BgAS+99BKdndYZvrZv3055eTkzZ87kjDPOoLS0lKOPPpoXXjhw7Hr79u1MmzYNgPb2di699FKmT5/OJZdcQnt7e+RxN910U2Q55x/+0KqY3XvvvZSXl3Paaadx2mmnAVBSUkJNTQ0Ad911F9OmTWPatGncfffdkdebPHkyN9xwA1OnTuWss87a53WUUsklIRZp49VbYc+qAzZnhkKM9YdweZx7vwX6aujRMP+Obu/Oz8/n2GOP5bXXXuP888/nySef5JJLLiE1NZXnnnuOrKwsampqOP744znvvPO6PZ/tn/70J9LS0li5ciUrV66ktLQ0ct/PfvYz8vLyCAaDnHHGGaxcuZKbb76Zu+66i0WLFlFQULDPvpYtW8ZDDz3E4sWLMcZw3HHHMXfuXHJzc9m0aRNPPPEE999/PxdffDHPPvssV1xxxcG9J0qphJDQPf5Yiy73hMs8xhi+//3vM336dM4880x2795NZWVlt/t45513IgE8ffp0pk+fHrnvqaeeorS0lFmzZrFmzZoul3OO9t577/G5z32O9PR0MjIyuPDCC3n33XcBGDNmDDNnzgR02Welkl1i9Pi76Zm3tvnYWdfGUUWZpLgP/mQsvbngggu45ZZbWL58Oe3t7ZSWlvLwww9TXV3NsmXLcLvdlJSUdLkMc7Sufg1s27aNX//61yxZsoTc3FyuvvrqXvfT04FqXq83ct3pdGqpR6kkltA9/nCgxmoef0ZGBvPmzePaa6+NDOo2NjYyZMgQ3G43ixYtYseOHT3u49RTT+Xxxx8HYPXq1axcuRKwlnNOT08nOzubyspKXn311chzMjMzaW5u7nJfzz//PG1tbbS2tvLcc89xyimn9Nefq5RKEInR4+/G3lk9sTuC67LLLuPCCy+MlHwuv/xyzj33XObMmcPMmTOZNGlSj8+/6aabuOaaa5g+fTozZ87k2GOtQxxmzJjBrFmzmDp1KmPHjt1nOecbb7yR+fPnU1xczKJFiyLbS0tLufrqqyP7uP7665k1a5aWdZRS+4jZssz96VCXZW7u8LOtppVxhRmkexP6O67f6LLMSiWOI74sczzQY3WVUupACR38RGr88f+rRimljpRBHfy9BXosj9xNRPoFqVRyGLTBn5KSQm1tbY9hpatz9p0xhtraWlJSUga6KUqpGBu0I54jRoygrKyMnk7L6AuEqGruJFDnITUG8/gTTUpKCiNGjBjoZiilYmzQBr/b7WbMmDE9PmbDnmZuePwd/nh5KWdPLj5CLVNKqfg2aEs9feFyWrUefzA0wC1RSqn4kdDB73ZYf14gqEV+pZQKS+jgd9o9/mBIg18ppcISOvjdDrvUE9JSj1JKhSV08LucWupRSqn9JXTwOx06uKuUUvtL6OB3a41fKaUOkNDB7wrP6tHgV0qpiAQPfi31KKXU/hI6+B0OwSFa6lFKqWgJHfxgzezx66wepZSKSPjgdzuEgJZ6lFIqIuGD3+kQHdxVSqkoCR/8bqeDgB65q5RSEQkf/C6n6JG7SikVJfGD36GDu0opFS3xg98pBLXUo5RSEYkf/A7Br4O7SikVkQTB79DpnEopFSXxg98peuSuUkpFSYLg18FdpZSKlvDB73aIzuNXSqkoCR/8Todoj18ppaLENPhFJEdEnhGR9SKyTkROEJE8EXlTRDbZl7mxbIPb6dAav1JKRYl1j/8e4DVjzCRgBrAOuBV4yxgzAXjLvh0bH93PeS3/0Fk9SikVJWbBLyJZwKnAAwDGGJ8xpgE4H3jEftgjwAWxagOb3uTYtne11KOUUlFi2eMfC1QDD4nIxyLyVxFJB4qMMRUA9uWQmLXA4cJFQEs9SikVJZbB7wJKgT8ZY2YBrRxEWUdEbhSRpSKytLq6+tBa4HThJIhfZ/UopVRELIO/DCgzxiy2bz+D9UVQKSLFAPZlVVdPNsb8xRgzxxgzp7Cw8NBa4HDhNEFdnVMppaLELPiNMXuAXSIy0d50BrAWeBG4yt52FfBCrNqAw+rx6+CuUkrt5Yrx/r8OPC4iHmArcA3Wl81TInIdsBP4fMxe3eG2gl9r/EopFRHT4DfGrADmdHHXGbF83QiH0yr1GA1+pZQKS+wjd51uHATxa6lHKaUiEjv4HS4cJqjTOZVSKkrCB7/TBHRWj1JKRUn44HcYncevlFLRkiL4jUHLPUopZUv84CcIGF2TXymlbIkd/E5rtqoLPXpXKaXCEjv4HRr8Sim1v+QJfi31KKUUkPDB7wbASUiXbVBKKVuCB78TALcevauUUhGJHfzOcI9fa/xKKRWW2MG/T41fg18ppSBZgl90cFcppcKSI/i11KOUUhFJEfw6q0cppfZKiuB36+kXlVIqIrGDP2pWj19LPUopBSR68Nvz+F3oyViUUioswYN/7+CursmvlFKWBA9+u9QjIZ3Vo5RStgQP/vDgbkAHd5VSypYUwa/TOZVSaq/EDn6nLsuslFL7S+zgjx7c1Rq/UkoBCR/81uCuTudUSqm9Ejz4rXn8TkI6uKuUUrYED357Vo8EtNSjlFK2xA5+Z/SpF7XHr5RS0MfgF5FxIuK1r88TkZtFJCe2TesHeiIWpZQ6QF97/M8CQREZDzwAjAH+HrNW9Rddj18ppQ7Q1+APGWMCwOeAu40x3wSKY9esfhI5gEuXZVZKqbC+Br9fRC4DrgJesre5Y9OkfmQHf4pDj9xVSqmwvgb/NcAJwM+MMdtEZAzwWOya1U8i59zV4FdKqTBXXx5kjFkL3AwgIrlApjHmjlg2rF/Ywe+REE1a6lFKKaDvs3reFpEsEckDPgEeEpG7Ytu0fuBwgDjwiA7uKqVUWF9LPdnGmCbgQuAhY8xs4MzYNasfOdy4tdSjlFIRfQ1+l4gUAxezd3B3cHC48Dh0yQallArra/D/GHgd2GKMWSIiY4FNsWtWP3K4cIsewKWUUmF9Cn5jzNPGmOnGmJvs21uNMRf15bki4hSRj0XkJfv2GBFZLCKbROQfIuI59Ob3gdOFW0L4tcevlFJA3wd3R4jIcyJSJSKVIvKsiIzo42v8D7Au6vadwG+NMROAeuC6g2vyQXK48KDBr5RSYX0t9TwEvAgMA4YD/7K39cj+cjgH+Kt9W4DTgWfshzwCXHBwTT5IDhduh56IRSmlwvoa/IXGmIeMMQH738NAYR+edzfwv0C4u50PNNjLPwCUYX2RHEBEbhSRpSKytLq6uo/N7IJDSz1KKRWtr8FfIyJX2PV6p4hcAdT29AQR+SxQZYxZFr25i4d22RU3xvzFGDPHGDOnsLAv3zHdcLhwE8QX0OBXSino45G7wLXA74HfYgX1f7GWcejJScB5InI2kAJkYf0CyBERl93rHwGUH0rD+0x7/EoptY++zurZaYw5zxhTaIwZYoy5AOtgrp6e8z1jzAhjTAlwKfBvY8zlwCJggf2wq4AXDr35feB045KQ1viVUsp2OGfguuUQn/dd4BYR2YxV83/gMNrQO4cTFwHt8SullK2vpZ6udFWv75Ix5m3gbfv6VuDYw3jdg+Nw4yKET4NfKaWAw+vxD47aicOFS+fxK6VURI89fhFppuuAFyA1Ji3qbw4XLtp1Vo9SStl6DH5jTOaRakjMOF04dXBXKaUiDqfUMzg4XLhMAL/2+JVSCkiS4HcSPPKDu742eGwB1G45sq+rlFK9SJLgH4DB3fptsPlNKFt6ZF9XKaV6kRzBbwKEDASP5Jr8QZ91Geg4cq+plFJ9kBTB7yAIcGR7/QE7+MNfAEopFScSP/idbpzGCv4jWucPdlqX2uNXSsWZxA9+hxOHvQr0EZ3ZEyn1dB6511RKqT5IguB34zDhUs8RrPEHNPiVUvEpCYLfFRX8A9DjD2rwK6XiS5IEv1Xq6eyp1LP+ZXjlO/33ulrqUUrFqcQPfqcL6UuPf9Ob8PFj/fe6GvxKqTiV+MEf1ePvMfgDneBvg1A/lYPCga/Br5SKM0kR/BLqS/C325f9NP0y6O/f/SmlVD9JguB3IxiEEL5AD7N6wj1zf1v/vG54UFcP4FJKxZkkCH4nAG6CPff4/XaP39faP68b0CUblFLxKQmC3zrlgLO34O/3Hr8O7iql4lPiB7/TDdD76RfDNX5fP5d6NPiVUnEm8YPf7vG7CODr6cjdSI+/n0o94cFdPYBLKRVnkij4Qz2v1ROuxfdXj1+ncyql4lTSBH+vZ+Hy28Hfbz1+rfErpeJT0gS/S3ob3A0Hf3v/vK4Gv1IqTiV+8EcGd4P4BqLUozV+pVScSfzgt+fxuwh2vyyzMVE9/n4e3NUev1IqziRB8EcN7nZX6gn6wdj36XROpVSCS4Lgt0o97p5q/NFH1/b3AVwhf/8t/KaUUv0gCYLf6vGnOELdz+qJDv7+XrIBtM6vlIorSRD8Vo0/xWnwd7dIWyx7/PvvXymlBljiB789q8frNN2XevyxDn5doVMpFT8SP/gjpZ4+1vj7bXBXe/xKqfiUBMFv9/gdpvt5/NEzb/qrxx/oBLHKTLomv1IqniRB8Fvh63WYHgZ37aN1PZn9N7gb9IE3096/9viVUvEjCYLfKvV4HT3M4w/3+NNy+7fG782y9689fqVU/Ej84LcHdz2OUPdH7obX50nN68clG3yQEg5+7fErpeJH4gd/pMff0+BuuMef17+rc4ZLPTqPXykVR5Ig+K0av0d6Gty1e/xp+f3T4zfGCvtIjV+DXykVP2IW/CIyUkQWicg6EVkjIv9jb88TkTdFZJN9mRurNgCRWT2evtT4U/OsJRbCC6wdqlDAutTgV0rFoVj2+APAt4wxk4Hjga+KyBTgVuAtY8wE4C37duzsM7jbS40/Lc++fZi9/nDQa/ArpeJQzILfGFNhjFluX28G1gHDgfOBR+yHPQJcEKs2AJHg9/S4SFu4xp9vXR5uuSc8b19r/EqpOHREavwiUgLMAhYDRcaYCrC+HIAhMX1xpxX8bullkTZx7p1+2VuPf9s78MBZ3U/TjAR/eFaPBr9SKn7EPPhFJAN4FviGMabpIJ53o4gsFZGl1dXVh96ASI+/pxp/B7hSwJNm3e7tIK5dH8GuxdDaTbu01KOUimMxDX4RcWOF/uPGmH/amytFpNi+vxio6uq5xpi/GGPmGGPmFBYWHnojHFE9/m5n9XSAOwXcdvD31uPvbLYuOxq7vj88OKxH7iql4lAsZ/UI8ACwzhhzV9RdLwJX2devAl6IVRuA/U7E0t3grt3jd/exxx8J/oau7w/X9D3p9m09clcpFT9cMdz3ScCVwCoRWWFv+z5wB/CUiFwH7AQ+H8M2RObxuyWEv6cef3Spp9cev12x6rbHbwe9KwWcXu3xK6XiSsyC3xjzHiDd3H1GrF73ACLgcOEi2PPgrisF3HYPPTy9szu9lXrCg75Ot7VfXatHKRVHEv/IXQCHq/dz7roPYnA3HPztvZR6nF5webTHr5SKK0kT/C5ChAwEQ13U+fev8fdXqcfpsfarNX6lVBxJnuCXIEDXvf5Ijd8u9fR2AFdvg7vh0o7LY4W/9viVUnEkaYLfjRX8Xdb5A532QKzbmgXU2wqdvU7n3K/Hr/P4lVJxJGmC34UV+NEze6qb7UAOtIPLC4DxpOFrb+l+X8ZAR19LPeEavwa/Uip+JEfwO904CZd6rBr/8p31HPvzhWyuarGC2Z0KQEPAzQfrd3a/r0CntYIn9DC4G1XqcaXoWj1KqbiSHMHvcEaCP3z07vaaVoyBnXWt1vRNu8ffFvLQ0dZDjz9c5oEepnOGZ/WEa/wa/Eqp+JEcwZ+SQ4rf6p2Ha/z1bVavva7Vb9f4rR5/i/HiCLTT4Q92va/wjB6Hq/clG7TGr5SKQ8kR/DkjSWvfA+yd1VPfapVj6lo7IzV+YwzNQQ9pdFJW381BXOEef9aw3pdscHq0xq+UijvJEfzZI0ltLwfM3uBvs4K/vqXdOmOWO5XGdj+txku6tFNW382UznCPP3uUdT3UxS+DyHROr9b4lVJxJ2mC3xVoI4eWA4K/pdmu57u81LR0UkM2BdLUe48/Z6R12VW5Jzy463DZa/X0Mfg7W+Dpq2mv3sYj/91OqKuDzZRS6jAlSfCPAGC41OILWGFaZ5d6WtrsOfuuVKqbfVSZHAppoKyuux6/HfzZPQV/pxX4Ilavv6/Bv2sxrHmO5f95gR++uIaVu7sZQ1BKqcOQHMFv986HS3Wkx99gD+62tu7t8de2dlJtcvBKgPq6yq73FQl+68uk6+D3R2YJHVTwV68HoGJ3GWCPPyilVD9LjuC3e+fDpDYS/OEef3u4x+9Opaa5kyqTA0BH3e6u9xWu8UdKPV0M8AY6raOAwQr+vtb4q9YB0FS3x26jv2/PU0qpg5AcwZ+WT8iVwnCpwR8MYYyJ9Pjb28OlHi81LT6qsYI/0Lin6311NluzddLtUwV3V+N32j1+p9e6HepmZdBodo8/K2TtMzzzSCml+lNyBL8IgYzhDJMafEFDq89amz/N4yTQadfyXSnUtHTiS7UC3dte1fVc/o4m65SKKdnW7a6O3g369u3xh7f1xBio3gBAnjTjcgh1bRr8Sqn+lxzBDwSzRlg9/kAo0pMeV5iBx9jlFFcKNS0+TEYRAEOkgd0NXczs6Wy2gj/V+mXQZY8/0LlvjR+gai28e5cV8NE+/BNsehOadkfKSCO9beSle7THr5SKiaQJfpM1wprVEwxFpnKOLUwnRfaeJrGmpZPMrByCrnQKpbHrKZ3h4PdkgDi7H9x1euz92sH/8rfgrR+xbuN6nllWZjfKwFs/gde/D1VWmWe3yWeIs4W8dE9kHEIppfpT8gR/9kgKpZGgrz0SqOMKM/Bi9/jdVvAXZHgxGUUMkfquD+LqbAZvtjVVMyW768HdYOfe4A/X+suXA/DqOx/wg+dXYYyBpnJrCeiajfDx3wBYHJpMeqCB3DRP5Auq5z/MwKpn9OhgpVSfJU3wS84oADyt5ZGB3XGFGaSwt8df2+IjP92DM2soRdLQTY/frvGDHfzdDO5GSj0pdgOsk777q7fQ4Q9R0+KD2k17n7P2eTq8+WwJDcMVaGVIKn3r8Zd/DM9eB+v+1ftjlVKKJAp+pz39MqW1Ym+Pf0g6XrG+BNpCbtr9QQoyvUhmEcXOJnbWdtXj70PwB6IHd+2e/5xrMQ4X6W27AKxfEzV28JecAkBt6hjqsPY93NsaWUiuR3VbrcvGst4fq5RSJFPw51k9/rT23dS3+XAIlOSnR3r8tZ0CQEGGFzKGUki9tVb//sI1frAGeLud1WP3+IdOt4L9lFvoTB/OaLEODNtV3w61m62xglO+BUCZazRt7lwAil2tNLT5uj5HcLSGHdZlc0Vf3wqlVJJLnuDPHoYfJxk1q6hv85GT5iHF7eRM1yd0ODOoDlglmfwMD2QWkWLa2VNTQ2D/UzVGB39PpZ5wjT9vDDULnoWsYdR6hjFKqoCoHn/+OBgzF465noWe03GkFwAwxNVMyEBTey+9/vrt1mVT+aG8LSrOLFxbSZsvMNDNUAkuaYJfXB4+yDiL0vqXMQ3l5KS5Yfv7zJPlLMz7AtXtVo+/0O7xA+SG6tgeXe4JdFqhHgn+HGitPvDgrKAvUuL57+YajvnZQpbtqGenGUKJo4rcNLc1flCzCfIngMMB5/yGDzpH480qBKBArKUhep3LX2/3+DX4B72dtW1c/+hS/rm8m6PGleonSRP8AGVHfxUxhmN3P0xeqhsW/pBaRz4veM+lpsWaFVOQ4YVMey4/DWyuijrjVnidHm+WdVlyMrTXwfZ39n2hwN5ZPct31mMMPPrBdtZ15JNNC5NyguypqYfGXVAwIfK0ioYO0nOt18421mv1Opc/3OPXUs+gt9NeGLDblWGV6idJFfxTpxzN08G5fMb3Br+vuwHKlvBizhfZ0+6gptkK2Lx0T6THP0Qa2FQZVecPr9OTYgf/5PMgNReWPrTvC0WVetbtsQL8lVUVLGuyDvqakV6Po24rYCB/PAAd/iC1rT6y84aAOCPLNvQ4sycYsAZ1xQnNe7o+N4AaHHytlNdbn5WKRg1+FVvJFfzDsnjQcRFVJpfGlGFw3u9YXXQe1c2dvLOpmsJMLx6XAzKt4J+Q3srG6AHeDiv4tzYJNzy6lJpOgRlfgPUvQUvV3sdFBf+GPc0cVZSBPwSDXTIAABlJSURBVGjYErSWg5joqSWteZv1WLvHv6exA4DinDRIyyM9YA0a7zOXv6Np3zGFpjIwQSiebl1Gt0ENHv52uHcWQ9f8FbB++SkVS0kV/C6ng2ElR3GK7x7+OfV3UPpFctNT2NPUwbId9Xz/7EnWA1NzwelhQmormyqbqWv1cflfP2T7bquc8q8NLby5tpIbHl1K54wrrTN4vXwLvPBVWP+KNZ3T5aXDH2RbTSufnjqUk8bns9NYwV/iqGKUseu4do+/wg7+YTmpkJZPiq8e2G+Fzqe+CA98eu85fcP1/VEnWJfNWucflDa9AS2V5NStBKBce/wqxpIq+AGOG5MHQG6a1SPPTbcuPz97BJ+bZa+xLwKZxcwMrmJ3TT33vb2Z7K0vk/v6VzEOFy/v8jJpaCYrdjXwrUXtMHaedQDV6n/CU1eCrwWcHjZXtRAMGSYOzeSWT03kzBljMelDKApWcJSjDF9aMXjSgb0/74uzUyCtAGdHHSlux94ev78ddrwP1etg8Z+tbeH6fjj4dYB3cFr1DAA57dYXeWVTh559TcWUa6AbcKSFgz/PDvwzJg9hZ20bPzxvyr4PPOP/MezZ67hH7sKxGOZ5VrDWX8LaM+9j48t+7j9rImvLm/jtwo1cee0fOe4ir3XQ1gNnWcsrOz1ssOv7k4ZmMX5IBrNH58IDYygqe53znE3szDuPUfbLhXv8xdmpkJ4PVevIS/NQ22IHf9lSq4SUUQRv3wFHf96awy9OGHGM9ZgmHeAddDqaYOPr4HBRFCjHKSH8QQc1LZ0MyUoZ6NapBJV0Pf7Zo3P55UXTmT/NquNPGprFnQumk+bZ7zvw6AWUnfAjTneuYI6sZ8mk73Bu50/49vsuUtwOTh5fwJfmjqUoy8uv3tqBScu35vV/4SnIGwdDJrF+TxMel4OS/LS9+80bh9PXxNOBU3mp5NbI5vKGdnLS3KR6nJBWAK015KZHrdez47+AwKVPQKAD3rjN6vHnjLS+DBxua4VPNag8/sgfIdhJaMYX8OLn1EKrA1DeqHV+FTtJF/wiwsXHjCQzxd3rY3PnfY0r/Lfx87GPMvvi2yjOzWB3QzunTCgk1eMkxe3ka6dPYOmOet7eWG0/aTTcvBymXcT6Pc1MGJKByxn1Ns/9X7jkMe703szCjQ1c+Mf3uXvhRioaO6zePkBaPrTXk5/m3DurZ8d7MHQajJgNp34bVj1tLeecM9o6DiCz+MhM6exstmYx6aJwhy0QDDFy9yuUyxBqxn0OgNMLrEH9iq6WBFeqnyRd8B+MdK+Lr1x7Lf/7+dNwOIQLZw0H4FNTiiKPuWTOSEbmpfL9f67ik137Lt+wYU8zk4Zm7bvTvDEw+VxG5aexfGcDG/Y0c/fCTSzZVsewbPunfXoBYBjh7bR6/AEf7FpCaPRJrNjVwH2h82nLm2xNL80dbT0nq3jfGn9nS2T9nlDIcN3DS3jgvW2H/6Z8eB+89A147XuHv68kt7NsJyfKKp73H8+SlnwAZqXXAHR9Lgil+okGfy9OHFdAjj0QfOUJJVx5/GjOPro4cr/H5eBPl8/GIcLn7/uAF1ZY5ZY9jR1UNXcyaWhml/u97Zwp3HPpTBbfdiYTizJp7gxQnBMd/HBO81OEWmusJZ0D7fxyfQEX/OF97nhjKzc0XYdxuAkUTOJvH2xnY3smjVU78AXso4hf+ibcPR3+/TNeWrGdt9ZX8cdFm+kMHMZcf2OsXxpOLyx9AFY8cej7UjQvfxaXhPhX8ASeXN1Oo0ljVGg3KW5HZMxHqVjQ4D8IhZlefnLBNDK8+44HTBuezUtfP5lZo3L41lOf8O/1lXzt78vxuhzMm1jY5b5mj87l/JnDyfC6uPeyWaS6nRxVZH9JHPUZmPRZTqr6O4vMjbQ9djkAz1aP5CcXTOPv1x/H4rbhfG/U41y9agb/98Ia3tnjxt1ayY9eXG3N9V/3onU8wju/ZPRLX2BoaojaVh+vre7mXMJdqd6w7yJ0lauhZgOc9VNr4bmXvsmytRt5eumug3ofe9S4Gx45F2o2998+41Tu1hfZbIZT5hnL+1tq2WqGkd6ynWHZqXoQl4opDf5+kpvu4f6r5jB+SAbXPryUpTvq+c3FM5hQ1HWPP9rEoZl8+L0zuOI4u2zjSYdLH2frxQt5Ju3zfNxexNPBufz4srlcefxoThxfwM1nTODJ9QE+3NHEby+ZwbXzTyRNOvnXR+tY8srD1gDwxY/y3vRfcHRwHS8NvZ+xeR4e/3DngQ3Y8QEsvN2aOWSfGjK46S3Mn04k8PR1ex+36hlwuGDaRXDObyDQzpJnfsP3/rkqsuTFYXvnV7DtHXjnl/2zvyPp/XsjUzN71VjGqOYVfJA2jzkleYQM7HaOwFm3meKcFMr1IC4VQ0k3nTOWslLcPHj1MVz78BIuKh3BZ6cP6/Nzs9MOHGweO+UYxk45hg17msnwB5kxMidy303zxtHU7mfexCGcPKEA1lgTQ79avJHAilfpzB1DY9ZUvra6jptyvs6XKu7lBe8GFu4ex+67O8lr24Zr8nzcQybCWz+yDkJ777eYIVN43zGb0oqnEBykbl2IqViJFE2D1c/CuNOt6abp+WzNOYEL61/jrtB8nv94N9efMrbrP27nh7DoZzD/VzBkEnzyD9j+Low6HiaeDWnWFFsadsHHj1lrIa16Bk7/AeSM6nqfffDSynL2NHZ0367+tPU/8Ob/WW2fcNbeZT26s/IpAHYPP4djR+SzaEM1DamjofltSoYbFlbt1+MPhaxBfKX6gX6S+tmwnFRe+8ap3HBq/4XNxKGZ+4Q+gNvp4AefnWKFPljlodEncWPj3RznWMvf24/nu8+uot0X5MwrvguffxjvqNmc5FhLTV0db7WPJ/TJU/Dm/1GRdxw/mfA062f/iG3NTk7e8zfaPbncN/GvtBove179Fbz3G2jcxX+887j6oY+4/cU1/LR2HkOkga8UrOC1Jesw/i56qe318My1Vi/+kXOtQeHnbrSC/YWvYv4y11pnCOC9u6zLy5/BiND53u+tQeq2ur37C4UOOGG9PxjitdV7aPftHb94a10lNz/xMT99eR0fbKm1nxs88GT3/SHQaZ1TOb3QGnBf9pBVInvpm9avqGjBACz6BebfP+GD4BSKxkzh2DHWORg6sscAMNlTSVVzJ/7wkuCv3wa/nQK7llgD/Yv/DJsWHlQTmzr8hze+k0gCnbH5HAwiYgbBGzBnzhyzdOnS3h+Y7Doa4eFzMHtWc1rnXWw3Rdx29uR9voSaOvx0+IMs2VbPj//xNsc5NvCyvxSP20O73wqG/zcvj2vnTsLvyeaFO6/mQt+LODC8xCnc3PElRuVnUNHYgccpfJz/f7jqNgIQdKXhPOpT1lLTTrc1xrDxdWtJgvP/CG/8AFqr2FJ8Dj8IfRnZ9SF/9fwGV8E4PKPmYD5+jJapX6B67h2UP3w1J7QsxCkG43Ajp30PiqYRevW7iNODzL8Txp1GKGT49lMrWLhiIyOLi/njReOQN75PYMdH/DvjHJYFxjLXLOXiwp049qwETxrBwqk4Zn0BmXEpOKxTYlK7xZoVNer4vWdPA2tmlL/DKr912msl5Yyyjp3obIKKT+Cj+60xlcufhf/ea42N5IyCso/AnQ6XPw0lJ1lfgk9fDVvfZk/J5zhj/Wd58MbTmDUql2N/vpDvzAxy+fJLqcmZzn3VR+M95kqyqpbypfIfYJwpBI2hyTOEvI5d1nty+VPWL7BerN7dyBcf/IjhGcLfzs8hZ/jEvUuLdyXQaR0Y6IyDgkBbnfV+jjx273+rw7HxdasjMmwWnHMXFB5l/dL88E9QuQqmXwLTFoB7v4PnfK1WW1qqYMu/oWotTDnPev93fmgdQ5NRZE2vLpgADTth+3vWrLvhc6yOz9a3wd8GCGQNsz5T7XVWh8SdZk2VbqmE9AJM/nhk8nnWbL3DICLLjDFzDtg+EMEvIp8B7gGcwF+NMXf09HgN/oPQ3gC1W3h0Vz4rdjXwqwUzcDqky4cu2lDFvW9t4uoTS5g/rZiF6yrxB0OcP3N45DGLV3zC1OfOYlFoJq9O+AnXzR3P7NF5+IMhOvxBMqtX0LHmX9z1fh3TvFWcHFpCdqgBJ3vPUfDu6K/w5+AFOOq3MLzxY54MnMrEodnMPaqQ7R+9yB+4E4PweOB0fh24mBbSGO+p48c5L/NBXSaTZDvnOD8CYEuoGLeEGCWV1HuGUesaQmbrdoqkgXqTSRAhhxY2O8cyKWQNEPuNk63eyVRlTqG5uYnxHas4yrGb1vSROLOH4+6owVlnPTbgzaF5yByc3jRS69bjtr/U9mfEiRi7B+1KpaP0et4r+TpbFv+LL+34FkEcrJn5/xi39W+ktOyioWA26e3leFrLKT/55zzWeSr3/WcLK28/i6wUN9XNnWSlOPD+5+e0rvoX6Y2baDKpIA52hQq41vcd7vX8nmKp4w7/pXzd9TwljireLbiUzpR8ynzplHd4GJ/vZdKQVDIys3CYIK3lG9ix9iOOdmxjTGgnbgnid2ezZ9KVkD2CFPHjcbtpbmqgZt17FLdvojBUTSg1j47ZX6Ku6ESqmjrISXUzKj8Fj0MI+toJVm8m1FyJL2sk4k4lo349+FvxeXMJePOR9Dza29roaK4l19FGmvis41MyiiBjCIjD+rJtq7XWngr5rXJjWr51TIo4oGYjfPAH6GwikDWK2vEXYfLHkZqaRlagDvFkWMHa3mAtcR4KYIwhaCDQ2QZ1WxETxDn6BJodWdRvWUrJuj/TmF6Ct72KlFArIXHhMn5C4qQlpZis9jKMw4VkDYOUHAxASyXSUhn1X1+s8mRbbTf/EwpwYK4aTyaSmmP9nS2VYELWYo4OF/jbCLozqCWbNH89GbQRxIlvwjmknv0TyC3p5rV6FjfBLyJOYCPwKaAMWAJcZoxZ291zNPgH1jurtzCqqIiSwoxuH/OHRZtZuK4Sj9NhrXAaCrJ751YyAnWsZixTh+UwIjeVkoJ0zpsxjMnFVg18VVkjP3ngKXyebM495RgyU1zUtfq4YOZwhmansLGymTfW7GHo7jfJ9O1ha8ml1DZ3MHTTExS3rGaoqcadP4ajS0+kafd6qivLaTn+Fo4+Zh7OssXQtJtfbR7OCxva6AyEGFuQTumoHJpXPMen2l7FK37ajJd3Q0dTbvKZ7/yISbKLFHzsNgX8OzSLGpNFunTSbFJpIZWRUsVQqafeZLDTFPGhYwaNAWvKb6bXyT35z7KopYS/Nc0kn0a+6XqGaY5tpNHJ9/3XsdRYiwGOykvjnf897YD3MhQyfPDhu5RuvY+Uio9458RHWOMv4qzJQxhTkMHuhg4+WLGK4z74MiWBrb3+92uUTLwjZ1OTNZnfrXRwpvmQTzmXHfC4XRSxzTORFW15zJCtzHWu7NPnAyBohA68pEvXg9JBBGcXYRj5mxFCOHCxbznqXccxvB48hvPNQo5xdP0l3J0qk4MQolCaItveDM7mf/xfpSQLvpT2NpW1DTSEUnk+eBLl5HOCYy1zXaspppYM0wpArcliB0XUkUMzGXwsR9Ek2ZzmWM4Us5X/+o9iK8MZm9rKeFcVJaFdVISyeds3maHBCmY6NrMsdBTvh6bhcXtI8zjJ9BhSJEB1hwsjgkugqsVHTpqbk8bmUyIV5K3/O+c63qf6ireYOmH8Qf3tYfEU/CcAtxtjPm3f/h6AMeYX3T1Hg39w6vAHWb27kQlDMrscvA5r8wXwOB37HuHcB6GQoanDHznO4mAEgiEWb6tjd307De0+MrxuslJdZKW4cYjQ1OGnsd1PU7uf3HQPo/LSaO0MUNXcSYc/iD8YwhcI4QsafIEQWakuZo/KZcbIHFLczsj+vS4HhZleGtv91Lf5McbQGQhR3+pj4tBMZo3KPei27yPot0oQbTXQ3kDA4aas0U9LcyNBI+SMmMSw4aNwu6wySX2rj90N7XTWl9Pe2UlL0EV7pw+Xy8PppZNI97rYVNnM2oomnNVrKQhUUpDppb41wK6GDkJGcLg9tKSPJphWQJ6vAvG3sckMoxMvQ1IMmaYJV0c9aamppGTns73ZxeY6P55AM5mBejICtThMkFrvCFpceQTFhRGrfVnSRn6oljafn1p/Cm0pQ8lMcTGuMJ2hqSFczbtobm1jS1s6/vYmsjrK8bkyaUsbjsuTQorbgdftxOX24PSmEwyGcNVvJdvlY9TYiRQWDSPF5SAv3YOIUNnUwX82VjOxKJP8DA/vbqphe00rDofgcggOsX4th4whZAzBEPal9U8E0j0uDIbaFh9tviAGSHM7yUp1kZ3qJt3rwhcI0eYL0uYL2JdBQsaQ7nXhEGj3hZg5KocFpSOsZVuAXXVtPPbBFr7zmakH/f9GWDwF/wLgM8aY6+3bVwLHGWO+tt/jbgRuBBg1atTsHTt2HNF2KqXUYNdd8A/ErJ6uCs4HfPsYY/5ijJljjJlTWNj1QVBKKaUO3kAEfxkwMur2CEAXkldKqSNkIIJ/CTBBRMaIiAe4FHhxANqhlFJJ6YhP1DXGBETka8DrWNM5HzTGrDnS7VBKqWQ1IEdoGGNeAV4ZiNdWSqlkp0s2KKVUktHgV0qpJKPBr5RSSWZQLNImItXAoR7BVQDU9GNzjpTB2m4YvG0frO2Gwdt2bXdsjTbGHHAg1KAI/sMhIku7OnIt3g3WdsPgbftgbTcM3rZruweGlnqUUirJaPArpVSSSYbg/8tAN+AQDdZ2w+Bt+2BtNwzetmu7B0DC1/iVUkrtKxl6/EoppaJo8CulVJJJ6OAXkc+IyAYR2Switw50e7ojIiNFZJGIrBORNSLyP/b220Vkt4issP+dPdBt3Z+IbBeRVXb7ltrb8kTkTRHZZF8e5mmm+p+ITIx6X1eISJOIfCMe33MReVBEqkRkddS2Lt9jsdxrf+ZXikjpwLW827b/SkTW2+17TkRy7O0lItIe9d7fF2ft7vazISLfs9/zDSLy6YFp9UEwxiTkP6yVP7cAYwEP8AkwZaDb1U1bi4FS+3om1jmJpwC3A98e6Pb10vbtQMF+234J3GpfvxW4c6Db2YfPyh5gdDy+58CpQCmwurf3GDgbeBXrhEfHA4vjsO1nAS77+p1RbS+JflwctrvLz4b9/+ongBcYY+eOc6D/hp7+JXKP/1hgszFmqzHGBzwJnD/AbeqSMabCGLPcvt4MrAOGD2yrDsv5wCP29UeACwawLX1xBrDFGBOX5/c0xrwD1O23ubv3+HzgUWP5EMgRkeIj09IDddV2Y8wbxpiAffNDrJMxxZVu3vPunA88aYzpNMZsAzZj5U/cSuTgHw7sirpdxiAIUxEpAWYBi+1NX7N/Ej8YjyUTrNNmviEiy+zzJAMUGWMqwPpSA4YMWOv65lLgiajb8f6eQ/fv8WD73F+L9QslbIyIfCwi/xGRUwaqUT3o6rMx2N7zhA7+Pp3bN56ISAbwLPANY0wT8CdgHDATqAB+M4DN685JxphSYD7wVRE5daAbdDDss8CdBzxtbxoM73lPBs3nXkRuAwLA4/amCmCUMWYWcAvwdxHJGqj2daG7z8agec/DEjn4B9W5fUXEjRX6jxtj/glgjKk0xgSNMSHgfuLw56Mxpty+rAKew2pjZbi8YF9WDVwLezUfWG6MqYTB8Z7bunuPB8XnXkSuAj4LXG7sQrldKqm1ry/DqpUfNXCt3FcPn41B8Z5HS+TgHzTn9hURAR4A1hlj7oraHl2b/Rywev/nDiQRSReRzPB1rEG71Vjv81X2w64CXhiYFvbJZUSVeeL9PY/S3Xv8IvBFe3bP8UBjuCQUL0TkM8B3gfOMMW1R2wtFxGlfHwtMALYOTCsP1MNn40XgUhHxisgYrHZ/dKTbd1AGenQ5lv+wZjhsxOo53DbQ7emhnSdj/TRcCayw/50N/A1YZW9/ESge6Lbu1+6xWLMZPgHWhN9jIB94C9hkX+YNdFu7aX8aUAtkR22Lu/cc64upAvBj9S6v6+49xio7/MH+zK8C5sRh2zdj1cTDn/X77MdeZH+OPgGWA+fGWbu7/WwAt9nv+QZg/kB/Znr7p0s2KKVUkknkUo9SSqkuaPArpVSS0eBXSqkko8GvlFJJRoNfKaWSjAa/UoCIBPdbrbPfVnO1V52M1+MBVBJyDXQDlIoT7caYmQPdCKWOBO3xK9UD+3wDd4rIR/a/8fb20SLylr1g11siMsreXmSvMf+J/e9Ee1dOEblfrPMtvCEiqQP2R6mkp8GvlCV1v1LPJVH3NRljjgV+D9xtb/s91vLH07EWGbvX3n4v8B9jzAys9dzX2NsnAH8wxkwFGrCOUlVqQOiRu0oBItJijMnoYvt24HRjzFZ7Ib09xph8EanBOmTfb2+vMMYUiEg1MMIY0xm1jxLgTWPMBPv2dwG3Meansf/LlDqQ9viV6p3p5np3j+lKZ9T1IDq+pgaQBr9Svbsk6vID+/p/sVZ8BbgceM++/hZwE4CIOONsPXmlAO11KBWWKiIrom6/ZowJT+n0ishirI7SZfa2m4EHReQ7QDVwjb39f4C/iMh1WD37m7BWeVQqbmiNX6ke2DX+OcaYmoFui1L9RUs9SimVZLTHr5RSSUZ7/EoplWQ0+JVSKslo8CulVJLR4FdKqSSjwa+UUknm/wNVyqVExwNyagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfit checks:\n",
      "Model Accuracy: 0.7751592397689819\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------- Data from the paper ------------------------------------\")\n",
    "frame = load_frame()\n",
    "data_x, data_y, number_of_features = load_all_data_static(frame)\n",
    "x_train, y_train, x_test, y_test, x_validate, y_validate = median(data_x, data_y, frame)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dense(number_of_features, activation='relu', input_dim=number_of_features))\n",
    "model.add(keras.layers.Dense(40, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "model.add(keras.layers.Dense(20, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping_monitor = keras.callbacks.EarlyStopping(patience=40,restore_best_weights=True)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=1000, verbose=0,\n",
    "          validation_data=(x_validate, y_validate), callbacks=[early_stopping_monitor])\n",
    "\n",
    "silent_evaluation(model, x_test, y_test)\n",
    "plot_graphs(history)\n",
    "print(\"Overfit checks:\")\n",
    "silent_evaluation(model, x_train, y_train)\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "print(\"-------------------------- Data from the paper + mine ------------------------------------\")\n",
    "\n",
    "frame = load_frame()\n",
    "data_x, data_y, number_of_features = load_all_data_with_mine(frame)\n",
    "x_train, y_train, x_test, y_test, x_validate, y_validate = median(data_x, data_y, frame)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dense(number_of_features, activation='relu', input_dim=number_of_features))\n",
    "model.add(keras.layers.Dense(40, activation='relu'))\n",
    "model.add(keras.layers.Dense(20, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping_monitor = keras.callbacks.EarlyStopping(patience=40,restore_best_weights=True)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=1000, verbose=0,\n",
    "          validation_data=(x_validate, y_validate), callbacks=[early_stopping_monitor])\n",
    "\n",
    "silent_evaluation(model, x_test, y_test)\n",
    "plot_graphs(history)\n",
    "print(\"Overfit checks:\")\n",
    "silent_evaluation(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #4: Take half of the data - Static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Data from the paper ------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 83.93%\n",
      "Overfit: 92.15%\n",
      "-------------------------------------------\n",
      "accuracy: 91.07%\n",
      "Overfit: 93.74%\n",
      "-------------------------------------------\n",
      "accuracy: 85.71%\n",
      "Overfit: 92.35%\n",
      "-------------------------------------------\n",
      "accuracy: 86.61%\n",
      "Overfit: 91.95%\n",
      "-------------------------------------------\n",
      "accuracy: 85.71%\n",
      "Overfit: 89.56%\n",
      "-------------------------------------------\n",
      "accuracy: 90.18%\n",
      "Overfit: 94.14%\n",
      "-------------------------------------------\n",
      "accuracy: 87.50%\n",
      "Overfit: 94.23%\n",
      "-------------------------------------------\n",
      "accuracy: 86.61%\n",
      "Overfit: 94.33%\n",
      "-------------------------------------------\n",
      "accuracy: 83.78%\n",
      "Overfit: 95.13%\n",
      "-------------------------------------------\n",
      "accuracy: 94.59%\n",
      "Overfit: 92.85%\n",
      "-------------------------------------------\n",
      "87.57% (+/- 3.24%)\n",
      "-------------------------- Data from the paper + mine ------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 87.50%\n",
      "Overfit: 93.34%\n",
      "-------------------------------------------\n",
      "accuracy: 83.04%\n",
      "Overfit: 92.05%\n",
      "-------------------------------------------\n",
      "accuracy: 86.61%\n",
      "Overfit: 92.84%\n",
      "-------------------------------------------\n",
      "accuracy: 88.39%\n",
      "Overfit: 88.87%\n",
      "-------------------------------------------\n",
      "accuracy: 91.96%\n",
      "Overfit: 92.84%\n",
      "-------------------------------------------\n",
      "accuracy: 94.64%\n",
      "Overfit: 91.55%\n",
      "-------------------------------------------\n",
      "accuracy: 90.18%\n",
      "Overfit: 91.55%\n",
      "-------------------------------------------\n",
      "accuracy: 90.18%\n",
      "Overfit: 89.26%\n",
      "-------------------------------------------\n",
      "accuracy: 88.29%\n",
      "Overfit: 94.44%\n",
      "-------------------------------------------\n",
      "accuracy: 94.59%\n",
      "Overfit: 92.06%\n",
      "-------------------------------------------\n",
      "89.54% (+/- 3.41%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nframe = load_frame()\\nframe = load_quartile(frame)\\ndata_x, data_y, number_of_features = load_all_data_with_mine_static(frame)\\nx_train, y_train, x_test, y_test, x_validate, y_validate = split_data(data_x, data_y)\\n\\n\\nprint(x_train.shape)\\n\\nmodel = keras.Sequential()\\n\\nmodel.add(keras.layers.Dropout(0.2, input_shape=(number_of_features,)))\\nmodel.add(keras.layers.Dense(40, activation=\\'relu\\', kernel_regularizer= keras.regularizers.l2(0.01)))\\nmodel.add(keras.layers.Dense(20, activation=\\'relu\\', kernel_regularizer= keras.regularizers.l2(0.01)))\\nmodel.add(keras.layers.Dense(3, activation=\\'softmax\\'))\\n\\nmodel.compile(optimizer=\\'adam\\',\\n              loss=\\'sparse_categorical_crossentropy\\',\\n              metrics=[\\'accuracy\\'])\\n\\n#early_stopping_monitor = keras.callbacks.EarlyStopping(patience=3,restore_best_weights=True)\\n\\nhistory = model.fit(x_train, y_train, epochs=100, verbose=0)#,\\n          #validation_data=(x_validate, y_validate), callbacks=[early_stopping_monitor])\\n\\nsilent_evaluation(model, x_test, y_test)\\nplot_graphs(history)\\nprint(\"Overfit checks:\")\\nsilent_evaluation(model, x_train, y_train)\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "print(\"-------------------------- Data from the paper ------------------------------------\")\n",
    "\n",
    "frame = load_frame()\n",
    "frame = load_quartile(frame)\n",
    "data_x, data_y, number_of_features = load_all_data_static(frame)\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "\n",
    "data_x = data_x.values\n",
    "data_y = data_y.values\n",
    "\n",
    "for train, test in kfold.split(data_x, data_y):\n",
    "    \n",
    "    \n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Dropout(0.2, input_shape=(number_of_features,)))\n",
    "    model.add(keras.layers.Dense(40, activation='relu'))#, kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(20, activation='relu'))#, kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    #early_stopping_monitor = keras.callbacks.EarlyStopping(patience=3,restore_best_weights=True)\n",
    "    \n",
    "    early_stopping_monitor = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                              min_delta=0,\n",
    "                              patience=20,\n",
    "                              verbose=0, mode='auto')\n",
    "   \n",
    "    history = model.fit(data_x[train], data_y[train], epochs=1000, verbose=0) #,\n",
    "              #validation_data=(x_validate, y_validate)\n",
    "                        #, callbacks=[early_stopping_monitor])\n",
    "   \n",
    "    #history = model.fit(data_x[train], data_y[train], epochs=400, verbose=0) #,\n",
    "              #validation_data=(x_validate, y_validate), callbacks=[early_stopping_monitor])\n",
    "\n",
    "    #silent_evaluation(model, x_test, y_test)\n",
    "    #plot_graphs(history)\n",
    "    #print(\"Overfit checks:\")\n",
    "    #silent_evaluation(model, x_train, y_train)\n",
    "    scores = model.evaluate(data_x[test], data_y[test], verbose=0)\n",
    "    overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"Overfit: %.2f%%\" % (overfit[1]*100))\n",
    "    print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "print(\"-------------------------- Data from the paper + mine ------------------------------------\")\n",
    "\n",
    "\n",
    "frame = load_frame()\n",
    "frame = load_quartile(frame)\n",
    "data_x, data_y, number_of_features = load_all_data_with_mine_static(frame)\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "\n",
    "data_x = data_x.values\n",
    "data_y = data_y.values\n",
    "\n",
    "for train, test in kfold.split(data_x, data_y):\n",
    "    \n",
    "    \n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Dropout(0.2, input_shape=(number_of_features,)))\n",
    "    model.add(keras.layers.Dense(40, activation='relu'))#, kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(20, activation='relu'))#, kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    #early_stopping_monitor = keras.callbacks.EarlyStopping(patience=3,restore_best_weights=True)\n",
    "    \n",
    "    \n",
    "    early_stopping_monitor = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                                           min_delta=0,\n",
    "                                                           patience=20,\n",
    "                                                           verbose=0, mode='auto')\n",
    "   \n",
    "    history = model.fit(data_x[train], data_y[train], epochs=1000, verbose=0) #,\n",
    "              #validation_data=(x_validate, y_validate)\n",
    "                       # , callbacks=[early_stopping_monitor])\n",
    "\n",
    "    #silent_evaluation(model, x_test, y_test)\n",
    "    #plot_graphs(history)\n",
    "    #print(\"Overfit checks:\")\n",
    "    #silent_evaluation(model, x_train, y_train)\n",
    "    scores = model.evaluate(data_x[test], data_y[test], verbose=0)\n",
    "    overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"Overfit: %.2f%%\" % (overfit[1]*100))\n",
    "    print(\"-------------------------------------------\")\n",
    "\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Data from the paper ------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 86.61%\n",
      "Overfit: 91.25%\n",
      "-------------------------------------------\n",
      "accuracy: 86.61%\n",
      "Overfit: 90.26%\n",
      "-------------------------------------------\n",
      "accuracy: 82.14%\n",
      "Overfit: 92.54%\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-2235f4086ff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m                               verbose=0, mode='auto')\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m               \u001b[0;31m#validation_data=(x_validate, y_validate)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                         \u001b[0;31m#, callbacks=[early_stopping_monitor])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "print(\"-------------------------- Data from the paper ------------------------------------\")\n",
    "\n",
    "frame = load_frame()\n",
    "frame = load_quartile(frame)\n",
    "data_x, data_y, number_of_features = load_all_data(frame)\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "\n",
    "data_x = data_x.values\n",
    "data_y = data_y.values\n",
    "\n",
    "for train, test in kfold.split(data_x, data_y):\n",
    "    \n",
    "    \n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Dropout(0.3, input_shape=(number_of_features,)))\n",
    "    model.add(keras.layers.Dense(40, activation='relu'))#, kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(20, activation='relu'))#, kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    #early_stopping_monitor = keras.callbacks.EarlyStopping(patience=3,restore_best_weights=True)\n",
    "    \n",
    "    early_stopping_monitor = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                              min_delta=0,\n",
    "                              patience=20,\n",
    "                              verbose=0, mode='auto')\n",
    "   \n",
    "    history = model.fit(data_x[train], data_y[train], epochs=1000, verbose=0) #,\n",
    "              #validation_data=(x_validate, y_validate)\n",
    "                        #, callbacks=[early_stopping_monitor])\n",
    "   \n",
    "    #history = model.fit(data_x[train], data_y[train], epochs=400, verbose=0) #,\n",
    "              #validation_data=(x_validate, y_validate), callbacks=[early_stopping_monitor])\n",
    "\n",
    "    #silent_evaluation(model, x_test, y_test)\n",
    "    #plot_graphs(history)\n",
    "    #print(\"Overfit checks:\")\n",
    "    #silent_evaluation(model, x_train, y_train)\n",
    "    scores = model.evaluate(data_x[test], data_y[test], verbose=0)\n",
    "    overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"Overfit: %.2f%%\" % (overfit[1]*100))\n",
    "    print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "print(\"-------------------------- Data from the paper + mine ------------------------------------\")\n",
    "\n",
    "\n",
    "frame = load_frame()\n",
    "frame = load_quartile(frame)\n",
    "data_x, data_y, number_of_features = load_all_data_with_mine(frame)\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "\n",
    "data_x = data_x.values\n",
    "data_y = data_y.values\n",
    "\n",
    "for train, test in kfold.split(data_x, data_y):\n",
    "    \n",
    "    \n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Dropout(0.3, input_shape=(number_of_features,)))\n",
    "    model.add(keras.layers.Dense(40, activation='relu'))#, kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(20, activation='relu'))#, kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    #early_stopping_monitor = keras.callbacks.EarlyStopping(patience=3,restore_best_weights=True)\n",
    "    \n",
    "    \n",
    "    early_stopping_monitor = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                                           min_delta=0,\n",
    "                                                           patience=20,\n",
    "                                                           verbose=0, mode='auto')\n",
    "   \n",
    "    history = model.fit(data_x[train], data_y[train], epochs=1000, verbose=0) #,\n",
    "              #validation_data=(x_validate, y_validate)\n",
    "                       # , callbacks=[early_stopping_monitor])\n",
    "\n",
    "    #silent_evaluation(model, x_test, y_test)\n",
    "    #plot_graphs(history)\n",
    "    #print(\"Overfit checks:\")\n",
    "    #silent_evaluation(model, x_train, y_train)\n",
    "    scores = model.evaluate(data_x[test], data_y[test], verbose=0)\n",
    "    overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"Overfit: %.2f%%\" % (overfit[1]*100))\n",
    "    print(\"-------------------------------------------\")\n",
    "\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #5: Predicting Mutation Score\n",
    "   Try to predict the mutation score itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1570, 82)\n",
      "Train on 1570 samples, validate on 336 samples\n",
      "Epoch 1/1000\n",
      "1570/1570 [==============================] - 1s 734us/sample - loss: 113182.8795 - mae: 106.0400 - val_loss: 139054.0076 - val_mae: 153.7570\n",
      "Epoch 2/1000\n",
      "1570/1570 [==============================] - 0s 139us/sample - loss: 113736.5660 - mae: 83.2776 - val_loss: 52778.3592 - val_mae: 78.8578\n",
      "Epoch 3/1000\n",
      "1570/1570 [==============================] - 0s 142us/sample - loss: 174392.0985 - mae: 107.4330 - val_loss: 3250.6254 - val_mae: 27.2419\n",
      "Epoch 4/1000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 7450.4787 - mae: 23.5551 - val_loss: 1853.9014 - val_mae: 15.7264\n",
      "Epoch 5/1000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 3544.1816 - mae: 16.4785 - val_loss: 913.2954 - val_mae: 11.5479\n",
      "Epoch 6/1000\n",
      "1570/1570 [==============================] - 0s 140us/sample - loss: 4650.2080 - mae: 18.3478 - val_loss: 4315.4333 - val_mae: 25.4449\n",
      "Epoch 7/1000\n",
      "1570/1570 [==============================] - 0s 134us/sample - loss: 34967.7774 - mae: 48.6661 - val_loss: 9044.7032 - val_mae: 43.4314\n",
      "Epoch 8/1000\n",
      "1570/1570 [==============================] - 0s 138us/sample - loss: 10337.8360 - mae: 44.2289 - val_loss: 881.9847 - val_mae: 14.6640\n",
      "Epoch 9/1000\n",
      "1570/1570 [==============================] - 0s 146us/sample - loss: 1972.7937 - mae: 13.1601 - val_loss: 506.5002 - val_mae: 9.4510\n",
      "Epoch 10/1000\n",
      "1570/1570 [==============================] - 0s 146us/sample - loss: 817.0697 - mae: 9.6683 - val_loss: 594.6676 - val_mae: 9.1803\n",
      "Epoch 11/1000\n",
      "1570/1570 [==============================] - 0s 151us/sample - loss: 1137.4786 - mae: 12.6008 - val_loss: 967.8354 - val_mae: 11.4093\n",
      "Epoch 12/1000\n",
      "1570/1570 [==============================] - 0s 136us/sample - loss: 5235.4332 - mae: 27.0049 - val_loss: 495.9033 - val_mae: 8.4890\n",
      "Epoch 13/1000\n",
      "1570/1570 [==============================] - 0s 136us/sample - loss: 3276.6045 - mae: 18.2883 - val_loss: 526.4773 - val_mae: 9.4714\n",
      "Epoch 14/1000\n",
      "1570/1570 [==============================] - 0s 138us/sample - loss: 1783.5492 - mae: 15.6018 - val_loss: 837.8792 - val_mae: 10.6467\n",
      "Epoch 15/1000\n",
      "1570/1570 [==============================] - 0s 138us/sample - loss: 5763.3074 - mae: 16.5517 - val_loss: 5563.1964 - val_mae: 30.8733\n",
      "Epoch 16/1000\n",
      "1570/1570 [==============================] - 0s 141us/sample - loss: 2723.0138 - mae: 20.4057 - val_loss: 867.9810 - val_mae: 11.3747\n",
      "Epoch 17/1000\n",
      "1570/1570 [==============================] - 0s 145us/sample - loss: 3412.1744 - mae: 15.7719 - val_loss: 6571.4067 - val_mae: 30.8788\n",
      "Epoch 18/1000\n",
      "1570/1570 [==============================] - 0s 144us/sample - loss: 7286.0687 - mae: 26.5797 - val_loss: 2589.5335 - val_mae: 21.0122\n",
      "Epoch 19/1000\n",
      "1570/1570 [==============================] - 0s 137us/sample - loss: 39214.5195 - mae: 50.6475 - val_loss: 130055.7245 - val_mae: 144.1137\n",
      "Epoch 20/1000\n",
      "1570/1570 [==============================] - 0s 135us/sample - loss: 13990.0745 - mae: 49.9680 - val_loss: 5913.8545 - val_mae: 24.4840\n",
      "Epoch 21/1000\n",
      "1570/1570 [==============================] - 0s 135us/sample - loss: 14643.5697 - mae: 32.1846 - val_loss: 1480.8941 - val_mae: 16.1084\n",
      "Epoch 22/1000\n",
      "1570/1570 [==============================] - 0s 143us/sample - loss: 15190.1122 - mae: 32.5613 - val_loss: 1447.3317 - val_mae: 17.9688\n",
      "Epoch 23/1000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 1075.0520 - mae: 13.0598 - val_loss: 931.0670 - val_mae: 12.7477\n",
      "Epoch 24/1000\n",
      "1570/1570 [==============================] - 0s 151us/sample - loss: 487.0555 - mae: 9.1824 - val_loss: 627.7720 - val_mae: 10.6310\n",
      "Epoch 25/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 413.2343 - mae: 8.8187 - val_loss: 267.1695 - val_mae: 7.5034\n",
      "Epoch 26/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 249.5182 - mae: 7.0423 - val_loss: 334.1821 - val_mae: 8.0195\n",
      "Epoch 27/1000\n",
      "1570/1570 [==============================] - 0s 142us/sample - loss: 233.7093 - mae: 7.0463 - val_loss: 500.8739 - val_mae: 9.5919\n",
      "Epoch 28/1000\n",
      "1570/1570 [==============================] - 0s 136us/sample - loss: 170.6320 - mae: 6.6542 - val_loss: 112.6687 - val_mae: 5.4869\n",
      "Epoch 29/1000\n",
      "1570/1570 [==============================] - 0s 151us/sample - loss: 292.2411 - mae: 7.1180 - val_loss: 134.9743 - val_mae: 5.6343\n",
      "Epoch 30/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 129.7848 - mae: 5.7369 - val_loss: 124.4690 - val_mae: 5.3980\n",
      "Epoch 31/1000\n",
      "1570/1570 [==============================] - 0s 136us/sample - loss: 402.0762 - mae: 6.6273 - val_loss: 205.3842 - val_mae: 6.8562\n",
      "Epoch 32/1000\n",
      "1570/1570 [==============================] - 0s 138us/sample - loss: 1615.9511 - mae: 10.5904 - val_loss: 1080.1087 - val_mae: 13.1435\n",
      "Epoch 33/1000\n",
      "1570/1570 [==============================] - 0s 138us/sample - loss: 351.5496 - mae: 7.4158 - val_loss: 169.3035 - val_mae: 6.6985\n",
      "Epoch 34/1000\n",
      "1570/1570 [==============================] - 0s 138us/sample - loss: 161.7573 - mae: 5.5853 - val_loss: 124.1131 - val_mae: 5.7676\n",
      "Epoch 35/1000\n",
      "1570/1570 [==============================] - 0s 141us/sample - loss: 158.8670 - mae: 5.4452 - val_loss: 139.5126 - val_mae: 5.4448\n",
      "Epoch 36/1000\n",
      "1570/1570 [==============================] - 0s 152us/sample - loss: 268.2858 - mae: 6.1216 - val_loss: 200.2166 - val_mae: 5.3807\n",
      "Epoch 37/1000\n",
      "1570/1570 [==============================] - 0s 134us/sample - loss: 630.0390 - mae: 9.9504 - val_loss: 91.9009 - val_mae: 4.8865\n",
      "Epoch 38/1000\n",
      "1570/1570 [==============================] - 0s 143us/sample - loss: 1277.4299 - mae: 10.7615 - val_loss: 651.8568 - val_mae: 10.3234\n",
      "Epoch 39/1000\n",
      "1570/1570 [==============================] - 0s 143us/sample - loss: 1765.0878 - mae: 17.7560 - val_loss: 156.2526 - val_mae: 5.9187\n",
      "Epoch 40/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 3496.2974 - mae: 19.6493 - val_loss: 302.1187 - val_mae: 6.5281\n",
      "Epoch 41/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 876.0633 - mae: 10.2616 - val_loss: 185.4892 - val_mae: 5.7217\n",
      "Epoch 42/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 549.4786 - mae: 7.0062 - val_loss: 371.5427 - val_mae: 7.0064\n",
      "Epoch 43/1000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 152.9221 - mae: 5.5307 - val_loss: 246.7181 - val_mae: 5.7764\n",
      "Epoch 44/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 301.5520 - mae: 6.5656 - val_loss: 91.9426 - val_mae: 4.7482\n",
      "Epoch 45/1000\n",
      "1570/1570 [==============================] - 0s 140us/sample - loss: 2406.1068 - mae: 13.0791 - val_loss: 448.2472 - val_mae: 9.1895\n",
      "Epoch 46/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 248.5199 - mae: 6.4661 - val_loss: 355.8395 - val_mae: 8.3022\n",
      "Epoch 47/1000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 135.1347 - mae: 4.9343 - val_loss: 95.8755 - val_mae: 4.5560\n",
      "Epoch 48/1000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 117.2835 - mae: 4.4129 - val_loss: 79.1344 - val_mae: 4.2479\n",
      "Epoch 49/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 113.6899 - mae: 4.1629 - val_loss: 118.8744 - val_mae: 4.5765\n",
      "Epoch 50/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 98.5975 - mae: 3.9892 - val_loss: 58.5101 - val_mae: 3.8313\n",
      "Epoch 51/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 70.3216 - mae: 3.7738 - val_loss: 61.8210 - val_mae: 3.8338\n",
      "Epoch 52/1000\n",
      "1570/1570 [==============================] - 0s 144us/sample - loss: 97.9892 - mae: 3.7350 - val_loss: 270.8237 - val_mae: 5.9715\n",
      "Epoch 53/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 1098.1083 - mae: 7.8061 - val_loss: 58.0322 - val_mae: 3.7500\n",
      "Epoch 54/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 232.7806 - mae: 5.3090 - val_loss: 100.9055 - val_mae: 4.3301\n",
      "Epoch 55/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 1336.0965 - mae: 7.9809 - val_loss: 143.7688 - val_mae: 4.6235\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570/1570 [==============================] - 0s 163us/sample - loss: 440.5948 - mae: 9.1376 - val_loss: 101.6034 - val_mae: 4.5005\n",
      "Epoch 57/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 314.8555 - mae: 6.1410 - val_loss: 208.3716 - val_mae: 5.3296\n",
      "Epoch 58/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 265.6742 - mae: 5.7123 - val_loss: 100.1253 - val_mae: 4.5011\n",
      "Epoch 59/1000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 360.7085 - mae: 5.4468 - val_loss: 570.0254 - val_mae: 8.8078\n",
      "Epoch 60/1000\n",
      "1570/1570 [==============================] - 0s 143us/sample - loss: 1554.4353 - mae: 10.2607 - val_loss: 5483.1824 - val_mae: 20.8382\n",
      "Epoch 61/1000\n",
      "1570/1570 [==============================] - 0s 144us/sample - loss: 8075.4440 - mae: 25.2770 - val_loss: 4581.4790 - val_mae: 23.8613\n",
      "Epoch 62/1000\n",
      "1570/1570 [==============================] - 0s 139us/sample - loss: 61576.1067 - mae: 50.3083 - val_loss: 6456.0847 - val_mae: 30.0983\n",
      "Epoch 63/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 1426.8734 - mae: 16.6091 - val_loss: 1544.9214 - val_mae: 14.3170\n",
      "Epoch 64/1000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 3675.6793 - mae: 11.5127 - val_loss: 570.9763 - val_mae: 8.9891\n",
      "Epoch 65/1000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 14058.0051 - mae: 14.6195 - val_loss: 17157.7266 - val_mae: 15.9856\n",
      "Epoch 66/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 132840.2647 - mae: 31.5427 - val_loss: 3362.0762 - val_mae: 23.3706\n",
      "Epoch 67/1000\n",
      "1570/1570 [==============================] - 0s 141us/sample - loss: 9658.5605 - mae: 17.5164 - val_loss: 1736.2243 - val_mae: 16.3676\n",
      "Epoch 68/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 401.4570 - mae: 7.5592 - val_loss: 116.9845 - val_mae: 3.3850\n",
      "Epoch 69/1000\n",
      "1570/1570 [==============================] - 0s 142us/sample - loss: 202.4246 - mae: 3.6328 - val_loss: 129.6219 - val_mae: 3.6790\n",
      "Epoch 70/1000\n",
      "1570/1570 [==============================] - 0s 142us/sample - loss: 53.3617 - mae: 3.0035 - val_loss: 66.3888 - val_mae: 2.8896\n",
      "Epoch 71/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 39.6030 - mae: 2.6729 - val_loss: 74.9491 - val_mae: 2.9411\n",
      "Epoch 72/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 35.9795 - mae: 2.5998 - val_loss: 58.4259 - val_mae: 2.7858\n",
      "Epoch 73/1000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 33.4195 - mae: 2.5410 - val_loss: 67.3222 - val_mae: 2.7915\n",
      "Epoch 74/1000\n",
      "1570/1570 [==============================] - 0s 151us/sample - loss: 32.2191 - mae: 2.4947 - val_loss: 51.3648 - val_mae: 2.6638\n",
      "Epoch 75/1000\n",
      "1570/1570 [==============================] - 0s 146us/sample - loss: 29.7240 - mae: 2.4141 - val_loss: 47.1695 - val_mae: 2.5839\n",
      "Epoch 76/1000\n",
      "1570/1570 [==============================] - 0s 142us/sample - loss: 27.7788 - mae: 2.3679 - val_loss: 53.0511 - val_mae: 2.5771\n",
      "Epoch 77/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 27.3658 - mae: 2.3288 - val_loss: 45.7899 - val_mae: 2.4933\n",
      "Epoch 78/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 25.3821 - mae: 2.2823 - val_loss: 49.8658 - val_mae: 2.5001\n",
      "Epoch 79/1000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 31.6838 - mae: 2.3313 - val_loss: 48.5050 - val_mae: 2.4548\n",
      "Epoch 80/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 24.2849 - mae: 2.2340 - val_loss: 46.3611 - val_mae: 2.4425\n",
      "Epoch 81/1000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 22.9841 - mae: 2.1684 - val_loss: 43.1202 - val_mae: 2.3777\n",
      "Epoch 82/1000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 23.7875 - mae: 2.1665 - val_loss: 42.8203 - val_mae: 2.3590\n",
      "Epoch 83/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 21.4758 - mae: 2.1055 - val_loss: 30.7812 - val_mae: 2.2219\n",
      "Epoch 84/1000\n",
      "1570/1570 [==============================] - 0s 192us/sample - loss: 21.3790 - mae: 2.1106 - val_loss: 40.2865 - val_mae: 2.3110\n",
      "Epoch 85/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 24.5469 - mae: 2.1672 - val_loss: 26.1973 - val_mae: 2.1471\n",
      "Epoch 86/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 21.5422 - mae: 2.0596 - val_loss: 29.7444 - val_mae: 2.1511\n",
      "Epoch 87/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 19.5674 - mae: 2.0408 - val_loss: 32.5762 - val_mae: 2.1877\n",
      "Epoch 88/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 19.4433 - mae: 2.0422 - val_loss: 26.2103 - val_mae: 2.0907\n",
      "Epoch 89/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 19.2798 - mae: 1.9981 - val_loss: 27.6171 - val_mae: 2.1293\n",
      "Epoch 90/1000\n",
      "1570/1570 [==============================] - 0s 151us/sample - loss: 19.7616 - mae: 2.0142 - val_loss: 28.3116 - val_mae: 2.1128\n",
      "Epoch 91/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 19.8199 - mae: 2.0231 - val_loss: 30.5524 - val_mae: 2.1407\n",
      "Epoch 92/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 18.2512 - mae: 1.9681 - val_loss: 25.1902 - val_mae: 2.0445\n",
      "Epoch 93/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 17.8948 - mae: 1.9226 - val_loss: 23.1431 - val_mae: 2.0658\n",
      "Epoch 94/1000\n",
      "1570/1570 [==============================] - 0s 196us/sample - loss: 39.3707 - mae: 2.1526 - val_loss: 61.5754 - val_mae: 2.4800\n",
      "Epoch 95/1000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 214.5920 - mae: 3.0704 - val_loss: 40.6510 - val_mae: 2.2823\n",
      "Epoch 96/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 28.4772 - mae: 2.1355 - val_loss: 25.5161 - val_mae: 2.0735\n",
      "Epoch 97/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 20.2834 - mae: 1.9864 - val_loss: 38.3781 - val_mae: 2.2433\n",
      "Epoch 98/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 18.5856 - mae: 1.9531 - val_loss: 23.9134 - val_mae: 2.0966\n",
      "Epoch 99/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 128.4256 - mae: 2.6701 - val_loss: 57.0816 - val_mae: 2.4631\n",
      "Epoch 100/1000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 303.1508 - mae: 3.5628 - val_loss: 201.0278 - val_mae: 3.2790\n",
      "Epoch 101/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 612.4201 - mae: 4.6931 - val_loss: 60.4546 - val_mae: 2.7061\n",
      "Epoch 102/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 355.4245 - mae: 3.3072 - val_loss: 112.5672 - val_mae: 2.8776\n",
      "Epoch 103/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 432.4704 - mae: 4.3270 - val_loss: 309.8089 - val_mae: 5.5457\n",
      "Epoch 104/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 106.8898 - mae: 3.1404 - val_loss: 55.3360 - val_mae: 2.2552\n",
      "Epoch 105/1000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 226.2607 - mae: 2.8023 - val_loss: 23.6595 - val_mae: 2.3398\n",
      "Epoch 106/1000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 20.6854 - mae: 2.0283 - val_loss: 19.2515 - val_mae: 1.7803\n",
      "Epoch 107/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 15.8112 - mae: 1.7261 - val_loss: 15.7781 - val_mae: 1.7487\n",
      "Epoch 108/1000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 33.6350 - mae: 1.9811 - val_loss: 30.3509 - val_mae: 1.8779\n",
      "Epoch 109/1000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 173.7526 - mae: 2.8100 - val_loss: 23.8245 - val_mae: 1.9068\n",
      "Epoch 110/1000\n",
      "1570/1570 [==============================] - 0s 245us/sample - loss: 22.9580 - mae: 1.9103 - val_loss: 11.1039 - val_mae: 1.6669\n",
      "Epoch 111/1000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 110.4746 - mae: 2.5290 - val_loss: 53.2280 - val_mae: 3.5190\n",
      "Epoch 112/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 498.0144 - mae: 3.4350 - val_loss: 175.3477 - val_mae: 4.3108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 3260.6287 - mae: 7.9197 - val_loss: 43.0516 - val_mae: 2.4566\n",
      "Epoch 114/1000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 1005.8430 - mae: 5.1977 - val_loss: 469.5725 - val_mae: 5.1665\n",
      "Epoch 115/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 7654.0933 - mae: 10.2062 - val_loss: 211.5944 - val_mae: 4.4589\n",
      "Epoch 116/1000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 546.0067 - mae: 3.9360 - val_loss: 285.3604 - val_mae: 4.3094\n",
      "Epoch 117/1000\n",
      "1570/1570 [==============================] - 0s 202us/sample - loss: 270.0816 - mae: 3.8784 - val_loss: 87.6496 - val_mae: 2.5590\n",
      "Epoch 118/1000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 91.4600 - mae: 2.3059 - val_loss: 81.2252 - val_mae: 2.3175\n",
      "Epoch 119/1000\n",
      "1570/1570 [==============================] - 0s 206us/sample - loss: 21.9667 - mae: 1.7421 - val_loss: 68.8830 - val_mae: 2.0568\n",
      "Epoch 120/1000\n",
      "1570/1570 [==============================] - 0s 251us/sample - loss: 91.2090 - mae: 1.9119 - val_loss: 70.4363 - val_mae: 2.0346\n",
      "Epoch 121/1000\n",
      "1570/1570 [==============================] - 0s 271us/sample - loss: 25.3467 - mae: 1.5602 - val_loss: 61.2637 - val_mae: 1.8624\n",
      "Epoch 122/1000\n",
      "1570/1570 [==============================] - 0s 232us/sample - loss: 14.8971 - mae: 1.4212 - val_loss: 67.9202 - val_mae: 1.9465\n",
      "Epoch 123/1000\n",
      "1570/1570 [==============================] - 1s 450us/sample - loss: 11.2313 - mae: 1.3317 - val_loss: 62.5224 - val_mae: 1.8838\n",
      "Epoch 124/1000\n",
      "1570/1570 [==============================] - 0s 235us/sample - loss: 9.7173 - mae: 1.2945 - val_loss: 62.8077 - val_mae: 1.8803\n",
      "Epoch 125/1000\n",
      "1570/1570 [==============================] - 0s 239us/sample - loss: 8.9198 - mae: 1.2617 - val_loss: 61.8141 - val_mae: 1.8958\n",
      "Epoch 126/1000\n",
      "1570/1570 [==============================] - 0s 233us/sample - loss: 8.5327 - mae: 1.2226 - val_loss: 63.2781 - val_mae: 2.0229\n",
      "Epoch 127/1000\n",
      "1570/1570 [==============================] - 0s 232us/sample - loss: 7.8584 - mae: 1.2378 - val_loss: 58.9059 - val_mae: 1.7993\n",
      "Epoch 128/1000\n",
      "1570/1570 [==============================] - 0s 224us/sample - loss: 7.0751 - mae: 1.1825 - val_loss: 58.3656 - val_mae: 1.7911\n",
      "Epoch 129/1000\n",
      "1570/1570 [==============================] - 0s 189us/sample - loss: 8.4620 - mae: 1.2261 - val_loss: 64.5295 - val_mae: 1.8149\n",
      "Epoch 130/1000\n",
      "1570/1570 [==============================] - 0s 188us/sample - loss: 6.9633 - mae: 1.1815 - val_loss: 56.9324 - val_mae: 1.7790\n",
      "Epoch 131/1000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 6.2887 - mae: 1.1255 - val_loss: 56.7399 - val_mae: 1.7882\n",
      "Epoch 132/1000\n",
      "1570/1570 [==============================] - 0s 206us/sample - loss: 6.0705 - mae: 1.1196 - val_loss: 57.8057 - val_mae: 1.7612\n",
      "Epoch 133/1000\n",
      "1570/1570 [==============================] - 0s 198us/sample - loss: 5.7296 - mae: 1.0870 - val_loss: 53.8872 - val_mae: 1.7365\n",
      "Epoch 134/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 5.4669 - mae: 1.0821 - val_loss: 54.7679 - val_mae: 1.7638\n",
      "Epoch 135/1000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 7.2221 - mae: 1.1763 - val_loss: 50.0116 - val_mae: 1.6688\n",
      "Epoch 136/1000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 6.2122 - mae: 1.1194 - val_loss: 52.7747 - val_mae: 1.6747\n",
      "Epoch 137/1000\n",
      "1570/1570 [==============================] - 0s 205us/sample - loss: 5.4696 - mae: 1.0781 - val_loss: 49.6090 - val_mae: 1.6556\n",
      "Epoch 138/1000\n",
      "1570/1570 [==============================] - 0s 233us/sample - loss: 5.1171 - mae: 1.0513 - val_loss: 48.4399 - val_mae: 1.7396\n",
      "Epoch 139/1000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 5.0918 - mae: 1.0744 - val_loss: 47.3409 - val_mae: 1.6118\n",
      "Epoch 140/1000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 4.7791 - mae: 1.0246 - val_loss: 47.7612 - val_mae: 1.6373\n",
      "Epoch 141/1000\n",
      "1570/1570 [==============================] - 0s 209us/sample - loss: 4.6495 - mae: 1.0238 - val_loss: 43.2407 - val_mae: 1.6569\n",
      "Epoch 142/1000\n",
      "1570/1570 [==============================] - 0s 224us/sample - loss: 5.0526 - mae: 1.0348 - val_loss: 44.5034 - val_mae: 1.5883\n",
      "Epoch 143/1000\n",
      "1570/1570 [==============================] - 0s 194us/sample - loss: 6.9032 - mae: 1.0676 - val_loss: 40.7868 - val_mae: 1.6170\n",
      "Epoch 144/1000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 4.7263 - mae: 1.0043 - val_loss: 37.2939 - val_mae: 1.5977\n",
      "Epoch 145/1000\n",
      "1570/1570 [==============================] - 0s 265us/sample - loss: 4.2850 - mae: 0.9999 - val_loss: 41.5014 - val_mae: 1.5981\n",
      "Epoch 146/1000\n",
      "1570/1570 [==============================] - 0s 243us/sample - loss: 4.4037 - mae: 0.9991 - val_loss: 39.0011 - val_mae: 1.5752\n",
      "Epoch 147/1000\n",
      "1570/1570 [==============================] - 0s 304us/sample - loss: 4.2588 - mae: 0.9722 - val_loss: 35.8997 - val_mae: 1.5522\n",
      "Epoch 148/1000\n",
      "1570/1570 [==============================] - 0s 240us/sample - loss: 7.1103 - mae: 1.1217 - val_loss: 36.4303 - val_mae: 1.5799\n",
      "Epoch 149/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 6.4831 - mae: 1.0255 - val_loss: 25.1343 - val_mae: 1.4259\n",
      "Epoch 150/1000\n",
      "1570/1570 [==============================] - 0s 194us/sample - loss: 9.9049 - mae: 1.0685 - val_loss: 27.3094 - val_mae: 1.4532\n",
      "Epoch 151/1000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 23.9618 - mae: 1.1801 - val_loss: 26.7278 - val_mae: 1.3855\n",
      "Epoch 152/1000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 6.8983 - mae: 1.0111 - val_loss: 41.5273 - val_mae: 1.5298\n",
      "Epoch 153/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 5.0254 - mae: 0.9345 - val_loss: 35.0613 - val_mae: 1.4874\n",
      "Epoch 154/1000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 57.4023 - mae: 1.2647 - val_loss: 42.3293 - val_mae: 1.5632\n",
      "Epoch 155/1000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 119.7729 - mae: 1.5776 - val_loss: 89.7868 - val_mae: 2.2669\n",
      "Epoch 156/1000\n",
      "1570/1570 [==============================] - 0s 194us/sample - loss: 1373.5387 - mae: 3.6213 - val_loss: 215.2677 - val_mae: 4.0413\n",
      "Epoch 157/1000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 2390.5139 - mae: 6.4427 - val_loss: 516.5102 - val_mae: 8.8577\n",
      "Epoch 158/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 249.2257 - mae: 3.9062 - val_loss: 7.8878 - val_mae: 0.8225\n",
      "Epoch 159/1000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 66.1424 - mae: 1.3485 - val_loss: 6.9385 - val_mae: 0.8936\n",
      "Epoch 160/1000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 78.8209 - mae: 1.1942 - val_loss: 2.4249 - val_mae: 0.6638\n",
      "Epoch 161/1000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.8883 - mae: 0.4857 - val_loss: 1.4487 - val_mae: 0.4222\n",
      "Epoch 162/1000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.7684 - mae: 0.3904 - val_loss: 1.4200 - val_mae: 0.4274\n",
      "Epoch 163/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.7420 - mae: 0.3871 - val_loss: 1.3669 - val_mae: 0.4129\n",
      "Epoch 164/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.7247 - mae: 0.3730 - val_loss: 1.2659 - val_mae: 0.3873\n",
      "Epoch 165/1000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.7306 - mae: 0.3714 - val_loss: 1.2519 - val_mae: 0.3908\n",
      "Epoch 166/1000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.7130 - mae: 0.3588 - val_loss: 1.2056 - val_mae: 0.3812\n",
      "Epoch 167/1000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.7013 - mae: 0.3506 - val_loss: 1.1709 - val_mae: 0.3735\n",
      "Epoch 168/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.6942 - mae: 0.3413 - val_loss: 1.1475 - val_mae: 0.3757\n",
      "Epoch 169/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.6885 - mae: 0.3393 - val_loss: 1.0905 - val_mae: 0.3579\n",
      "Epoch 170/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.6789 - mae: 0.3252 - val_loss: 1.0681 - val_mae: 0.3578\n",
      "Epoch 171/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.6697 - mae: 0.3240 - val_loss: 1.0232 - val_mae: 0.3377\n",
      "Epoch 172/1000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.6635 - mae: 0.3140 - val_loss: 0.9771 - val_mae: 0.3287\n",
      "Epoch 173/1000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.6576 - mae: 0.3088 - val_loss: 0.9562 - val_mae: 0.3248\n",
      "Epoch 174/1000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.6517 - mae: 0.2988 - val_loss: 0.9626 - val_mae: 0.3301\n",
      "Epoch 175/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.6511 - mae: 0.2982 - val_loss: 0.9257 - val_mae: 0.3241\n",
      "Epoch 176/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.6378 - mae: 0.2875 - val_loss: 0.8700 - val_mae: 0.3013\n",
      "Epoch 177/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.6415 - mae: 0.2876 - val_loss: 0.8516 - val_mae: 0.2980\n",
      "Epoch 178/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.6326 - mae: 0.2778 - val_loss: 0.8488 - val_mae: 0.3011\n",
      "Epoch 179/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.6274 - mae: 0.2763 - val_loss: 0.8093 - val_mae: 0.2879\n",
      "Epoch 180/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.6281 - mae: 0.2711 - val_loss: 0.8193 - val_mae: 0.2980\n",
      "Epoch 181/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.6225 - mae: 0.2706 - val_loss: 0.7930 - val_mae: 0.2887\n",
      "Epoch 182/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.6165 - mae: 0.2658 - val_loss: 0.7689 - val_mae: 0.2791\n",
      "Epoch 183/1000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.6144 - mae: 0.2633 - val_loss: 0.7511 - val_mae: 0.2748\n",
      "Epoch 184/1000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.6155 - mae: 0.2606 - val_loss: 0.7510 - val_mae: 0.2805\n",
      "Epoch 185/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.6044 - mae: 0.2510 - val_loss: 0.7099 - val_mae: 0.2650\n",
      "Epoch 186/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.6487 - mae: 0.2750 - val_loss: 0.7291 - val_mae: 0.2788\n",
      "Epoch 187/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.6106 - mae: 0.2468 - val_loss: 0.6888 - val_mae: 0.2614\n",
      "Epoch 188/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.6100 - mae: 0.2544 - val_loss: 0.6829 - val_mae: 0.2614\n",
      "Epoch 189/1000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.6034 - mae: 0.2494 - val_loss: 0.6789 - val_mae: 0.2614\n",
      "Epoch 190/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.6016 - mae: 0.2430 - val_loss: 0.6859 - val_mae: 0.2719\n",
      "Epoch 191/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.6050 - mae: 0.2510 - val_loss: 0.6663 - val_mae: 0.2620\n",
      "Epoch 192/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.6102 - mae: 0.2430 - val_loss: 0.6583 - val_mae: 0.2601\n",
      "Epoch 193/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.6001 - mae: 0.2442 - val_loss: 0.6613 - val_mae: 0.2672\n",
      "Epoch 194/1000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.5988 - mae: 0.2448 - val_loss: 0.6283 - val_mae: 0.2497\n",
      "Epoch 195/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.5916 - mae: 0.2364 - val_loss: 0.6332 - val_mae: 0.2533\n",
      "Epoch 196/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.5903 - mae: 0.2367 - val_loss: 0.6185 - val_mae: 0.2480\n",
      "Epoch 197/1000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.5955 - mae: 0.2407 - val_loss: 0.6147 - val_mae: 0.2472\n",
      "Epoch 198/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.6015 - mae: 0.2420 - val_loss: 0.6218 - val_mae: 0.2538\n",
      "Epoch 199/1000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.6330 - mae: 0.2499 - val_loss: 0.6078 - val_mae: 0.2460\n",
      "Epoch 200/1000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.5862 - mae: 0.2320 - val_loss: 0.6106 - val_mae: 0.2501\n",
      "Epoch 201/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.5868 - mae: 0.2320 - val_loss: 0.6073 - val_mae: 0.2499\n",
      "Epoch 202/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.5904 - mae: 0.2350 - val_loss: 0.5949 - val_mae: 0.2429\n",
      "Epoch 203/1000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.5836 - mae: 0.2293 - val_loss: 0.5967 - val_mae: 0.2444\n",
      "Epoch 204/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.5828 - mae: 0.2292 - val_loss: 0.5983 - val_mae: 0.2466\n",
      "Epoch 205/1000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.5895 - mae: 0.2298 - val_loss: 0.5952 - val_mae: 0.2460\n",
      "Epoch 206/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.5826 - mae: 0.2304 - val_loss: 0.5941 - val_mae: 0.2466\n",
      "Epoch 207/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.5840 - mae: 0.2334 - val_loss: 0.5881 - val_mae: 0.2426\n",
      "Epoch 208/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.5819 - mae: 0.2309 - val_loss: 0.5845 - val_mae: 0.2413\n",
      "Epoch 209/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.5842 - mae: 0.2325 - val_loss: 0.5812 - val_mae: 0.2400\n",
      "Epoch 210/1000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.5851 - mae: 0.2321 - val_loss: 0.5793 - val_mae: 0.2393\n",
      "Epoch 211/1000\n",
      "1570/1570 [==============================] - 0s 185us/sample - loss: 0.5795 - mae: 0.2271 - val_loss: 0.5771 - val_mae: 0.2389\n",
      "Epoch 212/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.5801 - mae: 0.2280 - val_loss: 0.5819 - val_mae: 0.2447\n",
      "Epoch 213/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.5852 - mae: 0.2342 - val_loss: 0.5984 - val_mae: 0.2609\n",
      "Epoch 214/1000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.7150 - mae: 0.2581 - val_loss: 0.5843 - val_mae: 0.2513\n",
      "Epoch 215/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.5786 - mae: 0.2292 - val_loss: 0.5741 - val_mae: 0.2420\n",
      "Epoch 216/1000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.5781 - mae: 0.2286 - val_loss: 0.5753 - val_mae: 0.2446\n",
      "Epoch 217/1000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.6327 - mae: 0.2442 - val_loss: 0.6001 - val_mae: 0.2674\n",
      "Epoch 218/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.6570 - mae: 0.2691 - val_loss: 0.8398 - val_mae: 0.3614\n",
      "Epoch 219/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 1.0437 - mae: 0.2951 - val_loss: 0.5641 - val_mae: 0.2356\n",
      "Epoch 220/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 10.9609 - mae: 0.7463 - val_loss: 5.3912 - val_mae: 0.9096\n",
      "Epoch 221/1000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 14.1868 - mae: 0.6403 - val_loss: 0.5819 - val_mae: 0.2485\n",
      "Epoch 222/1000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.5936 - mae: 0.2283 - val_loss: 0.5593 - val_mae: 0.2313\n",
      "Epoch 223/1000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.5637 - mae: 0.2233 - val_loss: 0.5589 - val_mae: 0.2322\n",
      "Epoch 224/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.5629 - mae: 0.2235 - val_loss: 0.5591 - val_mae: 0.2341\n",
      "Epoch 225/1000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.5777 - mae: 0.2333 - val_loss: 0.6147 - val_mae: 0.2801\n",
      "Epoch 226/1000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 1.2804 - mae: 0.3042 - val_loss: 0.6012 - val_mae: 0.2736\n",
      "Epoch 227/1000\n",
      "1570/1570 [==============================] - 0s 186us/sample - loss: 1.1138 - mae: 0.2790 - val_loss: 0.5609 - val_mae: 0.2403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/1000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 0.5878 - mae: 0.2293 - val_loss: 0.5597 - val_mae: 0.2393\n",
      "Epoch 229/1000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.5718 - mae: 0.2267 - val_loss: 0.5870 - val_mae: 0.2656\n",
      "Epoch 230/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 2.1003 - mae: 0.3379 - val_loss: 0.5543 - val_mae: 0.2305\n",
      "Epoch 231/1000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 4.7005 - mae: 0.5619 - val_loss: 3.1539 - val_mae: 0.6791\n",
      "Epoch 232/1000\n",
      "1570/1570 [==============================] - 0s 183us/sample - loss: 7.0914 - mae: 0.4853 - val_loss: 0.6384 - val_mae: 0.2730\n",
      "Epoch 233/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 4.4459 - mae: 0.3724 - val_loss: 0.6216 - val_mae: 0.2813\n",
      "Epoch 234/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 2.0704 - mae: 0.3218 - val_loss: 3.5759 - val_mae: 0.6479\n",
      "Epoch 235/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 21.0127 - mae: 0.5794 - val_loss: 0.5655 - val_mae: 0.2507\n",
      "Epoch 236/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 27.2177 - mae: 0.5031 - val_loss: 0.5604 - val_mae: 0.2460\n",
      "Epoch 237/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 4.6604 - mae: 0.3146 - val_loss: 0.5590 - val_mae: 0.2447\n",
      "Epoch 238/1000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.8403 - mae: 0.2631 - val_loss: 0.5571 - val_mae: 0.2418\n",
      "Epoch 239/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.6060 - mae: 0.2440 - val_loss: 0.5559 - val_mae: 0.2403\n",
      "Epoch 240/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.5561 - mae: 0.2352 - val_loss: 0.5551 - val_mae: 0.2394\n",
      "Epoch 241/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.5525 - mae: 0.2320 - val_loss: 0.5544 - val_mae: 0.2387\n",
      "Epoch 242/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.5522 - mae: 0.2307 - val_loss: 0.5538 - val_mae: 0.2380\n",
      "Epoch 243/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.5498 - mae: 0.2288 - val_loss: 0.5533 - val_mae: 0.2375\n",
      "Epoch 244/1000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.5489 - mae: 0.2278 - val_loss: 0.5529 - val_mae: 0.2371\n",
      "Epoch 245/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.5482 - mae: 0.2271 - val_loss: 0.5525 - val_mae: 0.2368\n",
      "Epoch 246/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.5476 - mae: 0.2264 - val_loss: 0.5522 - val_mae: 0.2365\n",
      "Epoch 247/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.5472 - mae: 0.2261 - val_loss: 0.5518 - val_mae: 0.2363\n",
      "Epoch 248/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.5467 - mae: 0.2258 - val_loss: 0.5514 - val_mae: 0.2362\n",
      "Epoch 249/1000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.5462 - mae: 0.2256 - val_loss: 0.5511 - val_mae: 0.2362\n",
      "Epoch 250/1000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.5457 - mae: 0.2254 - val_loss: 0.5507 - val_mae: 0.2361\n",
      "Epoch 251/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.5453 - mae: 0.2252 - val_loss: 0.5504 - val_mae: 0.2359\n",
      "Epoch 252/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.5449 - mae: 0.2252 - val_loss: 0.5500 - val_mae: 0.2359\n",
      "Epoch 253/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.5444 - mae: 0.2249 - val_loss: 0.5496 - val_mae: 0.2358\n",
      "Epoch 254/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.5440 - mae: 0.2247 - val_loss: 0.5493 - val_mae: 0.2356\n",
      "Epoch 255/1000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.5436 - mae: 0.2245 - val_loss: 0.5489 - val_mae: 0.2355\n",
      "Epoch 256/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.5431 - mae: 0.2245 - val_loss: 0.5485 - val_mae: 0.2356\n",
      "Epoch 257/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.5427 - mae: 0.2245 - val_loss: 0.5482 - val_mae: 0.2355\n",
      "Epoch 258/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.5423 - mae: 0.2245 - val_loss: 0.5478 - val_mae: 0.2356\n",
      "Epoch 259/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.5419 - mae: 0.2246 - val_loss: 0.5473 - val_mae: 0.2357\n",
      "Epoch 260/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.5415 - mae: 0.2246 - val_loss: 0.5469 - val_mae: 0.2358\n",
      "Epoch 261/1000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.5411 - mae: 0.2248 - val_loss: 0.5465 - val_mae: 0.2358\n",
      "Epoch 262/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.5406 - mae: 0.2245 - val_loss: 0.5462 - val_mae: 0.2357\n",
      "Epoch 263/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.5402 - mae: 0.2244 - val_loss: 0.5459 - val_mae: 0.2359\n",
      "Epoch 264/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.5398 - mae: 0.2243 - val_loss: 0.5454 - val_mae: 0.2356\n",
      "Epoch 265/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.5394 - mae: 0.2243 - val_loss: 0.5450 - val_mae: 0.2356\n",
      "Epoch 266/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.5390 - mae: 0.2245 - val_loss: 0.5445 - val_mae: 0.2357\n",
      "Epoch 267/1000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.5386 - mae: 0.2243 - val_loss: 0.5442 - val_mae: 0.2356\n",
      "Epoch 268/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.5381 - mae: 0.2242 - val_loss: 0.5438 - val_mae: 0.2356\n",
      "Epoch 269/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.5377 - mae: 0.2244 - val_loss: 0.5433 - val_mae: 0.2357\n",
      "Epoch 270/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.5373 - mae: 0.2245 - val_loss: 0.5429 - val_mae: 0.2358\n",
      "Epoch 271/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.5369 - mae: 0.2245 - val_loss: 0.5424 - val_mae: 0.2358\n",
      "Epoch 272/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.5365 - mae: 0.2244 - val_loss: 0.5420 - val_mae: 0.2357\n",
      "Epoch 273/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.5360 - mae: 0.2243 - val_loss: 0.5417 - val_mae: 0.2356\n",
      "Epoch 274/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.5356 - mae: 0.2243 - val_loss: 0.5412 - val_mae: 0.2356\n",
      "Epoch 275/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.5352 - mae: 0.2241 - val_loss: 0.5408 - val_mae: 0.2355\n",
      "Epoch 276/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.5347 - mae: 0.2241 - val_loss: 0.5404 - val_mae: 0.2356\n",
      "Epoch 277/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.5343 - mae: 0.2243 - val_loss: 0.5399 - val_mae: 0.2357\n",
      "Epoch 278/1000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.5339 - mae: 0.2244 - val_loss: 0.5395 - val_mae: 0.2357\n",
      "Epoch 279/1000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.5334 - mae: 0.2245 - val_loss: 0.5390 - val_mae: 0.2358\n",
      "Epoch 280/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.5330 - mae: 0.2243 - val_loss: 0.5386 - val_mae: 0.2356\n",
      "Epoch 281/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.5326 - mae: 0.2241 - val_loss: 0.5382 - val_mae: 0.2356\n",
      "Epoch 282/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.5321 - mae: 0.2241 - val_loss: 0.5378 - val_mae: 0.2356\n",
      "Epoch 283/1000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.5317 - mae: 0.2240 - val_loss: 0.5373 - val_mae: 0.2355\n",
      "Epoch 284/1000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.5312 - mae: 0.2238 - val_loss: 0.5369 - val_mae: 0.2354\n",
      "Epoch 285/1000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.5308 - mae: 0.2240 - val_loss: 0.5364 - val_mae: 0.2355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.5303 - mae: 0.2239 - val_loss: 0.5360 - val_mae: 0.2354\n",
      "Epoch 287/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.5299 - mae: 0.2238 - val_loss: 0.5356 - val_mae: 0.2353\n",
      "Epoch 288/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.5294 - mae: 0.2240 - val_loss: 0.5351 - val_mae: 0.2355\n",
      "Epoch 289/1000\n",
      "1570/1570 [==============================] - 0s 193us/sample - loss: 0.5290 - mae: 0.2240 - val_loss: 0.5346 - val_mae: 0.2355\n",
      "Epoch 290/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.5285 - mae: 0.2244 - val_loss: 0.5341 - val_mae: 0.2356\n",
      "Epoch 291/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.5280 - mae: 0.2239 - val_loss: 0.5336 - val_mae: 0.2355\n",
      "Epoch 292/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.5275 - mae: 0.2240 - val_loss: 0.5332 - val_mae: 0.2354\n",
      "Epoch 293/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.5271 - mae: 0.2238 - val_loss: 0.5328 - val_mae: 0.2354\n",
      "Epoch 294/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.5267 - mae: 0.2242 - val_loss: 0.5322 - val_mae: 0.2356\n",
      "Epoch 295/1000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.5262 - mae: 0.2243 - val_loss: 0.5317 - val_mae: 0.2357\n",
      "Epoch 296/1000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.5257 - mae: 0.2242 - val_loss: 0.5312 - val_mae: 0.2356\n",
      "Epoch 297/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.5252 - mae: 0.2246 - val_loss: 0.5307 - val_mae: 0.2357\n",
      "Epoch 298/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.5247 - mae: 0.2245 - val_loss: 0.5302 - val_mae: 0.2357\n",
      "Epoch 299/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.5242 - mae: 0.2245 - val_loss: 0.5297 - val_mae: 0.2357\n",
      "Epoch 300/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.5237 - mae: 0.2243 - val_loss: 0.5292 - val_mae: 0.2355\n",
      "Epoch 301/1000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.5234 - mae: 0.2248 - val_loss: 0.5287 - val_mae: 0.2357\n",
      "Epoch 302/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.5233 - mae: 0.2253 - val_loss: 0.5282 - val_mae: 0.2358\n",
      "Epoch 303/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.5410 - mae: 0.2285 - val_loss: 0.5284 - val_mae: 0.2361\n",
      "Epoch 304/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.6410 - mae: 0.2332 - val_loss: 0.5274 - val_mae: 0.2355\n",
      "Epoch 305/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.5214 - mae: 0.2245 - val_loss: 0.5269 - val_mae: 0.2355\n",
      "Epoch 306/1000\n",
      "1570/1570 [==============================] - 0s 191us/sample - loss: 0.5208 - mae: 0.2242 - val_loss: 0.5263 - val_mae: 0.2355\n",
      "Epoch 307/1000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.5203 - mae: 0.2241 - val_loss: 0.5259 - val_mae: 0.2354\n",
      "Epoch 308/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.5198 - mae: 0.2243 - val_loss: 0.5253 - val_mae: 0.2354\n",
      "Epoch 309/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.5193 - mae: 0.2238 - val_loss: 0.5249 - val_mae: 0.2352\n",
      "Epoch 310/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.5187 - mae: 0.2235 - val_loss: 0.5244 - val_mae: 0.2352\n",
      "Epoch 311/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.5182 - mae: 0.2244 - val_loss: 0.5237 - val_mae: 0.2356\n",
      "Epoch 312/1000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.5177 - mae: 0.2241 - val_loss: 0.5232 - val_mae: 0.2354\n",
      "Epoch 313/1000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.5171 - mae: 0.2246 - val_loss: 0.5226 - val_mae: 0.2355\n",
      "Epoch 314/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.5165 - mae: 0.2243 - val_loss: 0.5220 - val_mae: 0.2355\n",
      "Epoch 315/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.5160 - mae: 0.2243 - val_loss: 0.5215 - val_mae: 0.2355\n",
      "Epoch 316/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.5155 - mae: 0.2245 - val_loss: 0.5209 - val_mae: 0.2355\n",
      "Epoch 317/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.5149 - mae: 0.2246 - val_loss: 0.5203 - val_mae: 0.2356\n",
      "Epoch 318/1000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.5143 - mae: 0.2243 - val_loss: 0.5198 - val_mae: 0.2354\n",
      "Epoch 319/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.5138 - mae: 0.2235 - val_loss: 0.5193 - val_mae: 0.2352\n",
      "Epoch 320/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.5132 - mae: 0.2247 - val_loss: 0.5185 - val_mae: 0.2358\n",
      "Epoch 321/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.5126 - mae: 0.2251 - val_loss: 0.5179 - val_mae: 0.2359\n",
      "Epoch 322/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.5120 - mae: 0.2245 - val_loss: 0.5175 - val_mae: 0.2355\n",
      "Epoch 323/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.5115 - mae: 0.2240 - val_loss: 0.5169 - val_mae: 0.2354\n",
      "Epoch 324/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.5108 - mae: 0.2242 - val_loss: 0.5163 - val_mae: 0.2352\n",
      "Epoch 325/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.5103 - mae: 0.2238 - val_loss: 0.5158 - val_mae: 0.2351\n",
      "Epoch 326/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.5097 - mae: 0.2240 - val_loss: 0.5151 - val_mae: 0.2353\n",
      "Epoch 327/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.5110 - mae: 0.2259 - val_loss: 0.5144 - val_mae: 0.2355\n",
      "Epoch 328/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.5086 - mae: 0.2254 - val_loss: 0.5137 - val_mae: 0.2358\n",
      "Epoch 329/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.5078 - mae: 0.2244 - val_loss: 0.5132 - val_mae: 0.2354\n",
      "Epoch 330/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.5072 - mae: 0.2238 - val_loss: 0.5126 - val_mae: 0.2352\n",
      "Epoch 331/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.5066 - mae: 0.2237 - val_loss: 0.5120 - val_mae: 0.2352\n",
      "Epoch 332/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.5059 - mae: 0.2248 - val_loss: 0.5112 - val_mae: 0.2357\n",
      "Epoch 333/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.5053 - mae: 0.2250 - val_loss: 0.5106 - val_mae: 0.2356\n",
      "Epoch 334/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.5047 - mae: 0.2244 - val_loss: 0.5101 - val_mae: 0.2353\n",
      "Epoch 335/1000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.5041 - mae: 0.2240 - val_loss: 0.5095 - val_mae: 0.2351\n",
      "Epoch 336/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.5034 - mae: 0.2242 - val_loss: 0.5088 - val_mae: 0.2352\n",
      "Epoch 337/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.5027 - mae: 0.2243 - val_loss: 0.5081 - val_mae: 0.2354\n",
      "Epoch 338/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.5022 - mae: 0.2249 - val_loss: 0.5074 - val_mae: 0.2356\n",
      "Epoch 339/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.5014 - mae: 0.2241 - val_loss: 0.5068 - val_mae: 0.2352\n",
      "Epoch 340/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.5009 - mae: 0.2242 - val_loss: 0.5061 - val_mae: 0.2352\n",
      "Epoch 341/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.5001 - mae: 0.2246 - val_loss: 0.5054 - val_mae: 0.2353\n",
      "Epoch 342/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.5001 - mae: 0.2252 - val_loss: 0.5047 - val_mae: 0.2353\n",
      "Epoch 343/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.4990 - mae: 0.2242 - val_loss: 0.5042 - val_mae: 0.2351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.4982 - mae: 0.2246 - val_loss: 0.5034 - val_mae: 0.2351\n",
      "Epoch 345/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.5003 - mae: 0.2263 - val_loss: 0.5028 - val_mae: 0.2349\n",
      "Epoch 346/1000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.5862 - mae: 0.2366 - val_loss: 0.5019 - val_mae: 0.2351\n",
      "Epoch 347/1000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.5069 - mae: 0.2277 - val_loss: 0.5012 - val_mae: 0.2353\n",
      "Epoch 348/1000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.4982 - mae: 0.2266 - val_loss: 0.5004 - val_mae: 0.2356\n",
      "Epoch 349/1000\n",
      "1570/1570 [==============================] - 0s 182us/sample - loss: 0.4953 - mae: 0.2261 - val_loss: 0.4997 - val_mae: 0.2355\n",
      "Epoch 350/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.4940 - mae: 0.2242 - val_loss: 0.4991 - val_mae: 0.2348\n",
      "Epoch 351/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.4933 - mae: 0.2242 - val_loss: 0.4984 - val_mae: 0.2349\n",
      "Epoch 352/1000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.4926 - mae: 0.2251 - val_loss: 0.4975 - val_mae: 0.2354\n",
      "Epoch 353/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.4918 - mae: 0.2243 - val_loss: 0.4968 - val_mae: 0.2353\n",
      "Epoch 354/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.4911 - mae: 0.2241 - val_loss: 0.4963 - val_mae: 0.2346\n",
      "Epoch 355/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.4903 - mae: 0.2233 - val_loss: 0.4955 - val_mae: 0.2349\n",
      "Epoch 356/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.4896 - mae: 0.2240 - val_loss: 0.4947 - val_mae: 0.2351\n",
      "Epoch 357/1000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.4889 - mae: 0.2247 - val_loss: 0.4939 - val_mae: 0.2352\n",
      "Epoch 358/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.4881 - mae: 0.2243 - val_loss: 0.4933 - val_mae: 0.2349\n",
      "Epoch 359/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.4876 - mae: 0.2250 - val_loss: 0.4924 - val_mae: 0.2351\n",
      "Epoch 360/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.4866 - mae: 0.2242 - val_loss: 0.4916 - val_mae: 0.2352\n",
      "Epoch 361/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.4874 - mae: 0.2254 - val_loss: 0.4909 - val_mae: 0.2349\n",
      "Epoch 362/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.4851 - mae: 0.2240 - val_loss: 0.4902 - val_mae: 0.2348\n",
      "Epoch 363/1000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.4845 - mae: 0.2236 - val_loss: 0.4893 - val_mae: 0.2349\n",
      "Epoch 364/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.4835 - mae: 0.2247 - val_loss: 0.4885 - val_mae: 0.2350\n",
      "Epoch 365/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.4829 - mae: 0.2244 - val_loss: 0.4879 - val_mae: 0.2346\n",
      "Epoch 366/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.4819 - mae: 0.2241 - val_loss: 0.4869 - val_mae: 0.2348\n",
      "Epoch 367/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.4811 - mae: 0.2238 - val_loss: 0.4860 - val_mae: 0.2353\n",
      "Epoch 368/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.4803 - mae: 0.2242 - val_loss: 0.4852 - val_mae: 0.2352\n",
      "Epoch 369/1000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.4795 - mae: 0.2242 - val_loss: 0.4845 - val_mae: 0.2349\n",
      "Epoch 370/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.4787 - mae: 0.2244 - val_loss: 0.4836 - val_mae: 0.2349\n",
      "Epoch 371/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.4779 - mae: 0.2243 - val_loss: 0.4829 - val_mae: 0.2346\n",
      "Epoch 372/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.4770 - mae: 0.2234 - val_loss: 0.4821 - val_mae: 0.2346\n",
      "Epoch 373/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.4762 - mae: 0.2240 - val_loss: 0.4812 - val_mae: 0.2348\n",
      "Epoch 374/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.4782 - mae: 0.2258 - val_loss: 0.4803 - val_mae: 0.2348\n",
      "Epoch 375/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.5947 - mae: 0.2368 - val_loss: 0.4792 - val_mae: 0.2350\n",
      "Epoch 376/1000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 0.4735 - mae: 0.2236 - val_loss: 0.4784 - val_mae: 0.2344\n",
      "Epoch 377/1000\n",
      "1570/1570 [==============================] - 0s 152us/sample - loss: 0.4726 - mae: 0.2237 - val_loss: 0.4776 - val_mae: 0.2345\n",
      "Epoch 378/1000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 0.4717 - mae: 0.2232 - val_loss: 0.4767 - val_mae: 0.2343\n",
      "Epoch 379/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.4708 - mae: 0.2236 - val_loss: 0.4758 - val_mae: 0.2344\n",
      "Epoch 380/1000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.4699 - mae: 0.2234 - val_loss: 0.4749 - val_mae: 0.2344\n",
      "Epoch 381/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.4690 - mae: 0.2238 - val_loss: 0.4740 - val_mae: 0.2344\n",
      "Epoch 382/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.4682 - mae: 0.2243 - val_loss: 0.4732 - val_mae: 0.2344\n",
      "Epoch 383/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.4672 - mae: 0.2239 - val_loss: 0.4721 - val_mae: 0.2347\n",
      "Epoch 384/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.4664 - mae: 0.2250 - val_loss: 0.4712 - val_mae: 0.2347\n",
      "Epoch 385/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.4654 - mae: 0.2241 - val_loss: 0.4704 - val_mae: 0.2344\n",
      "Epoch 386/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.4645 - mae: 0.2237 - val_loss: 0.4695 - val_mae: 0.2344\n",
      "Epoch 387/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.4635 - mae: 0.2232 - val_loss: 0.4686 - val_mae: 0.2342\n",
      "Epoch 388/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.4626 - mae: 0.2230 - val_loss: 0.4677 - val_mae: 0.2341\n",
      "Epoch 389/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.4617 - mae: 0.2235 - val_loss: 0.4667 - val_mae: 0.2343\n",
      "Epoch 390/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.4607 - mae: 0.2244 - val_loss: 0.4656 - val_mae: 0.2347\n",
      "Epoch 391/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.4598 - mae: 0.2230 - val_loss: 0.4647 - val_mae: 0.2344\n",
      "Epoch 392/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.4587 - mae: 0.2239 - val_loss: 0.4636 - val_mae: 0.2346\n",
      "Epoch 393/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.4577 - mae: 0.2232 - val_loss: 0.4628 - val_mae: 0.2342\n",
      "Epoch 394/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.4568 - mae: 0.2229 - val_loss: 0.4617 - val_mae: 0.2344\n",
      "Epoch 395/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.4560 - mae: 0.2249 - val_loss: 0.4609 - val_mae: 0.2340\n",
      "Epoch 396/1000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.4547 - mae: 0.2229 - val_loss: 0.4598 - val_mae: 0.2341\n",
      "Epoch 397/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.4537 - mae: 0.2228 - val_loss: 0.4586 - val_mae: 0.2345\n",
      "Epoch 398/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.4527 - mae: 0.2235 - val_loss: 0.4576 - val_mae: 0.2344\n",
      "Epoch 399/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 0.4517 - mae: 0.2230 - val_loss: 0.4566 - val_mae: 0.2342\n",
      "Epoch 400/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.4506 - mae: 0.2234 - val_loss: 0.4555 - val_mae: 0.2345\n",
      "Epoch 401/1000\n",
      "1570/1570 [==============================] - 0s 152us/sample - loss: 0.4495 - mae: 0.2231 - val_loss: 0.4544 - val_mae: 0.2345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.4485 - mae: 0.2241 - val_loss: 0.4534 - val_mae: 0.2343\n",
      "Epoch 403/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.4474 - mae: 0.2233 - val_loss: 0.4525 - val_mae: 0.2339\n",
      "Epoch 404/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.4464 - mae: 0.2230 - val_loss: 0.4514 - val_mae: 0.2340\n",
      "Epoch 405/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.4452 - mae: 0.2230 - val_loss: 0.4502 - val_mae: 0.2342\n",
      "Epoch 406/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.4441 - mae: 0.2236 - val_loss: 0.4491 - val_mae: 0.2342\n",
      "Epoch 407/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.4429 - mae: 0.2231 - val_loss: 0.4479 - val_mae: 0.2343\n",
      "Epoch 408/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.4418 - mae: 0.2236 - val_loss: 0.4468 - val_mae: 0.2343\n",
      "Epoch 409/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.4407 - mae: 0.2235 - val_loss: 0.4456 - val_mae: 0.2345\n",
      "Epoch 410/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.4395 - mae: 0.2231 - val_loss: 0.4445 - val_mae: 0.2343\n",
      "Epoch 411/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.4384 - mae: 0.2230 - val_loss: 0.4432 - val_mae: 0.2347\n",
      "Epoch 412/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.4372 - mae: 0.2235 - val_loss: 0.4420 - val_mae: 0.2346\n",
      "Epoch 413/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.4361 - mae: 0.2231 - val_loss: 0.4410 - val_mae: 0.2343\n",
      "Epoch 414/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.4348 - mae: 0.2235 - val_loss: 0.4397 - val_mae: 0.2344\n",
      "Epoch 415/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.4336 - mae: 0.2233 - val_loss: 0.4385 - val_mae: 0.2344\n",
      "Epoch 416/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.4324 - mae: 0.2231 - val_loss: 0.4374 - val_mae: 0.2341\n",
      "Epoch 417/1000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 0.4313 - mae: 0.2235 - val_loss: 0.4363 - val_mae: 0.2340\n",
      "Epoch 418/1000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 0.4300 - mae: 0.2233 - val_loss: 0.4348 - val_mae: 0.2344\n",
      "Epoch 419/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.4287 - mae: 0.2234 - val_loss: 0.4335 - val_mae: 0.2346\n",
      "Epoch 420/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.4274 - mae: 0.2234 - val_loss: 0.4324 - val_mae: 0.2342\n",
      "Epoch 421/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.4262 - mae: 0.2229 - val_loss: 0.4311 - val_mae: 0.2343\n",
      "Epoch 422/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.4250 - mae: 0.2242 - val_loss: 0.4298 - val_mae: 0.2344\n",
      "Epoch 423/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.4237 - mae: 0.2229 - val_loss: 0.4285 - val_mae: 0.2343\n",
      "Epoch 424/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.4224 - mae: 0.2241 - val_loss: 0.4271 - val_mae: 0.2345\n",
      "Epoch 425/1000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.4211 - mae: 0.2227 - val_loss: 0.4259 - val_mae: 0.2343\n",
      "Epoch 426/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.4197 - mae: 0.2236 - val_loss: 0.4244 - val_mae: 0.2348\n",
      "Epoch 427/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.4184 - mae: 0.2241 - val_loss: 0.4231 - val_mae: 0.2348\n",
      "Epoch 428/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.4170 - mae: 0.2241 - val_loss: 0.4219 - val_mae: 0.2344\n",
      "Epoch 429/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.4157 - mae: 0.2233 - val_loss: 0.4204 - val_mae: 0.2346\n",
      "Epoch 430/1000\n",
      "1570/1570 [==============================] - 0s 184us/sample - loss: 0.4143 - mae: 0.2234 - val_loss: 0.4192 - val_mae: 0.2343\n",
      "Epoch 431/1000\n",
      "1570/1570 [==============================] - 0s 201us/sample - loss: 0.4130 - mae: 0.2236 - val_loss: 0.4180 - val_mae: 0.2340\n",
      "Epoch 432/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.4115 - mae: 0.2230 - val_loss: 0.4163 - val_mae: 0.2347\n",
      "Epoch 433/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.4102 - mae: 0.2242 - val_loss: 0.4149 - val_mae: 0.2346\n",
      "Epoch 434/1000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 0.4087 - mae: 0.2237 - val_loss: 0.4137 - val_mae: 0.2342\n",
      "Epoch 435/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.4074 - mae: 0.2227 - val_loss: 0.4122 - val_mae: 0.2342\n",
      "Epoch 436/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.4093 - mae: 0.2246 - val_loss: 0.4107 - val_mae: 0.2344\n",
      "Epoch 437/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.4145 - mae: 0.2253 - val_loss: 0.4098 - val_mae: 0.2342\n",
      "Epoch 438/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.4037 - mae: 0.2249 - val_loss: 0.4082 - val_mae: 0.2349\n",
      "Epoch 439/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 0.4021 - mae: 0.2238 - val_loss: 0.4069 - val_mae: 0.2343\n",
      "Epoch 440/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.4006 - mae: 0.2235 - val_loss: 0.4054 - val_mae: 0.2346\n",
      "Epoch 441/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.3993 - mae: 0.2244 - val_loss: 0.4039 - val_mae: 0.2347\n",
      "Epoch 442/1000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.3979 - mae: 0.2244 - val_loss: 0.4026 - val_mae: 0.2343\n",
      "Epoch 443/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.3964 - mae: 0.2229 - val_loss: 0.4012 - val_mae: 0.2341\n",
      "Epoch 444/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.3948 - mae: 0.2230 - val_loss: 0.3996 - val_mae: 0.2343\n",
      "Epoch 445/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.3934 - mae: 0.2235 - val_loss: 0.3981 - val_mae: 0.2344\n",
      "Epoch 446/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.3918 - mae: 0.2233 - val_loss: 0.3965 - val_mae: 0.2346\n",
      "Epoch 447/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.3904 - mae: 0.2240 - val_loss: 0.3951 - val_mae: 0.2342\n",
      "Epoch 448/1000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.3888 - mae: 0.2240 - val_loss: 0.3935 - val_mae: 0.2344\n",
      "Epoch 449/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.3873 - mae: 0.2226 - val_loss: 0.3919 - val_mae: 0.2346\n",
      "Epoch 450/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.3858 - mae: 0.2243 - val_loss: 0.3903 - val_mae: 0.2347\n",
      "Epoch 451/1000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 0.3842 - mae: 0.2244 - val_loss: 0.3887 - val_mae: 0.2345\n",
      "Epoch 452/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.3826 - mae: 0.2238 - val_loss: 0.3867 - val_mae: 0.2340\n",
      "Epoch 453/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.3874 - mae: 0.2223 - val_loss: 0.3917 - val_mae: 0.2311\n",
      "Epoch 454/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.3811 - mae: 0.2146 - val_loss: 0.3721 - val_mae: 0.2091\n",
      "Epoch 455/1000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 0.3653 - mae: 0.1983 - val_loss: 0.3650 - val_mae: 0.1987\n",
      "Epoch 456/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.3661 - mae: 0.1978 - val_loss: 0.3663 - val_mae: 0.2034\n",
      "Epoch 457/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.3616 - mae: 0.1961 - val_loss: 0.3642 - val_mae: 0.2066\n",
      "Epoch 458/1000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 0.3590 - mae: 0.1964 - val_loss: 0.3615 - val_mae: 0.2061\n",
      "Epoch 459/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.3613 - mae: 0.2010 - val_loss: 0.4051 - val_mae: 0.2439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.3644 - mae: 0.2065 - val_loss: 0.3628 - val_mae: 0.2090\n",
      "Epoch 461/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.3541 - mae: 0.1964 - val_loss: 0.3557 - val_mae: 0.2051\n",
      "Epoch 462/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.3540 - mae: 0.1978 - val_loss: 0.3537 - val_mae: 0.2002\n",
      "Epoch 463/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.3501 - mae: 0.1926 - val_loss: 0.3543 - val_mae: 0.2042\n",
      "Epoch 464/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.3484 - mae: 0.1929 - val_loss: 0.3557 - val_mae: 0.2052\n",
      "Epoch 465/1000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.3469 - mae: 0.1930 - val_loss: 0.3518 - val_mae: 0.2065\n",
      "Epoch 466/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.3459 - mae: 0.1969 - val_loss: 0.3473 - val_mae: 0.2032\n",
      "Epoch 467/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.3419 - mae: 0.1915 - val_loss: 0.3644 - val_mae: 0.2205\n",
      "Epoch 468/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.3431 - mae: 0.1918 - val_loss: 0.3476 - val_mae: 0.2022\n",
      "Epoch 469/1000\n",
      "1570/1570 [==============================] - 0s 152us/sample - loss: 0.3396 - mae: 0.1914 - val_loss: 0.3499 - val_mae: 0.2119\n",
      "Epoch 470/1000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 0.3384 - mae: 0.1895 - val_loss: 0.3411 - val_mae: 0.1993\n",
      "Epoch 471/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.3334 - mae: 0.1866 - val_loss: 0.3383 - val_mae: 0.1921\n",
      "Epoch 472/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.3318 - mae: 0.1849 - val_loss: 0.3384 - val_mae: 0.1945\n",
      "Epoch 473/1000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 0.3312 - mae: 0.1849 - val_loss: 0.3368 - val_mae: 0.1972\n",
      "Epoch 474/1000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 0.3283 - mae: 0.1858 - val_loss: 0.3327 - val_mae: 0.1980\n",
      "Epoch 475/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 0.3327 - mae: 0.1948 - val_loss: 0.3466 - val_mae: 0.2201\n",
      "Epoch 476/1000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 0.3295 - mae: 0.1944 - val_loss: 0.3289 - val_mae: 0.1963\n",
      "Epoch 477/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.3301 - mae: 0.1954 - val_loss: 0.3315 - val_mae: 0.1932\n",
      "Epoch 478/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.3216 - mae: 0.1833 - val_loss: 0.3274 - val_mae: 0.1969\n",
      "Epoch 479/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.3223 - mae: 0.1893 - val_loss: 0.3243 - val_mae: 0.1977\n",
      "Epoch 480/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.3174 - mae: 0.1856 - val_loss: 0.3244 - val_mae: 0.1983\n",
      "Epoch 481/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.3165 - mae: 0.1832 - val_loss: 0.3257 - val_mae: 0.1989\n",
      "Epoch 482/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.3143 - mae: 0.1829 - val_loss: 0.3177 - val_mae: 0.1915\n",
      "Epoch 483/1000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.3107 - mae: 0.1795 - val_loss: 0.3166 - val_mae: 0.1912\n",
      "Epoch 484/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.3091 - mae: 0.1807 - val_loss: 0.3186 - val_mae: 0.2004\n",
      "Epoch 485/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.3077 - mae: 0.1802 - val_loss: 0.3137 - val_mae: 0.1918\n",
      "Epoch 486/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.3058 - mae: 0.1796 - val_loss: 0.3131 - val_mae: 0.1928\n",
      "Epoch 487/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 0.3044 - mae: 0.1803 - val_loss: 0.3071 - val_mae: 0.1912\n",
      "Epoch 488/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.3003 - mae: 0.1772 - val_loss: 0.3058 - val_mae: 0.1866\n",
      "Epoch 489/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.3013 - mae: 0.1790 - val_loss: 0.3048 - val_mae: 0.1875\n",
      "Epoch 490/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 0.2978 - mae: 0.1778 - val_loss: 0.3110 - val_mae: 0.2019\n",
      "Epoch 491/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.2994 - mae: 0.1851 - val_loss: 0.3020 - val_mae: 0.1893\n",
      "Epoch 492/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.2953 - mae: 0.1796 - val_loss: 0.3018 - val_mae: 0.1914\n",
      "Epoch 493/1000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 0.2986 - mae: 0.1873 - val_loss: 0.3119 - val_mae: 0.2166\n",
      "Epoch 494/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.2944 - mae: 0.1860 - val_loss: 0.3036 - val_mae: 0.2080\n",
      "Epoch 495/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.2924 - mae: 0.1854 - val_loss: 0.2926 - val_mae: 0.1870\n",
      "Epoch 496/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.2862 - mae: 0.1757 - val_loss: 0.2901 - val_mae: 0.1850\n",
      "Epoch 497/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.2858 - mae: 0.1793 - val_loss: 0.2906 - val_mae: 0.1895\n",
      "Epoch 498/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.2925 - mae: 0.1923 - val_loss: 0.3056 - val_mae: 0.2197\n",
      "Epoch 499/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.2883 - mae: 0.1858 - val_loss: 0.2921 - val_mae: 0.1962\n",
      "Epoch 500/1000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.2846 - mae: 0.1862 - val_loss: 0.2937 - val_mae: 0.2047\n",
      "Epoch 501/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.2828 - mae: 0.1836 - val_loss: 0.2859 - val_mae: 0.1883\n",
      "Epoch 502/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.2816 - mae: 0.1849 - val_loss: 0.2889 - val_mae: 0.2049\n",
      "Epoch 503/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.2789 - mae: 0.1840 - val_loss: 0.2897 - val_mae: 0.2024\n",
      "Epoch 504/1000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 0.2775 - mae: 0.1843 - val_loss: 0.3226 - val_mae: 0.2446\n",
      "Epoch 505/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.2816 - mae: 0.1934 - val_loss: 0.2916 - val_mae: 0.2170\n",
      "Epoch 506/1000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.2789 - mae: 0.1960 - val_loss: 0.2820 - val_mae: 0.2047\n",
      "Epoch 507/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2761 - mae: 0.1931 - val_loss: 0.2729 - val_mae: 0.1904\n",
      "Epoch 508/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.2731 - mae: 0.1902 - val_loss: 0.2769 - val_mae: 0.2008\n",
      "Epoch 509/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 0.2736 - mae: 0.1932 - val_loss: 0.2941 - val_mae: 0.2287\n",
      "Epoch 510/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.2746 - mae: 0.2002 - val_loss: 0.2915 - val_mae: 0.2241\n",
      "Epoch 511/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.2678 - mae: 0.1908 - val_loss: 0.2715 - val_mae: 0.1987\n",
      "Epoch 512/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.2632 - mae: 0.1834 - val_loss: 0.2744 - val_mae: 0.2042\n",
      "Epoch 513/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.2609 - mae: 0.1824 - val_loss: 0.2632 - val_mae: 0.1906\n",
      "Epoch 514/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.2576 - mae: 0.1794 - val_loss: 0.2611 - val_mae: 0.1892\n",
      "Epoch 515/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.2565 - mae: 0.1793 - val_loss: 0.2599 - val_mae: 0.1868\n",
      "Epoch 516/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.2600 - mae: 0.1866 - val_loss: 0.2921 - val_mae: 0.2314\n",
      "Epoch 517/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2787 - mae: 0.2232 - val_loss: 0.2788 - val_mae: 0.2326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 518/1000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2729 - mae: 0.2227 - val_loss: 0.2738 - val_mae: 0.2298\n",
      "Epoch 519/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.2592 - mae: 0.2038 - val_loss: 0.2556 - val_mae: 0.2003\n",
      "Epoch 520/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.2471 - mae: 0.1798 - val_loss: 0.2528 - val_mae: 0.1900\n",
      "Epoch 521/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.2436 - mae: 0.1753 - val_loss: 0.2529 - val_mae: 0.1914\n",
      "Epoch 522/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.2449 - mae: 0.1790 - val_loss: 0.2678 - val_mae: 0.2140\n",
      "Epoch 523/1000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.3074 - mae: 0.2398 - val_loss: 0.2857 - val_mae: 0.2383\n",
      "Epoch 524/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.2836 - mae: 0.2287 - val_loss: 0.2699 - val_mae: 0.2340\n",
      "Epoch 525/1000\n",
      "1570/1570 [==============================] - 0s 151us/sample - loss: 0.2639 - mae: 0.2243 - val_loss: 0.2694 - val_mae: 0.2359\n",
      "Epoch 526/1000\n",
      "1570/1570 [==============================] - 0s 151us/sample - loss: 0.2622 - mae: 0.2236 - val_loss: 0.2664 - val_mae: 0.2345\n",
      "Epoch 527/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.2606 - mae: 0.2243 - val_loss: 0.2647 - val_mae: 0.2345\n",
      "Epoch 528/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.2589 - mae: 0.2248 - val_loss: 0.2632 - val_mae: 0.2342\n",
      "Epoch 529/1000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2573 - mae: 0.2247 - val_loss: 0.2614 - val_mae: 0.2345\n",
      "Epoch 530/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.2556 - mae: 0.2237 - val_loss: 0.2598 - val_mae: 0.2343\n",
      "Epoch 531/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.2539 - mae: 0.2239 - val_loss: 0.2582 - val_mae: 0.2343\n",
      "Epoch 532/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.2523 - mae: 0.2236 - val_loss: 0.2565 - val_mae: 0.2344\n",
      "Epoch 533/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.2507 - mae: 0.2243 - val_loss: 0.2548 - val_mae: 0.2347\n",
      "Epoch 534/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.2491 - mae: 0.2238 - val_loss: 0.2533 - val_mae: 0.2344\n",
      "Epoch 535/1000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2474 - mae: 0.2246 - val_loss: 0.2515 - val_mae: 0.2349\n",
      "Epoch 536/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.2458 - mae: 0.2243 - val_loss: 0.2502 - val_mae: 0.2341\n",
      "Epoch 537/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.2444 - mae: 0.2236 - val_loss: 0.2483 - val_mae: 0.2348\n",
      "Epoch 538/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.2426 - mae: 0.2248 - val_loss: 0.2469 - val_mae: 0.2343\n",
      "Epoch 539/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.2411 - mae: 0.2253 - val_loss: 0.2452 - val_mae: 0.2346\n",
      "Epoch 540/1000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.2394 - mae: 0.2242 - val_loss: 0.2437 - val_mae: 0.2343\n",
      "Epoch 541/1000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.2381 - mae: 0.2239 - val_loss: 0.2421 - val_mae: 0.2346\n",
      "Epoch 542/1000\n",
      "1570/1570 [==============================] - 0s 152us/sample - loss: 0.2364 - mae: 0.2241 - val_loss: 0.2405 - val_mae: 0.2345\n",
      "Epoch 543/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.2348 - mae: 0.2243 - val_loss: 0.2389 - val_mae: 0.2346\n",
      "Epoch 544/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.2332 - mae: 0.2248 - val_loss: 0.2373 - val_mae: 0.2348\n",
      "Epoch 545/1000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 0.2317 - mae: 0.2244 - val_loss: 0.2359 - val_mae: 0.2348\n",
      "Epoch 546/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.2303 - mae: 0.2252 - val_loss: 0.2345 - val_mae: 0.2348\n",
      "Epoch 547/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.2288 - mae: 0.2247 - val_loss: 0.2331 - val_mae: 0.2343\n",
      "Epoch 548/1000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 0.2273 - mae: 0.2246 - val_loss: 0.2314 - val_mae: 0.2346\n",
      "Epoch 549/1000\n",
      "1570/1570 [==============================] - 0s 146us/sample - loss: 0.2257 - mae: 0.2244 - val_loss: 0.2300 - val_mae: 0.2344\n",
      "Epoch 550/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 0.2242 - mae: 0.2240 - val_loss: 0.2284 - val_mae: 0.2345\n",
      "Epoch 551/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.2228 - mae: 0.2237 - val_loss: 0.2269 - val_mae: 0.2346\n",
      "Epoch 552/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.2212 - mae: 0.2254 - val_loss: 0.2253 - val_mae: 0.2348\n",
      "Epoch 553/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.2196 - mae: 0.2247 - val_loss: 0.2239 - val_mae: 0.2345\n",
      "Epoch 554/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.2182 - mae: 0.2235 - val_loss: 0.2224 - val_mae: 0.2345\n",
      "Epoch 555/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.2167 - mae: 0.2251 - val_loss: 0.2210 - val_mae: 0.2342\n",
      "Epoch 556/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.2152 - mae: 0.2240 - val_loss: 0.2195 - val_mae: 0.2343\n",
      "Epoch 557/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.2137 - mae: 0.2247 - val_loss: 0.2179 - val_mae: 0.2346\n",
      "Epoch 558/1000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.2123 - mae: 0.2239 - val_loss: 0.2164 - val_mae: 0.2349\n",
      "Epoch 559/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.2107 - mae: 0.2245 - val_loss: 0.2150 - val_mae: 0.2346\n",
      "Epoch 560/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.2094 - mae: 0.2252 - val_loss: 0.2134 - val_mae: 0.2350\n",
      "Epoch 561/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.2079 - mae: 0.2243 - val_loss: 0.2121 - val_mae: 0.2345\n",
      "Epoch 562/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.2064 - mae: 0.2240 - val_loss: 0.2107 - val_mae: 0.2344\n",
      "Epoch 563/1000\n",
      "1570/1570 [==============================] - 0s 152us/sample - loss: 0.2050 - mae: 0.2243 - val_loss: 0.2093 - val_mae: 0.2344\n",
      "Epoch 564/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.2058 - mae: 0.2251 - val_loss: 0.2080 - val_mae: 0.2350\n",
      "Epoch 565/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.2027 - mae: 0.2247 - val_loss: 0.2072 - val_mae: 0.2344\n",
      "Epoch 566/1000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 0.2016 - mae: 0.2248 - val_loss: 0.2058 - val_mae: 0.2348\n",
      "Epoch 567/1000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 0.2002 - mae: 0.2240 - val_loss: 0.2046 - val_mae: 0.2343\n",
      "Epoch 568/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.1989 - mae: 0.2245 - val_loss: 0.2031 - val_mae: 0.2345\n",
      "Epoch 569/1000\n",
      "1570/1570 [==============================] - 0s 151us/sample - loss: 0.1975 - mae: 0.2239 - val_loss: 0.2018 - val_mae: 0.2345\n",
      "Epoch 570/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1962 - mae: 0.2249 - val_loss: 0.2003 - val_mae: 0.2350\n",
      "Epoch 571/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1948 - mae: 0.2249 - val_loss: 0.1989 - val_mae: 0.2350\n",
      "Epoch 572/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.1935 - mae: 0.2247 - val_loss: 0.1976 - val_mae: 0.2349\n",
      "Epoch 573/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.1922 - mae: 0.2249 - val_loss: 0.1963 - val_mae: 0.2349\n",
      "Epoch 574/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.1907 - mae: 0.2247 - val_loss: 0.1950 - val_mae: 0.2346\n",
      "Epoch 575/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.1894 - mae: 0.2243 - val_loss: 0.1937 - val_mae: 0.2346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 576/1000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1881 - mae: 0.2244 - val_loss: 0.1925 - val_mae: 0.2343\n",
      "Epoch 577/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1868 - mae: 0.2244 - val_loss: 0.1912 - val_mae: 0.2343\n",
      "Epoch 578/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.1855 - mae: 0.2239 - val_loss: 0.1899 - val_mae: 0.2343\n",
      "Epoch 579/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.1842 - mae: 0.2242 - val_loss: 0.1884 - val_mae: 0.2347\n",
      "Epoch 580/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.1828 - mae: 0.2245 - val_loss: 0.1871 - val_mae: 0.2347\n",
      "Epoch 581/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.1816 - mae: 0.2242 - val_loss: 0.1858 - val_mae: 0.2347\n",
      "Epoch 582/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1803 - mae: 0.2248 - val_loss: 0.1846 - val_mae: 0.2346\n",
      "Epoch 583/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.1791 - mae: 0.2243 - val_loss: 0.1833 - val_mae: 0.2348\n",
      "Epoch 584/1000\n",
      "1570/1570 [==============================] - 0s 146us/sample - loss: 0.1779 - mae: 0.2256 - val_loss: 0.1820 - val_mae: 0.2346\n",
      "Epoch 585/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.1764 - mae: 0.2240 - val_loss: 0.1808 - val_mae: 0.2344\n",
      "Epoch 586/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 0.1752 - mae: 0.2240 - val_loss: 0.1795 - val_mae: 0.2346\n",
      "Epoch 587/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.1740 - mae: 0.2250 - val_loss: 0.1783 - val_mae: 0.2346\n",
      "Epoch 588/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1727 - mae: 0.2247 - val_loss: 0.1769 - val_mae: 0.2349\n",
      "Epoch 589/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.1715 - mae: 0.2245 - val_loss: 0.1757 - val_mae: 0.2347\n",
      "Epoch 590/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.1702 - mae: 0.2245 - val_loss: 0.1745 - val_mae: 0.2347\n",
      "Epoch 591/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.1690 - mae: 0.2244 - val_loss: 0.1733 - val_mae: 0.2346\n",
      "Epoch 592/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.1678 - mae: 0.2249 - val_loss: 0.1720 - val_mae: 0.2348\n",
      "Epoch 593/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1665 - mae: 0.2242 - val_loss: 0.1709 - val_mae: 0.2344\n",
      "Epoch 594/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1653 - mae: 0.2241 - val_loss: 0.1697 - val_mae: 0.2344\n",
      "Epoch 595/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.1641 - mae: 0.2240 - val_loss: 0.1684 - val_mae: 0.2346\n",
      "Epoch 596/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.1629 - mae: 0.2253 - val_loss: 0.1674 - val_mae: 0.2342\n",
      "Epoch 597/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.1617 - mae: 0.2238 - val_loss: 0.1661 - val_mae: 0.2344\n",
      "Epoch 598/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.1605 - mae: 0.2242 - val_loss: 0.1648 - val_mae: 0.2346\n",
      "Epoch 599/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1593 - mae: 0.2243 - val_loss: 0.1637 - val_mae: 0.2345\n",
      "Epoch 600/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1582 - mae: 0.2253 - val_loss: 0.1625 - val_mae: 0.2346\n",
      "Epoch 601/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.1580 - mae: 0.2249 - val_loss: 0.1614 - val_mae: 0.2346\n",
      "Epoch 602/1000\n",
      "1570/1570 [==============================] - 0s 146us/sample - loss: 0.1564 - mae: 0.2246 - val_loss: 0.1607 - val_mae: 0.2341\n",
      "Epoch 603/1000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 0.1550 - mae: 0.2239 - val_loss: 0.1593 - val_mae: 0.2348\n",
      "Epoch 604/1000\n",
      "1570/1570 [==============================] - 0s 152us/sample - loss: 0.1550 - mae: 0.2252 - val_loss: 0.1581 - val_mae: 0.2341\n",
      "Epoch 605/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1552 - mae: 0.2268 - val_loss: 0.1572 - val_mae: 0.2348\n",
      "Epoch 606/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1519 - mae: 0.2242 - val_loss: 0.1563 - val_mae: 0.2344\n",
      "Epoch 607/1000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 0.1508 - mae: 0.2247 - val_loss: 0.1550 - val_mae: 0.2350\n",
      "Epoch 608/1000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 0.1497 - mae: 0.2242 - val_loss: 0.1540 - val_mae: 0.2347\n",
      "Epoch 609/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1486 - mae: 0.2245 - val_loss: 0.1528 - val_mae: 0.2349\n",
      "Epoch 610/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.1475 - mae: 0.2243 - val_loss: 0.1520 - val_mae: 0.2345\n",
      "Epoch 611/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1467 - mae: 0.2240 - val_loss: 0.1511 - val_mae: 0.2348\n",
      "Epoch 612/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1457 - mae: 0.2258 - val_loss: 0.1499 - val_mae: 0.2352\n",
      "Epoch 613/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.1446 - mae: 0.2241 - val_loss: 0.1490 - val_mae: 0.2345\n",
      "Epoch 614/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.1436 - mae: 0.2244 - val_loss: 0.1479 - val_mae: 0.2347\n",
      "Epoch 615/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.1425 - mae: 0.2242 - val_loss: 0.1470 - val_mae: 0.2345\n",
      "Epoch 616/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.1415 - mae: 0.2246 - val_loss: 0.1459 - val_mae: 0.2345\n",
      "Epoch 617/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.1404 - mae: 0.2247 - val_loss: 0.1449 - val_mae: 0.2346\n",
      "Epoch 618/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.1394 - mae: 0.2236 - val_loss: 0.1439 - val_mae: 0.2346\n",
      "Epoch 619/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.1384 - mae: 0.2243 - val_loss: 0.1428 - val_mae: 0.2346\n",
      "Epoch 620/1000\n",
      "1570/1570 [==============================] - 0s 146us/sample - loss: 0.1374 - mae: 0.2249 - val_loss: 0.1421 - val_mae: 0.2340\n",
      "Epoch 621/1000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 0.1364 - mae: 0.2239 - val_loss: 0.1408 - val_mae: 0.2345\n",
      "Epoch 622/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.1354 - mae: 0.2244 - val_loss: 0.1399 - val_mae: 0.2343\n",
      "Epoch 623/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.1344 - mae: 0.2239 - val_loss: 0.1391 - val_mae: 0.2340\n",
      "Epoch 624/1000\n",
      "1570/1570 [==============================] - 0s 151us/sample - loss: 0.1334 - mae: 0.2248 - val_loss: 0.1379 - val_mae: 0.2344\n",
      "Epoch 625/1000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 0.1325 - mae: 0.2234 - val_loss: 0.1369 - val_mae: 0.2346\n",
      "Epoch 626/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.1314 - mae: 0.2251 - val_loss: 0.1358 - val_mae: 0.2348\n",
      "Epoch 627/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.1304 - mae: 0.2248 - val_loss: 0.1349 - val_mae: 0.2346\n",
      "Epoch 628/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1295 - mae: 0.2247 - val_loss: 0.1340 - val_mae: 0.2345\n",
      "Epoch 629/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.1285 - mae: 0.2243 - val_loss: 0.1330 - val_mae: 0.2346\n",
      "Epoch 630/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.1275 - mae: 0.2244 - val_loss: 0.1320 - val_mae: 0.2345\n",
      "Epoch 631/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.1266 - mae: 0.2248 - val_loss: 0.1311 - val_mae: 0.2346\n",
      "Epoch 632/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.1257 - mae: 0.2243 - val_loss: 0.1300 - val_mae: 0.2349\n",
      "Epoch 633/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1247 - mae: 0.2249 - val_loss: 0.1292 - val_mae: 0.2344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 634/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.1238 - mae: 0.2235 - val_loss: 0.1282 - val_mae: 0.2348\n",
      "Epoch 635/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.1228 - mae: 0.2238 - val_loss: 0.1274 - val_mae: 0.2345\n",
      "Epoch 636/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1219 - mae: 0.2246 - val_loss: 0.1264 - val_mae: 0.2347\n",
      "Epoch 637/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.1210 - mae: 0.2243 - val_loss: 0.1256 - val_mae: 0.2344\n",
      "Epoch 638/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.1370 - mae: 0.2345 - val_loss: 0.1248 - val_mae: 0.2364\n",
      "Epoch 639/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.1195 - mae: 0.2249 - val_loss: 0.1242 - val_mae: 0.2343\n",
      "Epoch 640/1000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.1187 - mae: 0.2239 - val_loss: 0.1231 - val_mae: 0.2347\n",
      "Epoch 641/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.1178 - mae: 0.2245 - val_loss: 0.1223 - val_mae: 0.2345\n",
      "Epoch 642/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.1169 - mae: 0.2244 - val_loss: 0.1214 - val_mae: 0.2346\n",
      "Epoch 643/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.1161 - mae: 0.2243 - val_loss: 0.1207 - val_mae: 0.2342\n",
      "Epoch 644/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 0.1152 - mae: 0.2255 - val_loss: 0.1196 - val_mae: 0.2349\n",
      "Epoch 645/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.1145 - mae: 0.2234 - val_loss: 0.1188 - val_mae: 0.2347\n",
      "Epoch 646/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1135 - mae: 0.2250 - val_loss: 0.1178 - val_mae: 0.2352\n",
      "Epoch 647/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.1126 - mae: 0.2253 - val_loss: 0.1170 - val_mae: 0.2348\n",
      "Epoch 648/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 0.1320 - mae: 0.2348 - val_loss: 0.1170 - val_mae: 0.2359\n",
      "Epoch 649/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.1124 - mae: 0.2256 - val_loss: 0.1169 - val_mae: 0.2347\n",
      "Epoch 650/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.1115 - mae: 0.2236 - val_loss: 0.1161 - val_mae: 0.2344\n",
      "Epoch 651/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1107 - mae: 0.2251 - val_loss: 0.1152 - val_mae: 0.2346\n",
      "Epoch 652/1000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.1099 - mae: 0.2244 - val_loss: 0.1146 - val_mae: 0.2343\n",
      "Epoch 653/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.1091 - mae: 0.2242 - val_loss: 0.1135 - val_mae: 0.2351\n",
      "Epoch 654/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.1569 - mae: 0.2404 - val_loss: 0.1138 - val_mae: 0.2376\n",
      "Epoch 655/1000\n",
      "1570/1570 [==============================] - 0s 152us/sample - loss: 0.1087 - mae: 0.2262 - val_loss: 0.1131 - val_mae: 0.2345\n",
      "Epoch 656/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.1079 - mae: 0.2237 - val_loss: 0.1122 - val_mae: 0.2349\n",
      "Epoch 657/1000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.1071 - mae: 0.2256 - val_loss: 0.1115 - val_mae: 0.2347\n",
      "Epoch 658/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.1062 - mae: 0.2242 - val_loss: 0.1108 - val_mae: 0.2347\n",
      "Epoch 659/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.1055 - mae: 0.2247 - val_loss: 0.1101 - val_mae: 0.2347\n",
      "Epoch 660/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.1048 - mae: 0.2244 - val_loss: 0.1094 - val_mae: 0.2345\n",
      "Epoch 661/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.1040 - mae: 0.2244 - val_loss: 0.1088 - val_mae: 0.2344\n",
      "Epoch 662/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.1034 - mae: 0.2245 - val_loss: 0.1080 - val_mae: 0.2346\n",
      "Epoch 663/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.1027 - mae: 0.2246 - val_loss: 0.1072 - val_mae: 0.2349\n",
      "Epoch 664/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.1021 - mae: 0.2259 - val_loss: 0.1066 - val_mae: 0.2348\n",
      "Epoch 665/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.1014 - mae: 0.2245 - val_loss: 0.1063 - val_mae: 0.2338\n",
      "Epoch 666/1000\n",
      "1570/1570 [==============================] - 0s 152us/sample - loss: 0.1115 - mae: 0.2298 - val_loss: 0.1057 - val_mae: 0.2355\n",
      "Epoch 667/1000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 0.1012 - mae: 0.2265 - val_loss: 0.1057 - val_mae: 0.2346\n",
      "Epoch 668/1000\n",
      "1570/1570 [==============================] - 0s 151us/sample - loss: 0.1004 - mae: 0.2237 - val_loss: 0.1051 - val_mae: 0.2344\n",
      "Epoch 669/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.0998 - mae: 0.2244 - val_loss: 0.1044 - val_mae: 0.2348\n",
      "Epoch 670/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.0991 - mae: 0.2240 - val_loss: 0.1038 - val_mae: 0.2345\n",
      "Epoch 671/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0986 - mae: 0.2248 - val_loss: 0.1033 - val_mae: 0.2344\n",
      "Epoch 672/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.0979 - mae: 0.2246 - val_loss: 0.1027 - val_mae: 0.2345\n",
      "Epoch 673/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0974 - mae: 0.2243 - val_loss: 0.1021 - val_mae: 0.2344\n",
      "Epoch 674/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.0968 - mae: 0.2239 - val_loss: 0.1016 - val_mae: 0.2344\n",
      "Epoch 675/1000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.0962 - mae: 0.2245 - val_loss: 0.1010 - val_mae: 0.2344\n",
      "Epoch 676/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.0957 - mae: 0.2243 - val_loss: 0.1005 - val_mae: 0.2343\n",
      "Epoch 677/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.0952 - mae: 0.2241 - val_loss: 0.0999 - val_mae: 0.2343\n",
      "Epoch 678/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0947 - mae: 0.2251 - val_loss: 0.0994 - val_mae: 0.2343\n",
      "Epoch 679/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.0941 - mae: 0.2245 - val_loss: 0.0990 - val_mae: 0.2341\n",
      "Epoch 680/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.0935 - mae: 0.2234 - val_loss: 0.0983 - val_mae: 0.2344\n",
      "Epoch 681/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.0930 - mae: 0.2245 - val_loss: 0.0978 - val_mae: 0.2346\n",
      "Epoch 682/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.0926 - mae: 0.2243 - val_loss: 0.0986 - val_mae: 0.2358\n",
      "Epoch 683/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0923 - mae: 0.2240 - val_loss: 0.0971 - val_mae: 0.2347\n",
      "Epoch 684/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0920 - mae: 0.2249 - val_loss: 0.0967 - val_mae: 0.2348\n",
      "Epoch 685/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.0915 - mae: 0.2237 - val_loss: 0.0963 - val_mae: 0.2344\n",
      "Epoch 686/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.0911 - mae: 0.2246 - val_loss: 0.0958 - val_mae: 0.2346\n",
      "Epoch 687/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.0906 - mae: 0.2242 - val_loss: 0.0954 - val_mae: 0.2344\n",
      "Epoch 688/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0901 - mae: 0.2244 - val_loss: 0.0950 - val_mae: 0.2343\n",
      "Epoch 689/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0897 - mae: 0.2244 - val_loss: 0.0945 - val_mae: 0.2345\n",
      "Epoch 690/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0892 - mae: 0.2249 - val_loss: 0.0940 - val_mae: 0.2345\n",
      "Epoch 691/1000\n",
      "1570/1570 [==============================] - 0s 151us/sample - loss: 0.0888 - mae: 0.2242 - val_loss: 0.0936 - val_mae: 0.2346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 692/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.0899 - mae: 0.2260 - val_loss: 0.0934 - val_mae: 0.2343\n",
      "Epoch 693/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.0881 - mae: 0.2237 - val_loss: 0.0931 - val_mae: 0.2341\n",
      "Epoch 694/1000\n",
      "1570/1570 [==============================] - 0s 146us/sample - loss: 0.0878 - mae: 0.2241 - val_loss: 0.0925 - val_mae: 0.2347\n",
      "Epoch 695/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 0.0874 - mae: 0.2243 - val_loss: 0.0923 - val_mae: 0.2344\n",
      "Epoch 696/1000\n",
      "1570/1570 [==============================] - 0s 152us/sample - loss: 0.0870 - mae: 0.2246 - val_loss: 0.0918 - val_mae: 0.2346\n",
      "Epoch 697/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.0867 - mae: 0.2235 - val_loss: 0.0915 - val_mae: 0.2346\n",
      "Epoch 698/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.0863 - mae: 0.2242 - val_loss: 0.0911 - val_mae: 0.2348\n",
      "Epoch 699/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.0860 - mae: 0.2249 - val_loss: 0.0909 - val_mae: 0.2343\n",
      "Epoch 700/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0857 - mae: 0.2239 - val_loss: 0.0905 - val_mae: 0.2344\n",
      "Epoch 701/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0854 - mae: 0.2240 - val_loss: 0.0903 - val_mae: 0.2343\n",
      "Epoch 702/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0850 - mae: 0.2239 - val_loss: 0.0899 - val_mae: 0.2346\n",
      "Epoch 703/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.0848 - mae: 0.2245 - val_loss: 0.0896 - val_mae: 0.2345\n",
      "Epoch 704/1000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.0846 - mae: 0.2260 - val_loss: 0.0893 - val_mae: 0.2344\n",
      "Epoch 705/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.0841 - mae: 0.2236 - val_loss: 0.0890 - val_mae: 0.2344\n",
      "Epoch 706/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0839 - mae: 0.2247 - val_loss: 0.0888 - val_mae: 0.2344\n",
      "Epoch 707/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0836 - mae: 0.2235 - val_loss: 0.0884 - val_mae: 0.2346\n",
      "Epoch 708/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0833 - mae: 0.2243 - val_loss: 0.0882 - val_mae: 0.2344\n",
      "Epoch 709/1000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.0830 - mae: 0.2239 - val_loss: 0.0880 - val_mae: 0.2343\n",
      "Epoch 710/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.0829 - mae: 0.2241 - val_loss: 0.0877 - val_mae: 0.2343\n",
      "Epoch 711/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.0825 - mae: 0.2249 - val_loss: 0.0874 - val_mae: 0.2347\n",
      "Epoch 712/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.0823 - mae: 0.2240 - val_loss: 0.0872 - val_mae: 0.2344\n",
      "Epoch 713/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.0821 - mae: 0.2245 - val_loss: 0.0869 - val_mae: 0.2347\n",
      "Epoch 714/1000\n",
      "1570/1570 [==============================] - 0s 152us/sample - loss: 0.0819 - mae: 0.2253 - val_loss: 0.0867 - val_mae: 0.2344\n",
      "Epoch 715/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.0816 - mae: 0.2237 - val_loss: 0.0864 - val_mae: 0.2347\n",
      "Epoch 716/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.0814 - mae: 0.2246 - val_loss: 0.0862 - val_mae: 0.2348\n",
      "Epoch 717/1000\n",
      "1570/1570 [==============================] - 0s 152us/sample - loss: 0.0812 - mae: 0.2249 - val_loss: 0.0860 - val_mae: 0.2346\n",
      "Epoch 718/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 0.0809 - mae: 0.2242 - val_loss: 0.0859 - val_mae: 0.2345\n",
      "Epoch 719/1000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 0.0808 - mae: 0.2241 - val_loss: 0.0855 - val_mae: 0.2351\n",
      "Epoch 720/1000\n",
      "1570/1570 [==============================] - 0s 151us/sample - loss: 0.0806 - mae: 0.2255 - val_loss: 0.0855 - val_mae: 0.2345\n",
      "Epoch 721/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.0805 - mae: 0.2231 - val_loss: 0.0853 - val_mae: 0.2346\n",
      "Epoch 722/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.0802 - mae: 0.2243 - val_loss: 0.0851 - val_mae: 0.2346\n",
      "Epoch 723/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0800 - mae: 0.2238 - val_loss: 0.0850 - val_mae: 0.2344\n",
      "Epoch 724/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0799 - mae: 0.2240 - val_loss: 0.0848 - val_mae: 0.2346\n",
      "Epoch 725/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0797 - mae: 0.2246 - val_loss: 0.0846 - val_mae: 0.2345\n",
      "Epoch 726/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.0797 - mae: 0.2244 - val_loss: 0.0846 - val_mae: 0.2343\n",
      "Epoch 727/1000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.0794 - mae: 0.2235 - val_loss: 0.0845 - val_mae: 0.2342\n",
      "Epoch 728/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.0792 - mae: 0.2239 - val_loss: 0.0842 - val_mae: 0.2344\n",
      "Epoch 729/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0792 - mae: 0.2243 - val_loss: 0.0839 - val_mae: 0.2348\n",
      "Epoch 730/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.0790 - mae: 0.2245 - val_loss: 0.0837 - val_mae: 0.2352\n",
      "Epoch 731/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0789 - mae: 0.2252 - val_loss: 0.0837 - val_mae: 0.2347\n",
      "Epoch 732/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.0812 - mae: 0.2249 - val_loss: 0.0838 - val_mae: 0.2347\n",
      "Epoch 733/1000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.0788 - mae: 0.2246 - val_loss: 0.0836 - val_mae: 0.2350\n",
      "Epoch 734/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.0788 - mae: 0.2240 - val_loss: 0.0836 - val_mae: 0.2349\n",
      "Epoch 735/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.0788 - mae: 0.2249 - val_loss: 0.0834 - val_mae: 0.2352\n",
      "Epoch 736/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.0785 - mae: 0.2248 - val_loss: 0.0834 - val_mae: 0.2347\n",
      "Epoch 737/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0783 - mae: 0.2242 - val_loss: 0.0834 - val_mae: 0.2343\n",
      "Epoch 738/1000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.0782 - mae: 0.2239 - val_loss: 0.0832 - val_mae: 0.2345\n",
      "Epoch 739/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.0781 - mae: 0.2238 - val_loss: 0.0831 - val_mae: 0.2343\n",
      "Epoch 740/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.0780 - mae: 0.2237 - val_loss: 0.0828 - val_mae: 0.2350\n",
      "Epoch 741/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.0780 - mae: 0.2255 - val_loss: 0.0829 - val_mae: 0.2343\n",
      "Epoch 742/1000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 0.0779 - mae: 0.2237 - val_loss: 0.0829 - val_mae: 0.2341\n",
      "Epoch 743/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 0.0777 - mae: 0.2238 - val_loss: 0.0826 - val_mae: 0.2346\n",
      "Epoch 744/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.0776 - mae: 0.2240 - val_loss: 0.0826 - val_mae: 0.2344\n",
      "Epoch 745/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.0775 - mae: 0.2243 - val_loss: 0.0825 - val_mae: 0.2343\n",
      "Epoch 746/1000\n",
      "1570/1570 [==============================] - 0s 151us/sample - loss: 0.0774 - mae: 0.2242 - val_loss: 0.0825 - val_mae: 0.2343\n",
      "Epoch 747/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.0773 - mae: 0.2244 - val_loss: 0.0823 - val_mae: 0.2345\n",
      "Epoch 748/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0773 - mae: 0.2251 - val_loss: 0.0821 - val_mae: 0.2348\n",
      "Epoch 749/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.0772 - mae: 0.2245 - val_loss: 0.0820 - val_mae: 0.2347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 750/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.0771 - mae: 0.2242 - val_loss: 0.0819 - val_mae: 0.2350\n",
      "Epoch 751/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.0771 - mae: 0.2254 - val_loss: 0.0819 - val_mae: 0.2345\n",
      "Epoch 752/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0771 - mae: 0.2243 - val_loss: 0.0818 - val_mae: 0.2347\n",
      "Epoch 753/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0768 - mae: 0.2236 - val_loss: 0.0818 - val_mae: 0.2345\n",
      "Epoch 754/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.0768 - mae: 0.2244 - val_loss: 0.0817 - val_mae: 0.2345\n",
      "Epoch 755/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.0767 - mae: 0.2237 - val_loss: 0.0816 - val_mae: 0.2346\n",
      "Epoch 756/1000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.0766 - mae: 0.2238 - val_loss: 0.0815 - val_mae: 0.2348\n",
      "Epoch 757/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.0765 - mae: 0.2244 - val_loss: 0.0815 - val_mae: 0.2344\n",
      "Epoch 758/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.0764 - mae: 0.2238 - val_loss: 0.0813 - val_mae: 0.2348\n",
      "Epoch 759/1000\n",
      "1570/1570 [==============================] - 0s 152us/sample - loss: 0.0764 - mae: 0.2252 - val_loss: 0.0814 - val_mae: 0.2343\n",
      "Epoch 760/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0763 - mae: 0.2235 - val_loss: 0.0813 - val_mae: 0.2344\n",
      "Epoch 761/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.0762 - mae: 0.2240 - val_loss: 0.0812 - val_mae: 0.2346\n",
      "Epoch 762/1000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.0762 - mae: 0.2238 - val_loss: 0.0811 - val_mae: 0.2346\n",
      "Epoch 763/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0764 - mae: 0.2254 - val_loss: 0.0811 - val_mae: 0.2344\n",
      "Epoch 764/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0760 - mae: 0.2252 - val_loss: 0.0809 - val_mae: 0.2347\n",
      "Epoch 765/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.0759 - mae: 0.2243 - val_loss: 0.0812 - val_mae: 0.2338\n",
      "Epoch 766/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.0760 - mae: 0.2234 - val_loss: 0.0808 - val_mae: 0.2348\n",
      "Epoch 767/1000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.0759 - mae: 0.2248 - val_loss: 0.0808 - val_mae: 0.2346\n",
      "Epoch 768/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.0758 - mae: 0.2242 - val_loss: 0.0808 - val_mae: 0.2343\n",
      "Epoch 769/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0757 - mae: 0.2245 - val_loss: 0.0806 - val_mae: 0.2346\n",
      "Epoch 770/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.0758 - mae: 0.2254 - val_loss: 0.0807 - val_mae: 0.2341\n",
      "Epoch 771/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0757 - mae: 0.2241 - val_loss: 0.0804 - val_mae: 0.2349\n",
      "Epoch 772/1000\n",
      "1570/1570 [==============================] - 0s 151us/sample - loss: 0.0755 - mae: 0.2243 - val_loss: 0.0805 - val_mae: 0.2343\n",
      "Epoch 773/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.0755 - mae: 0.2237 - val_loss: 0.0804 - val_mae: 0.2346\n",
      "Epoch 774/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.0754 - mae: 0.2242 - val_loss: 0.0805 - val_mae: 0.2342\n",
      "Epoch 775/1000\n",
      "1570/1570 [==============================] - 0s 149us/sample - loss: 0.0753 - mae: 0.2240 - val_loss: 0.0804 - val_mae: 0.2342\n",
      "Epoch 776/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 0.0753 - mae: 0.2237 - val_loss: 0.0803 - val_mae: 0.2344\n",
      "Epoch 777/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0752 - mae: 0.2242 - val_loss: 0.0802 - val_mae: 0.2344\n",
      "Epoch 778/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.0751 - mae: 0.2241 - val_loss: 0.0801 - val_mae: 0.2344\n",
      "Epoch 779/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.0751 - mae: 0.2243 - val_loss: 0.0801 - val_mae: 0.2343\n",
      "Epoch 780/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.0750 - mae: 0.2242 - val_loss: 0.0800 - val_mae: 0.2346\n",
      "Epoch 781/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0750 - mae: 0.2249 - val_loss: 0.0798 - val_mae: 0.2353\n",
      "Epoch 782/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0751 - mae: 0.2250 - val_loss: 0.0798 - val_mae: 0.2347\n",
      "Epoch 783/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0749 - mae: 0.2239 - val_loss: 0.0797 - val_mae: 0.2350\n",
      "Epoch 784/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.0750 - mae: 0.2262 - val_loss: 0.0796 - val_mae: 0.2350\n",
      "Epoch 785/1000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.0748 - mae: 0.2250 - val_loss: 0.0797 - val_mae: 0.2346\n",
      "Epoch 786/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.0747 - mae: 0.2239 - val_loss: 0.0795 - val_mae: 0.2351\n",
      "Epoch 787/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0749 - mae: 0.2247 - val_loss: 0.0797 - val_mae: 0.2344\n",
      "Epoch 788/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0747 - mae: 0.2252 - val_loss: 0.0797 - val_mae: 0.2343\n",
      "Epoch 789/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0746 - mae: 0.2238 - val_loss: 0.0795 - val_mae: 0.2345\n",
      "Epoch 790/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.0747 - mae: 0.2245 - val_loss: 0.0796 - val_mae: 0.2342\n",
      "Epoch 791/1000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.0745 - mae: 0.2250 - val_loss: 0.0796 - val_mae: 0.2340\n",
      "Epoch 792/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.0744 - mae: 0.2237 - val_loss: 0.0793 - val_mae: 0.2349\n",
      "Epoch 793/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0744 - mae: 0.2245 - val_loss: 0.0793 - val_mae: 0.2347\n",
      "Epoch 794/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0743 - mae: 0.2248 - val_loss: 0.0793 - val_mae: 0.2345\n",
      "Epoch 795/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0743 - mae: 0.2238 - val_loss: 0.0792 - val_mae: 0.2348\n",
      "Epoch 796/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.0747 - mae: 0.2262 - val_loss: 0.0792 - val_mae: 0.2344\n",
      "Epoch 797/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.0743 - mae: 0.2247 - val_loss: 0.0794 - val_mae: 0.2340\n",
      "Epoch 798/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0742 - mae: 0.2244 - val_loss: 0.0791 - val_mae: 0.2345\n",
      "Epoch 799/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0741 - mae: 0.2249 - val_loss: 0.0791 - val_mae: 0.2345\n",
      "Epoch 800/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0741 - mae: 0.2250 - val_loss: 0.0792 - val_mae: 0.2341\n",
      "Epoch 801/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.0740 - mae: 0.2244 - val_loss: 0.0790 - val_mae: 0.2346\n",
      "Epoch 802/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.0740 - mae: 0.2244 - val_loss: 0.0791 - val_mae: 0.2341\n",
      "Epoch 803/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.0741 - mae: 0.2237 - val_loss: 0.0788 - val_mae: 0.2350\n",
      "Epoch 804/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0741 - mae: 0.2256 - val_loss: 0.0790 - val_mae: 0.2342\n",
      "Epoch 805/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0739 - mae: 0.2243 - val_loss: 0.0788 - val_mae: 0.2347\n",
      "Epoch 806/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0738 - mae: 0.2239 - val_loss: 0.0788 - val_mae: 0.2346\n",
      "Epoch 807/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.0737 - mae: 0.2243 - val_loss: 0.0788 - val_mae: 0.2343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 808/1000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.0737 - mae: 0.2243 - val_loss: 0.0787 - val_mae: 0.2347\n",
      "Epoch 809/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0737 - mae: 0.2251 - val_loss: 0.0788 - val_mae: 0.2343\n",
      "Epoch 810/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0737 - mae: 0.2250 - val_loss: 0.0786 - val_mae: 0.2345\n",
      "Epoch 811/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0736 - mae: 0.2239 - val_loss: 0.0785 - val_mae: 0.2351\n",
      "Epoch 812/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0743 - mae: 0.2244 - val_loss: 0.0787 - val_mae: 0.2352\n",
      "Epoch 813/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.0740 - mae: 0.2258 - val_loss: 0.0790 - val_mae: 0.2343\n",
      "Epoch 814/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.0739 - mae: 0.2238 - val_loss: 0.0788 - val_mae: 0.2346\n",
      "Epoch 815/1000\n",
      "1570/1570 [==============================] - 0s 152us/sample - loss: 0.0739 - mae: 0.2242 - val_loss: 0.0787 - val_mae: 0.2349\n",
      "Epoch 816/1000\n",
      "1570/1570 [==============================] - 0s 147us/sample - loss: 0.0738 - mae: 0.2248 - val_loss: 0.0787 - val_mae: 0.2348\n",
      "Epoch 817/1000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 0.0739 - mae: 0.2258 - val_loss: 0.0787 - val_mae: 0.2343\n",
      "Epoch 818/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0736 - mae: 0.2243 - val_loss: 0.0785 - val_mae: 0.2349\n",
      "Epoch 819/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.0737 - mae: 0.2244 - val_loss: 0.0784 - val_mae: 0.2353\n",
      "Epoch 820/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.0737 - mae: 0.2256 - val_loss: 0.0786 - val_mae: 0.2343\n",
      "Epoch 821/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0736 - mae: 0.2242 - val_loss: 0.0785 - val_mae: 0.2347\n",
      "Epoch 822/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0734 - mae: 0.2240 - val_loss: 0.0785 - val_mae: 0.2344\n",
      "Epoch 823/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0735 - mae: 0.2257 - val_loss: 0.0784 - val_mae: 0.2345\n",
      "Epoch 824/1000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.0734 - mae: 0.2248 - val_loss: 0.0785 - val_mae: 0.2342\n",
      "Epoch 825/1000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.0733 - mae: 0.2240 - val_loss: 0.0782 - val_mae: 0.2353\n",
      "Epoch 826/1000\n",
      "1570/1570 [==============================] - 0s 303us/sample - loss: 0.0735 - mae: 0.2248 - val_loss: 0.0784 - val_mae: 0.2345\n",
      "Epoch 827/1000\n",
      "1570/1570 [==============================] - 0s 221us/sample - loss: 0.0734 - mae: 0.2253 - val_loss: 0.0782 - val_mae: 0.2350\n",
      "Epoch 828/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.0735 - mae: 0.2251 - val_loss: 0.0783 - val_mae: 0.2346\n",
      "Epoch 829/1000\n",
      "1570/1570 [==============================] - 0s 181us/sample - loss: 0.0736 - mae: 0.2266 - val_loss: 0.0785 - val_mae: 0.2340\n",
      "Epoch 830/1000\n",
      "1570/1570 [==============================] - 0s 177us/sample - loss: 0.0733 - mae: 0.2236 - val_loss: 0.0782 - val_mae: 0.2346\n",
      "Epoch 831/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.0733 - mae: 0.2238 - val_loss: 0.0781 - val_mae: 0.2350\n",
      "Epoch 832/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.0732 - mae: 0.2248 - val_loss: 0.0782 - val_mae: 0.2345\n",
      "Epoch 833/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.0732 - mae: 0.2244 - val_loss: 0.0780 - val_mae: 0.2351\n",
      "Epoch 834/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.0731 - mae: 0.2251 - val_loss: 0.0782 - val_mae: 0.2343\n",
      "Epoch 835/1000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.0733 - mae: 0.2242 - val_loss: 0.0783 - val_mae: 0.2341\n",
      "Epoch 836/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.0732 - mae: 0.2232 - val_loss: 0.0779 - val_mae: 0.2352\n",
      "Epoch 837/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.0730 - mae: 0.2246 - val_loss: 0.0781 - val_mae: 0.2345\n",
      "Epoch 838/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0730 - mae: 0.2244 - val_loss: 0.0779 - val_mae: 0.2349\n",
      "Epoch 839/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0730 - mae: 0.2240 - val_loss: 0.0780 - val_mae: 0.2346\n",
      "Epoch 840/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.0730 - mae: 0.2248 - val_loss: 0.0781 - val_mae: 0.2342\n",
      "Epoch 841/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.0730 - mae: 0.2252 - val_loss: 0.0778 - val_mae: 0.2349\n",
      "Epoch 842/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0731 - mae: 0.2238 - val_loss: 0.0779 - val_mae: 0.2345\n",
      "Epoch 843/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.0729 - mae: 0.2242 - val_loss: 0.0779 - val_mae: 0.2346\n",
      "Epoch 844/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0730 - mae: 0.2251 - val_loss: 0.0779 - val_mae: 0.2346\n",
      "Epoch 845/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.0729 - mae: 0.2249 - val_loss: 0.0778 - val_mae: 0.2347\n",
      "Epoch 846/1000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.0729 - mae: 0.2250 - val_loss: 0.0778 - val_mae: 0.2346\n",
      "Epoch 847/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.0729 - mae: 0.2247 - val_loss: 0.0778 - val_mae: 0.2345\n",
      "Epoch 848/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.0728 - mae: 0.2241 - val_loss: 0.0779 - val_mae: 0.2342\n",
      "Epoch 849/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0728 - mae: 0.2245 - val_loss: 0.0778 - val_mae: 0.2347\n",
      "Epoch 850/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0728 - mae: 0.2244 - val_loss: 0.0779 - val_mae: 0.2343\n",
      "Epoch 851/1000\n",
      "1570/1570 [==============================] - 0s 152us/sample - loss: 0.0728 - mae: 0.2249 - val_loss: 0.0781 - val_mae: 0.2339\n",
      "Epoch 852/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.0728 - mae: 0.2236 - val_loss: 0.0777 - val_mae: 0.2347\n",
      "Epoch 853/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0728 - mae: 0.2243 - val_loss: 0.0779 - val_mae: 0.2342\n",
      "Epoch 854/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.0728 - mae: 0.2256 - val_loss: 0.0777 - val_mae: 0.2346\n",
      "Epoch 855/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.0728 - mae: 0.2247 - val_loss: 0.0778 - val_mae: 0.2344\n",
      "Epoch 856/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0727 - mae: 0.2244 - val_loss: 0.0778 - val_mae: 0.2342\n",
      "Epoch 857/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.0728 - mae: 0.2232 - val_loss: 0.0777 - val_mae: 0.2344\n",
      "Epoch 858/1000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.0727 - mae: 0.2234 - val_loss: 0.0775 - val_mae: 0.2351\n",
      "Epoch 859/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.0727 - mae: 0.2246 - val_loss: 0.0779 - val_mae: 0.2340\n",
      "Epoch 860/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0726 - mae: 0.2238 - val_loss: 0.0776 - val_mae: 0.2349\n",
      "Epoch 861/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0726 - mae: 0.2245 - val_loss: 0.0777 - val_mae: 0.2344\n",
      "Epoch 862/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0726 - mae: 0.2238 - val_loss: 0.0777 - val_mae: 0.2344\n",
      "Epoch 863/1000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.0726 - mae: 0.2243 - val_loss: 0.0778 - val_mae: 0.2340\n",
      "Epoch 864/1000\n",
      "1570/1570 [==============================] - 0s 175us/sample - loss: 0.0728 - mae: 0.2236 - val_loss: 0.0774 - val_mae: 0.2353\n",
      "Epoch 865/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0727 - mae: 0.2249 - val_loss: 0.0775 - val_mae: 0.2348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 866/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.0728 - mae: 0.2251 - val_loss: 0.0774 - val_mae: 0.2353\n",
      "Epoch 867/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0727 - mae: 0.2262 - val_loss: 0.0777 - val_mae: 0.2342\n",
      "Epoch 868/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.0726 - mae: 0.2235 - val_loss: 0.0776 - val_mae: 0.2345\n",
      "Epoch 869/1000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.0726 - mae: 0.2243 - val_loss: 0.0777 - val_mae: 0.2342\n",
      "Epoch 870/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.0727 - mae: 0.2238 - val_loss: 0.0775 - val_mae: 0.2348\n",
      "Epoch 871/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.0726 - mae: 0.2247 - val_loss: 0.0776 - val_mae: 0.2343\n",
      "Epoch 872/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0726 - mae: 0.2237 - val_loss: 0.0774 - val_mae: 0.2353\n",
      "Epoch 873/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.0727 - mae: 0.2257 - val_loss: 0.0774 - val_mae: 0.2352\n",
      "Epoch 874/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.0725 - mae: 0.2248 - val_loss: 0.0776 - val_mae: 0.2343\n",
      "Epoch 875/1000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.0726 - mae: 0.2244 - val_loss: 0.0777 - val_mae: 0.2341\n",
      "Epoch 876/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.0726 - mae: 0.2234 - val_loss: 0.0774 - val_mae: 0.2348\n",
      "Epoch 877/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.0726 - mae: 0.2250 - val_loss: 0.0775 - val_mae: 0.2345\n",
      "Epoch 878/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0726 - mae: 0.2238 - val_loss: 0.0775 - val_mae: 0.2346\n",
      "Epoch 879/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0725 - mae: 0.2241 - val_loss: 0.0776 - val_mae: 0.2344\n",
      "Epoch 880/1000\n",
      "1570/1570 [==============================] - 0s 168us/sample - loss: 0.0726 - mae: 0.2240 - val_loss: 0.0773 - val_mae: 0.2352\n",
      "Epoch 881/1000\n",
      "1570/1570 [==============================] - 0s 172us/sample - loss: 0.0725 - mae: 0.2246 - val_loss: 0.0776 - val_mae: 0.2343\n",
      "Epoch 882/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.0725 - mae: 0.2246 - val_loss: 0.0776 - val_mae: 0.2342\n",
      "Epoch 883/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.0725 - mae: 0.2242 - val_loss: 0.0775 - val_mae: 0.2344\n",
      "Epoch 884/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0724 - mae: 0.2241 - val_loss: 0.0774 - val_mae: 0.2347\n",
      "Epoch 885/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.0727 - mae: 0.2250 - val_loss: 0.0777 - val_mae: 0.2346\n",
      "Epoch 886/1000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.0730 - mae: 0.2245 - val_loss: 0.0775 - val_mae: 0.2352\n",
      "Epoch 887/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.0726 - mae: 0.2244 - val_loss: 0.0776 - val_mae: 0.2344\n",
      "Epoch 888/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0727 - mae: 0.2249 - val_loss: 0.0776 - val_mae: 0.2345\n",
      "Epoch 889/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.0727 - mae: 0.2242 - val_loss: 0.0775 - val_mae: 0.2348\n",
      "Epoch 890/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0725 - mae: 0.2244 - val_loss: 0.0775 - val_mae: 0.2346\n",
      "Epoch 891/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.0725 - mae: 0.2236 - val_loss: 0.0776 - val_mae: 0.2343\n",
      "Epoch 892/1000\n",
      "1570/1570 [==============================] - 0s 179us/sample - loss: 0.0725 - mae: 0.2239 - val_loss: 0.0774 - val_mae: 0.2349\n",
      "Epoch 893/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.0725 - mae: 0.2249 - val_loss: 0.0774 - val_mae: 0.2347\n",
      "Epoch 894/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.0726 - mae: 0.2242 - val_loss: 0.0774 - val_mae: 0.2348\n",
      "Epoch 895/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.0725 - mae: 0.2248 - val_loss: 0.0774 - val_mae: 0.2346\n",
      "Epoch 896/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.0725 - mae: 0.2239 - val_loss: 0.0774 - val_mae: 0.2348\n",
      "Epoch 897/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.0725 - mae: 0.2253 - val_loss: 0.0774 - val_mae: 0.2345\n",
      "Epoch 898/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.0728 - mae: 0.2227 - val_loss: 0.0773 - val_mae: 0.2355\n",
      "Epoch 899/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.0724 - mae: 0.2252 - val_loss: 0.0777 - val_mae: 0.2339\n",
      "Epoch 900/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.0724 - mae: 0.2238 - val_loss: 0.0774 - val_mae: 0.2348\n",
      "Epoch 901/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.0726 - mae: 0.2252 - val_loss: 0.0773 - val_mae: 0.2349\n",
      "Epoch 902/1000\n",
      "1570/1570 [==============================] - 0s 180us/sample - loss: 0.0724 - mae: 0.2247 - val_loss: 0.0774 - val_mae: 0.2346\n",
      "Epoch 903/1000\n",
      "1570/1570 [==============================] - 0s 206us/sample - loss: 0.0724 - mae: 0.2238 - val_loss: 0.0773 - val_mae: 0.2348\n",
      "Epoch 904/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.0725 - mae: 0.2237 - val_loss: 0.0773 - val_mae: 0.2352\n",
      "Epoch 905/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0725 - mae: 0.2249 - val_loss: 0.0773 - val_mae: 0.2347\n",
      "Epoch 906/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.0724 - mae: 0.2240 - val_loss: 0.0774 - val_mae: 0.2347\n",
      "Epoch 907/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.0724 - mae: 0.2249 - val_loss: 0.0777 - val_mae: 0.2338\n",
      "Epoch 908/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.0724 - mae: 0.2234 - val_loss: 0.0774 - val_mae: 0.2345\n",
      "Epoch 909/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.0725 - mae: 0.2250 - val_loss: 0.0775 - val_mae: 0.2342\n",
      "Epoch 910/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0725 - mae: 0.2255 - val_loss: 0.0774 - val_mae: 0.2344\n",
      "Epoch 911/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0725 - mae: 0.2255 - val_loss: 0.0774 - val_mae: 0.2345\n",
      "Epoch 912/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0724 - mae: 0.2241 - val_loss: 0.0774 - val_mae: 0.2346\n",
      "Epoch 913/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0724 - mae: 0.2243 - val_loss: 0.0773 - val_mae: 0.2347\n",
      "Epoch 914/1000\n",
      "1570/1570 [==============================] - 0s 176us/sample - loss: 0.0724 - mae: 0.2246 - val_loss: 0.0775 - val_mae: 0.2342\n",
      "Epoch 915/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.0725 - mae: 0.2233 - val_loss: 0.0773 - val_mae: 0.2347\n",
      "Epoch 916/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0724 - mae: 0.2244 - val_loss: 0.0773 - val_mae: 0.2347\n",
      "Epoch 917/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0724 - mae: 0.2244 - val_loss: 0.0774 - val_mae: 0.2344\n",
      "Epoch 918/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0724 - mae: 0.2241 - val_loss: 0.0773 - val_mae: 0.2347\n",
      "Epoch 919/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.0726 - mae: 0.2247 - val_loss: 0.0773 - val_mae: 0.2347\n",
      "Epoch 920/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.0724 - mae: 0.2245 - val_loss: 0.0775 - val_mae: 0.2341\n",
      "Epoch 921/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.0724 - mae: 0.2234 - val_loss: 0.0772 - val_mae: 0.2350\n",
      "Epoch 922/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.0723 - mae: 0.2251 - val_loss: 0.0777 - val_mae: 0.2339\n",
      "Epoch 923/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.0725 - mae: 0.2227 - val_loss: 0.0774 - val_mae: 0.2345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 924/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.0724 - mae: 0.2257 - val_loss: 0.0775 - val_mae: 0.2342\n",
      "Epoch 925/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.0724 - mae: 0.2232 - val_loss: 0.0773 - val_mae: 0.2349\n",
      "Epoch 926/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.0725 - mae: 0.2256 - val_loss: 0.0773 - val_mae: 0.2347\n",
      "Epoch 927/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0724 - mae: 0.2247 - val_loss: 0.0775 - val_mae: 0.2343\n",
      "Epoch 928/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0725 - mae: 0.2248 - val_loss: 0.0773 - val_mae: 0.2347\n",
      "Epoch 929/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0726 - mae: 0.2247 - val_loss: 0.0777 - val_mae: 0.2344\n",
      "Epoch 930/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0728 - mae: 0.2257 - val_loss: 0.0778 - val_mae: 0.2343\n",
      "Epoch 931/1000\n",
      "1570/1570 [==============================] - 0s 171us/sample - loss: 0.0727 - mae: 0.2237 - val_loss: 0.0775 - val_mae: 0.2353\n",
      "Epoch 932/1000\n",
      "1570/1570 [==============================] - 0s 163us/sample - loss: 0.0729 - mae: 0.2264 - val_loss: 0.0777 - val_mae: 0.2344\n",
      "Epoch 933/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.0726 - mae: 0.2250 - val_loss: 0.0776 - val_mae: 0.2344\n",
      "Epoch 934/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0727 - mae: 0.2239 - val_loss: 0.0774 - val_mae: 0.2352\n",
      "Epoch 935/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0726 - mae: 0.2241 - val_loss: 0.0775 - val_mae: 0.2346\n",
      "Epoch 936/1000\n",
      "1570/1570 [==============================] - 0s 150us/sample - loss: 0.0725 - mae: 0.2242 - val_loss: 0.0775 - val_mae: 0.2348\n",
      "Epoch 937/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.0726 - mae: 0.2244 - val_loss: 0.0775 - val_mae: 0.2347\n",
      "Epoch 938/1000\n",
      "1570/1570 [==============================] - 0s 160us/sample - loss: 0.0725 - mae: 0.2247 - val_loss: 0.0776 - val_mae: 0.2343\n",
      "Epoch 939/1000\n",
      "1570/1570 [==============================] - 0s 148us/sample - loss: 0.0725 - mae: 0.2240 - val_loss: 0.0775 - val_mae: 0.2346\n",
      "Epoch 940/1000\n",
      "1570/1570 [==============================] - 0s 146us/sample - loss: 0.0725 - mae: 0.2246 - val_loss: 0.0775 - val_mae: 0.2344\n",
      "Epoch 941/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0725 - mae: 0.2241 - val_loss: 0.0774 - val_mae: 0.2349\n",
      "Epoch 942/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0725 - mae: 0.2244 - val_loss: 0.0776 - val_mae: 0.2341\n",
      "Epoch 943/1000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.0725 - mae: 0.2239 - val_loss: 0.0774 - val_mae: 0.2350\n",
      "Epoch 944/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.0725 - mae: 0.2244 - val_loss: 0.0774 - val_mae: 0.2346\n",
      "Epoch 945/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0725 - mae: 0.2245 - val_loss: 0.0775 - val_mae: 0.2344\n",
      "Epoch 946/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.0725 - mae: 0.2250 - val_loss: 0.0775 - val_mae: 0.2343\n",
      "Epoch 947/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0725 - mae: 0.2236 - val_loss: 0.0773 - val_mae: 0.2349\n",
      "Epoch 948/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.0725 - mae: 0.2243 - val_loss: 0.0776 - val_mae: 0.2342\n",
      "Epoch 949/1000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.0725 - mae: 0.2248 - val_loss: 0.0777 - val_mae: 0.2339\n",
      "Epoch 950/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.0725 - mae: 0.2247 - val_loss: 0.0775 - val_mae: 0.2344\n",
      "Epoch 951/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0725 - mae: 0.2244 - val_loss: 0.0774 - val_mae: 0.2346\n",
      "Epoch 952/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0724 - mae: 0.2245 - val_loss: 0.0773 - val_mae: 0.2350\n",
      "Epoch 953/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0725 - mae: 0.2254 - val_loss: 0.0775 - val_mae: 0.2343\n",
      "Epoch 954/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.0724 - mae: 0.2247 - val_loss: 0.0776 - val_mae: 0.2341\n",
      "Epoch 955/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.0725 - mae: 0.2240 - val_loss: 0.0776 - val_mae: 0.2340\n",
      "Epoch 956/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0726 - mae: 0.2240 - val_loss: 0.0775 - val_mae: 0.2343\n",
      "Epoch 957/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.0725 - mae: 0.2247 - val_loss: 0.0773 - val_mae: 0.2348\n",
      "Epoch 958/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0724 - mae: 0.2241 - val_loss: 0.0775 - val_mae: 0.2342\n",
      "Epoch 959/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0724 - mae: 0.2242 - val_loss: 0.0775 - val_mae: 0.2343\n",
      "Epoch 960/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.0726 - mae: 0.2247 - val_loss: 0.0777 - val_mae: 0.2338\n",
      "Epoch 961/1000\n",
      "1570/1570 [==============================] - 0s 165us/sample - loss: 0.0724 - mae: 0.2241 - val_loss: 0.0772 - val_mae: 0.2351\n",
      "Epoch 962/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.0725 - mae: 0.2243 - val_loss: 0.0773 - val_mae: 0.2348\n",
      "Epoch 963/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0724 - mae: 0.2242 - val_loss: 0.0774 - val_mae: 0.2346\n",
      "Epoch 964/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0725 - mae: 0.2255 - val_loss: 0.0773 - val_mae: 0.2349\n",
      "Epoch 965/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.0726 - mae: 0.2239 - val_loss: 0.0772 - val_mae: 0.2353\n",
      "Epoch 966/1000\n",
      "1570/1570 [==============================] - 0s 169us/sample - loss: 0.0725 - mae: 0.2249 - val_loss: 0.0773 - val_mae: 0.2349\n",
      "Epoch 967/1000\n",
      "1570/1570 [==============================] - 0s 166us/sample - loss: 0.0724 - mae: 0.2242 - val_loss: 0.0773 - val_mae: 0.2349\n",
      "Epoch 968/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0725 - mae: 0.2250 - val_loss: 0.0773 - val_mae: 0.2346\n",
      "Epoch 969/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0725 - mae: 0.2246 - val_loss: 0.0775 - val_mae: 0.2341\n",
      "Epoch 970/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0724 - mae: 0.2235 - val_loss: 0.0773 - val_mae: 0.2347\n",
      "Epoch 971/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.0724 - mae: 0.2238 - val_loss: 0.0773 - val_mae: 0.2346\n",
      "Epoch 972/1000\n",
      "1570/1570 [==============================] - 0s 173us/sample - loss: 0.0725 - mae: 0.2253 - val_loss: 0.0775 - val_mae: 0.2343\n",
      "Epoch 973/1000\n",
      "1570/1570 [==============================] - 0s 159us/sample - loss: 0.0724 - mae: 0.2242 - val_loss: 0.0776 - val_mae: 0.2340\n",
      "Epoch 974/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0724 - mae: 0.2246 - val_loss: 0.0774 - val_mae: 0.2346\n",
      "Epoch 975/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0725 - mae: 0.2251 - val_loss: 0.0773 - val_mae: 0.2347\n",
      "Epoch 976/1000\n",
      "1570/1570 [==============================] - 0s 154us/sample - loss: 0.0725 - mae: 0.2249 - val_loss: 0.0773 - val_mae: 0.2346\n",
      "Epoch 977/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.0725 - mae: 0.2251 - val_loss: 0.0773 - val_mae: 0.2349\n",
      "Epoch 978/1000\n",
      "1570/1570 [==============================] - 0s 170us/sample - loss: 0.0725 - mae: 0.2252 - val_loss: 0.0776 - val_mae: 0.2341\n",
      "Epoch 979/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0725 - mae: 0.2253 - val_loss: 0.0775 - val_mae: 0.2343\n",
      "Epoch 980/1000\n",
      "1570/1570 [==============================] - 0s 153us/sample - loss: 0.0725 - mae: 0.2230 - val_loss: 0.0774 - val_mae: 0.2344\n",
      "Epoch 981/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0724 - mae: 0.2248 - val_loss: 0.0773 - val_mae: 0.2348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 982/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0724 - mae: 0.2245 - val_loss: 0.0772 - val_mae: 0.2353\n",
      "Epoch 983/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.0726 - mae: 0.2250 - val_loss: 0.0774 - val_mae: 0.2344\n",
      "Epoch 984/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.0724 - mae: 0.2251 - val_loss: 0.0773 - val_mae: 0.2347\n",
      "Epoch 985/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.0724 - mae: 0.2245 - val_loss: 0.0773 - val_mae: 0.2348\n",
      "Epoch 986/1000\n",
      "1570/1570 [==============================] - 0s 161us/sample - loss: 0.0724 - mae: 0.2239 - val_loss: 0.0772 - val_mae: 0.2350\n",
      "Epoch 987/1000\n",
      "1570/1570 [==============================] - 0s 164us/sample - loss: 0.0726 - mae: 0.2258 - val_loss: 0.0773 - val_mae: 0.2348\n",
      "Epoch 988/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.0724 - mae: 0.2250 - val_loss: 0.0776 - val_mae: 0.2340\n",
      "Epoch 989/1000\n",
      "1570/1570 [==============================] - 0s 178us/sample - loss: 0.0732 - mae: 0.2245 - val_loss: 0.0776 - val_mae: 0.2346\n",
      "Epoch 990/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.0727 - mae: 0.2243 - val_loss: 0.0776 - val_mae: 0.2344\n",
      "Epoch 991/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.0726 - mae: 0.2240 - val_loss: 0.0775 - val_mae: 0.2345\n",
      "Epoch 992/1000\n",
      "1570/1570 [==============================] - 0s 162us/sample - loss: 0.0726 - mae: 0.2241 - val_loss: 0.0773 - val_mae: 0.2356\n",
      "Epoch 993/1000\n",
      "1570/1570 [==============================] - 0s 156us/sample - loss: 0.0727 - mae: 0.2264 - val_loss: 0.0774 - val_mae: 0.2347\n",
      "Epoch 994/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.0725 - mae: 0.2247 - val_loss: 0.0775 - val_mae: 0.2345\n",
      "Epoch 995/1000\n",
      "1570/1570 [==============================] - 0s 167us/sample - loss: 0.0725 - mae: 0.2242 - val_loss: 0.0773 - val_mae: 0.2350\n",
      "Epoch 996/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0726 - mae: 0.2250 - val_loss: 0.0774 - val_mae: 0.2348\n",
      "Epoch 997/1000\n",
      "1570/1570 [==============================] - 0s 155us/sample - loss: 0.0725 - mae: 0.2248 - val_loss: 0.0774 - val_mae: 0.2348\n",
      "Epoch 998/1000\n",
      "1570/1570 [==============================] - 0s 157us/sample - loss: 0.0725 - mae: 0.2255 - val_loss: 0.0774 - val_mae: 0.2345\n",
      "Epoch 999/1000\n",
      "1570/1570 [==============================] - 0s 158us/sample - loss: 0.0725 - mae: 0.2233 - val_loss: 0.0773 - val_mae: 0.2350\n",
      "Epoch 1000/1000\n",
      "1570/1570 [==============================] - 0s 174us/sample - loss: 0.0725 - mae: 0.2246 - val_loss: 0.0775 - val_mae: 0.2343\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.22884522378444672\n",
      "Overfit checks:\n",
      "Model Accuracy: 0.2240038514137268\n"
     ]
    }
   ],
   "source": [
    "frame = load_frame()\n",
    "data_x, data_y, number_of_features = load_all_data_with_mine_static(frame)\n",
    "data_y = pd.concat([frame.mutation], axis = 1).round(2) #.mul(10)\n",
    "\n",
    "sns.distplot(data_y);\n",
    "\n",
    "\n",
    "x_train, y_train, x_test, y_test, x_validate, y_validate = split_data(data_x, data_y)\n",
    "\n",
    "print(x_train.shape)\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(number_of_features, activation='relu', input_dim=number_of_features))\n",
    "model.add(keras.layers.Dense(40, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "model.add(keras.layers.Dense(20, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])\n",
    "\n",
    "#early_stopping_monitor = keras.callbacks.EarlyStopping(patience=50,restore_best_weights=True)\n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=1000, verbose=1, validation_data=(x_validate, y_validate))\n",
    "#, callbacks=[early_stopping_monitor])\n",
    "\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['mae'])\n",
    "plt.plot(history.history['val_mae'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "silent_evaluation(model, x_test, y_test)\n",
    "\n",
    "\n",
    "print(\"Overfit checks:\")\n",
    "silent_evaluation(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame = load_frame()\n",
    "data_x, data_y, number_of_features = load_all_data_with_mine(frame)\n",
    "data_y = pd.concat([frame.mutation], axis = 1) #.round(2) #.mul(10)\n",
    "\n",
    "sns.distplot(data_y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7476723982640964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/factor_analyzer/utils.py:248: UserWarning: The inverse of the variance-covariance matrix was calculated using the Moore-Penrose generalized matrix inversion, due to its determinant being at or very close to zero.\n",
      "  warnings.warn('The inverse of the variance-covariance matrix '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FactorAnalyzer(bounds=(0.005, 1), impute='median', is_corr_matrix=False,\n",
       "               method='minres', n_factors=6, rotation='varimax',\n",
       "               rotation_kwargs={}, use_smc=True)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "from factor_analyzer.factor_analyzer import FactorAnalyzer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kmo_all,kmo_model=calculate_kmo(data_x)\n",
    "print(kmo_model)\n",
    "\n",
    "fa = FactorAnalyzer(n_factors=6, rotation='varimax')\n",
    "data_x = data_x.dropna()\n",
    "fa.fit(data_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 83.93%\n",
      "Overfit: 86.28%\n",
      "accuracy: 80.36%\n",
      "Overfit: 84.39%\n",
      "accuracy: 82.14%\n",
      "Overfit: 83.80%\n",
      "accuracy: 78.57%\n",
      "Overfit: 83.90%\n",
      "accuracy: 82.14%\n",
      "Overfit: 88.17%\n",
      "accuracy: 89.29%\n",
      "Overfit: 87.38%\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.38%\n",
      "accuracy: 89.29%\n",
      "Overfit: 87.48%\n",
      "accuracy: 85.71%\n",
      "Overfit: 87.98%\n",
      "accuracy: 94.64%\n",
      "Overfit: 87.49%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.15 is:\n",
      "85.36% (+/- 4.64%)\n",
      "And overfit of 86.32% (+/- 1.61%)\n",
      "-------------------------------------------\n",
      "accuracy: 80.36%\n",
      "Overfit: 86.78%\n",
      "accuracy: 76.79%\n",
      "Overfit: 79.03%\n",
      "accuracy: 82.14%\n",
      "Overfit: 88.57%\n",
      "accuracy: 78.57%\n",
      "Overfit: 88.47%\n",
      "accuracy: 83.93%\n",
      "Overfit: 87.57%\n",
      "accuracy: 91.07%\n",
      "Overfit: 88.97%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.98%\n",
      "accuracy: 91.07%\n",
      "Overfit: 87.77%\n",
      "accuracy: 80.36%\n",
      "Overfit: 85.80%\n",
      "accuracy: 92.86%\n",
      "Overfit: 88.58%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.1515 is:\n",
      "84.29% (+/- 5.40%)\n",
      "And overfit of 86.75% (+/- 2.78%)\n",
      "-------------------------------------------\n",
      "accuracy: 76.79%\n",
      "Overfit: 85.49%\n",
      "accuracy: 82.14%\n",
      "Overfit: 81.61%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.68%\n",
      "accuracy: 76.79%\n",
      "Overfit: 86.88%\n",
      "accuracy: 82.14%\n",
      "Overfit: 88.67%\n",
      "accuracy: 91.07%\n",
      "Overfit: 87.38%\n",
      "accuracy: 89.29%\n",
      "Overfit: 85.98%\n",
      "accuracy: 85.71%\n",
      "Overfit: 87.57%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.10%\n",
      "accuracy: 92.86%\n",
      "Overfit: 86.49%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.15301499999999998 is:\n",
      "84.11% (+/- 5.26%)\n",
      "And overfit of 86.29% (+/- 1.78%)\n",
      "-------------------------------------------\n",
      "accuracy: 80.36%\n",
      "Overfit: 85.88%\n",
      "accuracy: 87.50%\n",
      "Overfit: 85.49%\n",
      "accuracy: 85.71%\n",
      "Overfit: 86.38%\n",
      "accuracy: 75.00%\n",
      "Overfit: 86.88%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.38%\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.38%\n",
      "accuracy: 83.93%\n",
      "Overfit: 85.19%\n",
      "accuracy: 94.64%\n",
      "Overfit: 88.37%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.00%\n",
      "accuracy: 91.07%\n",
      "Overfit: 86.69%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.15454515 is:\n",
      "85.18% (+/- 5.42%)\n",
      "And overfit of 86.36% (+/- 0.83%)\n",
      "-------------------------------------------\n",
      "accuracy: 82.14%\n",
      "Overfit: 83.90%\n",
      "accuracy: 82.14%\n",
      "Overfit: 82.11%\n",
      "accuracy: 85.71%\n",
      "Overfit: 88.47%\n",
      "accuracy: 73.21%\n",
      "Overfit: 85.29%\n",
      "accuracy: 83.93%\n",
      "Overfit: 89.17%\n",
      "accuracy: 91.07%\n",
      "Overfit: 90.16%\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.27%\n",
      "accuracy: 91.07%\n",
      "Overfit: 88.47%\n",
      "accuracy: 83.93%\n",
      "Overfit: 83.52%\n",
      "accuracy: 92.86%\n",
      "Overfit: 85.20%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.15609060149999998 is:\n",
      "85.36% (+/- 5.46%)\n",
      "And overfit of 86.45% (+/- 2.64%)\n",
      "-------------------------------------------\n",
      "accuracy: 78.57%\n",
      "Overfit: 85.19%\n",
      "accuracy: 76.79%\n",
      "Overfit: 75.35%\n",
      "accuracy: 82.14%\n",
      "Overfit: 89.07%\n",
      "accuracy: 75.00%\n",
      "Overfit: 85.49%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.78%\n",
      "accuracy: 91.07%\n",
      "Overfit: 89.17%\n",
      "accuracy: 83.93%\n",
      "Overfit: 84.59%\n",
      "accuracy: 92.86%\n",
      "Overfit: 88.57%\n",
      "accuracy: 80.36%\n",
      "Overfit: 85.90%\n",
      "accuracy: 89.29%\n",
      "Overfit: 84.11%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.15765150751499998 is:\n",
      "83.21% (+/- 5.77%)\n",
      "And overfit of 85.42% (+/- 3.78%)\n",
      "-------------------------------------------\n",
      "accuracy: 78.57%\n",
      "Overfit: 86.48%\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.99%\n",
      "accuracy: 83.93%\n",
      "Overfit: 88.57%\n",
      "accuracy: 80.36%\n",
      "Overfit: 87.57%\n",
      "accuracy: 78.57%\n",
      "Overfit: 88.57%\n",
      "accuracy: 87.50%\n",
      "Overfit: 85.49%\n",
      "accuracy: 89.29%\n",
      "Overfit: 87.08%\n",
      "accuracy: 91.07%\n",
      "Overfit: 87.87%\n",
      "accuracy: 80.36%\n",
      "Overfit: 86.40%\n",
      "accuracy: 92.86%\n",
      "Overfit: 87.59%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.15922802259014998 is:\n",
      "84.46% (+/- 5.05%)\n",
      "And overfit of 87.06% (+/- 1.15%)\n",
      "-------------------------------------------\n",
      "accuracy: 85.71%\n",
      "Overfit: 89.26%\n",
      "accuracy: 78.57%\n",
      "Overfit: 81.61%\n",
      "accuracy: 82.14%\n",
      "Overfit: 87.67%\n",
      "accuracy: 76.79%\n",
      "Overfit: 84.79%\n",
      "accuracy: 80.36%\n",
      "Overfit: 87.48%\n",
      "accuracy: 91.07%\n",
      "Overfit: 88.37%\n",
      "accuracy: 83.93%\n",
      "Overfit: 88.47%\n",
      "accuracy: 85.71%\n",
      "Overfit: 87.38%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.69%\n",
      "accuracy: 91.07%\n",
      "Overfit: 85.80%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.16082030281605147 is:\n",
      "83.75% (+/- 4.55%)\n",
      "And overfit of 86.75% (+/- 2.12%)\n",
      "-------------------------------------------\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.68%\n",
      "accuracy: 82.14%\n",
      "Overfit: 77.53%\n",
      "accuracy: 85.71%\n",
      "Overfit: 89.26%\n",
      "accuracy: 78.57%\n",
      "Overfit: 88.37%\n",
      "accuracy: 85.71%\n",
      "Overfit: 86.68%\n",
      "accuracy: 89.29%\n",
      "Overfit: 88.47%\n",
      "accuracy: 91.07%\n",
      "Overfit: 88.47%\n",
      "accuracy: 87.50%\n",
      "Overfit: 85.09%\n",
      "accuracy: 76.79%\n",
      "Overfit: 85.60%\n",
      "accuracy: 91.07%\n",
      "Overfit: 86.20%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.16242850584421198 is:\n",
      "85.00% (+/- 4.74%)\n",
      "And overfit of 86.24% (+/- 3.19%)\n",
      "-------------------------------------------\n",
      "accuracy: 76.79%\n",
      "Overfit: 86.38%\n",
      "accuracy: 82.14%\n",
      "Overfit: 82.60%\n",
      "accuracy: 83.93%\n",
      "Overfit: 87.57%\n",
      "accuracy: 71.43%\n",
      "Overfit: 85.88%\n",
      "accuracy: 83.93%\n",
      "Overfit: 85.09%\n",
      "accuracy: 89.29%\n",
      "Overfit: 87.97%\n",
      "accuracy: 85.71%\n",
      "Overfit: 88.57%\n",
      "accuracy: 87.50%\n",
      "Overfit: 87.97%\n",
      "accuracy: 80.36%\n",
      "Overfit: 83.32%\n",
      "accuracy: 91.07%\n",
      "Overfit: 84.11%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.1640527909026541 is:\n",
      "83.21% (+/- 5.60%)\n",
      "And overfit of 85.95% (+/- 2.00%)\n",
      "-------------------------------------------\n",
      "accuracy: 80.36%\n",
      "Overfit: 86.98%\n",
      "accuracy: 80.36%\n",
      "Overfit: 80.82%\n",
      "accuracy: 78.57%\n",
      "Overfit: 85.39%\n",
      "accuracy: 82.14%\n",
      "Overfit: 88.37%\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.67%\n",
      "accuracy: 87.50%\n",
      "Overfit: 85.09%\n",
      "accuracy: 89.29%\n",
      "Overfit: 85.59%\n",
      "accuracy: 85.71%\n",
      "Overfit: 88.07%\n",
      "accuracy: 83.93%\n",
      "Overfit: 88.48%\n",
      "accuracy: 92.86%\n",
      "Overfit: 86.10%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.16569331881168065 is:\n",
      "84.82% (+/- 4.32%)\n",
      "And overfit of 86.35% (+/- 2.26%)\n",
      "-------------------------------------------\n",
      "accuracy: 78.57%\n",
      "Overfit: 87.08%\n",
      "accuracy: 75.00%\n",
      "Overfit: 86.18%\n",
      "accuracy: 89.29%\n",
      "Overfit: 88.17%\n",
      "accuracy: 73.21%\n",
      "Overfit: 84.10%\n",
      "accuracy: 85.71%\n",
      "Overfit: 87.48%\n",
      "accuracy: 89.29%\n",
      "Overfit: 81.81%\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.08%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.98%\n",
      "accuracy: 78.57%\n",
      "Overfit: 82.52%\n",
      "accuracy: 89.29%\n",
      "Overfit: 83.81%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.16735025199979744 is:\n",
      "82.86% (+/- 5.88%)\n",
      "And overfit of 85.42% (+/- 2.09%)\n",
      "-------------------------------------------\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.58%\n",
      "accuracy: 76.79%\n",
      "Overfit: 83.70%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.18%\n",
      "accuracy: 73.21%\n",
      "Overfit: 89.46%\n",
      "accuracy: 83.93%\n",
      "Overfit: 87.28%\n",
      "accuracy: 85.71%\n",
      "Overfit: 82.31%\n",
      "accuracy: 87.50%\n",
      "Overfit: 87.28%\n",
      "accuracy: 85.71%\n",
      "Overfit: 86.58%\n",
      "accuracy: 80.36%\n",
      "Overfit: 87.69%\n",
      "accuracy: 91.07%\n",
      "Overfit: 86.10%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.16902375451979543 is:\n",
      "82.86% (+/- 4.94%)\n",
      "And overfit of 86.31% (+/- 1.92%)\n",
      "-------------------------------------------\n",
      "accuracy: 80.36%\n",
      "Overfit: 86.38%\n",
      "accuracy: 85.71%\n",
      "Overfit: 83.70%\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.98%\n",
      "accuracy: 73.21%\n",
      "Overfit: 85.29%\n",
      "accuracy: 80.36%\n",
      "Overfit: 84.00%\n",
      "accuracy: 83.93%\n",
      "Overfit: 84.19%\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.88%\n",
      "accuracy: 92.86%\n",
      "Overfit: 88.97%\n",
      "accuracy: 83.93%\n",
      "Overfit: 87.09%\n",
      "accuracy: 87.50%\n",
      "Overfit: 80.83%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.17071399206499338 is:\n",
      "84.29% (+/- 5.10%)\n",
      "And overfit of 85.43% (+/- 2.20%)\n",
      "-------------------------------------------\n",
      "accuracy: 78.57%\n",
      "Overfit: 84.89%\n",
      "accuracy: 73.21%\n",
      "Overfit: 82.21%\n",
      "accuracy: 78.57%\n",
      "Overfit: 88.17%\n",
      "accuracy: 75.00%\n",
      "Overfit: 85.09%\n",
      "accuracy: 82.14%\n",
      "Overfit: 83.80%\n",
      "accuracy: 89.29%\n",
      "Overfit: 88.27%\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.97%\n",
      "accuracy: 91.07%\n",
      "Overfit: 87.67%\n",
      "accuracy: 73.21%\n",
      "Overfit: 83.71%\n",
      "accuracy: 89.29%\n",
      "Overfit: 85.60%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.17242113198564332 is:\n",
      "81.79% (+/- 6.67%)\n",
      "And overfit of 85.84% (+/- 2.19%)\n",
      "-------------------------------------------\n",
      "accuracy: 80.36%\n",
      "Overfit: 85.09%\n",
      "accuracy: 71.43%\n",
      "Overfit: 82.80%\n",
      "accuracy: 78.57%\n",
      "Overfit: 84.89%\n",
      "accuracy: 75.00%\n",
      "Overfit: 83.50%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.69%\n",
      "accuracy: 92.86%\n",
      "Overfit: 87.97%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.49%\n",
      "accuracy: 91.07%\n",
      "Overfit: 86.68%\n",
      "accuracy: 83.93%\n",
      "Overfit: 85.80%\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.79%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.17414534330549974 is:\n",
      "83.21% (+/- 6.50%)\n",
      "And overfit of 85.47% (+/- 1.45%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 80.36%\n",
      "Overfit: 86.28%\n",
      "accuracy: 83.93%\n",
      "Overfit: 81.41%\n",
      "accuracy: 83.93%\n",
      "Overfit: 88.57%\n",
      "accuracy: 73.21%\n",
      "Overfit: 85.49%\n",
      "accuracy: 82.14%\n",
      "Overfit: 87.57%\n",
      "accuracy: 92.86%\n",
      "Overfit: 87.38%\n",
      "accuracy: 89.29%\n",
      "Overfit: 82.01%\n",
      "accuracy: 78.57%\n",
      "Overfit: 82.50%\n",
      "accuracy: 83.93%\n",
      "Overfit: 85.80%\n",
      "accuracy: 91.07%\n",
      "Overfit: 84.21%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.17588679673855476 is:\n",
      "83.93% (+/- 5.65%)\n",
      "And overfit of 85.12% (+/- 2.37%)\n",
      "-------------------------------------------\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.78%\n",
      "accuracy: 73.21%\n",
      "Overfit: 80.72%\n",
      "accuracy: 82.14%\n",
      "Overfit: 87.67%\n",
      "accuracy: 73.21%\n",
      "Overfit: 86.48%\n",
      "accuracy: 83.93%\n",
      "Overfit: 89.26%\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.69%\n",
      "accuracy: 80.36%\n",
      "Overfit: 83.60%\n",
      "accuracy: 92.86%\n",
      "Overfit: 87.48%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.69%\n",
      "accuracy: 91.07%\n",
      "Overfit: 84.61%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.17764566470594031 is:\n",
      "83.04% (+/- 6.35%)\n",
      "And overfit of 85.80% (+/- 2.32%)\n",
      "-------------------------------------------\n",
      "accuracy: 87.50%\n",
      "Overfit: 87.38%\n",
      "accuracy: 80.36%\n",
      "Overfit: 87.77%\n",
      "accuracy: 82.14%\n",
      "Overfit: 82.41%\n",
      "accuracy: 80.36%\n",
      "Overfit: 89.46%\n",
      "accuracy: 83.93%\n",
      "Overfit: 88.97%\n",
      "accuracy: 92.86%\n",
      "Overfit: 88.27%\n",
      "accuracy: 83.93%\n",
      "Overfit: 88.47%\n",
      "accuracy: 91.07%\n",
      "Overfit: 88.07%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.00%\n",
      "accuracy: 96.43%\n",
      "Overfit: 86.40%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.17942212135299973 is:\n",
      "86.07% (+/- 5.35%)\n",
      "And overfit of 87.32% (+/- 1.92%)\n",
      "-------------------------------------------\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.18%\n",
      "accuracy: 71.43%\n",
      "Overfit: 77.83%\n",
      "accuracy: 85.71%\n",
      "Overfit: 88.27%\n",
      "accuracy: 75.00%\n",
      "Overfit: 87.38%\n",
      "accuracy: 80.36%\n",
      "Overfit: 86.68%\n",
      "accuracy: 82.14%\n",
      "Overfit: 87.57%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.49%\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.38%\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.10%\n",
      "accuracy: 94.64%\n",
      "Overfit: 85.40%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.18121634256652974 is:\n",
      "82.86% (+/- 6.14%)\n",
      "And overfit of 85.73% (+/- 2.77%)\n",
      "-------------------------------------------\n",
      "accuracy: 75.00%\n",
      "Overfit: 81.01%\n",
      "accuracy: 78.57%\n",
      "Overfit: 84.29%\n",
      "accuracy: 85.71%\n",
      "Overfit: 88.37%\n",
      "accuracy: 67.86%\n",
      "Overfit: 85.39%\n",
      "accuracy: 80.36%\n",
      "Overfit: 85.69%\n",
      "accuracy: 91.07%\n",
      "Overfit: 88.27%\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.98%\n",
      "accuracy: 91.07%\n",
      "Overfit: 87.38%\n",
      "accuracy: 78.57%\n",
      "Overfit: 82.42%\n",
      "accuracy: 91.07%\n",
      "Overfit: 82.62%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.18302850599219503 is:\n",
      "82.32% (+/- 7.34%)\n",
      "And overfit of 85.24% (+/- 2.46%)\n",
      "-------------------------------------------\n",
      "accuracy: 82.14%\n",
      "Overfit: 82.60%\n",
      "accuracy: 82.14%\n",
      "Overfit: 78.43%\n",
      "accuracy: 80.36%\n",
      "Overfit: 83.30%\n",
      "accuracy: 78.57%\n",
      "Overfit: 85.88%\n",
      "accuracy: 83.93%\n",
      "Overfit: 89.66%\n",
      "accuracy: 83.93%\n",
      "Overfit: 78.53%\n",
      "accuracy: 87.50%\n",
      "Overfit: 87.38%\n",
      "accuracy: 83.93%\n",
      "Overfit: 82.80%\n",
      "accuracy: 83.93%\n",
      "Overfit: 88.08%\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.00%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.18485879105211697 is:\n",
      "83.57% (+/- 2.97%)\n",
      "And overfit of 84.27% (+/- 3.63%)\n",
      "-------------------------------------------\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.08%\n",
      "accuracy: 85.71%\n",
      "Overfit: 89.66%\n",
      "accuracy: 78.57%\n",
      "Overfit: 87.87%\n",
      "accuracy: 71.43%\n",
      "Overfit: 85.19%\n",
      "accuracy: 80.36%\n",
      "Overfit: 85.69%\n",
      "accuracy: 85.71%\n",
      "Overfit: 83.80%\n",
      "accuracy: 87.50%\n",
      "Overfit: 87.18%\n",
      "accuracy: 83.93%\n",
      "Overfit: 85.88%\n",
      "accuracy: 80.36%\n",
      "Overfit: 85.70%\n",
      "accuracy: 92.86%\n",
      "Overfit: 86.30%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.18670737896263814 is:\n",
      "83.39% (+/- 5.65%)\n",
      "And overfit of 86.33% (+/- 1.52%)\n",
      "-------------------------------------------\n",
      "accuracy: 76.79%\n",
      "Overfit: 83.60%\n",
      "accuracy: 82.14%\n",
      "Overfit: 81.71%\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.97%\n",
      "accuracy: 73.21%\n",
      "Overfit: 83.40%\n",
      "accuracy: 78.57%\n",
      "Overfit: 88.97%\n",
      "accuracy: 89.29%\n",
      "Overfit: 88.67%\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.58%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.68%\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.51%\n",
      "accuracy: 89.29%\n",
      "Overfit: 85.10%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.18857445275226453 is:\n",
      "83.04% (+/- 5.43%)\n",
      "And overfit of 85.82% (+/- 2.43%)\n",
      "-------------------------------------------\n",
      "accuracy: 78.57%\n",
      "Overfit: 86.18%\n",
      "accuracy: 76.79%\n",
      "Overfit: 72.86%\n",
      "accuracy: 83.93%\n",
      "Overfit: 87.77%\n",
      "accuracy: 76.79%\n",
      "Overfit: 88.07%\n",
      "accuracy: 80.36%\n",
      "Overfit: 88.67%\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.48%\n",
      "accuracy: 83.93%\n",
      "Overfit: 84.89%\n",
      "accuracy: 89.29%\n",
      "Overfit: 87.08%\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.59%\n",
      "accuracy: 92.86%\n",
      "Overfit: 85.70%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.1904601972797872 is:\n",
      "83.04% (+/- 4.94%)\n",
      "And overfit of 85.43% (+/- 4.32%)\n",
      "-------------------------------------------\n",
      "accuracy: 80.36%\n",
      "Overfit: 82.31%\n",
      "accuracy: 80.36%\n",
      "Overfit: 84.10%\n",
      "accuracy: 80.36%\n",
      "Overfit: 88.67%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.68%\n",
      "accuracy: 85.71%\n",
      "Overfit: 86.38%\n",
      "accuracy: 89.29%\n",
      "Overfit: 88.47%\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.18%\n",
      "accuracy: 87.50%\n",
      "Overfit: 85.49%\n",
      "accuracy: 87.50%\n",
      "Overfit: 87.79%\n",
      "accuracy: 91.07%\n",
      "Overfit: 85.10%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.19236479925258507 is:\n",
      "85.18% (+/- 3.83%)\n",
      "And overfit of 86.12% (+/- 1.88%)\n",
      "-------------------------------------------\n",
      "accuracy: 78.57%\n",
      "Overfit: 83.60%\n",
      "accuracy: 76.79%\n",
      "Overfit: 78.63%\n",
      "accuracy: 78.57%\n",
      "Overfit: 86.18%\n",
      "accuracy: 71.43%\n",
      "Overfit: 77.73%\n",
      "accuracy: 80.36%\n",
      "Overfit: 88.97%\n",
      "accuracy: 85.71%\n",
      "Overfit: 88.07%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.19%\n",
      "accuracy: 89.29%\n",
      "Overfit: 87.18%\n",
      "accuracy: 82.14%\n",
      "Overfit: 85.60%\n",
      "accuracy: 92.86%\n",
      "Overfit: 85.10%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.1942884472451109 is:\n",
      "82.14% (+/- 6.03%)\n",
      "And overfit of 84.63% (+/- 3.55%)\n",
      "-------------------------------------------\n",
      "accuracy: 83.93%\n",
      "Overfit: 87.38%\n",
      "accuracy: 76.79%\n",
      "Overfit: 87.77%\n",
      "accuracy: 80.36%\n",
      "Overfit: 84.79%\n",
      "accuracy: 78.57%\n",
      "Overfit: 87.28%\n",
      "accuracy: 85.71%\n",
      "Overfit: 87.97%\n",
      "accuracy: 91.07%\n",
      "Overfit: 84.59%\n",
      "accuracy: 94.64%\n",
      "Overfit: 85.59%\n",
      "accuracy: 92.86%\n",
      "Overfit: 87.97%\n",
      "accuracy: 80.36%\n",
      "Overfit: 84.81%\n",
      "accuracy: 92.86%\n",
      "Overfit: 85.10%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.19623133171756202 is:\n",
      "85.71% (+/- 6.34%)\n",
      "And overfit of 86.33% (+/- 1.39%)\n",
      "-------------------------------------------\n",
      "accuracy: 78.57%\n",
      "Overfit: 83.40%\n",
      "accuracy: 73.21%\n",
      "Overfit: 80.62%\n",
      "accuracy: 87.50%\n",
      "Overfit: 87.97%\n",
      "accuracy: 78.57%\n",
      "Overfit: 89.36%\n",
      "accuracy: 80.36%\n",
      "Overfit: 88.37%\n",
      "accuracy: 91.07%\n",
      "Overfit: 85.79%\n",
      "accuracy: 83.93%\n",
      "Overfit: 85.79%\n",
      "accuracy: 92.86%\n",
      "Overfit: 89.76%\n",
      "accuracy: 75.00%\n",
      "Overfit: 83.71%\n",
      "accuracy: 92.86%\n",
      "Overfit: 84.41%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.19819364503473763 is:\n",
      "83.39% (+/- 6.96%)\n",
      "And overfit of 85.92% (+/- 2.80%)\n",
      "-------------------------------------------\n",
      "accuracy: 80.36%\n",
      "Overfit: 86.58%\n",
      "accuracy: 75.00%\n",
      "Overfit: 80.82%\n",
      "accuracy: 85.71%\n",
      "Overfit: 89.66%\n",
      "accuracy: 76.79%\n",
      "Overfit: 85.29%\n",
      "accuracy: 85.71%\n",
      "Overfit: 87.77%\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.28%\n",
      "accuracy: 76.79%\n",
      "Overfit: 83.20%\n",
      "accuracy: 89.29%\n",
      "Overfit: 84.29%\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.79%\n",
      "accuracy: 91.07%\n",
      "Overfit: 85.70%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.20017558148508502 is:\n",
      "83.21% (+/- 5.37%)\n",
      "And overfit of 85.64% (+/- 2.33%)\n",
      "-------------------------------------------\n",
      "accuracy: 80.36%\n",
      "Overfit: 86.58%\n",
      "accuracy: 82.14%\n",
      "Overfit: 82.90%\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.68%\n",
      "accuracy: 71.43%\n",
      "Overfit: 86.68%\n",
      "accuracy: 85.71%\n",
      "Overfit: 86.58%\n",
      "accuracy: 91.07%\n",
      "Overfit: 87.38%\n",
      "accuracy: 87.50%\n",
      "Overfit: 87.38%\n",
      "accuracy: 89.29%\n",
      "Overfit: 88.07%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.30%\n",
      "accuracy: 91.07%\n",
      "Overfit: 82.72%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.20217733729993587 is:\n",
      "84.46% (+/- 5.65%)\n",
      "And overfit of 86.13% (+/- 1.73%)\n",
      "-------------------------------------------\n",
      "accuracy: 80.36%\n",
      "Overfit: 86.28%\n",
      "accuracy: 85.71%\n",
      "Overfit: 78.43%\n",
      "accuracy: 80.36%\n",
      "Overfit: 87.08%\n",
      "accuracy: 73.21%\n",
      "Overfit: 84.79%\n",
      "accuracy: 83.93%\n",
      "Overfit: 88.17%\n",
      "accuracy: 91.07%\n",
      "Overfit: 85.79%\n",
      "accuracy: 89.29%\n",
      "Overfit: 83.20%\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.58%\n",
      "accuracy: 80.36%\n",
      "Overfit: 85.80%\n",
      "accuracy: 89.29%\n",
      "Overfit: 82.72%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.20419911067293522 is:\n",
      "84.11% (+/- 5.26%)\n",
      "And overfit of 84.88% (+/- 2.67%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 78.57%\n",
      "Overfit: 86.58%\n",
      "accuracy: 80.36%\n",
      "Overfit: 80.62%\n",
      "accuracy: 83.93%\n",
      "Overfit: 87.97%\n",
      "accuracy: 71.43%\n",
      "Overfit: 84.39%\n",
      "accuracy: 82.14%\n",
      "Overfit: 89.26%\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.98%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.88%\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.88%\n",
      "accuracy: 83.93%\n",
      "Overfit: 85.10%\n",
      "accuracy: 91.07%\n",
      "Overfit: 84.71%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.20624110177966457 is:\n",
      "83.04% (+/- 5.25%)\n",
      "And overfit of 85.84% (+/- 2.25%)\n",
      "-------------------------------------------\n",
      "accuracy: 80.36%\n",
      "Overfit: 83.30%\n",
      "accuracy: 76.79%\n",
      "Overfit: 80.22%\n",
      "accuracy: 85.71%\n",
      "Overfit: 88.37%\n",
      "accuracy: 76.79%\n",
      "Overfit: 90.26%\n",
      "accuracy: 85.71%\n",
      "Overfit: 88.17%\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.98%\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.28%\n",
      "accuracy: 80.36%\n",
      "Overfit: 85.09%\n",
      "accuracy: 82.14%\n",
      "Overfit: 85.70%\n",
      "accuracy: 91.07%\n",
      "Overfit: 84.81%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.2083035127974612 is:\n",
      "83.21% (+/- 4.60%)\n",
      "And overfit of 85.92% (+/- 2.69%)\n",
      "-------------------------------------------\n",
      "accuracy: 76.79%\n",
      "Overfit: 80.42%\n",
      "accuracy: 83.93%\n",
      "Overfit: 82.60%\n",
      "accuracy: 78.57%\n",
      "Overfit: 88.97%\n",
      "accuracy: 76.79%\n",
      "Overfit: 83.60%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.38%\n",
      "accuracy: 91.07%\n",
      "Overfit: 87.48%\n",
      "accuracy: 91.07%\n",
      "Overfit: 86.38%\n",
      "accuracy: 89.29%\n",
      "Overfit: 87.77%\n",
      "accuracy: 76.79%\n",
      "Overfit: 79.64%\n",
      "accuracy: 94.64%\n",
      "Overfit: 85.10%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.21038654792543582 is:\n",
      "84.11% (+/- 6.56%)\n",
      "And overfit of 84.83% (+/- 3.01%)\n",
      "-------------------------------------------\n",
      "accuracy: 78.57%\n",
      "Overfit: 84.79%\n",
      "accuracy: 78.57%\n",
      "Overfit: 84.29%\n",
      "accuracy: 82.14%\n",
      "Overfit: 89.07%\n",
      "accuracy: 73.21%\n",
      "Overfit: 79.92%\n",
      "accuracy: 78.57%\n",
      "Overfit: 85.69%\n",
      "accuracy: 92.86%\n",
      "Overfit: 86.38%\n",
      "accuracy: 85.71%\n",
      "Overfit: 87.28%\n",
      "accuracy: 91.07%\n",
      "Overfit: 85.79%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.20%\n",
      "accuracy: 92.86%\n",
      "Overfit: 86.99%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.2124904134046902 is:\n",
      "83.93% (+/- 6.49%)\n",
      "And overfit of 85.54% (+/- 2.28%)\n",
      "-------------------------------------------\n",
      "accuracy: 83.93%\n",
      "Overfit: 84.89%\n",
      "accuracy: 83.93%\n",
      "Overfit: 82.80%\n",
      "accuracy: 85.71%\n",
      "Overfit: 89.66%\n",
      "accuracy: 69.64%\n",
      "Overfit: 84.29%\n",
      "accuracy: 80.36%\n",
      "Overfit: 89.46%\n",
      "accuracy: 87.50%\n",
      "Overfit: 83.90%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.98%\n",
      "accuracy: 87.50%\n",
      "Overfit: 85.29%\n",
      "accuracy: 80.36%\n",
      "Overfit: 83.71%\n",
      "accuracy: 91.07%\n",
      "Overfit: 85.10%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.21461531753873708 is:\n",
      "83.57% (+/- 5.58%)\n",
      "And overfit of 85.51% (+/- 2.20%)\n",
      "-------------------------------------------\n",
      "accuracy: 80.36%\n",
      "Overfit: 84.79%\n",
      "accuracy: 73.21%\n",
      "Overfit: 77.44%\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.98%\n",
      "accuracy: 69.64%\n",
      "Overfit: 83.90%\n",
      "accuracy: 82.14%\n",
      "Overfit: 85.88%\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.18%\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.28%\n",
      "accuracy: 91.07%\n",
      "Overfit: 86.58%\n",
      "accuracy: 83.93%\n",
      "Overfit: 87.19%\n",
      "accuracy: 91.07%\n",
      "Overfit: 82.72%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.21676147071412447 is:\n",
      "82.68% (+/- 6.59%)\n",
      "And overfit of 84.79% (+/- 2.80%)\n",
      "-------------------------------------------\n",
      "accuracy: 78.57%\n",
      "Overfit: 86.58%\n",
      "accuracy: 75.00%\n",
      "Overfit: 82.01%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.58%\n",
      "accuracy: 73.21%\n",
      "Overfit: 84.10%\n",
      "accuracy: 83.93%\n",
      "Overfit: 88.87%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.88%\n",
      "accuracy: 85.71%\n",
      "Overfit: 84.49%\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.28%\n",
      "accuracy: 83.93%\n",
      "Overfit: 84.91%\n",
      "accuracy: 91.07%\n",
      "Overfit: 83.61%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.2189290854212657 is:\n",
      "82.50% (+/- 5.40%)\n",
      "And overfit of 85.43% (+/- 1.88%)\n",
      "-------------------------------------------\n",
      "accuracy: 83.93%\n",
      "Overfit: 85.19%\n",
      "accuracy: 76.79%\n",
      "Overfit: 85.69%\n",
      "accuracy: 83.93%\n",
      "Overfit: 90.16%\n",
      "accuracy: 76.79%\n",
      "Overfit: 86.68%\n",
      "accuracy: 80.36%\n",
      "Overfit: 85.09%\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.58%\n",
      "accuracy: 73.21%\n",
      "Overfit: 79.22%\n",
      "accuracy: 89.29%\n",
      "Overfit: 84.00%\n",
      "accuracy: 87.50%\n",
      "Overfit: 87.39%\n",
      "accuracy: 87.50%\n",
      "Overfit: 83.61%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.22111837627547837 is:\n",
      "82.68% (+/- 5.30%)\n",
      "And overfit of 85.36% (+/- 2.70%)\n",
      "-------------------------------------------\n",
      "accuracy: 75.00%\n",
      "Overfit: 84.49%\n",
      "accuracy: 75.00%\n",
      "Overfit: 77.63%\n",
      "accuracy: 83.93%\n",
      "Overfit: 88.07%\n",
      "accuracy: 75.00%\n",
      "Overfit: 85.88%\n",
      "accuracy: 83.93%\n",
      "Overfit: 84.29%\n",
      "accuracy: 83.93%\n",
      "Overfit: 84.99%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.19%\n",
      "accuracy: 82.14%\n",
      "Overfit: 85.59%\n",
      "accuracy: 78.57%\n",
      "Overfit: 86.79%\n",
      "accuracy: 92.86%\n",
      "Overfit: 84.71%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.22332956003823315 is:\n",
      "81.61% (+/- 5.48%)\n",
      "And overfit of 84.76% (+/- 2.61%)\n",
      "-------------------------------------------\n",
      "accuracy: 76.79%\n",
      "Overfit: 84.10%\n",
      "accuracy: 82.14%\n",
      "Overfit: 83.00%\n",
      "accuracy: 78.57%\n",
      "Overfit: 88.47%\n",
      "accuracy: 82.14%\n",
      "Overfit: 88.27%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.38%\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.38%\n",
      "accuracy: 85.71%\n",
      "Overfit: 86.58%\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.98%\n",
      "accuracy: 82.14%\n",
      "Overfit: 83.61%\n",
      "accuracy: 89.29%\n",
      "Overfit: 83.61%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.22556285563861547 is:\n",
      "83.75% (+/- 4.26%)\n",
      "And overfit of 85.74% (+/- 1.90%)\n",
      "-------------------------------------------\n",
      "accuracy: 76.79%\n",
      "Overfit: 84.69%\n",
      "accuracy: 80.36%\n",
      "Overfit: 80.62%\n",
      "accuracy: 83.93%\n",
      "Overfit: 88.17%\n",
      "accuracy: 67.86%\n",
      "Overfit: 76.64%\n",
      "accuracy: 85.71%\n",
      "Overfit: 84.79%\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.98%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.88%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.18%\n",
      "accuracy: 80.36%\n",
      "Overfit: 85.30%\n",
      "accuracy: 92.86%\n",
      "Overfit: 82.32%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.22781848419500164 is:\n",
      "82.32% (+/- 6.41%)\n",
      "And overfit of 84.16% (+/- 3.25%)\n",
      "-------------------------------------------\n",
      "accuracy: 82.14%\n",
      "Overfit: 85.39%\n",
      "accuracy: 85.71%\n",
      "Overfit: 88.97%\n",
      "accuracy: 85.71%\n",
      "Overfit: 87.77%\n",
      "accuracy: 76.79%\n",
      "Overfit: 85.88%\n",
      "accuracy: 78.57%\n",
      "Overfit: 86.78%\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.68%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.48%\n",
      "accuracy: 89.29%\n",
      "Overfit: 85.88%\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.69%\n",
      "accuracy: 89.29%\n",
      "Overfit: 85.30%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.23009666903695167 is:\n",
      "84.29% (+/- 4.21%)\n",
      "And overfit of 86.58% (+/- 1.06%)\n",
      "-------------------------------------------\n",
      "accuracy: 82.14%\n",
      "Overfit: 85.19%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.38%\n",
      "accuracy: 80.36%\n",
      "Overfit: 85.98%\n",
      "accuracy: 66.07%\n",
      "Overfit: 84.19%\n",
      "accuracy: 80.36%\n",
      "Overfit: 87.08%\n",
      "accuracy: 85.71%\n",
      "Overfit: 84.19%\n",
      "accuracy: 87.50%\n",
      "Overfit: 84.39%\n",
      "accuracy: 91.07%\n",
      "Overfit: 86.58%\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.71%\n",
      "accuracy: 89.29%\n",
      "Overfit: 84.21%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.2323976357273212 is:\n",
      "82.68% (+/- 6.59%)\n",
      "And overfit of 85.29% (+/- 1.06%)\n",
      "-------------------------------------------\n",
      "accuracy: 76.79%\n",
      "Overfit: 84.59%\n",
      "accuracy: 75.00%\n",
      "Overfit: 79.92%\n",
      "accuracy: 78.57%\n",
      "Overfit: 85.19%\n",
      "accuracy: 69.64%\n",
      "Overfit: 85.88%\n",
      "accuracy: 78.57%\n",
      "Overfit: 87.28%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.49%\n",
      "accuracy: 80.36%\n",
      "Overfit: 80.02%\n",
      "accuracy: 85.71%\n",
      "Overfit: 86.48%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.40%\n",
      "accuracy: 91.07%\n",
      "Overfit: 84.61%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.2347216120845944 is:\n",
      "80.71% (+/- 6.02%)\n",
      "And overfit of 84.49% (+/- 2.38%)\n",
      "-------------------------------------------\n",
      "accuracy: 75.00%\n",
      "Overfit: 79.72%\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.89%\n",
      "accuracy: 78.57%\n",
      "Overfit: 88.47%\n",
      "accuracy: 75.00%\n",
      "Overfit: 87.38%\n",
      "accuracy: 83.93%\n",
      "Overfit: 87.57%\n",
      "accuracy: 87.50%\n",
      "Overfit: 83.80%\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.49%\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.48%\n",
      "accuracy: 83.93%\n",
      "Overfit: 85.00%\n",
      "accuracy: 92.86%\n",
      "Overfit: 85.40%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.23706882820544037 is:\n",
      "82.86% (+/- 5.37%)\n",
      "And overfit of 85.32% (+/- 2.35%)\n",
      "-------------------------------------------\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.58%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.69%\n",
      "accuracy: 82.14%\n",
      "Overfit: 83.90%\n",
      "accuracy: 71.43%\n",
      "Overfit: 86.08%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.68%\n",
      "accuracy: 87.50%\n",
      "Overfit: 83.60%\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.58%\n",
      "accuracy: 89.29%\n",
      "Overfit: 84.99%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.89%\n",
      "accuracy: 89.29%\n",
      "Overfit: 83.71%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.23943951648749479 is:\n",
      "83.93% (+/- 5.05%)\n",
      "And overfit of 85.47% (+/- 1.25%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 82.14%\n",
      "Overfit: 88.07%\n",
      "accuracy: 71.43%\n",
      "Overfit: 73.66%\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.88%\n",
      "accuracy: 67.86%\n",
      "Overfit: 81.21%\n",
      "accuracy: 87.50%\n",
      "Overfit: 84.69%\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.98%\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.27%\n",
      "accuracy: 92.86%\n",
      "Overfit: 88.57%\n",
      "accuracy: 85.71%\n",
      "Overfit: 86.49%\n",
      "accuracy: 92.86%\n",
      "Overfit: 85.00%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.24183391165236973 is:\n",
      "84.11% (+/- 7.96%)\n",
      "And overfit of 84.98% (+/- 4.31%)\n",
      "-------------------------------------------\n",
      "accuracy: 82.14%\n",
      "Overfit: 85.98%\n",
      "accuracy: 82.14%\n",
      "Overfit: 85.69%\n",
      "accuracy: 83.93%\n",
      "Overfit: 88.77%\n",
      "accuracy: 69.64%\n",
      "Overfit: 86.18%\n",
      "accuracy: 80.36%\n",
      "Overfit: 83.00%\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.57%\n",
      "accuracy: 85.71%\n",
      "Overfit: 82.70%\n",
      "accuracy: 85.71%\n",
      "Overfit: 87.48%\n",
      "accuracy: 78.57%\n",
      "Overfit: 86.79%\n",
      "accuracy: 91.07%\n",
      "Overfit: 84.31%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.24425225076889343 is:\n",
      "82.68% (+/- 5.54%)\n",
      "And overfit of 85.95% (+/- 2.00%)\n",
      "-------------------------------------------\n",
      "accuracy: 85.71%\n",
      "Overfit: 86.08%\n",
      "accuracy: 80.36%\n",
      "Overfit: 78.23%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.88%\n",
      "accuracy: 75.00%\n",
      "Overfit: 87.08%\n",
      "accuracy: 85.71%\n",
      "Overfit: 86.18%\n",
      "accuracy: 89.29%\n",
      "Overfit: 87.18%\n",
      "accuracy: 85.71%\n",
      "Overfit: 79.62%\n",
      "accuracy: 83.93%\n",
      "Overfit: 87.08%\n",
      "accuracy: 80.36%\n",
      "Overfit: 84.71%\n",
      "accuracy: 91.07%\n",
      "Overfit: 83.42%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.24669477327658237 is:\n",
      "84.29% (+/- 4.43%)\n",
      "And overfit of 84.55% (+/- 3.03%)\n",
      "-------------------------------------------\n",
      "accuracy: 80.36%\n",
      "Overfit: 86.48%\n",
      "accuracy: 75.00%\n",
      "Overfit: 75.65%\n",
      "accuracy: 82.14%\n",
      "Overfit: 87.28%\n",
      "accuracy: 67.86%\n",
      "Overfit: 81.91%\n",
      "accuracy: 85.71%\n",
      "Overfit: 87.18%\n",
      "accuracy: 89.29%\n",
      "Overfit: 87.77%\n",
      "accuracy: 85.71%\n",
      "Overfit: 88.17%\n",
      "accuracy: 91.07%\n",
      "Overfit: 85.49%\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.21%\n",
      "accuracy: 91.07%\n",
      "Overfit: 84.51%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.2491617210093482 is:\n",
      "83.04% (+/- 6.97%)\n",
      "And overfit of 84.86% (+/- 3.58%)\n",
      "-------------------------------------------\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.08%\n",
      "accuracy: 80.36%\n",
      "Overfit: 86.08%\n",
      "accuracy: 78.57%\n",
      "Overfit: 85.09%\n",
      "accuracy: 78.57%\n",
      "Overfit: 87.38%\n",
      "accuracy: 85.71%\n",
      "Overfit: 86.38%\n",
      "accuracy: 89.29%\n",
      "Overfit: 87.67%\n",
      "accuracy: 83.93%\n",
      "Overfit: 84.49%\n",
      "accuracy: 91.07%\n",
      "Overfit: 87.97%\n",
      "accuracy: 78.57%\n",
      "Overfit: 84.21%\n",
      "accuracy: 91.07%\n",
      "Overfit: 84.71%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.2516533382194417 is:\n",
      "84.64% (+/- 5.06%)\n",
      "And overfit of 86.01% (+/- 1.29%)\n",
      "-------------------------------------------\n",
      "accuracy: 85.71%\n",
      "Overfit: 86.98%\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.10%\n",
      "accuracy: 85.71%\n",
      "Overfit: 84.29%\n",
      "accuracy: 71.43%\n",
      "Overfit: 85.98%\n",
      "accuracy: 83.93%\n",
      "Overfit: 87.18%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.49%\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.38%\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.98%\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.91%\n",
      "accuracy: 91.07%\n",
      "Overfit: 84.61%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.2541698716016361 is:\n",
      "84.29% (+/- 4.97%)\n",
      "And overfit of 85.69% (+/- 1.11%)\n",
      "-------------------------------------------\n",
      "accuracy: 78.57%\n",
      "Overfit: 85.09%\n",
      "accuracy: 80.36%\n",
      "Overfit: 83.50%\n",
      "accuracy: 85.71%\n",
      "Overfit: 84.59%\n",
      "accuracy: 69.64%\n",
      "Overfit: 82.70%\n",
      "accuracy: 82.14%\n",
      "Overfit: 87.28%\n",
      "accuracy: 87.50%\n",
      "Overfit: 83.50%\n",
      "accuracy: 85.71%\n",
      "Overfit: 86.08%\n",
      "accuracy: 85.71%\n",
      "Overfit: 87.18%\n",
      "accuracy: 75.00%\n",
      "Overfit: 82.72%\n",
      "accuracy: 91.07%\n",
      "Overfit: 82.42%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.25671157031765246 is:\n",
      "82.14% (+/- 6.08%)\n",
      "And overfit of 84.51% (+/- 1.74%)\n",
      "-------------------------------------------\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.99%\n",
      "accuracy: 71.43%\n",
      "Overfit: 78.33%\n",
      "accuracy: 82.14%\n",
      "Overfit: 88.07%\n",
      "accuracy: 73.21%\n",
      "Overfit: 84.29%\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.98%\n",
      "accuracy: 92.86%\n",
      "Overfit: 86.88%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.79%\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.98%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.50%\n",
      "accuracy: 91.07%\n",
      "Overfit: 84.41%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.259278686020829 is:\n",
      "83.75% (+/- 6.66%)\n",
      "And overfit of 85.22% (+/- 2.58%)\n",
      "-------------------------------------------\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.28%\n",
      "accuracy: 75.00%\n",
      "Overfit: 80.22%\n",
      "accuracy: 78.57%\n",
      "Overfit: 84.39%\n",
      "accuracy: 73.21%\n",
      "Overfit: 86.08%\n",
      "accuracy: 78.57%\n",
      "Overfit: 84.00%\n",
      "accuracy: 91.07%\n",
      "Overfit: 87.97%\n",
      "accuracy: 83.93%\n",
      "Overfit: 79.32%\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.89%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.79%\n",
      "accuracy: 91.07%\n",
      "Overfit: 83.12%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.2618714728810373 is:\n",
      "81.79% (+/- 5.64%)\n",
      "And overfit of 84.31% (+/- 2.65%)\n",
      "-------------------------------------------\n",
      "accuracy: 76.79%\n",
      "Overfit: 80.42%\n",
      "accuracy: 78.57%\n",
      "Overfit: 85.59%\n",
      "accuracy: 80.36%\n",
      "Overfit: 88.47%\n",
      "accuracy: 76.79%\n",
      "Overfit: 87.87%\n",
      "accuracy: 82.14%\n",
      "Overfit: 83.80%\n",
      "accuracy: 91.07%\n",
      "Overfit: 87.08%\n",
      "accuracy: 85.71%\n",
      "Overfit: 87.28%\n",
      "accuracy: 85.71%\n",
      "Overfit: 87.28%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.90%\n",
      "accuracy: 91.07%\n",
      "Overfit: 83.71%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.26449018760984766 is:\n",
      "83.39% (+/- 5.05%)\n",
      "And overfit of 85.74% (+/- 2.34%)\n",
      "-------------------------------------------\n",
      "accuracy: 80.36%\n",
      "Overfit: 83.70%\n",
      "accuracy: 73.21%\n",
      "Overfit: 76.54%\n",
      "accuracy: 83.93%\n",
      "Overfit: 88.37%\n",
      "accuracy: 71.43%\n",
      "Overfit: 84.69%\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.48%\n",
      "accuracy: 91.07%\n",
      "Overfit: 85.39%\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.88%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.39%\n",
      "accuracy: 78.57%\n",
      "Overfit: 83.22%\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.69%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.26713508948594616 is:\n",
      "83.21% (+/- 6.69%)\n",
      "And overfit of 84.73% (+/- 3.10%)\n",
      "-------------------------------------------\n",
      "accuracy: 80.36%\n",
      "Overfit: 85.49%\n",
      "accuracy: 75.00%\n",
      "Overfit: 76.44%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.18%\n",
      "accuracy: 73.21%\n",
      "Overfit: 86.48%\n",
      "accuracy: 78.57%\n",
      "Overfit: 79.52%\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.48%\n",
      "accuracy: 91.07%\n",
      "Overfit: 85.39%\n",
      "accuracy: 83.93%\n",
      "Overfit: 84.79%\n",
      "accuracy: 82.14%\n",
      "Overfit: 83.71%\n",
      "accuracy: 89.29%\n",
      "Overfit: 84.31%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.26980644038080565 is:\n",
      "82.50% (+/- 5.75%)\n",
      "And overfit of 83.88% (+/- 3.15%)\n",
      "-------------------------------------------\n",
      "accuracy: 78.57%\n",
      "Overfit: 84.89%\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.19%\n",
      "accuracy: 80.36%\n",
      "Overfit: 86.28%\n",
      "accuracy: 73.21%\n",
      "Overfit: 84.89%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.48%\n",
      "accuracy: 91.07%\n",
      "Overfit: 87.48%\n",
      "accuracy: 89.29%\n",
      "Overfit: 84.69%\n",
      "accuracy: 87.50%\n",
      "Overfit: 83.40%\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.10%\n",
      "accuracy: 92.86%\n",
      "Overfit: 86.69%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.2725045047846137 is:\n",
      "84.11% (+/- 5.78%)\n",
      "And overfit of 85.51% (+/- 1.22%)\n",
      "-------------------------------------------\n",
      "accuracy: 78.57%\n",
      "Overfit: 85.09%\n",
      "accuracy: 83.93%\n",
      "Overfit: 82.01%\n",
      "accuracy: 82.14%\n",
      "Overfit: 87.77%\n",
      "accuracy: 75.00%\n",
      "Overfit: 84.59%\n",
      "accuracy: 78.57%\n",
      "Overfit: 85.98%\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.28%\n",
      "accuracy: 87.50%\n",
      "Overfit: 84.59%\n",
      "accuracy: 83.93%\n",
      "Overfit: 85.88%\n",
      "accuracy: 82.14%\n",
      "Overfit: 85.60%\n",
      "accuracy: 89.29%\n",
      "Overfit: 82.82%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.27522954983245984 is:\n",
      "83.04% (+/- 4.54%)\n",
      "And overfit of 85.06% (+/- 1.60%)\n",
      "-------------------------------------------\n",
      "accuracy: 76.79%\n",
      "Overfit: 83.50%\n",
      "accuracy: 78.57%\n",
      "Overfit: 83.80%\n",
      "accuracy: 80.36%\n",
      "Overfit: 85.98%\n",
      "accuracy: 69.64%\n",
      "Overfit: 84.89%\n",
      "accuracy: 83.93%\n",
      "Overfit: 87.48%\n",
      "accuracy: 87.50%\n",
      "Overfit: 81.11%\n",
      "accuracy: 87.50%\n",
      "Overfit: 85.39%\n",
      "accuracy: 83.93%\n",
      "Overfit: 85.39%\n",
      "accuracy: 87.50%\n",
      "Overfit: 85.30%\n",
      "accuracy: 89.29%\n",
      "Overfit: 82.32%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.27798184533078446 is:\n",
      "82.50% (+/- 5.86%)\n",
      "And overfit of 84.52% (+/- 1.76%)\n",
      "-------------------------------------------\n",
      "accuracy: 78.57%\n",
      "Overfit: 85.39%\n",
      "accuracy: 75.00%\n",
      "Overfit: 74.85%\n",
      "accuracy: 80.36%\n",
      "Overfit: 86.08%\n",
      "accuracy: 76.79%\n",
      "Overfit: 83.50%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.98%\n",
      "accuracy: 87.50%\n",
      "Overfit: 84.39%\n",
      "accuracy: 85.71%\n",
      "Overfit: 86.08%\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.39%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.30%\n",
      "accuracy: 91.07%\n",
      "Overfit: 86.20%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.2807616637840923 is:\n",
      "82.50% (+/- 4.78%)\n",
      "And overfit of 84.52% (+/- 3.36%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 80.36%\n",
      "Overfit: 83.70%\n",
      "accuracy: 85.71%\n",
      "Overfit: 81.41%\n",
      "accuracy: 73.21%\n",
      "Overfit: 84.49%\n",
      "accuracy: 73.21%\n",
      "Overfit: 82.41%\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.88%\n",
      "accuracy: 85.71%\n",
      "Overfit: 86.78%\n",
      "accuracy: 89.29%\n",
      "Overfit: 84.89%\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.88%\n",
      "accuracy: 75.00%\n",
      "Overfit: 85.30%\n",
      "accuracy: 91.07%\n",
      "Overfit: 83.61%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.2835692804219332 is:\n",
      "82.50% (+/- 6.48%)\n",
      "And overfit of 84.64% (+/- 1.80%)\n",
      "-------------------------------------------\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.69%\n",
      "accuracy: 83.93%\n",
      "Overfit: 84.69%\n",
      "accuracy: 83.93%\n",
      "Overfit: 87.28%\n",
      "accuracy: 78.57%\n",
      "Overfit: 84.69%\n",
      "accuracy: 75.00%\n",
      "Overfit: 79.82%\n",
      "accuracy: 91.07%\n",
      "Overfit: 85.59%\n",
      "accuracy: 83.93%\n",
      "Overfit: 85.69%\n",
      "accuracy: 89.29%\n",
      "Overfit: 87.18%\n",
      "accuracy: 82.14%\n",
      "Overfit: 85.70%\n",
      "accuracy: 91.07%\n",
      "Overfit: 81.93%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.28640497322615255 is:\n",
      "84.11% (+/- 4.95%)\n",
      "And overfit of 84.72% (+/- 2.17%)\n",
      "-------------------------------------------\n",
      "accuracy: 82.14%\n",
      "Overfit: 85.39%\n",
      "accuracy: 82.14%\n",
      "Overfit: 83.90%\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.48%\n",
      "accuracy: 73.21%\n",
      "Overfit: 86.48%\n",
      "accuracy: 78.57%\n",
      "Overfit: 83.40%\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.58%\n",
      "accuracy: 85.71%\n",
      "Overfit: 86.78%\n",
      "accuracy: 89.29%\n",
      "Overfit: 85.19%\n",
      "accuracy: 82.14%\n",
      "Overfit: 85.10%\n",
      "accuracy: 89.29%\n",
      "Overfit: 83.22%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.28926902295841406 is:\n",
      "83.04% (+/- 4.54%)\n",
      "And overfit of 85.25% (+/- 1.29%)\n",
      "-------------------------------------------\n",
      "accuracy: 82.14%\n",
      "Overfit: 85.98%\n",
      "accuracy: 75.00%\n",
      "Overfit: 79.82%\n",
      "accuracy: 80.36%\n",
      "Overfit: 88.37%\n",
      "accuracy: 80.36%\n",
      "Overfit: 86.98%\n",
      "accuracy: 85.71%\n",
      "Overfit: 83.30%\n",
      "accuracy: 89.29%\n",
      "Overfit: 85.29%\n",
      "accuracy: 87.50%\n",
      "Overfit: 85.29%\n",
      "accuracy: 91.07%\n",
      "Overfit: 83.90%\n",
      "accuracy: 83.93%\n",
      "Overfit: 85.10%\n",
      "accuracy: 89.29%\n",
      "Overfit: 82.42%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.2921617131879982 is:\n",
      "84.46% (+/- 4.79%)\n",
      "And overfit of 84.65% (+/- 2.30%)\n",
      "-------------------------------------------\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.78%\n",
      "accuracy: 80.36%\n",
      "Overfit: 83.00%\n",
      "accuracy: 80.36%\n",
      "Overfit: 83.80%\n",
      "accuracy: 71.43%\n",
      "Overfit: 84.99%\n",
      "accuracy: 82.14%\n",
      "Overfit: 87.57%\n",
      "accuracy: 87.50%\n",
      "Overfit: 87.38%\n",
      "accuracy: 87.50%\n",
      "Overfit: 85.79%\n",
      "accuracy: 78.57%\n",
      "Overfit: 86.88%\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.71%\n",
      "accuracy: 89.29%\n",
      "Overfit: 84.61%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.2950833303198782 is:\n",
      "82.32% (+/- 4.95%)\n",
      "And overfit of 85.55% (+/- 1.49%)\n",
      "-------------------------------------------\n",
      "accuracy: 83.93%\n",
      "Overfit: 85.88%\n",
      "accuracy: 78.57%\n",
      "Overfit: 77.73%\n",
      "accuracy: 76.79%\n",
      "Overfit: 82.80%\n",
      "accuracy: 71.43%\n",
      "Overfit: 84.99%\n",
      "accuracy: 75.00%\n",
      "Overfit: 86.88%\n",
      "accuracy: 85.71%\n",
      "Overfit: 80.62%\n",
      "accuracy: 82.14%\n",
      "Overfit: 82.11%\n",
      "accuracy: 94.64%\n",
      "Overfit: 86.48%\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.41%\n",
      "accuracy: 92.86%\n",
      "Overfit: 86.69%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.298034163623077 is:\n",
      "82.32% (+/- 7.03%)\n",
      "And overfit of 83.86% (+/- 2.86%)\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "frame = load_frame()\n",
    "frame = load_quartile(frame)\n",
    "\n",
    "data_x, data_y, number_of_features = load_all_data_with_mine_static(frame)\n",
    "\n",
    "data_x = data_x.values\n",
    "data_y = data_y.values\n",
    "\n",
    "dropout = 0.15\n",
    "while dropout < 0.3:\n",
    "    \n",
    "    seed = 7\n",
    "    np.random.seed(seed)\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    cvscores = []\n",
    "    overscores = []\n",
    "    \n",
    "    for train, validation_and_test in kfold.split(data_x, data_y):\n",
    "        \n",
    "        x_validation, x_test, y_validation, y_test = train_test_split(data_x[validation_and_test], data_y[validation_and_test], test_size=.5, random_state=seed)\n",
    "\n",
    "        model = keras.Sequential()\n",
    "\n",
    "        model.add(keras.layers.Dropout(dropout, input_shape=(number_of_features,)))\n",
    "        model.add(keras.layers.Dense(40, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "        model.add(keras.layers.Dense(20, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "        model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "        early_stopping_monitor = keras.callbacks.EarlyStopping(patience=40,restore_best_weights=True)\n",
    "\n",
    "        history = model.fit(data_x[train], data_y[train], epochs=1000, verbose=0,\n",
    "                            validation_data=(x_validation, y_validation), callbacks=[early_stopping_monitor])\n",
    "\n",
    "        #plot_graphs(history)\n",
    "     \n",
    "        scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "        overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        print(\"Overfit: %.2f%%\" % (overfit[1]*100))\n",
    "        #print(\"-------------------------------------------\")\n",
    "\n",
    "        cvscores.append(scores[1] * 100)\n",
    "        overscores.append(overfit[1]*100)\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"The result, with a dropout of {} is:\".format(dropout))\n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "    print(\"And overfit of %.2f%% (+/- %.2f%%)\" % (np.mean(overscores), np.std(overscores)))\n",
    "    print(\"-------------------------------------------\")\n",
    "    dropout *= 1.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conditions            0.070423\n",
       "TryCatch              0.070250\n",
       "Loop                  0.109013\n",
       "Hamcrest              0.002298\n",
       "Mockito              -0.067717\n",
       "BadApi               -0.137157\n",
       "LOC                   0.091534\n",
       "Expressions           0.104815\n",
       "Depth                 0.301232\n",
       "Vocabulary            0.136554\n",
       "Understandability     0.076682\n",
       "BodySize              0.110602\n",
       "Dexterity            -0.116257\n",
       "NonWhiteCharacters    0.098463\n",
       "mutation              1.000000\n",
       "Name: mutation, dtype: float64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = load_frame()\n",
    "data_x, data_y, number_of_features = load_mine(frame)\n",
    "\n",
    "\n",
    "data_x[data_x.columns[1:]].corr()['mutation'][:]\n",
    "\n",
    "\n",
    "#matrix = np.triu(data_x.corr())\n",
    "#sns.heatmap(data_x.corr(), annot=True, mask=matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_x = StandardScaler().fit_transform(data_x)\n",
    "\n",
    "#pca = PCA(.95) #(n_components=2) \n",
    "# Here we can also give the percentage as a paramter to the PCA function as pca = PCA(.95). .95 means that we want to include 95% of the variance. Hence PCA will return the no of components which describe 95% of the variance. However we know from above computation that 2 components are enough so we have passed the 2 components.\n",
    "#principalComponents = pca.fit_transform(data_x) \n",
    "#data_x = pd.DataFrame(data = principalComponents) #, columns = ['principal component 1', 'principal component 2'])\n",
    "#data_x.head(5) # prints the top 5 rows\n",
    "\n",
    "#number_of_features = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 91.07%\n",
      "Overfit: 88.97%\n",
      "accuracy: 87.50%\n",
      "Overfit: 85.59%\n",
      "accuracy: 78.57%\n",
      "Overfit: 87.87%\n",
      "accuracy: 76.79%\n",
      "Overfit: 90.56%\n",
      "accuracy: 82.14%\n",
      "Overfit: 88.07%\n",
      "accuracy: 89.29%\n",
      "Overfit: 89.07%\n",
      "accuracy: 91.07%\n",
      "Overfit: 89.76%\n",
      "accuracy: 83.93%\n",
      "Overfit: 88.47%\n",
      "accuracy: 82.14%\n",
      "Overfit: 89.28%\n",
      "accuracy: 91.07%\n",
      "Overfit: 86.10%\n",
      "-------------------------------------------\n",
      "The result, with a dropout of 0.3010145052593078 is:\n",
      "85.36% (+/- 5.10%)\n",
      "And overfit of 88.37% (+/- 1.47%)\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "\n",
    "frame = load_frame()\n",
    "frame = load_quartile(frame)\n",
    "\n",
    "data_x, data_y, number_of_features = load_all_data_with_mine_static(frame)\n",
    "\n",
    "data_x = data_x.values\n",
    "data_y = data_y.values\n",
    "\n",
    "    \n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "overscores = []\n",
    "\n",
    "for train, validation_and_test in kfold.split(data_x, data_y):\n",
    "\n",
    "    x_validation, x_test, y_validation, y_test = train_test_split(data_x[validation_and_test], data_y[validation_and_test], test_size=.5, random_state=seed)\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Dropout(0.2, input_shape=(number_of_features,)))\n",
    "    model.add(keras.layers.Dense(40, activation='relu'))\n",
    "    model.add(keras.layers.Dense(20, activation='relu'))\n",
    "    model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "          loss='sparse_categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "    early_stopping_monitor = keras.callbacks.EarlyStopping(patience=100,restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(data_x[train], data_y[train], epochs=1000, verbose=0,\n",
    "                        validation_data=(x_validation, y_validation), callbacks=[early_stopping_monitor])\n",
    "\n",
    "    #plot_graphs(history)\n",
    "\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"Overfit: %.2f%%\" % (overfit[1]*100))\n",
    "    #print(\"-------------------------------------------\")\n",
    "\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    overscores.append(overfit[1]*100)\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"The result, with a dropout of {} is:\".format(dropout))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "print(\"And overfit of %.2f%% (+/- %.2f%%)\" % (np.mean(overscores), np.std(overscores)))\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 89.29%\n",
      "Overfit: 91.75%\n",
      "accuracy: 89.29%\n",
      "Overfit: 90.06%\n",
      "accuracy: 85.71%\n",
      "Overfit: 95.53%\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.87%\n",
      "accuracy: 85.71%\n",
      "Overfit: 98.21%\n",
      "accuracy: 85.71%\n",
      "Overfit: 94.73%\n",
      "accuracy: 82.14%\n",
      "Overfit: 90.76%\n",
      "accuracy: 91.07%\n",
      "Overfit: 97.12%\n",
      "accuracy: 89.29%\n",
      "Overfit: 89.28%\n",
      "accuracy: 87.50%\n",
      "Overfit: 93.74%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0 is:\n",
      "87.32% (+/- 2.45%)\n",
      "And overfit of 93.00% (+/- 3.17%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 89.29%\n",
      "Overfit: 91.75%\n",
      "accuracy: 89.29%\n",
      "Overfit: 90.06%\n",
      "accuracy: 85.71%\n",
      "Overfit: 95.53%\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.87%\n",
      "accuracy: 85.71%\n",
      "Overfit: 98.21%\n",
      "accuracy: 85.71%\n",
      "Overfit: 94.73%\n",
      "accuracy: 82.14%\n",
      "Overfit: 90.76%\n",
      "accuracy: 91.07%\n",
      "Overfit: 97.12%\n",
      "accuracy: 89.29%\n",
      "Overfit: 89.28%\n",
      "accuracy: 87.50%\n",
      "Overfit: 93.74%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 1 is:\n",
      "87.32% (+/- 2.45%)\n",
      "And overfit of 93.00% (+/- 3.17%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.86%\n",
      "Overfit: 94.53%\n",
      "accuracy: 92.86%\n",
      "Overfit: 94.63%\n",
      "accuracy: 89.29%\n",
      "Overfit: 98.01%\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.87%\n",
      "accuracy: 89.29%\n",
      "Overfit: 99.30%\n",
      "accuracy: 85.71%\n",
      "Overfit: 94.73%\n",
      "accuracy: 87.50%\n",
      "Overfit: 93.14%\n",
      "accuracy: 91.07%\n",
      "Overfit: 97.12%\n",
      "accuracy: 89.29%\n",
      "Overfit: 89.28%\n",
      "accuracy: 85.71%\n",
      "Overfit: 97.72%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 2 is:\n",
      "89.11% (+/- 2.45%)\n",
      "And overfit of 94.73% (+/- 3.36%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.86%\n",
      "Overfit: 94.53%\n",
      "accuracy: 92.86%\n",
      "Overfit: 94.63%\n",
      "accuracy: 89.29%\n",
      "Overfit: 98.01%\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.87%\n",
      "accuracy: 89.29%\n",
      "Overfit: 99.80%\n",
      "accuracy: 85.71%\n",
      "Overfit: 94.73%\n",
      "accuracy: 87.50%\n",
      "Overfit: 98.81%\n",
      "accuracy: 91.07%\n",
      "Overfit: 97.12%\n",
      "accuracy: 87.50%\n",
      "Overfit: 97.12%\n",
      "accuracy: 85.71%\n",
      "Overfit: 97.72%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 3 is:\n",
      "88.93% (+/- 2.50%)\n",
      "And overfit of 96.13% (+/- 2.97%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.86%\n",
      "Overfit: 94.53%\n",
      "accuracy: 92.86%\n",
      "Overfit: 94.63%\n",
      "accuracy: 89.29%\n",
      "Overfit: 98.01%\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.87%\n",
      "accuracy: 89.29%\n",
      "Overfit: 99.80%\n",
      "accuracy: 85.71%\n",
      "Overfit: 94.73%\n",
      "accuracy: 87.50%\n",
      "Overfit: 98.81%\n",
      "accuracy: 91.07%\n",
      "Overfit: 97.12%\n",
      "accuracy: 85.71%\n",
      "Overfit: 98.31%\n",
      "accuracy: 85.71%\n",
      "Overfit: 97.72%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 4 is:\n",
      "88.75% (+/- 2.65%)\n",
      "And overfit of 96.25% (+/- 3.03%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.86%\n",
      "Overfit: 94.53%\n",
      "accuracy: 92.86%\n",
      "Overfit: 94.63%\n",
      "accuracy: 89.29%\n",
      "Overfit: 98.01%\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.87%\n",
      "accuracy: 89.29%\n",
      "Overfit: 99.80%\n",
      "accuracy: 85.71%\n",
      "Overfit: 94.73%\n",
      "accuracy: 87.50%\n",
      "Overfit: 98.81%\n",
      "accuracy: 91.07%\n",
      "Overfit: 97.12%\n",
      "accuracy: 85.71%\n",
      "Overfit: 98.31%\n",
      "accuracy: 85.71%\n",
      "Overfit: 97.72%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 5 is:\n",
      "88.75% (+/- 2.65%)\n",
      "And overfit of 96.25% (+/- 3.03%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.86%\n",
      "Overfit: 94.53%\n",
      "accuracy: 92.86%\n",
      "Overfit: 94.63%\n",
      "accuracy: 89.29%\n",
      "Overfit: 98.01%\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.87%\n",
      "accuracy: 89.29%\n",
      "Overfit: 99.80%\n",
      "accuracy: 85.71%\n",
      "Overfit: 94.73%\n",
      "accuracy: 87.50%\n",
      "Overfit: 98.81%\n",
      "accuracy: 91.07%\n",
      "Overfit: 97.12%\n",
      "accuracy: 85.71%\n",
      "Overfit: 98.31%\n",
      "accuracy: 85.71%\n",
      "Overfit: 97.72%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 7 is:\n",
      "88.75% (+/- 2.65%)\n",
      "And overfit of 96.25% (+/- 3.03%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.86%\n",
      "Overfit: 94.53%\n",
      "accuracy: 92.86%\n",
      "Overfit: 94.63%\n",
      "accuracy: 89.29%\n",
      "Overfit: 98.01%\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.87%\n",
      "accuracy: 91.07%\n",
      "Overfit: 100.00%\n",
      "accuracy: 85.71%\n",
      "Overfit: 94.73%\n",
      "accuracy: 87.50%\n",
      "Overfit: 98.81%\n",
      "accuracy: 91.07%\n",
      "Overfit: 97.12%\n",
      "accuracy: 85.71%\n",
      "Overfit: 98.31%\n",
      "accuracy: 85.71%\n",
      "Overfit: 97.72%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 10 is:\n",
      "88.93% (+/- 2.74%)\n",
      "And overfit of 96.27% (+/- 3.05%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.86%\n",
      "Overfit: 94.53%\n",
      "accuracy: 92.86%\n",
      "Overfit: 94.63%\n",
      "accuracy: 89.29%\n",
      "Overfit: 98.01%\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.87%\n",
      "accuracy: 91.07%\n",
      "Overfit: 100.00%\n",
      "accuracy: 85.71%\n",
      "Overfit: 94.73%\n",
      "accuracy: 87.50%\n",
      "Overfit: 98.81%\n",
      "accuracy: 91.07%\n",
      "Overfit: 97.12%\n",
      "accuracy: 85.71%\n",
      "Overfit: 98.31%\n",
      "accuracy: 85.71%\n",
      "Overfit: 97.72%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 12 is:\n",
      "88.93% (+/- 2.74%)\n",
      "And overfit of 96.27% (+/- 3.05%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.86%\n",
      "Overfit: 94.53%\n",
      "accuracy: 92.86%\n",
      "Overfit: 94.63%\n",
      "accuracy: 89.29%\n",
      "Overfit: 98.01%\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.87%\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ca4bbc48b3db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         history = model.fit(data_x[train], data_y[train], epochs=1000, verbose=0,\n\u001b[0;32m---> 48\u001b[0;31m                             validation_data=(x_validation, y_validation), callbacks=[early_stopping_monitor])\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m#plot_graphs(history)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             batch_end=step * batch_size + current_batch_size)\n\u001b[1;32m    173\u001b[0m       \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m       \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_batch\u001b[0;34m(self, step, mode, size)\u001b[0m\n\u001b[1;32m    698\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_exhausted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         self.callbacks._call_batch_hook(\n\u001b[0;32m--> 700\u001b[0;31m             mode, 'end', step, batch_logs)\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m       \u001b[0mbatch_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m       \u001b[0mbatch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \"\"\"\n\u001b[1;32m    517\u001b[0m     \u001b[0;31m# For backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    661\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pa = [0,1,2,3,4,5,7,10,12,15,18,20,25,30,35,40,50,60,70,80,90,100,150,250,350,450, 550,650,750,850,950]\n",
    "\n",
    "for p in pa:\n",
    "\n",
    "    import tensorflow\n",
    "\n",
    "    from numpy.random import seed\n",
    "    seed(1)\n",
    "    tensorflow.random.set_seed(2)\n",
    "\n",
    "\n",
    "    frame = load_frame()\n",
    "    frame = load_quartile(frame)\n",
    "\n",
    "    data_x, data_y, number_of_features = load_all_data_with_mine_static(frame)\n",
    "\n",
    "    data_x = data_x.values\n",
    "    data_y = data_y.values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data_x)\n",
    "    data_x = scaler.transform(data_x)\n",
    "       \n",
    "    seed = 7\n",
    "    np.random.seed(seed)\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed)\n",
    "    cvscores = []\n",
    "    overscores = []\n",
    "\n",
    "    for train, validation_and_test in kfold.split(data_x, data_y):\n",
    "\n",
    "        x_validation, x_test, y_validation, y_test = train_test_split(data_x[validation_and_test], data_y[validation_and_test], test_size=.5, random_state=seed)\n",
    "\n",
    "        model = keras.Sequential()\n",
    "\n",
    "        model.add(keras.layers.Dense(number_of_features, activation='relu', input_dim=number_of_features))\n",
    "        model.add(keras.layers.Dense(40, activation='relu'))\n",
    "        model.add(keras.layers.Dense(20, activation='relu'))\n",
    "        model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "        early_stopping_monitor = keras.callbacks.EarlyStopping(patience=p,restore_best_weights=True)\n",
    "\n",
    "        history = model.fit(data_x[train], data_y[train], epochs=1000, verbose=0,\n",
    "                            validation_data=(x_validation, y_validation), callbacks=[early_stopping_monitor])\n",
    "\n",
    "        #plot_graphs(history)\n",
    "\n",
    "        scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "        overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        print(\"Overfit: %.2f%%\" % (overfit[1]*100))\n",
    "        #print(\"-------------------------------------------\")\n",
    "\n",
    "        cvscores.append(scores[1] * 100)\n",
    "        overscores.append(overfit[1]*100)\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"The result, with a patience of {} is:\".format(p))\n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "    print(\"And overfit of %.2f%% (+/- %.2f%%)\" % (np.mean(overscores), np.std(overscores)))\n",
    "    print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 85.71%\n",
      "Overfit: 90.36%\n",
      "accuracy: 91.07%\n",
      "Overfit: 97.91%\n",
      "accuracy: 87.50%\n",
      "Overfit: 99.60%\n",
      "accuracy: 91.07%\n",
      "Overfit: 88.57%\n",
      "accuracy: 85.71%\n",
      "Overfit: 93.84%\n",
      "accuracy: 91.07%\n",
      "Overfit: 96.92%\n",
      "accuracy: 78.57%\n",
      "Overfit: 95.13%\n",
      "accuracy: 91.07%\n",
      "Overfit: 92.45%\n",
      "accuracy: 91.07%\n",
      "Overfit: 93.35%\n",
      "accuracy: 92.86%\n",
      "Overfit: 96.03%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 550 is:\n",
      "88.57% (+/- 4.09%)\n",
      "And overfit of 94.41% (+/- 3.23%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 85.71%\n",
      "Overfit: 90.36%\n",
      "accuracy: 91.07%\n",
      "Overfit: 97.91%\n",
      "accuracy: 87.50%\n",
      "Overfit: 99.60%\n",
      "accuracy: 91.07%\n",
      "Overfit: 88.57%\n",
      "accuracy: 85.71%\n",
      "Overfit: 93.84%\n",
      "accuracy: 91.07%\n",
      "Overfit: 96.92%\n",
      "accuracy: 78.57%\n",
      "Overfit: 95.13%\n",
      "accuracy: 91.07%\n",
      "Overfit: 92.45%\n",
      "accuracy: 91.07%\n",
      "Overfit: 93.35%\n",
      "accuracy: 92.86%\n",
      "Overfit: 96.03%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 650 is:\n",
      "88.57% (+/- 4.09%)\n",
      "And overfit of 94.41% (+/- 3.23%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.86%\n",
      "Overfit: 99.70%\n",
      "accuracy: 91.07%\n",
      "Overfit: 97.91%\n",
      "accuracy: 87.50%\n",
      "Overfit: 99.60%\n",
      "accuracy: 91.07%\n",
      "Overfit: 88.57%\n",
      "accuracy: 91.07%\n",
      "Overfit: 98.91%\n",
      "accuracy: 91.07%\n",
      "Overfit: 99.90%\n",
      "accuracy: 83.93%\n",
      "Overfit: 99.11%\n",
      "accuracy: 92.86%\n",
      "Overfit: 97.42%\n",
      "accuracy: 91.07%\n",
      "Overfit: 93.35%\n",
      "accuracy: 92.86%\n",
      "Overfit: 96.03%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 750 is:\n",
      "90.54% (+/- 2.65%)\n",
      "And overfit of 97.05% (+/- 3.42%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.86%\n",
      "Overfit: 99.70%\n",
      "accuracy: 91.07%\n",
      "Overfit: 97.91%\n",
      "accuracy: 87.50%\n",
      "Overfit: 99.60%\n",
      "accuracy: 91.07%\n",
      "Overfit: 88.57%\n",
      "accuracy: 91.07%\n",
      "Overfit: 98.91%\n",
      "accuracy: 91.07%\n",
      "Overfit: 99.90%\n",
      "accuracy: 83.93%\n",
      "Overfit: 99.11%\n",
      "accuracy: 92.86%\n",
      "Overfit: 97.42%\n",
      "accuracy: 91.07%\n",
      "Overfit: 93.35%\n",
      "accuracy: 85.71%\n",
      "Overfit: 99.70%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 850 is:\n",
      "89.82% (+/- 2.88%)\n",
      "And overfit of 97.42% (+/- 3.49%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.86%\n",
      "Overfit: 99.70%\n",
      "accuracy: 91.07%\n",
      "Overfit: 97.91%\n",
      "accuracy: 87.50%\n",
      "Overfit: 99.60%\n",
      "accuracy: 91.07%\n",
      "Overfit: 88.57%\n",
      "accuracy: 91.07%\n",
      "Overfit: 98.91%\n",
      "accuracy: 91.07%\n",
      "Overfit: 99.90%\n",
      "accuracy: 83.93%\n",
      "Overfit: 99.11%\n",
      "accuracy: 92.86%\n",
      "Overfit: 97.42%\n",
      "accuracy: 91.07%\n",
      "Overfit: 93.35%\n",
      "accuracy: 85.71%\n",
      "Overfit: 99.70%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 950 is:\n",
      "89.82% (+/- 2.88%)\n",
      "And overfit of 97.42% (+/- 3.49%)\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pa = [550,650,750,850,950]\n",
    "\n",
    "for p in pa:\n",
    "\n",
    "    import tensorflow\n",
    "\n",
    "    from numpy.random import seed\n",
    "    seed(1)\n",
    "    tensorflow.random.set_seed(2)\n",
    "\n",
    "\n",
    "    frame = load_frame()\n",
    "    frame = load_quartile(frame)\n",
    "\n",
    "    data_x, data_y, number_of_features = load_all_data_with_mine_static(frame)\n",
    "\n",
    "    data_x = data_x.values\n",
    "    data_y = data_y.values\n",
    "       \n",
    "    seed = 7\n",
    "    np.random.seed(seed)\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed)\n",
    "    cvscores = []\n",
    "    overscores = []\n",
    "\n",
    "    for train, validation_and_test in kfold.split(data_x, data_y):\n",
    "\n",
    "        x_validation, x_test, y_validation, y_test = train_test_split(data_x[validation_and_test], data_y[validation_and_test], test_size=.5, random_state=seed)\n",
    "\n",
    "        model = keras.Sequential()\n",
    "\n",
    "        model.add(keras.layers.Dense(number_of_features, activation='relu', input_dim=number_of_features))\n",
    "        model.add(keras.layers.Dense(40, activation='relu'))\n",
    "        model.add(keras.layers.Dense(20, activation='relu'))\n",
    "        model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "        early_stopping_monitor = keras.callbacks.EarlyStopping(patience=p,restore_best_weights=True)\n",
    "\n",
    "        history = model.fit(data_x[train], data_y[train], epochs=1000, verbose=0,\n",
    "                            validation_data=(x_validation, y_validation), callbacks=[early_stopping_monitor])\n",
    "\n",
    "        #plot_graphs(history)\n",
    "\n",
    "        scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "        overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        print(\"Overfit: %.2f%%\" % (overfit[1]*100))\n",
    "        #print(\"-------------------------------------------\")\n",
    "\n",
    "        cvscores.append(scores[1] * 100)\n",
    "        overscores.append(overfit[1]*100)\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"The result, with a patience of {} is:\".format(p))\n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "    print(\"And overfit of %.2f%% (+/- %.2f%%)\" % (np.mean(overscores), np.std(overscores)))\n",
    "    print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 91.07%\n",
      "Overfit: 99.80%\n",
      "accuracy: 88.39%\n",
      "Overfit: 99.01%\n",
      "accuracy: 84.82%\n",
      "Overfit: 100.00%\n",
      "accuracy: 91.96%\n",
      "Overfit: 100.00%\n",
      "accuracy: 89.29%\n",
      "Overfit: 94.04%\n",
      "accuracy: 94.64%\n",
      "Overfit: 99.50%\n",
      "accuracy: 88.39%\n",
      "Overfit: 98.81%\n",
      "accuracy: 88.39%\n",
      "Overfit: 100.00%\n",
      "accuracy: 90.09%\n",
      "Overfit: 97.42%\n",
      "accuracy: 93.69%\n",
      "Overfit: 97.22%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0 is:\n",
      "90.07% (+/- 2.74%)\n",
      "And overfit of 98.58% (+/- 1.80%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 90.18%\n",
      "Overfit: 99.30%\n",
      "accuracy: 93.75%\n",
      "Overfit: 96.12%\n",
      "accuracy: 86.61%\n",
      "Overfit: 98.91%\n",
      "accuracy: 91.07%\n",
      "Overfit: 99.40%\n",
      "accuracy: 92.86%\n",
      "Overfit: 97.32%\n",
      "accuracy: 91.96%\n",
      "Overfit: 98.71%\n",
      "accuracy: 86.61%\n",
      "Overfit: 98.61%\n",
      "accuracy: 86.61%\n",
      "Overfit: 99.60%\n",
      "accuracy: 89.19%\n",
      "Overfit: 97.32%\n",
      "accuracy: 93.69%\n",
      "Overfit: 99.40%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.02 is:\n",
      "90.25% (+/- 2.75%)\n",
      "And overfit of 98.47% (+/- 1.10%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 90.18%\n",
      "Overfit: 98.71%\n",
      "accuracy: 91.96%\n",
      "Overfit: 97.32%\n",
      "accuracy: 86.61%\n",
      "Overfit: 98.41%\n",
      "accuracy: 84.82%\n",
      "Overfit: 88.37%\n",
      "accuracy: 94.64%\n",
      "Overfit: 97.42%\n",
      "accuracy: 95.54%\n",
      "Overfit: 98.01%\n",
      "accuracy: 88.39%\n",
      "Overfit: 97.32%\n",
      "accuracy: 87.50%\n",
      "Overfit: 98.81%\n",
      "accuracy: 88.29%\n",
      "Overfit: 97.22%\n",
      "accuracy: 91.89%\n",
      "Overfit: 98.41%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.04 is:\n",
      "89.98% (+/- 3.31%)\n",
      "And overfit of 97.00% (+/- 2.93%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 91.07%\n",
      "Overfit: 97.61%\n",
      "accuracy: 93.75%\n",
      "Overfit: 93.44%\n",
      "accuracy: 86.61%\n",
      "Overfit: 99.01%\n",
      "accuracy: 93.75%\n",
      "Overfit: 99.30%\n",
      "accuracy: 91.96%\n",
      "Overfit: 97.02%\n",
      "accuracy: 93.75%\n",
      "Overfit: 99.50%\n",
      "accuracy: 87.50%\n",
      "Overfit: 97.91%\n",
      "accuracy: 88.39%\n",
      "Overfit: 99.01%\n",
      "accuracy: 86.49%\n",
      "Overfit: 95.73%\n",
      "accuracy: 94.59%\n",
      "Overfit: 98.61%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.05 is:\n",
      "90.79% (+/- 3.08%)\n",
      "And overfit of 97.71% (+/- 1.81%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 89.29%\n",
      "Overfit: 95.83%\n",
      "accuracy: 89.29%\n",
      "Overfit: 93.74%\n",
      "accuracy: 89.29%\n",
      "Overfit: 95.73%\n",
      "accuracy: 93.75%\n",
      "Overfit: 96.52%\n",
      "accuracy: 93.75%\n",
      "Overfit: 92.74%\n",
      "accuracy: 91.96%\n",
      "Overfit: 96.22%\n",
      "accuracy: 90.18%\n",
      "Overfit: 95.53%\n",
      "accuracy: 85.71%\n",
      "Overfit: 97.02%\n",
      "accuracy: 90.09%\n",
      "Overfit: 95.43%\n",
      "accuracy: 90.99%\n",
      "Overfit: 96.92%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.11 is:\n",
      "90.43% (+/- 2.26%)\n",
      "And overfit of 95.57% (+/- 1.29%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.39%\n",
      "Overfit: 94.63%\n",
      "accuracy: 90.18%\n",
      "Overfit: 90.85%\n",
      "accuracy: 91.07%\n",
      "Overfit: 95.13%\n",
      "accuracy: 90.18%\n",
      "Overfit: 96.62%\n",
      "accuracy: 91.96%\n",
      "Overfit: 93.04%\n",
      "accuracy: 91.07%\n",
      "Overfit: 95.33%\n",
      "accuracy: 89.29%\n",
      "Overfit: 94.04%\n",
      "accuracy: 89.29%\n",
      "Overfit: 95.92%\n",
      "accuracy: 90.99%\n",
      "Overfit: 94.74%\n",
      "accuracy: 89.19%\n",
      "Overfit: 94.84%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.15 is:\n",
      "90.16% (+/- 1.06%)\n",
      "And overfit of 94.51% (+/- 1.53%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.39%\n",
      "Overfit: 94.93%\n",
      "accuracy: 89.29%\n",
      "Overfit: 89.76%\n",
      "accuracy: 91.07%\n",
      "Overfit: 95.23%\n",
      "accuracy: 92.86%\n",
      "Overfit: 93.04%\n",
      "accuracy: 91.07%\n",
      "Overfit: 90.95%\n",
      "accuracy: 91.07%\n",
      "Overfit: 94.53%\n",
      "accuracy: 90.18%\n",
      "Overfit: 95.13%\n",
      "accuracy: 82.14%\n",
      "Overfit: 93.84%\n",
      "accuracy: 88.29%\n",
      "Overfit: 93.94%\n",
      "accuracy: 86.49%\n",
      "Overfit: 93.94%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.17 is:\n",
      "89.08% (+/- 2.89%)\n",
      "And overfit of 93.53% (+/- 1.73%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 87.50%\n",
      "Overfit: 94.53%\n",
      "accuracy: 90.18%\n",
      "Overfit: 91.45%\n",
      "accuracy: 87.50%\n",
      "Overfit: 93.94%\n",
      "accuracy: 93.75%\n",
      "Overfit: 96.22%\n",
      "accuracy: 91.07%\n",
      "Overfit: 91.25%\n",
      "accuracy: 91.07%\n",
      "Overfit: 95.23%\n",
      "accuracy: 88.39%\n",
      "Overfit: 92.05%\n",
      "accuracy: 87.50%\n",
      "Overfit: 94.73%\n",
      "accuracy: 89.19%\n",
      "Overfit: 91.36%\n",
      "accuracy: 87.39%\n",
      "Overfit: 95.63%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.19 is:\n",
      "89.35% (+/- 2.03%)\n",
      "And overfit of 93.64% (+/- 1.83%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 89.29%\n",
      "Overfit: 94.93%\n",
      "accuracy: 89.29%\n",
      "Overfit: 90.06%\n",
      "accuracy: 84.82%\n",
      "Overfit: 92.54%\n",
      "accuracy: 93.75%\n",
      "Overfit: 94.53%\n",
      "accuracy: 92.86%\n",
      "Overfit: 93.14%\n",
      "accuracy: 91.07%\n",
      "Overfit: 95.03%\n",
      "accuracy: 89.29%\n",
      "Overfit: 93.54%\n",
      "accuracy: 86.61%\n",
      "Overfit: 93.84%\n",
      "accuracy: 87.39%\n",
      "Overfit: 93.55%\n",
      "accuracy: 84.68%\n",
      "Overfit: 94.84%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.2 is:\n",
      "88.90% (+/- 2.94%)\n",
      "And overfit of 93.60% (+/- 1.42%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 90.18%\n",
      "Overfit: 94.63%\n",
      "accuracy: 89.29%\n",
      "Overfit: 90.16%\n",
      "accuracy: 87.50%\n",
      "Overfit: 93.44%\n",
      "accuracy: 93.75%\n",
      "Overfit: 94.43%\n",
      "accuracy: 89.29%\n",
      "Overfit: 90.95%\n",
      "accuracy: 92.86%\n",
      "Overfit: 93.54%\n",
      "accuracy: 88.39%\n",
      "Overfit: 92.74%\n",
      "accuracy: 85.71%\n",
      "Overfit: 94.53%\n",
      "accuracy: 88.29%\n",
      "Overfit: 91.96%\n",
      "accuracy: 86.49%\n",
      "Overfit: 93.94%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.21 is:\n",
      "89.17% (+/- 2.43%)\n",
      "And overfit of 93.03% (+/- 1.48%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 90.18%\n",
      "Overfit: 95.23%\n",
      "accuracy: 87.50%\n",
      "Overfit: 92.05%\n",
      "accuracy: 89.29%\n",
      "Overfit: 94.93%\n",
      "accuracy: 94.64%\n",
      "Overfit: 94.53%\n",
      "accuracy: 91.96%\n",
      "Overfit: 90.66%\n",
      "accuracy: 91.07%\n",
      "Overfit: 94.14%\n",
      "accuracy: 88.39%\n",
      "Overfit: 92.84%\n",
      "accuracy: 86.61%\n",
      "Overfit: 94.14%\n",
      "accuracy: 86.49%\n",
      "Overfit: 90.37%\n",
      "accuracy: 87.39%\n",
      "Overfit: 93.05%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.23 is:\n",
      "89.35% (+/- 2.50%)\n",
      "And overfit of 93.19% (+/- 1.63%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.39%\n",
      "Overfit: 94.33%\n",
      "accuracy: 87.50%\n",
      "Overfit: 89.86%\n",
      "accuracy: 89.29%\n",
      "Overfit: 90.66%\n",
      "accuracy: 93.75%\n",
      "Overfit: 93.14%\n",
      "accuracy: 91.07%\n",
      "Overfit: 91.95%\n",
      "accuracy: 91.07%\n",
      "Overfit: 94.33%\n",
      "accuracy: 87.50%\n",
      "Overfit: 92.35%\n",
      "accuracy: 85.71%\n",
      "Overfit: 94.33%\n",
      "accuracy: 87.39%\n",
      "Overfit: 91.46%\n",
      "accuracy: 85.59%\n",
      "Overfit: 94.04%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.25 is:\n",
      "88.73% (+/- 2.46%)\n",
      "And overfit of 92.65% (+/- 1.56%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 87.50%\n",
      "Overfit: 92.94%\n",
      "accuracy: 87.50%\n",
      "Overfit: 89.56%\n",
      "accuracy: 91.07%\n",
      "Overfit: 93.04%\n",
      "accuracy: 91.07%\n",
      "Overfit: 92.35%\n",
      "accuracy: 92.86%\n",
      "Overfit: 91.15%\n",
      "accuracy: 92.86%\n",
      "Overfit: 92.94%\n",
      "accuracy: 83.93%\n",
      "Overfit: 87.08%\n",
      "accuracy: 84.82%\n",
      "Overfit: 92.25%\n",
      "accuracy: 91.89%\n",
      "Overfit: 91.76%\n",
      "accuracy: 87.39%\n",
      "Overfit: 93.15%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.28 is:\n",
      "89.09% (+/- 3.11%)\n",
      "And overfit of 91.62% (+/- 1.84%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 86.61%\n",
      "Overfit: 92.05%\n",
      "accuracy: 88.39%\n",
      "Overfit: 89.66%\n",
      "accuracy: 89.29%\n",
      "Overfit: 91.35%\n",
      "accuracy: 92.86%\n",
      "Overfit: 90.85%\n",
      "accuracy: 86.61%\n",
      "Overfit: 89.86%\n",
      "accuracy: 89.29%\n",
      "Overfit: 91.85%\n",
      "accuracy: 88.39%\n",
      "Overfit: 90.95%\n",
      "accuracy: 87.50%\n",
      "Overfit: 91.65%\n",
      "accuracy: 88.29%\n",
      "Overfit: 90.17%\n",
      "accuracy: 85.59%\n",
      "Overfit: 91.46%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.33 is:\n",
      "88.28% (+/- 1.91%)\n",
      "And overfit of 90.99% (+/- 0.80%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 83.93%\n",
      "Overfit: 88.97%\n",
      "accuracy: 83.04%\n",
      "Overfit: 88.77%\n",
      "accuracy: 89.29%\n",
      "Overfit: 92.15%\n",
      "accuracy: 91.96%\n",
      "Overfit: 91.55%\n",
      "accuracy: 91.96%\n",
      "Overfit: 90.16%\n",
      "accuracy: 91.96%\n",
      "Overfit: 92.15%\n",
      "accuracy: 87.50%\n",
      "Overfit: 89.36%\n",
      "accuracy: 84.82%\n",
      "Overfit: 91.85%\n",
      "accuracy: 86.49%\n",
      "Overfit: 88.68%\n",
      "accuracy: 82.88%\n",
      "Overfit: 91.36%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.38 is:\n",
      "87.38% (+/- 3.54%)\n",
      "And overfit of 90.50% (+/- 1.38%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 85.71%\n",
      "Overfit: 88.37%\n",
      "accuracy: 86.61%\n",
      "Overfit: 88.77%\n",
      "accuracy: 84.82%\n",
      "Overfit: 90.06%\n",
      "accuracy: 93.75%\n",
      "Overfit: 91.05%\n",
      "accuracy: 90.18%\n",
      "Overfit: 90.26%\n",
      "accuracy: 89.29%\n",
      "Overfit: 90.46%\n",
      "accuracy: 85.71%\n",
      "Overfit: 90.66%\n",
      "accuracy: 84.82%\n",
      "Overfit: 89.26%\n",
      "accuracy: 84.68%\n",
      "Overfit: 87.98%\n",
      "accuracy: 82.88%\n",
      "Overfit: 90.57%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.44 is:\n",
      "86.85% (+/- 3.10%)\n",
      "And overfit of 89.74% (+/- 1.01%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 85.71%\n",
      "Overfit: 89.46%\n",
      "accuracy: 83.04%\n",
      "Overfit: 86.98%\n",
      "accuracy: 89.29%\n",
      "Overfit: 90.36%\n",
      "accuracy: 91.07%\n",
      "Overfit: 90.06%\n",
      "accuracy: 90.18%\n",
      "Overfit: 87.18%\n",
      "accuracy: 90.18%\n",
      "Overfit: 89.36%\n",
      "accuracy: 85.71%\n",
      "Overfit: 89.86%\n",
      "accuracy: 84.82%\n",
      "Overfit: 90.36%\n",
      "accuracy: 81.98%\n",
      "Overfit: 86.89%\n",
      "accuracy: 77.48%\n",
      "Overfit: 83.81%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.5 is:\n",
      "85.95% (+/- 4.13%)\n",
      "And overfit of 88.43% (+/- 2.04%)\n",
      "-------------------------------------------\n",
      "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "accuracy: 83.04%\n",
      "Overfit: 87.97%\n",
      "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "accuracy: 84.82%\n",
      "Overfit: 86.48%\n",
      "accuracy: 90.18%\n",
      "Overfit: 88.87%\n",
      "accuracy: 89.29%\n",
      "Overfit: 89.17%\n",
      "accuracy: 90.18%\n",
      "Overfit: 88.87%\n",
      "accuracy: 90.18%\n",
      "Overfit: 88.37%\n",
      "accuracy: 85.71%\n",
      "Overfit: 86.58%\n",
      "accuracy: 81.25%\n",
      "Overfit: 88.97%\n",
      "accuracy: 88.29%\n",
      "Overfit: 86.49%\n",
      "accuracy: 83.78%\n",
      "Overfit: 89.47%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.55 is:\n",
      "86.67% (+/- 3.19%)\n",
      "And overfit of 88.12% (+/- 1.12%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 81.25%\n",
      "Overfit: 85.09%\n",
      "accuracy: 87.50%\n",
      "Overfit: 85.59%\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.98%\n",
      "accuracy: 93.75%\n",
      "Overfit: 88.57%\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.28%\n",
      "accuracy: 91.07%\n",
      "Overfit: 88.57%\n",
      "accuracy: 80.36%\n",
      "Overfit: 88.37%\n",
      "accuracy: 83.93%\n",
      "Overfit: 89.76%\n",
      "accuracy: 86.49%\n",
      "Overfit: 86.69%\n",
      "accuracy: 81.98%\n",
      "Overfit: 89.47%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.6 is:\n",
      "86.31% (+/- 4.19%)\n",
      "And overfit of 87.54% (+/- 1.55%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 82.14%\n",
      "Overfit: 85.49%\n",
      "accuracy: 84.82%\n",
      "Overfit: 85.49%\n",
      "accuracy: 91.07%\n",
      "Overfit: 87.77%\n",
      "accuracy: 87.50%\n",
      "Overfit: 84.19%\n",
      "accuracy: 87.50%\n",
      "Overfit: 85.39%\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.67%\n",
      "accuracy: 78.57%\n",
      "Overfit: 86.78%\n",
      "accuracy: 87.50%\n",
      "Overfit: 87.97%\n",
      "accuracy: 87.39%\n",
      "Overfit: 86.40%\n",
      "accuracy: 81.98%\n",
      "Overfit: 90.17%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.65 is:\n",
      "85.60% (+/- 3.50%)\n",
      "And overfit of 86.83% (+/- 1.72%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 86.61%\n",
      "Overfit: 87.18%\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.38%\n",
      "accuracy: 88.39%\n",
      "Overfit: 86.58%\n",
      "accuracy: 88.39%\n",
      "Overfit: 85.59%\n",
      "accuracy: 84.82%\n",
      "Overfit: 85.69%\n",
      "accuracy: 86.61%\n",
      "Overfit: 87.77%\n",
      "accuracy: 81.25%\n",
      "Overfit: 87.57%\n",
      "accuracy: 86.61%\n",
      "Overfit: 87.18%\n",
      "accuracy: 89.19%\n",
      "Overfit: 85.00%\n",
      "accuracy: 83.78%\n",
      "Overfit: 87.69%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.7 is:\n",
      "85.96% (+/- 2.36%)\n",
      "And overfit of 86.66% (+/- 0.93%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 83.93%\n",
      "Overfit: 85.88%\n",
      "accuracy: 84.82%\n",
      "Overfit: 83.40%\n",
      "accuracy: 79.46%\n",
      "Overfit: 80.72%\n",
      "accuracy: 77.68%\n",
      "Overfit: 79.52%\n",
      "accuracy: 76.79%\n",
      "Overfit: 76.34%\n",
      "accuracy: 87.50%\n",
      "Overfit: 84.89%\n",
      "accuracy: 83.04%\n",
      "Overfit: 86.28%\n",
      "accuracy: 76.79%\n",
      "Overfit: 80.32%\n",
      "accuracy: 88.29%\n",
      "Overfit: 84.51%\n",
      "accuracy: 81.08%\n",
      "Overfit: 84.11%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.75 is:\n",
      "81.94% (+/- 4.04%)\n",
      "And overfit of 82.60% (+/- 3.06%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 82.14%\n",
      "Overfit: 82.90%\n",
      "accuracy: 81.25%\n",
      "Overfit: 81.21%\n",
      "accuracy: 87.50%\n",
      "Overfit: 83.50%\n",
      "accuracy: 67.86%\n",
      "Overfit: 70.28%\n",
      "accuracy: 72.32%\n",
      "Overfit: 69.38%\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.49%\n",
      "accuracy: 66.96%\n",
      "Overfit: 70.18%\n",
      "accuracy: 78.57%\n",
      "Overfit: 83.10%\n",
      "accuracy: 88.29%\n",
      "Overfit: 84.21%\n",
      "accuracy: 79.28%\n",
      "Overfit: 83.81%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.8 is:\n",
      "78.63% (+/- 7.04%)\n",
      "And overfit of 79.31% (+/- 6.19%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 82.14%\n",
      "Overfit: 83.30%\n",
      "accuracy: 83.93%\n",
      "Overfit: 83.50%\n",
      "accuracy: 89.29%\n",
      "Overfit: 84.39%\n",
      "accuracy: 77.68%\n",
      "Overfit: 73.36%\n",
      "accuracy: 73.21%\n",
      "Overfit: 71.77%\n",
      "accuracy: 83.04%\n",
      "Overfit: 84.59%\n",
      "accuracy: 75.00%\n",
      "Overfit: 71.97%\n",
      "accuracy: 78.57%\n",
      "Overfit: 81.81%\n",
      "accuracy: 84.68%\n",
      "Overfit: 82.72%\n",
      "accuracy: 74.77%\n",
      "Overfit: 77.76%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.85 is:\n",
      "80.23% (+/- 4.93%)\n",
      "And overfit of 79.52% (+/- 5.03%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 50.00%\n",
      "Overfit: 50.20%\n",
      "accuracy: 62.50%\n",
      "Overfit: 59.44%\n",
      "accuracy: 58.04%\n",
      "Overfit: 61.13%\n",
      "accuracy: 53.57%\n",
      "Overfit: 54.27%\n",
      "accuracy: 89.29%\n",
      "Overfit: 79.82%\n",
      "accuracy: 71.43%\n",
      "Overfit: 75.94%\n",
      "accuracy: 68.75%\n",
      "Overfit: 66.30%\n",
      "accuracy: 50.00%\n",
      "Overfit: 51.29%\n",
      "accuracy: 71.17%\n",
      "Overfit: 65.44%\n",
      "accuracy: 72.97%\n",
      "Overfit: 75.67%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.9 is:\n",
      "64.77% (+/- 11.75%)\n",
      "And overfit of 63.95% (+/- 10.06%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 50.00%\n",
      "Overfit: 50.10%\n",
      "accuracy: 50.89%\n",
      "Overfit: 48.51%\n",
      "accuracy: 50.00%\n",
      "Overfit: 49.90%\n",
      "accuracy: 50.00%\n",
      "Overfit: 49.90%\n",
      "accuracy: 56.25%\n",
      "Overfit: 54.97%\n",
      "accuracy: 50.89%\n",
      "Overfit: 51.09%\n",
      "accuracy: 50.00%\n",
      "Overfit: 49.90%\n",
      "accuracy: 50.00%\n",
      "Overfit: 50.20%\n",
      "accuracy: 50.45%\n",
      "Overfit: 52.63%\n",
      "accuracy: 51.35%\n",
      "Overfit: 52.93%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.95 is:\n",
      "50.98% (+/- 1.82%)\n",
      "And overfit of 51.01% (+/- 1.83%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 50.00%\n",
      "Overfit: 49.90%\n",
      "accuracy: 46.43%\n",
      "Overfit: 47.51%\n",
      "accuracy: 50.00%\n",
      "Overfit: 49.90%\n",
      "accuracy: 50.00%\n",
      "Overfit: 50.10%\n",
      "accuracy: 50.00%\n",
      "Overfit: 49.90%\n",
      "accuracy: 50.00%\n",
      "Overfit: 49.90%\n",
      "accuracy: 50.00%\n",
      "Overfit: 50.00%\n",
      "accuracy: 50.00%\n",
      "Overfit: 50.10%\n",
      "accuracy: 50.45%\n",
      "Overfit: 50.65%\n",
      "accuracy: 50.45%\n",
      "Overfit: 50.05%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.97 is:\n",
      "49.73% (+/- 1.12%)\n",
      "And overfit of 49.80% (+/- 0.79%)\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Only dropout \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "pa = [0,0.02,0.04,0.05,0.11,0.15,0.17,0.19,0.20,0.21,0.23,0.25,0.28,0.33,0.38,0.44,0.50,0.55,0.60,0.65,0.70,0.75,0.80,0.85,0.9,0.95,0.97]\n",
    "\n",
    "\n",
    "for p in pa:\n",
    "\n",
    "    import tensorflow\n",
    "\n",
    "    from numpy.random import seed\n",
    "    seed(1)\n",
    "    tensorflow.random.set_seed(2)\n",
    "\n",
    "\n",
    "    frame = load_frame()\n",
    "    frame = load_quartile(frame)\n",
    "\n",
    "    data_x, data_y, number_of_features = load_all_data_with_mine_static(frame)\n",
    "\n",
    "    data_x = data_x.values\n",
    "    data_y = data_y.values\n",
    "       \n",
    "    seed = 7\n",
    "    np.random.seed(seed)\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed)\n",
    "    cvscores = []\n",
    "    overscores = []\n",
    "\n",
    "    for train, test in kfold.split(data_x, data_y):\n",
    "\n",
    "        model = keras.Sequential()\n",
    "\n",
    "        model.add(keras.layers.Dropout(p, input_shape=(number_of_features,)))\n",
    "        model.add(keras.layers.Dense(40, activation='relu'))\n",
    "        model.add(keras.layers.Dense(20, activation='relu'))\n",
    "        model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        history = model.fit(data_x[train], data_y[train], epochs=2000, verbose=0)\n",
    "\n",
    "        scores = model.evaluate(data_x[test], data_y[test], verbose=0)\n",
    "        overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        print(\"Overfit: %.2f%%\" % (overfit[1]*100))\n",
    "        #print(\"-------------------------------------------\")\n",
    "\n",
    "        cvscores.append(scores[1] * 100)\n",
    "        overscores.append(overfit[1]*100)\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"The result, with a patience of {} is:\".format(p))\n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "    print(\"And overfit of %.2f%% (+/- %.2f%%)\" % (np.mean(overscores), np.std(overscores)))\n",
    "    print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00069: early stopping\n",
      "accuracy: 88.39%\n",
      "Overfit: 86.48%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00088: early stopping\n",
      "accuracy: 83.04%\n",
      "Overfit: 89.07%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00165: early stopping\n",
      "accuracy: 86.61%\n",
      "Overfit: 94.23%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00256: early stopping\n",
      "accuracy: 90.18%\n",
      "Overfit: 95.43%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00144: early stopping\n",
      "accuracy: 91.96%\n",
      "Overfit: 92.74%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00129: early stopping\n",
      "accuracy: 86.61%\n",
      "Overfit: 91.25%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00164: early stopping\n",
      "accuracy: 82.14%\n",
      "Overfit: 93.14%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00182: early stopping\n",
      "accuracy: 89.29%\n",
      "Overfit: 93.44%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00261: early stopping\n",
      "accuracy: 87.39%\n",
      "Overfit: 95.93%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00128: early stopping\n",
      "accuracy: 88.29%\n",
      "Overfit: 92.45%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0 is:\n",
      "87.39% (+/- 2.86%)\n",
      "And overfit of 92.42% (+/- 2.72%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00097: early stopping\n",
      "accuracy: 84.82%\n",
      "Overfit: 87.08%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00131: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 90.66%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00137: early stopping\n",
      "accuracy: 83.93%\n",
      "Overfit: 91.35%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00152: early stopping\n",
      "accuracy: 89.29%\n",
      "Overfit: 91.25%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00201: early stopping\n",
      "accuracy: 87.50%\n",
      "Overfit: 90.66%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00117: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 89.96%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00115: early stopping\n",
      "accuracy: 83.93%\n",
      "Overfit: 88.07%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00099: early stopping\n",
      "accuracy: 83.04%\n",
      "Overfit: 85.79%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00108: early stopping\n",
      "accuracy: 88.29%\n",
      "Overfit: 91.06%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00105: early stopping\n",
      "accuracy: 86.49%\n",
      "Overfit: 89.97%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.02 is:\n",
      "85.87% (+/- 1.93%)\n",
      "And overfit of 89.58% (+/- 1.84%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00100: early stopping\n",
      "accuracy: 81.25%\n",
      "Overfit: 86.58%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00109: early stopping\n",
      "accuracy: 88.39%\n",
      "Overfit: 89.86%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00064: early stopping\n",
      "accuracy: 83.04%\n",
      "Overfit: 86.98%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00102: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 82.90%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00127: early stopping\n",
      "accuracy: 90.18%\n",
      "Overfit: 90.16%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00117: early stopping\n",
      "accuracy: 84.82%\n",
      "Overfit: 89.17%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00149: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 88.87%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00119: early stopping\n",
      "accuracy: 87.50%\n",
      "Overfit: 89.86%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00142: early stopping\n",
      "accuracy: 86.49%\n",
      "Overfit: 90.96%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00133: early stopping\n",
      "accuracy: 87.39%\n",
      "Overfit: 89.77%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.04 is:\n",
      "86.05% (+/- 2.46%)\n",
      "And overfit of 88.51% (+/- 2.28%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00121: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 90.16%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00092: early stopping\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.67%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00127: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 89.26%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00125: early stopping\n",
      "accuracy: 89.29%\n",
      "Overfit: 91.35%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00113: early stopping\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.07%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00113: early stopping\n",
      "accuracy: 83.04%\n",
      "Overfit: 87.08%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00161: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 90.46%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00144: early stopping\n",
      "accuracy: 86.61%\n",
      "Overfit: 89.96%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00110: early stopping\n",
      "accuracy: 85.59%\n",
      "Overfit: 89.18%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00070: early stopping\n",
      "accuracy: 88.29%\n",
      "Overfit: 89.77%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.05 is:\n",
      "86.49% (+/- 1.66%)\n",
      "And overfit of 89.40% (+/- 1.17%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00113: early stopping\n",
      "accuracy: 75.89%\n",
      "Overfit: 74.35%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00133: early stopping\n",
      "accuracy: 82.14%\n",
      "Overfit: 85.49%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00079: early stopping\n",
      "accuracy: 86.61%\n",
      "Overfit: 87.87%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00104: early stopping\n",
      "accuracy: 88.39%\n",
      "Overfit: 88.47%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00185: early stopping\n",
      "accuracy: 84.82%\n",
      "Overfit: 85.59%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00105: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 88.87%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00074: early stopping\n",
      "accuracy: 75.00%\n",
      "Overfit: 79.72%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00084: early stopping\n",
      "accuracy: 75.89%\n",
      "Overfit: 77.93%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00187: early stopping\n",
      "accuracy: 85.59%\n",
      "Overfit: 88.88%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00137: early stopping\n",
      "accuracy: 78.38%\n",
      "Overfit: 83.61%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.11 is:\n",
      "81.84% (+/- 4.83%)\n",
      "And overfit of 84.08% (+/- 4.85%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00115: early stopping\n",
      "accuracy: 79.46%\n",
      "Overfit: 86.98%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00171: early stopping\n",
      "accuracy: 86.61%\n",
      "Overfit: 87.87%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00105: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 87.97%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00094: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 84.39%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00125: early stopping\n",
      "accuracy: 80.36%\n",
      "Overfit: 82.50%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00073: early stopping\n",
      "accuracy: 77.68%\n",
      "Overfit: 71.87%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00209: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 90.66%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00073: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.49%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00070: early stopping\n",
      "accuracy: 83.78%\n",
      "Overfit: 81.33%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00137: early stopping\n",
      "accuracy: 85.59%\n",
      "Overfit: 89.08%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.15 is:\n",
      "83.63% (+/- 3.06%)\n",
      "And overfit of 84.81% (+/- 5.12%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00121: early stopping\n",
      "accuracy: 86.61%\n",
      "Overfit: 88.57%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00082: early stopping\n",
      "accuracy: 78.57%\n",
      "Overfit: 85.09%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00195: early stopping\n",
      "accuracy: 90.18%\n",
      "Overfit: 89.46%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00159: early stopping\n",
      "accuracy: 88.39%\n",
      "Overfit: 90.06%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00162: early stopping\n",
      "accuracy: 90.18%\n",
      "Overfit: 87.08%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00073: early stopping\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.88%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00122: early stopping\n",
      "accuracy: 79.46%\n",
      "Overfit: 87.87%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00122: early stopping\n",
      "accuracy: 87.50%\n",
      "Overfit: 85.79%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00081: early stopping\n",
      "accuracy: 83.78%\n",
      "Overfit: 83.22%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00178: early stopping\n",
      "accuracy: 84.68%\n",
      "Overfit: 88.58%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.17 is:\n",
      "85.33% (+/- 3.84%)\n",
      "And overfit of 87.26% (+/- 2.00%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00137: early stopping\n",
      "accuracy: 84.82%\n",
      "Overfit: 83.80%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00102: early stopping\n",
      "accuracy: 91.07%\n",
      "Overfit: 87.77%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00125: early stopping\n",
      "accuracy: 86.61%\n",
      "Overfit: 85.39%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00097: early stopping\n",
      "accuracy: 88.39%\n",
      "Overfit: 86.58%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00125: early stopping\n",
      "accuracy: 83.04%\n",
      "Overfit: 78.93%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00073: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 86.78%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00110: early stopping\n",
      "accuracy: 80.36%\n",
      "Overfit: 85.79%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00112: early stopping\n",
      "accuracy: 82.14%\n",
      "Overfit: 85.88%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00136: early stopping\n",
      "accuracy: 81.98%\n",
      "Overfit: 86.59%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00174: early stopping\n",
      "accuracy: 84.68%\n",
      "Overfit: 88.08%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.19 is:\n",
      "84.88% (+/- 3.07%)\n",
      "And overfit of 85.56% (+/- 2.49%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00100: early stopping\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.77%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00125: early stopping\n",
      "accuracy: 82.14%\n",
      "Overfit: 81.31%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00201: early stopping\n",
      "accuracy: 90.18%\n",
      "Overfit: 88.77%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00170: early stopping\n",
      "accuracy: 80.36%\n",
      "Overfit: 78.53%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00094: early stopping\n",
      "accuracy: 79.46%\n",
      "Overfit: 83.90%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00077: early stopping\n",
      "accuracy: 86.61%\n",
      "Overfit: 84.79%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00104: early stopping\n",
      "accuracy: 78.57%\n",
      "Overfit: 87.57%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00114: early stopping\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.39%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00148: early stopping\n",
      "accuracy: 79.28%\n",
      "Overfit: 86.30%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00072: early stopping\n",
      "accuracy: 77.48%\n",
      "Overfit: 83.02%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.2 is:\n",
      "82.37% (+/- 4.07%)\n",
      "And overfit of 84.73% (+/- 3.11%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00095: early stopping\n",
      "accuracy: 88.39%\n",
      "Overfit: 87.18%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00201: early stopping\n",
      "accuracy: 87.50%\n",
      "Overfit: 88.57%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00110: early stopping\n",
      "accuracy: 86.61%\n",
      "Overfit: 87.87%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00092: early stopping\n",
      "accuracy: 90.18%\n",
      "Overfit: 87.28%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00112: early stopping\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.78%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00122: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 87.28%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00092: early stopping\n",
      "accuracy: 82.14%\n",
      "Overfit: 86.48%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00099: early stopping\n",
      "accuracy: 82.14%\n",
      "Overfit: 83.80%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00125: early stopping\n",
      "accuracy: 78.38%\n",
      "Overfit: 88.18%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00084: early stopping\n",
      "accuracy: 80.18%\n",
      "Overfit: 83.71%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.21 is:\n",
      "84.87% (+/- 3.70%)\n",
      "And overfit of 86.71% (+/- 1.59%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00170: early stopping\n",
      "accuracy: 84.82%\n",
      "Overfit: 88.37%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00091: early stopping\n",
      "accuracy: 81.25%\n",
      "Overfit: 86.48%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00082: early stopping\n",
      "accuracy: 83.04%\n",
      "Overfit: 83.90%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00097: early stopping\n",
      "accuracy: 91.07%\n",
      "Overfit: 87.57%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00166: early stopping\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.68%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00140: early stopping\n",
      "accuracy: 83.04%\n",
      "Overfit: 87.57%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00099: early stopping\n",
      "accuracy: 80.36%\n",
      "Overfit: 86.88%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00112: early stopping\n",
      "accuracy: 79.46%\n",
      "Overfit: 84.39%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00108: early stopping\n",
      "accuracy: 81.08%\n",
      "Overfit: 86.30%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00076: early stopping\n",
      "accuracy: 80.18%\n",
      "Overfit: 85.00%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.23 is:\n",
      "83.36% (+/- 3.75%)\n",
      "And overfit of 86.31% (+/- 1.38%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00138: early stopping\n",
      "accuracy: 86.61%\n",
      "Overfit: 86.48%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00120: early stopping\n",
      "accuracy: 86.61%\n",
      "Overfit: 86.98%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00126: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 85.49%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00125: early stopping\n",
      "accuracy: 89.29%\n",
      "Overfit: 87.48%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00110: early stopping\n",
      "accuracy: 84.82%\n",
      "Overfit: 86.08%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00159: early stopping\n",
      "accuracy: 86.61%\n",
      "Overfit: 86.88%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00095: early stopping\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.10%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00092: early stopping\n",
      "accuracy: 86.61%\n",
      "Overfit: 85.49%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00148: early stopping\n",
      "accuracy: 83.78%\n",
      "Overfit: 85.80%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00089: early stopping\n",
      "accuracy: 82.88%\n",
      "Overfit: 84.91%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.25 is:\n",
      "85.51% (+/- 2.02%)\n",
      "And overfit of 85.97% (+/- 0.98%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00149: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 88.17%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00077: early stopping\n",
      "accuracy: 83.93%\n",
      "Overfit: 85.19%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00089: early stopping\n",
      "accuracy: 91.07%\n",
      "Overfit: 86.88%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00129: early stopping\n",
      "accuracy: 89.29%\n",
      "Overfit: 86.68%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00166: early stopping\n",
      "accuracy: 84.82%\n",
      "Overfit: 81.31%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00159: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 87.77%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00120: early stopping\n",
      "accuracy: 80.36%\n",
      "Overfit: 86.88%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00176: early stopping\n",
      "accuracy: 83.04%\n",
      "Overfit: 85.09%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00125: early stopping\n",
      "accuracy: 80.18%\n",
      "Overfit: 85.90%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00069: early stopping\n",
      "accuracy: 80.18%\n",
      "Overfit: 83.52%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.28 is:\n",
      "84.43% (+/- 3.55%)\n",
      "And overfit of 85.74% (+/- 1.97%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00092: early stopping\n",
      "accuracy: 75.00%\n",
      "Overfit: 77.83%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00163: early stopping\n",
      "accuracy: 86.61%\n",
      "Overfit: 86.08%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00167: early stopping\n",
      "accuracy: 83.04%\n",
      "Overfit: 83.60%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00092: early stopping\n",
      "accuracy: 79.46%\n",
      "Overfit: 78.43%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00129: early stopping\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.39%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00092: early stopping\n",
      "accuracy: 81.25%\n",
      "Overfit: 86.08%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00092: early stopping\n",
      "accuracy: 76.79%\n",
      "Overfit: 85.59%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00094: early stopping\n",
      "accuracy: 74.11%\n",
      "Overfit: 79.82%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00136: early stopping\n",
      "accuracy: 82.88%\n",
      "Overfit: 83.81%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00114: early stopping\n",
      "accuracy: 81.08%\n",
      "Overfit: 85.40%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.33 is:\n",
      "80.24% (+/- 3.72%)\n",
      "And overfit of 83.10% (+/- 3.03%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00110: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 86.18%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00091: early stopping\n",
      "accuracy: 83.04%\n",
      "Overfit: 84.79%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00136: early stopping\n",
      "accuracy: 90.18%\n",
      "Overfit: 85.29%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00125: early stopping\n",
      "accuracy: 86.61%\n",
      "Overfit: 85.79%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00156: early stopping\n",
      "accuracy: 87.50%\n",
      "Overfit: 86.48%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00092: early stopping\n",
      "accuracy: 83.93%\n",
      "Overfit: 86.58%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00094: early stopping\n",
      "accuracy: 81.25%\n",
      "Overfit: 86.08%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00151: early stopping\n",
      "accuracy: 81.25%\n",
      "Overfit: 77.83%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00072: early stopping\n",
      "accuracy: 83.78%\n",
      "Overfit: 82.92%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00089: early stopping\n",
      "accuracy: 71.17%\n",
      "Overfit: 79.05%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.38 is:\n",
      "83.44% (+/- 4.88%)\n",
      "And overfit of 84.10% (+/- 3.02%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00140: early stopping\n",
      "accuracy: 87.50%\n",
      "Overfit: 84.99%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00130: early stopping\n",
      "accuracy: 83.93%\n",
      "Overfit: 85.69%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00172: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 82.80%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00077: early stopping\n",
      "accuracy: 68.75%\n",
      "Overfit: 72.27%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00189: early stopping\n",
      "accuracy: 90.18%\n",
      "Overfit: 84.49%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00106: early stopping\n",
      "accuracy: 80.36%\n",
      "Overfit: 82.70%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00094: early stopping\n",
      "accuracy: 71.43%\n",
      "Overfit: 81.11%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00100: early stopping\n",
      "accuracy: 75.89%\n",
      "Overfit: 74.95%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00081: early stopping\n",
      "accuracy: 77.48%\n",
      "Overfit: 82.62%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00072: early stopping\n",
      "accuracy: 80.18%\n",
      "Overfit: 83.61%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.44 is:\n",
      "80.14% (+/- 6.57%)\n",
      "And overfit of 81.52% (+/- 4.19%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00140: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 84.99%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00071: early stopping\n",
      "accuracy: 81.25%\n",
      "Overfit: 82.50%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00091: early stopping\n",
      "accuracy: 89.29%\n",
      "Overfit: 83.90%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00131: early stopping\n",
      "accuracy: 86.61%\n",
      "Overfit: 81.51%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00119: early stopping\n",
      "accuracy: 87.50%\n",
      "Overfit: 83.00%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00075: early stopping\n",
      "accuracy: 83.93%\n",
      "Overfit: 85.69%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00123: early stopping\n",
      "accuracy: 76.79%\n",
      "Overfit: 82.41%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00104: early stopping\n",
      "accuracy: 78.57%\n",
      "Overfit: 77.83%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00068: early stopping\n",
      "accuracy: 80.18%\n",
      "Overfit: 82.72%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00132: early stopping\n",
      "accuracy: 79.28%\n",
      "Overfit: 81.73%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.5 is:\n",
      "82.91% (+/- 4.05%)\n",
      "And overfit of 82.63% (+/- 2.04%)\n",
      "-------------------------------------------\n",
      "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00082: early stopping\n",
      "accuracy: 81.25%\n",
      "Overfit: 83.70%\n",
      "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00058: early stopping\n",
      "accuracy: 78.57%\n",
      "Overfit: 79.03%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00091: early stopping\n",
      "accuracy: 89.29%\n",
      "Overfit: 81.91%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00101: early stopping\n",
      "accuracy: 75.00%\n",
      "Overfit: 73.56%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00169: early stopping\n",
      "accuracy: 87.50%\n",
      "Overfit: 82.41%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00075: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 81.71%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00086: early stopping\n",
      "accuracy: 70.54%\n",
      "Overfit: 75.05%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00117: early stopping\n",
      "accuracy: 71.43%\n",
      "Overfit: 74.06%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00065: early stopping\n",
      "accuracy: 78.38%\n",
      "Overfit: 81.83%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00118: early stopping\n",
      "accuracy: 83.78%\n",
      "Overfit: 86.10%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.55 is:\n",
      "80.14% (+/- 6.19%)\n",
      "And overfit of 79.93% (+/- 4.11%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00090: early stopping\n",
      "accuracy: 79.46%\n",
      "Overfit: 83.30%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00142: early stopping\n",
      "accuracy: 81.25%\n",
      "Overfit: 77.44%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00122: early stopping\n",
      "accuracy: 87.50%\n",
      "Overfit: 77.73%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00092: early stopping\n",
      "accuracy: 80.36%\n",
      "Overfit: 81.41%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00092: early stopping\n",
      "accuracy: 80.36%\n",
      "Overfit: 77.93%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00094: early stopping\n",
      "accuracy: 83.04%\n",
      "Overfit: 83.80%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00097: early stopping\n",
      "accuracy: 76.79%\n",
      "Overfit: 82.41%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00094: early stopping\n",
      "accuracy: 66.96%\n",
      "Overfit: 69.78%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00125: early stopping\n",
      "accuracy: 78.38%\n",
      "Overfit: 85.50%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00090: early stopping\n",
      "accuracy: 75.68%\n",
      "Overfit: 82.32%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.6 is:\n",
      "78.98% (+/- 5.09%)\n",
      "And overfit of 80.16% (+/- 4.35%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00069: early stopping\n",
      "accuracy: 71.43%\n",
      "Overfit: 79.82%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00071: early stopping\n",
      "accuracy: 69.64%\n",
      "Overfit: 70.08%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00100: early stopping\n",
      "accuracy: 83.04%\n",
      "Overfit: 76.14%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00143: early stopping\n",
      "accuracy: 70.54%\n",
      "Overfit: 71.37%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00119: early stopping\n",
      "accuracy: 67.86%\n",
      "Overfit: 71.07%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00073: early stopping\n",
      "accuracy: 51.79%\n",
      "Overfit: 54.37%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00152: early stopping\n",
      "accuracy: 73.21%\n",
      "Overfit: 81.11%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00090: early stopping\n",
      "accuracy: 75.00%\n",
      "Overfit: 78.43%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00083: early stopping\n",
      "accuracy: 82.88%\n",
      "Overfit: 81.63%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00067: early stopping\n",
      "accuracy: 77.48%\n",
      "Overfit: 75.47%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.65 is:\n",
      "72.29% (+/- 8.45%)\n",
      "And overfit of 73.95% (+/- 7.65%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00115: early stopping\n",
      "accuracy: 80.36%\n",
      "Overfit: 82.50%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00108: early stopping\n",
      "accuracy: 82.14%\n",
      "Overfit: 84.19%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00099: early stopping\n",
      "accuracy: 59.82%\n",
      "Overfit: 55.47%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00080: early stopping\n",
      "accuracy: 75.89%\n",
      "Overfit: 76.94%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00067: early stopping\n",
      "accuracy: 50.89%\n",
      "Overfit: 50.20%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00094: early stopping\n",
      "accuracy: 85.71%\n",
      "Overfit: 84.49%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00094: early stopping\n",
      "accuracy: 63.39%\n",
      "Overfit: 64.91%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00109: early stopping\n",
      "accuracy: 75.00%\n",
      "Overfit: 76.44%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00134: early stopping\n",
      "accuracy: 79.28%\n",
      "Overfit: 79.44%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00139: early stopping\n",
      "accuracy: 65.77%\n",
      "Overfit: 75.57%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.7 is:\n",
      "71.83% (+/- 10.70%)\n",
      "And overfit of 73.02% (+/- 11.47%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00130: early stopping\n",
      "accuracy: 81.25%\n",
      "Overfit: 83.90%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00108: early stopping\n",
      "accuracy: 76.79%\n",
      "Overfit: 81.81%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00117: early stopping\n",
      "accuracy: 84.82%\n",
      "Overfit: 76.54%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00109: early stopping\n",
      "accuracy: 80.36%\n",
      "Overfit: 78.13%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00092: early stopping\n",
      "accuracy: 71.43%\n",
      "Overfit: 68.49%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00117: early stopping\n",
      "accuracy: 69.64%\n",
      "Overfit: 64.71%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00109: early stopping\n",
      "accuracy: 76.79%\n",
      "Overfit: 83.60%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00082: early stopping\n",
      "accuracy: 69.64%\n",
      "Overfit: 68.39%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00116: early stopping\n",
      "accuracy: 72.07%\n",
      "Overfit: 73.19%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00085: early stopping\n",
      "accuracy: 73.87%\n",
      "Overfit: 73.39%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.75 is:\n",
      "75.67% (+/- 4.96%)\n",
      "And overfit of 75.21% (+/- 6.40%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00090: early stopping\n",
      "accuracy: 83.04%\n",
      "Overfit: 80.52%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00106: early stopping\n",
      "accuracy: 77.68%\n",
      "Overfit: 78.93%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00088: early stopping\n",
      "accuracy: 81.25%\n",
      "Overfit: 70.68%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00106: early stopping\n",
      "accuracy: 74.11%\n",
      "Overfit: 73.16%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00140: early stopping\n",
      "accuracy: 50.00%\n",
      "Overfit: 50.70%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00067: early stopping\n",
      "accuracy: 75.89%\n",
      "Overfit: 68.89%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00130: early stopping\n",
      "accuracy: 77.68%\n",
      "Overfit: 71.17%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00110: early stopping\n",
      "accuracy: 75.00%\n",
      "Overfit: 77.93%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00071: early stopping\n",
      "accuracy: 77.48%\n",
      "Overfit: 72.39%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00083: early stopping\n",
      "accuracy: 69.37%\n",
      "Overfit: 71.90%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.8 is:\n",
      "74.15% (+/- 8.80%)\n",
      "And overfit of 71.63% (+/- 7.89%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00092: early stopping\n",
      "accuracy: 81.25%\n",
      "Overfit: 81.61%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00106: early stopping\n",
      "accuracy: 65.18%\n",
      "Overfit: 66.10%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00105: early stopping\n",
      "accuracy: 82.14%\n",
      "Overfit: 75.84%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00106: early stopping\n",
      "accuracy: 55.36%\n",
      "Overfit: 56.46%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00109: early stopping\n",
      "accuracy: 50.00%\n",
      "Overfit: 50.20%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00078: early stopping\n",
      "accuracy: 58.04%\n",
      "Overfit: 60.34%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00092: early stopping\n",
      "accuracy: 66.96%\n",
      "Overfit: 66.60%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00108: early stopping\n",
      "accuracy: 72.32%\n",
      "Overfit: 76.04%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00164: early stopping\n",
      "accuracy: 77.48%\n",
      "Overfit: 75.87%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00093: early stopping\n",
      "accuracy: 69.37%\n",
      "Overfit: 69.91%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.85 is:\n",
      "67.81% (+/- 10.38%)\n",
      "And overfit of 67.90% (+/- 9.44%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00087: early stopping\n",
      "accuracy: 80.36%\n",
      "Overfit: 81.31%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00135: early stopping\n",
      "accuracy: 71.43%\n",
      "Overfit: 72.86%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00089: early stopping\n",
      "accuracy: 58.93%\n",
      "Overfit: 56.96%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00089: early stopping\n",
      "accuracy: 78.57%\n",
      "Overfit: 79.22%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00127: early stopping\n",
      "accuracy: 51.79%\n",
      "Overfit: 51.09%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00108: early stopping\n",
      "accuracy: 59.82%\n",
      "Overfit: 59.54%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00096: early stopping\n",
      "accuracy: 70.54%\n",
      "Overfit: 73.66%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00102: early stopping\n",
      "accuracy: 75.89%\n",
      "Overfit: 78.53%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00122: early stopping\n",
      "accuracy: 50.45%\n",
      "Overfit: 50.35%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00072: early stopping\n",
      "accuracy: 57.66%\n",
      "Overfit: 57.00%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.9 is:\n",
      "65.54% (+/- 10.54%)\n",
      "And overfit of 66.05% (+/- 11.59%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00094: early stopping\n",
      "accuracy: 78.57%\n",
      "Overfit: 76.74%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00094: early stopping\n",
      "accuracy: 66.96%\n",
      "Overfit: 65.41%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00087: early stopping\n",
      "accuracy: 82.14%\n",
      "Overfit: 76.34%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00094: early stopping\n",
      "accuracy: 56.25%\n",
      "Overfit: 57.95%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00132: early stopping\n",
      "accuracy: 68.75%\n",
      "Overfit: 61.53%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00104: early stopping\n",
      "accuracy: 50.00%\n",
      "Overfit: 50.50%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00104: early stopping\n",
      "accuracy: 57.14%\n",
      "Overfit: 56.46%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00067: early stopping\n",
      "accuracy: 43.75%\n",
      "Overfit: 45.23%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00070: early stopping\n",
      "accuracy: 74.77%\n",
      "Overfit: 72.10%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00084: early stopping\n",
      "accuracy: 72.97%\n",
      "Overfit: 74.28%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.95 is:\n",
      "65.13% (+/- 12.12%)\n",
      "And overfit of 63.65% (+/- 10.59%)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00132: early stopping\n",
      "accuracy: 50.00%\n",
      "Overfit: 50.30%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00062: early stopping\n",
      "accuracy: 62.50%\n",
      "Overfit: 69.28%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00065: early stopping\n",
      "accuracy: 51.79%\n",
      "Overfit: 51.39%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00079: early stopping\n",
      "accuracy: 57.14%\n",
      "Overfit: 53.78%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00103: early stopping\n",
      "accuracy: 56.25%\n",
      "Overfit: 52.39%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00143: early stopping\n",
      "accuracy: 60.71%\n",
      "Overfit: 58.95%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00123: early stopping\n",
      "accuracy: 62.50%\n",
      "Overfit: 62.13%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00170: early stopping\n",
      "accuracy: 58.04%\n",
      "Overfit: 58.75%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00062: early stopping\n",
      "accuracy: 52.25%\n",
      "Overfit: 52.23%\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00062: early stopping\n",
      "accuracy: 45.95%\n",
      "Overfit: 45.08%\n",
      "-------------------------------------------\n",
      "The result, with a patience of 0.97 is:\n",
      "55.71% (+/- 5.29%)\n",
      "And overfit of 55.43% (+/- 6.57%)\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Only dropout \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "pa = [0,0.02,0.04,0.05,0.11,0.15,0.17,0.19,0.20,0.21,0.23,0.25,0.28,0.33,0.38,0.44,0.50,0.55,0.60,0.65,0.70,0.75,0.80,0.85,0.9,0.95,0.97]\n",
    "\n",
    "\n",
    "for p in pa:\n",
    "\n",
    "    import tensorflow\n",
    "\n",
    "    from numpy.random import seed\n",
    "    seed(1)\n",
    "    tensorflow.random.set_seed(2)\n",
    "\n",
    "\n",
    "    frame = load_frame()\n",
    "    frame = load_quartile(frame)\n",
    "\n",
    "    data_x, data_y, number_of_features = load_all_data_with_mine_static(frame)\n",
    "\n",
    "    data_x = data_x.values\n",
    "    data_y = data_y.values\n",
    "       \n",
    "    seed = 7\n",
    "    np.random.seed(seed)\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed)\n",
    "    cvscores = []\n",
    "    overscores = []\n",
    "\n",
    "    for train, test in kfold.split(data_x, data_y):\n",
    "\n",
    "        model = keras.Sequential()\n",
    "\n",
    "        model.add(keras.layers.Dropout(p, input_shape=(number_of_features,)))\n",
    "        model.add(keras.layers.Dense(40, activation='relu'))\n",
    "        model.add(keras.layers.Dense(20, activation='relu'))\n",
    "        model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "        early_stopping_monitor = keras.callbacks.EarlyStopping(monitor='accuracy', min_delta=0.003, patience=40, verbose=1, mode='max', restore_best_weights=True)\n",
    "\n",
    "        history = model.fit(data_x[train], data_y[train], epochs=2000, verbose=0,\n",
    "                            callbacks=[early_stopping_monitor])\n",
    "        \n",
    "        scores = model.evaluate(data_x[test], data_y[test], verbose=0)\n",
    "        overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        print(\"Overfit: %.2f%%\" % (overfit[1]*100))\n",
    "        #print(\"-------------------------------------------\")\n",
    "\n",
    "        cvscores.append(scores[1] * 100)\n",
    "        overscores.append(overfit[1]*100)\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"The result, with a patience of {} is:\".format(p))\n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "    print(\"And overfit of %.2f%% (+/- %.2f%%)\" % (np.mean(overscores), np.std(overscores)))\n",
    "    print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 0.17132797837257385\n",
      "Overfit mae: 0.11431755870580673\n",
      "mae: 0.21339420974254608\n",
      "Overfit mae: 0.22781069576740265\n",
      "mae: 0.13745127618312836\n",
      "Overfit mae: 0.10758867859840393\n",
      "mae: 0.1259179264307022\n",
      "Overfit mae: 0.10969855636358261\n",
      "mae: 0.24461963772773743\n",
      "Overfit mae: 0.22527958452701569\n",
      "mae: 0.12540178000926971\n",
      "Overfit mae: 0.10915671288967133\n",
      "mae: 0.13794752955436707\n",
      "Overfit mae: 0.09840158373117447\n",
      "mae: 0.21876104176044464\n",
      "Overfit mae: 0.2282463014125824\n",
      "mae: 0.2231644243001938\n",
      "Overfit mae: 0.2274065464735031\n",
      "mae: 0.21518519520759583\n",
      "Overfit mae: 0.22836452722549438\n",
      "-------------------------------------------\n",
      "Final results\n",
      "0.18131710588932037 (+/- 0.04408735781908035)\n",
      "And overfit of 0.16762706637382507 (+/- 0.05991357937455177)\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "\n",
    "frame = load_frame()\n",
    "data_x, data_y, number_of_features = load_all_data_with_mine_static(frame)\n",
    "data_y = pd.concat([frame.mutation], axis = 1).round(2) #.mul(10)\n",
    "\n",
    "\n",
    "data_x = data_x.values\n",
    "data_y = data_y.values\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = KFold(n_splits=10, shuffle=False, random_state=seed)\n",
    "cvscores = []\n",
    "overscores = []\n",
    "\n",
    "for train, test in kfold.split(data_x, data_y):\n",
    "\n",
    "    #x_validation, x_test, y_validation, y_test = train_test_split(data_x[validation_and_test], data_y[validation_and_test], test_size=.5, random_state=seed)\n",
    "\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(number_of_features, activation='relu', input_dim=number_of_features))\n",
    "    model.add(keras.layers.Dense(40, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(20, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mae'])\n",
    "\n",
    "\n",
    "    #early_stopping_monitor = keras.callbacks.EarlyStopping(patience=1,restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(data_x[train], data_y[train], epochs=2000, verbose=0)#,\n",
    "                        #validation_data=(x_validation, y_validation), callbacks=[early_stopping_monitor])\n",
    "\n",
    "\n",
    "        \n",
    "    scores = model.evaluate(data_x[test], data_y[test], verbose=0)\n",
    "    overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "    print('{}: {}'.format(model.metrics_names[1], scores[1]))\n",
    "    print('Overfit {}: {}'.format(model.metrics_names[1], overfit[1]))\n",
    "    #print(\"-------------------------------------------\")\n",
    "\n",
    "    cvscores.append(scores[1])\n",
    "    overscores.append(overfit[1])\n",
    "    \n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Final results\")\n",
    "print('{} (+/- {})'.format(np.mean(cvscores), np.std(cvscores)))\n",
    "print('And overfit of {} (+/- {})'.format(np.mean(overscores), np.std(overscores)))\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 0.16852757334709167\n",
      "Overfit mae: 0.10190494358539581\n",
      "mae: 0.2133183777332306\n",
      "Overfit mae: 0.22775670886039734\n",
      "mae: 0.13833077251911163\n",
      "Overfit mae: 0.0948004275560379\n",
      "mae: 0.12880386412143707\n",
      "Overfit mae: 0.11386672407388687\n",
      "mae: 0.16476523876190186\n",
      "Overfit mae: 0.11010368913412094\n",
      "mae: 0.2405385971069336\n",
      "Overfit mae: 0.22614240646362305\n",
      "mae: 0.13541461527347565\n",
      "Overfit mae: 0.07905972003936768\n",
      "mae: 0.2184688299894333\n",
      "Overfit mae: 0.22797422111034393\n",
      "mae: 0.2232544720172882\n",
      "Overfit mae: 0.22750604152679443\n",
      "mae: 0.14856231212615967\n",
      "Overfit mae: 0.10749660432338715\n",
      "-------------------------------------------\n",
      "Final results\n",
      "0.17799845337867737 (+/- 0.03972787782549858)\n",
      "And overfit of 0.15166115760803223 (+/- 0.062449872493743896)\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "\n",
    "frame = load_frame()\n",
    "data_x, data_y, number_of_features = load_all_data_static(frame)\n",
    "data_y = pd.concat([frame.mutation], axis = 1).round(2) #.mul(10)\n",
    "\n",
    "\n",
    "data_x = data_x.values\n",
    "data_y = data_y.values\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = KFold(n_splits=10, shuffle=False, random_state=seed)\n",
    "cvscores = []\n",
    "overscores = []\n",
    "\n",
    "for train, test in kfold.split(data_x, data_y):\n",
    "\n",
    "    #x_validation, x_test, y_validation, y_test = train_test_split(data_x[validation_and_test], data_y[validation_and_test], test_size=.5, random_state=seed)\n",
    "\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(number_of_features, activation='relu', input_dim=number_of_features))\n",
    "    model.add(keras.layers.Dense(40, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(20, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mae'])\n",
    "\n",
    "\n",
    "    #early_stopping_monitor = keras.callbacks.EarlyStopping(patience=1,restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(data_x[train], data_y[train], epochs=2000, verbose=0)#,\n",
    "                        #validation_data=(x_validation, y_validation), callbacks=[early_stopping_monitor])\n",
    "\n",
    "\n",
    "        \n",
    "    scores = model.evaluate(data_x[test], data_y[test], verbose=0)\n",
    "    overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "    print('{}: {}'.format(model.metrics_names[1], scores[1]))\n",
    "    print('Overfit {}: {}'.format(model.metrics_names[1], overfit[1]))\n",
    "    #print(\"-------------------------------------------\")\n",
    "\n",
    "    cvscores.append(scores[1])\n",
    "    overscores.append(overfit[1])\n",
    "    \n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Final results\")\n",
    "print('{} (+/- {})'.format(np.mean(cvscores), np.std(cvscores)))\n",
    "print('And overfit of {} (+/- {})'.format(np.mean(overscores), np.std(overscores)))\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2018 samples\n",
      "Epoch 1/2000\n",
      "2018/2018 [==============================] - 2s 832us/sample - loss: 43200.4320 - mae: 33.7596\n",
      "Epoch 2/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 32469.6353 - mae: 41.4310\n",
      "Epoch 3/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 12226.0816 - mae: 22.7271\n",
      "Epoch 4/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 8102.8799 - mae: 14.9574\n",
      "Epoch 5/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 14157.9800 - mae: 18.8441\n",
      "Epoch 6/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 23780.4693 - mae: 26.6500\n",
      "Epoch 7/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 4082.3070 - mae: 12.3490\n",
      "Epoch 8/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 9457.1414 - mae: 15.9385\n",
      "Epoch 9/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 17731.3191 - mae: 24.8896\n",
      "Epoch 10/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 52814.4196 - mae: 38.7415\n",
      "Epoch 11/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 34754.9409 - mae: 28.3024\n",
      "Epoch 12/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 8439.0046 - mae: 16.5404\n",
      "Epoch 13/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 2261.1262 - mae: 9.2329\n",
      "Epoch 14/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 540.8894 - mae: 5.7308\n",
      "Epoch 15/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 809.1645 - mae: 6.7105\n",
      "Epoch 16/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 2640.7591 - mae: 10.2047\n",
      "Epoch 17/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 2364.4818 - mae: 8.1346\n",
      "Epoch 18/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 455.5164 - mae: 5.7131\n",
      "Epoch 19/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 541.8954 - mae: 5.5468\n",
      "Epoch 20/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 1392.4795 - mae: 7.7705\n",
      "Epoch 21/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 3339.5699 - mae: 8.5152\n",
      "Epoch 22/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 10429.4253 - mae: 20.0078\n",
      "Epoch 23/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 3957.4987 - mae: 12.3312\n",
      "Epoch 24/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 3351.3812 - mae: 8.9583\n",
      "Epoch 25/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 2990.5588 - mae: 11.4343\n",
      "Epoch 26/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 1452.9263 - mae: 7.3325\n",
      "Epoch 27/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 340.8122 - mae: 4.0249\n",
      "Epoch 28/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 1665.5792 - mae: 6.8670\n",
      "Epoch 29/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 844.9382 - mae: 6.1938\n",
      "Epoch 30/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 422.6422 - mae: 4.4421\n",
      "Epoch 31/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 2234.0423 - mae: 8.4755\n",
      "Epoch 32/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 2483.6749 - mae: 8.7350\n",
      "Epoch 33/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 7722.9859 - mae: 12.4030\n",
      "Epoch 34/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 794.9107 - mae: 6.2342\n",
      "Epoch 35/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 7272.6988 - mae: 13.8589\n",
      "Epoch 36/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 7943.6266 - mae: 16.0321\n",
      "Epoch 37/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 1697.7531 - mae: 9.2345\n",
      "Epoch 38/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 2304.3887 - mae: 9.3326\n",
      "Epoch 39/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 4946.3661 - mae: 14.7289\n",
      "Epoch 40/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 3459.8018 - mae: 11.1396\n",
      "Epoch 41/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 8936.3849 - mae: 14.4366\n",
      "Epoch 42/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 6274.1286 - mae: 10.2615\n",
      "Epoch 43/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 666.0485 - mae: 4.8309\n",
      "Epoch 44/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 3184.5382 - mae: 8.2396\n",
      "Epoch 45/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 1588.0790 - mae: 6.2422\n",
      "Epoch 46/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 15969.3737 - mae: 18.2157\n",
      "Epoch 47/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 2825.0622 - mae: 7.1197\n",
      "Epoch 48/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 2648.0101 - mae: 10.7525\n",
      "Epoch 49/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 1506.4067 - mae: 7.3907\n",
      "Epoch 50/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 1316.3206 - mae: 6.0558\n",
      "Epoch 51/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 473.8079 - mae: 4.4815\n",
      "Epoch 52/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 977.3263 - mae: 5.9825\n",
      "Epoch 53/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 900.3386 - mae: 4.9149\n",
      "Epoch 54/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 942.6232 - mae: 4.5871\n",
      "Epoch 55/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 1347.4892 - mae: 4.8735\n",
      "Epoch 56/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 2425.8472 - mae: 6.4145\n",
      "Epoch 57/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 2591.7970 - mae: 6.6506\n",
      "Epoch 58/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 1580.0849 - mae: 6.4162\n",
      "Epoch 59/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 1023.3302 - mae: 4.6445\n",
      "Epoch 60/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 379.0196 - mae: 3.6552\n",
      "Epoch 61/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 115.1806 - mae: 2.7381\n",
      "Epoch 62/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 106.5058 - mae: 2.4273\n",
      "Epoch 63/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 32.7035 - mae: 1.8722\n",
      "Epoch 64/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 44.3781 - mae: 2.0867\n",
      "Epoch 65/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 67.7141 - mae: 2.0808\n",
      "Epoch 66/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 25.8367 - mae: 1.8191\n",
      "Epoch 67/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 41.7399 - mae: 1.8882\n",
      "Epoch 68/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 49.0275 - mae: 1.9643\n",
      "Epoch 69/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 30.9241 - mae: 1.8752\n",
      "Epoch 70/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 56.4272 - mae: 2.0328\n",
      "Epoch 71/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 20.4264 - mae: 1.7197\n",
      "Epoch 72/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 17.2979 - mae: 1.6422\n",
      "Epoch 73/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 18.5500 - mae: 1.6301\n",
      "Epoch 74/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 16.5383 - mae: 1.5944\n",
      "Epoch 75/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 16.6067 - mae: 1.5967\n",
      "Epoch 76/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 14.4717 - mae: 1.5446\n",
      "Epoch 77/2000\n",
      "2018/2018 [==============================] - 0s 102us/sample - loss: 13.4492 - mae: 1.5104\n",
      "Epoch 78/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 98us/sample - loss: 12.9186 - mae: 1.4947\n",
      "Epoch 79/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 13.3049 - mae: 1.5059\n",
      "Epoch 80/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 16.9405 - mae: 1.5593\n",
      "Epoch 81/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 18.7278 - mae: 1.5156\n",
      "Epoch 82/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 12.0640 - mae: 1.4487\n",
      "Epoch 83/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 13.4928 - mae: 1.4593\n",
      "Epoch 84/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 23.9651 - mae: 1.5408\n",
      "Epoch 85/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 10.9990 - mae: 1.3815\n",
      "Epoch 86/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 10.0536 - mae: 1.4197\n",
      "Epoch 87/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 78.3916 - mae: 1.9893\n",
      "Epoch 88/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 332.2876 - mae: 2.3209\n",
      "Epoch 89/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 43.1162 - mae: 1.7633\n",
      "Epoch 90/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 344.2663 - mae: 3.4976\n",
      "Epoch 91/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 1765.2226 - mae: 5.4952\n",
      "Epoch 92/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 2586.0682 - mae: 7.7947\n",
      "Epoch 93/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 1118.0644 - mae: 6.3794\n",
      "Epoch 94/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 303.7154 - mae: 3.5641\n",
      "Epoch 95/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 171.5579 - mae: 2.3429\n",
      "Epoch 96/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 54.5155 - mae: 2.0890\n",
      "Epoch 97/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 45.4057 - mae: 1.7855\n",
      "Epoch 98/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 29.8116 - mae: 1.6872\n",
      "Epoch 99/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 39.0623 - mae: 1.6802\n",
      "Epoch 100/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 17.8377 - mae: 1.5221\n",
      "Epoch 101/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 27.6489 - mae: 1.6006\n",
      "Epoch 102/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 13.3952 - mae: 1.4106\n",
      "Epoch 103/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 29.7124 - mae: 1.4551\n",
      "Epoch 104/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 13.0215 - mae: 1.3547\n",
      "Epoch 105/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 10.9000 - mae: 1.2942\n",
      "Epoch 106/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 18.0559 - mae: 1.4354\n",
      "Epoch 107/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 12.3434 - mae: 1.3832\n",
      "Epoch 108/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 12.8887 - mae: 1.2955\n",
      "Epoch 109/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 24.0774 - mae: 1.4089\n",
      "Epoch 110/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 21.0723 - mae: 1.4041\n",
      "Epoch 111/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 11.5930 - mae: 1.2937\n",
      "Epoch 112/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 7.4177 - mae: 1.1228\n",
      "Epoch 113/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 8.5716 - mae: 1.1583\n",
      "Epoch 114/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 8.1194 - mae: 1.1319\n",
      "Epoch 115/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 9.9426 - mae: 1.1352\n",
      "Epoch 116/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 23.0163 - mae: 1.3809\n",
      "Epoch 117/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 22.9865 - mae: 1.5029\n",
      "Epoch 118/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 697.0682 - mae: 4.7953\n",
      "Epoch 119/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 523.2511 - mae: 4.2601\n",
      "Epoch 120/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 118.5624 - mae: 2.5507\n",
      "Epoch 121/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 80.9144 - mae: 2.1383\n",
      "Epoch 122/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 21.2473 - mae: 1.4426\n",
      "Epoch 123/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 10.5454 - mae: 1.2121\n",
      "Epoch 124/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 9.1398 - mae: 1.1076\n",
      "Epoch 125/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 6.6013 - mae: 1.0693\n",
      "Epoch 126/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 22.2213 - mae: 1.3071\n",
      "Epoch 127/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 5.3877 - mae: 0.9878\n",
      "Epoch 128/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 4.2322 - mae: 0.9234\n",
      "Epoch 129/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 3.7696 - mae: 0.9170\n",
      "Epoch 130/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 5.3791 - mae: 0.9181\n",
      "Epoch 131/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 6.4279 - mae: 0.9560\n",
      "Epoch 132/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 7.0560 - mae: 0.9156\n",
      "Epoch 133/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 5.1946 - mae: 0.8603\n",
      "Epoch 134/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 3.3510 - mae: 0.8179\n",
      "Epoch 135/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 2.9588 - mae: 0.7913\n",
      "Epoch 136/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 3.7617 - mae: 0.8038\n",
      "Epoch 137/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 3.9344 - mae: 0.7933\n",
      "Epoch 138/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 5.4759 - mae: 0.8330\n",
      "Epoch 139/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 4.1029 - mae: 0.8213\n",
      "Epoch 140/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 2.3673 - mae: 0.7342\n",
      "Epoch 141/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 3.1392 - mae: 0.7511\n",
      "Epoch 142/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 3.0725 - mae: 0.7588\n",
      "Epoch 143/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 2.4819 - mae: 0.7361\n",
      "Epoch 144/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 3.3305 - mae: 0.7322\n",
      "Epoch 145/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 3.1686 - mae: 0.7256\n",
      "Epoch 146/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 3.4434 - mae: 0.7364\n",
      "Epoch 147/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 3.4221 - mae: 0.7279\n",
      "Epoch 148/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 4.7488 - mae: 0.7725\n",
      "Epoch 149/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 23.5854 - mae: 1.1723\n",
      "Epoch 150/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 81.2697 - mae: 1.6747\n",
      "Epoch 151/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 71.8627 - mae: 2.0728\n",
      "Epoch 152/2000\n",
      "2018/2018 [==============================] - 0s 97us/sample - loss: 62.9226 - mae: 1.7146\n",
      "Epoch 153/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 120.5595 - mae: 2.3543\n",
      "Epoch 154/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 306.7076 - mae: 3.4656\n",
      "Epoch 155/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 103.6298 - mae: 1.9313\n",
      "Epoch 156/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 73us/sample - loss: 153.1669 - mae: 2.3076\n",
      "Epoch 157/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 299.8847 - mae: 2.7681\n",
      "Epoch 158/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 314.0517 - mae: 2.9969\n",
      "Epoch 159/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 1433.8294 - mae: 3.2386\n",
      "Epoch 160/2000\n",
      "2018/2018 [==============================] - 0s 91us/sample - loss: 29.1063 - mae: 1.2473\n",
      "Epoch 161/2000\n",
      "2018/2018 [==============================] - 0s 94us/sample - loss: 11.6688 - mae: 0.9140\n",
      "Epoch 162/2000\n",
      "2018/2018 [==============================] - 0s 94us/sample - loss: 7.8860 - mae: 0.9192\n",
      "Epoch 163/2000\n",
      "2018/2018 [==============================] - 0s 96us/sample - loss: 4.3165 - mae: 0.7869\n",
      "Epoch 164/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 7.9042 - mae: 0.7880\n",
      "Epoch 165/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 9.1278 - mae: 0.7670\n",
      "Epoch 166/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 4.6028 - mae: 0.7914\n",
      "Epoch 167/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 3.0496 - mae: 0.6886\n",
      "Epoch 168/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 2.4963 - mae: 0.6502\n",
      "Epoch 169/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 2.3734 - mae: 0.6385\n",
      "Epoch 170/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 2.2568 - mae: 0.6203\n",
      "Epoch 171/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 2.0795 - mae: 0.6065\n",
      "Epoch 172/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 2.0234 - mae: 0.5959\n",
      "Epoch 173/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 1.9103 - mae: 0.5816\n",
      "Epoch 174/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 1.8357 - mae: 0.5712\n",
      "Epoch 175/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 1.8288 - mae: 0.5616\n",
      "Epoch 176/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 1.7529 - mae: 0.5602\n",
      "Epoch 177/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 1.6940 - mae: 0.5462\n",
      "Epoch 178/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 1.5863 - mae: 0.5335\n",
      "Epoch 179/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 1.5456 - mae: 0.5245\n",
      "Epoch 180/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 1.5024 - mae: 0.5155\n",
      "Epoch 181/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 1.5346 - mae: 0.5184\n",
      "Epoch 182/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 1.4772 - mae: 0.5094\n",
      "Epoch 183/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 1.5511 - mae: 0.5122\n",
      "Epoch 184/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 1.7343 - mae: 0.5141\n",
      "Epoch 185/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 2.3568 - mae: 0.5143\n",
      "Epoch 186/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 3.0535 - mae: 0.5310\n",
      "Epoch 187/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 4.2418 - mae: 0.5512\n",
      "Epoch 188/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 1.8133 - mae: 0.5100\n",
      "Epoch 189/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 1.9445 - mae: 0.5300\n",
      "Epoch 190/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 1.4153 - mae: 0.4861\n",
      "Epoch 191/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 1.3455 - mae: 0.4827\n",
      "Epoch 192/2000\n",
      "2018/2018 [==============================] - 0s 112us/sample - loss: 1.3559 - mae: 0.4807\n",
      "Epoch 193/2000\n",
      "2018/2018 [==============================] - 0s 126us/sample - loss: 1.2963 - mae: 0.4741\n",
      "Epoch 194/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 1.2777 - mae: 0.4660\n",
      "Epoch 195/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 2.1598 - mae: 0.5159\n",
      "Epoch 196/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 1.6606 - mae: 0.4922\n",
      "Epoch 197/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 2.0628 - mae: 0.5114\n",
      "Epoch 198/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 2.3424 - mae: 0.5337\n",
      "Epoch 199/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 2.6379 - mae: 0.5156\n",
      "Epoch 200/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 4.1538 - mae: 0.5469\n",
      "Epoch 201/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 4.9799 - mae: 0.5916\n",
      "Epoch 202/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 11.6524 - mae: 0.5945\n",
      "Epoch 203/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 9.2879 - mae: 0.7380\n",
      "Epoch 204/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 53.5644 - mae: 1.0727\n",
      "Epoch 205/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 50.1649 - mae: 1.3144\n",
      "Epoch 206/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 146.6236 - mae: 1.4424\n",
      "Epoch 207/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 11.4687 - mae: 0.8248\n",
      "Epoch 208/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 6.8051 - mae: 0.6592\n",
      "Epoch 209/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 4.2738 - mae: 0.6180\n",
      "Epoch 210/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 2.6736 - mae: 0.5491\n",
      "Epoch 211/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 1.6908 - mae: 0.4970\n",
      "Epoch 212/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 1.4464 - mae: 0.4733\n",
      "Epoch 213/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 1.4743 - mae: 0.4685\n",
      "Epoch 214/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 1.4062 - mae: 0.4646\n",
      "Epoch 215/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 1.6816 - mae: 0.4691\n",
      "Epoch 216/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 1.2932 - mae: 0.4518\n",
      "Epoch 217/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 1.3157 - mae: 0.4414\n",
      "Epoch 218/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 1.2201 - mae: 0.4340\n",
      "Epoch 219/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 1.4645 - mae: 0.4415\n",
      "Epoch 220/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 1.5373 - mae: 0.4486\n",
      "Epoch 221/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 1.5811 - mae: 0.4484\n",
      "Epoch 222/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 1.1783 - mae: 0.4159\n",
      "Epoch 223/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 2.1165 - mae: 0.4770\n",
      "Epoch 224/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 1.3285 - mae: 0.4200\n",
      "Epoch 225/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 1.4543 - mae: 0.4184\n",
      "Epoch 226/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 1.2057 - mae: 0.4112\n",
      "Epoch 227/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 1.2087 - mae: 0.4036\n",
      "Epoch 228/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 1.1663 - mae: 0.4006\n",
      "Epoch 229/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 1.2839 - mae: 0.4084\n",
      "Epoch 230/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 1.2722 - mae: 0.4033\n",
      "Epoch 231/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 1.2416 - mae: 0.4037\n",
      "Epoch 232/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 1.4103 - mae: 0.4117\n",
      "Epoch 233/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 1.3908 - mae: 0.4134\n",
      "Epoch 234/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 81us/sample - loss: 1.0220 - mae: 0.3836\n",
      "Epoch 235/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 1.0848 - mae: 0.3816\n",
      "Epoch 236/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 2.2210 - mae: 0.4436\n",
      "Epoch 237/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 5.5519 - mae: 0.5312\n",
      "Epoch 238/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 7.0093 - mae: 0.5807\n",
      "Epoch 239/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 23.6960 - mae: 0.9099\n",
      "Epoch 240/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 65.0805 - mae: 1.2666\n",
      "Epoch 241/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 120.4104 - mae: 1.5540\n",
      "Epoch 242/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 21.3045 - mae: 1.1691\n",
      "Epoch 243/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 16.7996 - mae: 0.9795\n",
      "Epoch 244/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 24.6465 - mae: 0.8626\n",
      "Epoch 245/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 153.8675 - mae: 1.8898\n",
      "Epoch 246/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 56.0294 - mae: 1.6330\n",
      "Epoch 247/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 22.9115 - mae: 1.0108\n",
      "Epoch 248/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 52.5062 - mae: 1.1293\n",
      "Epoch 249/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 5.4402 - mae: 0.7444\n",
      "Epoch 250/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 36.1724 - mae: 1.0398\n",
      "Epoch 251/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 52.8825 - mae: 0.9231\n",
      "Epoch 252/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 21.1168 - mae: 0.7893\n",
      "Epoch 253/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 18.4786 - mae: 1.2480\n",
      "Epoch 254/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 6.3354 - mae: 0.7882\n",
      "Epoch 255/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 2.9624 - mae: 0.5221\n",
      "Epoch 256/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 1.9402 - mae: 0.4951\n",
      "Epoch 257/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 1.0706 - mae: 0.4377\n",
      "Epoch 258/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 1.3059 - mae: 0.4154\n",
      "Epoch 259/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 2.4523 - mae: 0.5215\n",
      "Epoch 260/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 1.0517 - mae: 0.4006\n",
      "Epoch 261/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.8762 - mae: 0.3730\n",
      "Epoch 262/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.7289 - mae: 0.3423\n",
      "Epoch 263/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.6895 - mae: 0.3341\n",
      "Epoch 264/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.9951 - mae: 0.3608\n",
      "Epoch 265/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.6275 - mae: 0.3190\n",
      "Epoch 266/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.6525 - mae: 0.3175\n",
      "Epoch 267/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.6250 - mae: 0.3106\n",
      "Epoch 268/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.6412 - mae: 0.3178\n",
      "Epoch 269/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.6721 - mae: 0.3080\n",
      "Epoch 270/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.9146 - mae: 0.3345\n",
      "Epoch 271/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.6241 - mae: 0.3028\n",
      "Epoch 272/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.6068 - mae: 0.2929\n",
      "Epoch 273/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.5490 - mae: 0.2791\n",
      "Epoch 274/2000\n",
      "2018/2018 [==============================] - 0s 93us/sample - loss: 0.5349 - mae: 0.2709\n",
      "Epoch 275/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.5405 - mae: 0.2717\n",
      "Epoch 276/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.5601 - mae: 0.2701\n",
      "Epoch 277/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.5910 - mae: 0.2769\n",
      "Epoch 278/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.5931 - mae: 0.2775\n",
      "Epoch 279/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.5151 - mae: 0.2531\n",
      "Epoch 280/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.9177 - mae: 0.3093\n",
      "Epoch 281/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.7126 - mae: 0.2952\n",
      "Epoch 282/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.7192 - mae: 0.3009\n",
      "Epoch 283/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.6736 - mae: 0.2748\n",
      "Epoch 284/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.8777 - mae: 0.3049\n",
      "Epoch 285/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 31.8087 - mae: 0.9368\n",
      "Epoch 286/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 10.8561 - mae: 0.7675\n",
      "Epoch 287/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 20.3508 - mae: 0.8707\n",
      "Epoch 288/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 5.7257 - mae: 0.4764\n",
      "Epoch 289/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.7873 - mae: 0.3279\n",
      "Epoch 290/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.8217 - mae: 0.3016\n",
      "Epoch 291/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.8825 - mae: 0.3206\n",
      "Epoch 292/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 1.7222 - mae: 0.3597\n",
      "Epoch 293/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.7784 - mae: 0.3112\n",
      "Epoch 294/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.6627 - mae: 0.2845\n",
      "Epoch 295/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.6497 - mae: 0.2699\n",
      "Epoch 296/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.5946 - mae: 0.2685\n",
      "Epoch 297/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5126 - mae: 0.2446\n",
      "Epoch 298/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.5254 - mae: 0.2381\n",
      "Epoch 299/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4906 - mae: 0.2328\n",
      "Epoch 300/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4901 - mae: 0.2296\n",
      "Epoch 301/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.4813 - mae: 0.2260\n",
      "Epoch 302/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4755 - mae: 0.2247\n",
      "Epoch 303/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.4676 - mae: 0.2215\n",
      "Epoch 304/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4710 - mae: 0.2207\n",
      "Epoch 305/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.4905 - mae: 0.2238\n",
      "Epoch 306/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.5210 - mae: 0.2338\n",
      "Epoch 307/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.4971 - mae: 0.2256\n",
      "Epoch 308/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.7826 - mae: 0.2596\n",
      "Epoch 309/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.7701 - mae: 0.2715\n",
      "Epoch 310/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.6257 - mae: 0.2425\n",
      "Epoch 311/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.5272 - mae: 0.2322\n",
      "Epoch 312/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.4628 - mae: 0.2162\n",
      "Epoch 313/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4566 - mae: 0.2142\n",
      "Epoch 314/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.4534 - mae: 0.2123\n",
      "Epoch 315/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.4468 - mae: 0.2107\n",
      "Epoch 316/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.4428 - mae: 0.2080\n",
      "Epoch 317/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.4390 - mae: 0.2067\n",
      "Epoch 318/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.4529 - mae: 0.2118\n",
      "Epoch 319/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.4904 - mae: 0.2215\n",
      "Epoch 320/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.7066 - mae: 0.2437\n",
      "Epoch 321/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.5277 - mae: 0.2297\n",
      "Epoch 322/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4697 - mae: 0.2129\n",
      "Epoch 323/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4475 - mae: 0.2053\n",
      "Epoch 324/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4343 - mae: 0.2035\n",
      "Epoch 325/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4313 - mae: 0.2027\n",
      "Epoch 326/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.4288 - mae: 0.2033\n",
      "Epoch 327/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.4292 - mae: 0.2012\n",
      "Epoch 328/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.4336 - mae: 0.2015\n",
      "Epoch 329/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.4339 - mae: 0.2028\n",
      "Epoch 330/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4461 - mae: 0.2088\n",
      "Epoch 331/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4688 - mae: 0.2126\n",
      "Epoch 332/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4240 - mae: 0.2011\n",
      "Epoch 333/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.4320 - mae: 0.2014\n",
      "Epoch 334/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.5387 - mae: 0.2261\n",
      "Epoch 335/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.4393 - mae: 0.2032\n",
      "Epoch 336/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 1.0012 - mae: 0.2709\n",
      "Epoch 337/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.4618 - mae: 0.2107\n",
      "Epoch 338/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.7614 - mae: 0.2283\n",
      "Epoch 339/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 1.3364 - mae: 0.3045\n",
      "Epoch 340/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 3.7089 - mae: 0.3345\n",
      "Epoch 341/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4611 - mae: 0.2170\n",
      "Epoch 342/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4181 - mae: 0.2030\n",
      "Epoch 343/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.4102 - mae: 0.1981\n",
      "Epoch 344/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.4065 - mae: 0.1958\n",
      "Epoch 345/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4051 - mae: 0.1947\n",
      "Epoch 346/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.4018 - mae: 0.1924\n",
      "Epoch 347/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.3994 - mae: 0.1911\n",
      "Epoch 348/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.3976 - mae: 0.1905\n",
      "Epoch 349/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.3960 - mae: 0.1898\n",
      "Epoch 350/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.3941 - mae: 0.1891\n",
      "Epoch 351/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3923 - mae: 0.1873\n",
      "Epoch 352/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.3912 - mae: 0.1874\n",
      "Epoch 353/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3894 - mae: 0.1867\n",
      "Epoch 354/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.3877 - mae: 0.1860\n",
      "Epoch 355/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.3863 - mae: 0.1857\n",
      "Epoch 356/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.3847 - mae: 0.1853\n",
      "Epoch 357/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.3833 - mae: 0.1849\n",
      "Epoch 358/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.3820 - mae: 0.1849\n",
      "Epoch 359/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.3801 - mae: 0.1835\n",
      "Epoch 360/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.3791 - mae: 0.1831\n",
      "Epoch 361/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.3778 - mae: 0.1832\n",
      "Epoch 362/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.3760 - mae: 0.1823\n",
      "Epoch 363/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.3748 - mae: 0.1829\n",
      "Epoch 364/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.3747 - mae: 0.1825\n",
      "Epoch 365/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3726 - mae: 0.1827\n",
      "Epoch 366/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3701 - mae: 0.1805\n",
      "Epoch 367/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.3693 - mae: 0.1821\n",
      "Epoch 368/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.3671 - mae: 0.1800\n",
      "Epoch 369/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.3659 - mae: 0.1805\n",
      "Epoch 370/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.3643 - mae: 0.1800\n",
      "Epoch 371/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3624 - mae: 0.1795\n",
      "Epoch 372/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3630 - mae: 0.1812\n",
      "Epoch 373/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.3603 - mae: 0.1808\n",
      "Epoch 374/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3594 - mae: 0.1808\n",
      "Epoch 375/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3569 - mae: 0.1795\n",
      "Epoch 376/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3550 - mae: 0.1797\n",
      "Epoch 377/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3558 - mae: 0.1836\n",
      "Epoch 378/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.3526 - mae: 0.1806\n",
      "Epoch 379/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.3507 - mae: 0.1790\n",
      "Epoch 380/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.3487 - mae: 0.1788\n",
      "Epoch 381/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3470 - mae: 0.1781\n",
      "Epoch 382/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3460 - mae: 0.1781\n",
      "Epoch 383/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.3488 - mae: 0.1812\n",
      "Epoch 384/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3438 - mae: 0.1798\n",
      "Epoch 385/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3414 - mae: 0.1780\n",
      "Epoch 386/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3392 - mae: 0.1768\n",
      "Epoch 387/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3383 - mae: 0.1775\n",
      "Epoch 388/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.3358 - mae: 0.1770\n",
      "Epoch 389/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.3338 - mae: 0.1771\n",
      "Epoch 390/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.3325 - mae: 0.1768\n",
      "Epoch 391/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3302 - mae: 0.1756\n",
      "Epoch 392/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.3291 - mae: 0.1761\n",
      "Epoch 393/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.3270 - mae: 0.1760\n",
      "Epoch 394/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.3270 - mae: 0.1773\n",
      "Epoch 395/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.3242 - mae: 0.1765\n",
      "Epoch 396/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.3215 - mae: 0.1752\n",
      "Epoch 397/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3196 - mae: 0.1745\n",
      "Epoch 398/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3199 - mae: 0.1770\n",
      "Epoch 399/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.3170 - mae: 0.1759\n",
      "Epoch 400/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.3146 - mae: 0.1754\n",
      "Epoch 401/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.3124 - mae: 0.1751\n",
      "Epoch 402/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3113 - mae: 0.1751\n",
      "Epoch 403/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3080 - mae: 0.1741\n",
      "Epoch 404/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.3056 - mae: 0.1725\n",
      "Epoch 405/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.3039 - mae: 0.1729\n",
      "Epoch 406/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.3031 - mae: 0.1733\n",
      "Epoch 407/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.3004 - mae: 0.1722\n",
      "Epoch 408/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.2979 - mae: 0.1715\n",
      "Epoch 409/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.3003 - mae: 0.1792\n",
      "Epoch 410/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.2935 - mae: 0.1718\n",
      "Epoch 411/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.2913 - mae: 0.1714\n",
      "Epoch 412/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.2890 - mae: 0.1697\n",
      "Epoch 413/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.2879 - mae: 0.1710\n",
      "Epoch 414/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.2845 - mae: 0.1685\n",
      "Epoch 415/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.2829 - mae: 0.1695\n",
      "Epoch 416/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.2805 - mae: 0.1691\n",
      "Epoch 417/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.2820 - mae: 0.1735\n",
      "Epoch 418/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.2820 - mae: 0.1718\n",
      "Epoch 419/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.2845 - mae: 0.1742\n",
      "Epoch 420/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.2740 - mae: 0.1699\n",
      "Epoch 421/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.2706 - mae: 0.1685\n",
      "Epoch 422/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.2706 - mae: 0.1689\n",
      "Epoch 423/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.2672 - mae: 0.1681\n",
      "Epoch 424/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.2630 - mae: 0.1658\n",
      "Epoch 425/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.2600 - mae: 0.1652\n",
      "Epoch 426/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.2573 - mae: 0.1641\n",
      "Epoch 427/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.2547 - mae: 0.1632\n",
      "Epoch 428/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.2523 - mae: 0.1628\n",
      "Epoch 429/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.2515 - mae: 0.1652\n",
      "Epoch 430/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.2484 - mae: 0.1639\n",
      "Epoch 431/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.2469 - mae: 0.1647\n",
      "Epoch 432/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.2441 - mae: 0.1633\n",
      "Epoch 433/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.2406 - mae: 0.1618\n",
      "Epoch 434/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.2385 - mae: 0.1613\n",
      "Epoch 435/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.2376 - mae: 0.1633\n",
      "Epoch 436/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.2345 - mae: 0.1618\n",
      "Epoch 437/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.2320 - mae: 0.1613\n",
      "Epoch 438/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.2300 - mae: 0.1607\n",
      "Epoch 439/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.2274 - mae: 0.1599\n",
      "Epoch 440/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.2257 - mae: 0.1616\n",
      "Epoch 441/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.2233 - mae: 0.1600\n",
      "Epoch 442/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.2207 - mae: 0.1594\n",
      "Epoch 443/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.2284 - mae: 0.1640\n",
      "Epoch 444/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.2203 - mae: 0.1617\n",
      "Epoch 445/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.2148 - mae: 0.1586\n",
      "Epoch 446/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.2108 - mae: 0.1584\n",
      "Epoch 447/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.2085 - mae: 0.1573\n",
      "Epoch 448/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.2058 - mae: 0.1565\n",
      "Epoch 449/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.2034 - mae: 0.1560\n",
      "Epoch 450/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.2015 - mae: 0.1564\n",
      "Epoch 451/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.2000 - mae: 0.1584\n",
      "Epoch 452/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.1976 - mae: 0.1583\n",
      "Epoch 453/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.1948 - mae: 0.1559\n",
      "Epoch 454/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.1965 - mae: 0.1644\n",
      "Epoch 455/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1926 - mae: 0.1620\n",
      "Epoch 456/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1889 - mae: 0.1573\n",
      "Epoch 457/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.1865 - mae: 0.1569\n",
      "Epoch 458/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1844 - mae: 0.1568\n",
      "Epoch 459/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1842 - mae: 0.1576\n",
      "Epoch 460/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1818 - mae: 0.1574\n",
      "Epoch 461/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.1782 - mae: 0.1568\n",
      "Epoch 462/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.1760 - mae: 0.1573\n",
      "Epoch 463/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.1737 - mae: 0.1554\n",
      "Epoch 464/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.1716 - mae: 0.1552\n",
      "Epoch 465/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.1699 - mae: 0.1563\n",
      "Epoch 466/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1687 - mae: 0.1594\n",
      "Epoch 467/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.1644 - mae: 0.1545\n",
      "Epoch 468/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.2206 - mae: 0.1764\n",
      "Epoch 469/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1703 - mae: 0.1689\n",
      "Epoch 470/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.1622 - mae: 0.1597\n",
      "Epoch 471/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.1574 - mae: 0.1579\n",
      "Epoch 472/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.1549 - mae: 0.1565\n",
      "Epoch 473/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.1643 - mae: 0.1729\n",
      "Epoch 474/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.1609 - mae: 0.1730\n",
      "Epoch 475/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.1536 - mae: 0.1657\n",
      "Epoch 476/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.1508 - mae: 0.1628\n",
      "Epoch 477/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1493 - mae: 0.1630\n",
      "Epoch 478/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1460 - mae: 0.1611\n",
      "Epoch 479/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.1434 - mae: 0.1587\n",
      "Epoch 480/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.1445 - mae: 0.1642\n",
      "Epoch 481/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1530 - mae: 0.1686\n",
      "Epoch 482/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1430 - mae: 0.1702\n",
      "Epoch 483/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.1398 - mae: 0.1666\n",
      "Epoch 484/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.1363 - mae: 0.1625\n",
      "Epoch 485/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.1334 - mae: 0.1591\n",
      "Epoch 486/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.1310 - mae: 0.1579\n",
      "Epoch 487/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.1293 - mae: 0.1584\n",
      "Epoch 488/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.1268 - mae: 0.1571\n",
      "Epoch 489/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.1255 - mae: 0.1577\n",
      "Epoch 490/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1231 - mae: 0.1554\n",
      "Epoch 491/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.1213 - mae: 0.1556\n",
      "Epoch 492/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.1206 - mae: 0.1577\n",
      "Epoch 493/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.1189 - mae: 0.1560\n",
      "Epoch 494/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.1163 - mae: 0.1552\n",
      "Epoch 495/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.1146 - mae: 0.1558\n",
      "Epoch 496/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.1129 - mae: 0.1558\n",
      "Epoch 497/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.1119 - mae: 0.1566\n",
      "Epoch 498/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.1099 - mae: 0.1551\n",
      "Epoch 499/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.1213 - mae: 0.1675\n",
      "Epoch 500/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.1096 - mae: 0.1589\n",
      "Epoch 501/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.1109 - mae: 0.1636\n",
      "Epoch 502/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.1060 - mae: 0.1577\n",
      "Epoch 503/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.1037 - mae: 0.1541\n",
      "Epoch 504/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.1024 - mae: 0.1551\n",
      "Epoch 505/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.1013 - mae: 0.1546\n",
      "Epoch 506/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0996 - mae: 0.1547\n",
      "Epoch 507/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0980 - mae: 0.1531\n",
      "Epoch 508/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0962 - mae: 0.1531\n",
      "Epoch 509/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0952 - mae: 0.1533\n",
      "Epoch 510/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0937 - mae: 0.1535\n",
      "Epoch 511/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0925 - mae: 0.1525\n",
      "Epoch 512/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0910 - mae: 0.1531\n",
      "Epoch 513/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0896 - mae: 0.1518\n",
      "Epoch 514/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0885 - mae: 0.1524\n",
      "Epoch 515/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0870 - mae: 0.1507\n",
      "Epoch 516/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0856 - mae: 0.1511\n",
      "Epoch 517/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0843 - mae: 0.1494\n",
      "Epoch 518/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0834 - mae: 0.1509\n",
      "Epoch 519/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0823 - mae: 0.1504\n",
      "Epoch 520/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0826 - mae: 0.1546\n",
      "Epoch 521/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0809 - mae: 0.1525\n",
      "Epoch 522/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0796 - mae: 0.1519\n",
      "Epoch 523/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0781 - mae: 0.1503\n",
      "Epoch 524/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0774 - mae: 0.1506\n",
      "Epoch 525/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0768 - mae: 0.1516\n",
      "Epoch 526/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0747 - mae: 0.1496\n",
      "Epoch 527/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0745 - mae: 0.1510\n",
      "Epoch 528/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0742 - mae: 0.1530\n",
      "Epoch 529/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0730 - mae: 0.1515\n",
      "Epoch 530/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0723 - mae: 0.1529\n",
      "Epoch 531/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0702 - mae: 0.1493\n",
      "Epoch 532/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0709 - mae: 0.1530\n",
      "Epoch 533/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0688 - mae: 0.1507\n",
      "Epoch 534/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0676 - mae: 0.1493\n",
      "Epoch 535/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0665 - mae: 0.1481\n",
      "Epoch 536/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0662 - mae: 0.1498\n",
      "Epoch 537/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0652 - mae: 0.1486\n",
      "Epoch 538/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0640 - mae: 0.1477\n",
      "Epoch 539/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0635 - mae: 0.1477\n",
      "Epoch 540/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0625 - mae: 0.1479\n",
      "Epoch 541/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0624 - mae: 0.1496\n",
      "Epoch 542/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0637 - mae: 0.1540\n",
      "Epoch 543/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0611 - mae: 0.1493\n",
      "Epoch 544/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0599 - mae: 0.1487\n",
      "Epoch 545/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0585 - mae: 0.1462\n",
      "Epoch 546/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0590 - mae: 0.1505\n",
      "Epoch 547/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0579 - mae: 0.1481\n",
      "Epoch 548/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0593 - mae: 0.1518\n",
      "Epoch 549/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0566 - mae: 0.1476\n",
      "Epoch 550/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0554 - mae: 0.1466\n",
      "Epoch 551/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0549 - mae: 0.1460\n",
      "Epoch 552/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0539 - mae: 0.1454\n",
      "Epoch 553/2000\n",
      "2018/2018 [==============================] - 0s 100us/sample - loss: 0.0534 - mae: 0.1456\n",
      "Epoch 554/2000\n",
      "2018/2018 [==============================] - 0s 119us/sample - loss: 0.0535 - mae: 0.1471\n",
      "Epoch 555/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0531 - mae: 0.1478\n",
      "Epoch 556/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0546 - mae: 0.1519\n",
      "Epoch 557/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0513 - mae: 0.1457\n",
      "Epoch 558/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0504 - mae: 0.1454\n",
      "Epoch 559/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0509 - mae: 0.1470\n",
      "Epoch 560/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0497 - mae: 0.1458\n",
      "Epoch 561/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0488 - mae: 0.1445\n",
      "Epoch 562/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0482 - mae: 0.1439\n",
      "Epoch 563/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0491 - mae: 0.1473\n",
      "Epoch 564/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.1023 - mae: 0.1774\n",
      "Epoch 565/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0614 - mae: 0.1665\n",
      "Epoch 566/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0535 - mae: 0.1579\n",
      "Epoch 567/2000\n",
      "2018/2018 [==============================] - 0s 90us/sample - loss: 0.0570 - mae: 0.1642\n",
      "Epoch 568/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0510 - mae: 0.1551\n",
      "Epoch 569/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0487 - mae: 0.1503\n",
      "Epoch 570/2000\n",
      "2018/2018 [==============================] - 0s 100us/sample - loss: 0.0488 - mae: 0.1510\n",
      "Epoch 571/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0473 - mae: 0.1486\n",
      "Epoch 572/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0471 - mae: 0.1493\n",
      "Epoch 573/2000\n",
      "2018/2018 [==============================] - 0s 101us/sample - loss: 0.0465 - mae: 0.1485\n",
      "Epoch 574/2000\n",
      "2018/2018 [==============================] - 0s 120us/sample - loss: 0.0502 - mae: 0.1537\n",
      "Epoch 575/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0479 - mae: 0.1519\n",
      "Epoch 576/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0474 - mae: 0.1509\n",
      "Epoch 577/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0457 - mae: 0.1476\n",
      "Epoch 578/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0442 - mae: 0.1452\n",
      "Epoch 579/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0450 - mae: 0.1468\n",
      "Epoch 580/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0451 - mae: 0.1500\n",
      "Epoch 581/2000\n",
      "2018/2018 [==============================] - 0s 101us/sample - loss: 0.0505 - mae: 0.1500\n",
      "Epoch 582/2000\n",
      "2018/2018 [==============================] - 0s 151us/sample - loss: 0.0443 - mae: 0.1485\n",
      "Epoch 583/2000\n",
      "2018/2018 [==============================] - 0s 103us/sample - loss: 0.0427 - mae: 0.1437\n",
      "Epoch 584/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0423 - mae: 0.1431\n",
      "Epoch 585/2000\n",
      "2018/2018 [==============================] - 0s 93us/sample - loss: 0.0419 - mae: 0.1435\n",
      "Epoch 586/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0432 - mae: 0.1461\n",
      "Epoch 587/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0417 - mae: 0.1440\n",
      "Epoch 588/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0460 - mae: 0.1457\n",
      "Epoch 589/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0428 - mae: 0.1463\n",
      "Epoch 590/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0420 - mae: 0.1446\n",
      "Epoch 591/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0422 - mae: 0.1462\n",
      "Epoch 592/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0416 - mae: 0.1444\n",
      "Epoch 593/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0546 - mae: 0.1541\n",
      "Epoch 594/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0428 - mae: 0.1473\n",
      "Epoch 595/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0414 - mae: 0.1450\n",
      "Epoch 596/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0418 - mae: 0.1447\n",
      "Epoch 597/2000\n",
      "2018/2018 [==============================] - 0s 138us/sample - loss: 0.0422 - mae: 0.1476\n",
      "Epoch 598/2000\n",
      "2018/2018 [==============================] - 0s 127us/sample - loss: 0.0407 - mae: 0.1439\n",
      "Epoch 599/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.0405 - mae: 0.1431\n",
      "Epoch 600/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0395 - mae: 0.1419\n",
      "Epoch 601/2000\n",
      "2018/2018 [==============================] - 0s 94us/sample - loss: 0.0396 - mae: 0.1424\n",
      "Epoch 602/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0404 - mae: 0.1437\n",
      "Epoch 603/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0389 - mae: 0.1408\n",
      "Epoch 604/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0388 - mae: 0.1408\n",
      "Epoch 605/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0389 - mae: 0.1410\n",
      "Epoch 606/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0377 - mae: 0.1385\n",
      "Epoch 607/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0407 - mae: 0.1459\n",
      "Epoch 608/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0381 - mae: 0.1393\n",
      "Epoch 609/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0375 - mae: 0.1386\n",
      "Epoch 610/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0377 - mae: 0.1394\n",
      "Epoch 611/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0373 - mae: 0.1377\n",
      "Epoch 612/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0380 - mae: 0.1410\n",
      "Epoch 613/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0372 - mae: 0.1377\n",
      "Epoch 614/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0365 - mae: 0.1364\n",
      "Epoch 615/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0363 - mae: 0.1352\n",
      "Epoch 616/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0374 - mae: 0.1404\n",
      "Epoch 617/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0359 - mae: 0.1360\n",
      "Epoch 618/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0354 - mae: 0.1336\n",
      "Epoch 619/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0367 - mae: 0.1374\n",
      "Epoch 620/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0356 - mae: 0.1345\n",
      "Epoch 621/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0357 - mae: 0.1358\n",
      "Epoch 622/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0355 - mae: 0.1353\n",
      "Epoch 623/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0354 - mae: 0.1345\n",
      "Epoch 624/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0350 - mae: 0.1339\n",
      "Epoch 625/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0352 - mae: 0.1341\n",
      "Epoch 626/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0384 - mae: 0.1407\n",
      "Epoch 627/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0372 - mae: 0.1390\n",
      "Epoch 628/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0357 - mae: 0.1365\n",
      "Epoch 629/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0355 - mae: 0.1357\n",
      "Epoch 630/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0368 - mae: 0.1388\n",
      "Epoch 631/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0360 - mae: 0.1380\n",
      "Epoch 632/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.1044 - mae: 0.1485\n",
      "Epoch 633/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0399 - mae: 0.1452\n",
      "Epoch 634/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0378 - mae: 0.1407\n",
      "Epoch 635/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0373 - mae: 0.1393\n",
      "Epoch 636/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0375 - mae: 0.1394\n",
      "Epoch 637/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0376 - mae: 0.1394\n",
      "Epoch 638/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0364 - mae: 0.1370\n",
      "Epoch 639/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0369 - mae: 0.1390\n",
      "Epoch 640/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0354 - mae: 0.1352\n",
      "Epoch 641/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0352 - mae: 0.1344\n",
      "Epoch 642/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0342 - mae: 0.1325\n",
      "Epoch 643/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0343 - mae: 0.1329\n",
      "Epoch 644/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0340 - mae: 0.1321\n",
      "Epoch 645/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0349 - mae: 0.1341\n",
      "Epoch 646/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0345 - mae: 0.1326\n",
      "Epoch 647/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0374 - mae: 0.1383\n",
      "Epoch 648/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0357 - mae: 0.1357\n",
      "Epoch 649/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0351 - mae: 0.1326\n",
      "Epoch 650/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0356 - mae: 0.1349\n",
      "Epoch 651/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0349 - mae: 0.1340\n",
      "Epoch 652/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0342 - mae: 0.1318\n",
      "Epoch 653/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0336 - mae: 0.1304\n",
      "Epoch 654/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0350 - mae: 0.1350\n",
      "Epoch 655/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0378 - mae: 0.1392\n",
      "Epoch 656/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0343 - mae: 0.1332\n",
      "Epoch 657/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0339 - mae: 0.1322\n",
      "Epoch 658/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0335 - mae: 0.1307\n",
      "Epoch 659/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0336 - mae: 0.1303\n",
      "Epoch 660/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0329 - mae: 0.1301\n",
      "Epoch 661/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0335 - mae: 0.1303\n",
      "Epoch 662/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0321 - mae: 0.1271\n",
      "Epoch 663/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0336 - mae: 0.1308\n",
      "Epoch 664/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0327 - mae: 0.1296\n",
      "Epoch 665/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0323 - mae: 0.1281\n",
      "Epoch 666/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0319 - mae: 0.1274\n",
      "Epoch 667/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0316 - mae: 0.1264\n",
      "Epoch 668/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0324 - mae: 0.1286\n",
      "Epoch 669/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0316 - mae: 0.1268\n",
      "Epoch 670/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0316 - mae: 0.1273\n",
      "Epoch 671/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0311 - mae: 0.1263\n",
      "Epoch 672/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0321 - mae: 0.1287\n",
      "Epoch 673/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0311 - mae: 0.1266\n",
      "Epoch 674/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0315 - mae: 0.1283\n",
      "Epoch 675/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0317 - mae: 0.1275\n",
      "Epoch 676/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0310 - mae: 0.1262\n",
      "Epoch 677/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0327 - mae: 0.1314\n",
      "Epoch 678/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0308 - mae: 0.1263\n",
      "Epoch 679/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0298 - mae: 0.1239\n",
      "Epoch 680/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0296 - mae: 0.1243\n",
      "Epoch 681/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0297 - mae: 0.1239\n",
      "Epoch 682/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0291 - mae: 0.1232\n",
      "Epoch 683/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0296 - mae: 0.1237\n",
      "Epoch 684/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0304 - mae: 0.1266\n",
      "Epoch 685/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0290 - mae: 0.1237\n",
      "Epoch 686/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0288 - mae: 0.1223\n",
      "Epoch 687/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0291 - mae: 0.1229\n",
      "Epoch 688/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0287 - mae: 0.1223\n",
      "Epoch 689/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0289 - mae: 0.1232\n",
      "Epoch 690/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0293 - mae: 0.1238\n",
      "Epoch 691/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0285 - mae: 0.1218\n",
      "Epoch 692/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0285 - mae: 0.1222\n",
      "Epoch 693/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0289 - mae: 0.1228\n",
      "Epoch 694/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0296 - mae: 0.1252\n",
      "Epoch 695/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0290 - mae: 0.1234\n",
      "Epoch 696/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0279 - mae: 0.1210\n",
      "Epoch 697/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0277 - mae: 0.1196\n",
      "Epoch 698/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0277 - mae: 0.1208\n",
      "Epoch 699/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0274 - mae: 0.1191\n",
      "Epoch 700/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0278 - mae: 0.1204\n",
      "Epoch 701/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0276 - mae: 0.1202\n",
      "Epoch 702/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0286 - mae: 0.1240\n",
      "Epoch 703/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0273 - mae: 0.1184\n",
      "Epoch 704/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0273 - mae: 0.1188\n",
      "Epoch 705/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0279 - mae: 0.1215\n",
      "Epoch 706/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0276 - mae: 0.1201\n",
      "Epoch 707/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0272 - mae: 0.1204\n",
      "Epoch 708/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0273 - mae: 0.1192\n",
      "Epoch 709/2000\n",
      "2018/2018 [==============================] - 0s 144us/sample - loss: 0.0273 - mae: 0.1204\n",
      "Epoch 710/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.0274 - mae: 0.1196\n",
      "Epoch 711/2000\n",
      "2018/2018 [==============================] - 0s 97us/sample - loss: 0.0269 - mae: 0.1188\n",
      "Epoch 712/2000\n",
      "2018/2018 [==============================] - 0s 98us/sample - loss: 0.0264 - mae: 0.1171\n",
      "Epoch 713/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0270 - mae: 0.1195\n",
      "Epoch 714/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0273 - mae: 0.1215\n",
      "Epoch 715/2000\n",
      "2018/2018 [==============================] - 0s 93us/sample - loss: 0.0274 - mae: 0.1201\n",
      "Epoch 716/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0267 - mae: 0.1187\n",
      "Epoch 717/2000\n",
      "2018/2018 [==============================] - 0s 102us/sample - loss: 0.0280 - mae: 0.1212\n",
      "Epoch 718/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0270 - mae: 0.1195\n",
      "Epoch 719/2000\n",
      "2018/2018 [==============================] - 0s 90us/sample - loss: 0.0266 - mae: 0.1180\n",
      "Epoch 720/2000\n",
      "2018/2018 [==============================] - 0s 97us/sample - loss: 0.0267 - mae: 0.1186\n",
      "Epoch 721/2000\n",
      "2018/2018 [==============================] - 0s 98us/sample - loss: 0.0262 - mae: 0.1180\n",
      "Epoch 722/2000\n",
      "2018/2018 [==============================] - 0s 113us/sample - loss: 0.0266 - mae: 0.1184\n",
      "Epoch 723/2000\n",
      "2018/2018 [==============================] - 0s 147us/sample - loss: 0.0262 - mae: 0.1177\n",
      "Epoch 724/2000\n",
      "2018/2018 [==============================] - 0s 179us/sample - loss: 0.0265 - mae: 0.1173\n",
      "Epoch 725/2000\n",
      "2018/2018 [==============================] - 1s 257us/sample - loss: 0.0259 - mae: 0.1171\n",
      "Epoch 726/2000\n",
      "2018/2018 [==============================] - 0s 155us/sample - loss: 0.0267 - mae: 0.1194\n",
      "Epoch 727/2000\n",
      "2018/2018 [==============================] - 0s 183us/sample - loss: 0.0266 - mae: 0.1182\n",
      "Epoch 728/2000\n",
      "2018/2018 [==============================] - 0s 162us/sample - loss: 0.0267 - mae: 0.1199\n",
      "Epoch 729/2000\n",
      "2018/2018 [==============================] - 0s 158us/sample - loss: 0.0259 - mae: 0.1168\n",
      "Epoch 730/2000\n",
      "2018/2018 [==============================] - 0s 228us/sample - loss: 0.0258 - mae: 0.1170\n",
      "Epoch 731/2000\n",
      "2018/2018 [==============================] - 0s 178us/sample - loss: 0.0270 - mae: 0.1199\n",
      "Epoch 732/2000\n",
      "2018/2018 [==============================] - 0s 122us/sample - loss: 0.0256 - mae: 0.1162\n",
      "Epoch 733/2000\n",
      "2018/2018 [==============================] - 0s 108us/sample - loss: 0.0261 - mae: 0.1176\n",
      "Epoch 734/2000\n",
      "2018/2018 [==============================] - 0s 118us/sample - loss: 0.0258 - mae: 0.1162\n",
      "Epoch 735/2000\n",
      "2018/2018 [==============================] - 0s 220us/sample - loss: 0.0276 - mae: 0.1182\n",
      "Epoch 736/2000\n",
      "2018/2018 [==============================] - 0s 162us/sample - loss: 0.0269 - mae: 0.1203\n",
      "Epoch 737/2000\n",
      "2018/2018 [==============================] - 0s 98us/sample - loss: 0.0266 - mae: 0.1192\n",
      "Epoch 738/2000\n",
      "2018/2018 [==============================] - 0s 148us/sample - loss: 0.0258 - mae: 0.1180\n",
      "Epoch 739/2000\n",
      "2018/2018 [==============================] - 0s 139us/sample - loss: 0.0267 - mae: 0.1183\n",
      "Epoch 740/2000\n",
      "2018/2018 [==============================] - 0s 166us/sample - loss: 0.0257 - mae: 0.1172\n",
      "Epoch 741/2000\n",
      "2018/2018 [==============================] - 0s 146us/sample - loss: 0.0259 - mae: 0.1168\n",
      "Epoch 742/2000\n",
      "2018/2018 [==============================] - 0s 192us/sample - loss: 0.0254 - mae: 0.1156\n",
      "Epoch 743/2000\n",
      "2018/2018 [==============================] - 0s 168us/sample - loss: 0.0264 - mae: 0.1182\n",
      "Epoch 744/2000\n",
      "2018/2018 [==============================] - 0s 120us/sample - loss: 0.0257 - mae: 0.1175\n",
      "Epoch 745/2000\n",
      "2018/2018 [==============================] - 0s 215us/sample - loss: 0.0251 - mae: 0.1151s - loss: 0.0230 - mae: \n",
      "Epoch 746/2000\n",
      "2018/2018 [==============================] - 0s 198us/sample - loss: 0.0252 - mae: 0.1152\n",
      "Epoch 747/2000\n",
      "2018/2018 [==============================] - 0s 123us/sample - loss: 0.0258 - mae: 0.1169\n",
      "Epoch 748/2000\n",
      "2018/2018 [==============================] - 0s 118us/sample - loss: 0.0312 - mae: 0.1237\n",
      "Epoch 749/2000\n",
      "2018/2018 [==============================] - 0s 101us/sample - loss: 0.0298 - mae: 0.1267\n",
      "Epoch 750/2000\n",
      "2018/2018 [==============================] - 0s 109us/sample - loss: 0.0297 - mae: 0.1249\n",
      "Epoch 751/2000\n",
      "2018/2018 [==============================] - 0s 101us/sample - loss: 0.0271 - mae: 0.1204\n",
      "Epoch 752/2000\n",
      "2018/2018 [==============================] - 0s 97us/sample - loss: 0.0321 - mae: 0.1249\n",
      "Epoch 753/2000\n",
      "2018/2018 [==============================] - 0s 122us/sample - loss: 0.0279 - mae: 0.1214\n",
      "Epoch 754/2000\n",
      "2018/2018 [==============================] - 0s 106us/sample - loss: 0.0272 - mae: 0.1190\n",
      "Epoch 755/2000\n",
      "2018/2018 [==============================] - 0s 94us/sample - loss: 0.0267 - mae: 0.1192\n",
      "Epoch 756/2000\n",
      "2018/2018 [==============================] - 0s 96us/sample - loss: 0.0275 - mae: 0.1215\n",
      "Epoch 757/2000\n",
      "2018/2018 [==============================] - 0s 99us/sample - loss: 0.0259 - mae: 0.1167\n",
      "Epoch 758/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.0274 - mae: 0.1212\n",
      "Epoch 759/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0266 - mae: 0.1197\n",
      "Epoch 760/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0274 - mae: 0.1210\n",
      "Epoch 761/2000\n",
      "2018/2018 [==============================] - 0s 95us/sample - loss: 0.0252 - mae: 0.1151\n",
      "Epoch 762/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0264 - mae: 0.1178\n",
      "Epoch 763/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0259 - mae: 0.1171\n",
      "Epoch 764/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0260 - mae: 0.1180\n",
      "Epoch 765/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0255 - mae: 0.1159\n",
      "Epoch 766/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0262 - mae: 0.1187\n",
      "Epoch 767/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0249 - mae: 0.1137\n",
      "Epoch 768/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0248 - mae: 0.1140\n",
      "Epoch 769/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0247 - mae: 0.1147\n",
      "Epoch 770/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0254 - mae: 0.1149\n",
      "Epoch 771/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0250 - mae: 0.1151\n",
      "Epoch 772/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0255 - mae: 0.1169\n",
      "Epoch 773/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0249 - mae: 0.1145\n",
      "Epoch 774/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0249 - mae: 0.1148\n",
      "Epoch 775/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0245 - mae: 0.1138\n",
      "Epoch 776/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0281 - mae: 0.1254\n",
      "Epoch 777/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0250 - mae: 0.1152\n",
      "Epoch 778/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0254 - mae: 0.1180\n",
      "Epoch 779/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0248 - mae: 0.1145\n",
      "Epoch 780/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0244 - mae: 0.1141\n",
      "Epoch 781/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0263 - mae: 0.1189\n",
      "Epoch 782/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0261 - mae: 0.1178\n",
      "Epoch 783/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0285 - mae: 0.1248\n",
      "Epoch 784/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0253 - mae: 0.1154\n",
      "Epoch 785/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0248 - mae: 0.1154\n",
      "Epoch 786/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0238 - mae: 0.1123\n",
      "Epoch 787/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0242 - mae: 0.1134\n",
      "Epoch 788/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0246 - mae: 0.1138\n",
      "Epoch 789/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0243 - mae: 0.1133\n",
      "Epoch 790/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0239 - mae: 0.1123\n",
      "Epoch 791/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0238 - mae: 0.1119\n",
      "Epoch 792/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0236 - mae: 0.1120\n",
      "Epoch 793/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0238 - mae: 0.1122\n",
      "Epoch 794/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0239 - mae: 0.1123\n",
      "Epoch 795/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0242 - mae: 0.1142\n",
      "Epoch 796/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0233 - mae: 0.1108\n",
      "Epoch 797/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0238 - mae: 0.1125\n",
      "Epoch 798/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0251 - mae: 0.1172\n",
      "Epoch 799/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0233 - mae: 0.1106\n",
      "Epoch 800/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0237 - mae: 0.1114\n",
      "Epoch 801/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0239 - mae: 0.1126\n",
      "Epoch 802/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0235 - mae: 0.1118\n",
      "Epoch 803/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0238 - mae: 0.1124\n",
      "Epoch 804/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0256 - mae: 0.1169\n",
      "Epoch 805/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0246 - mae: 0.1147\n",
      "Epoch 806/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0236 - mae: 0.1115\n",
      "Epoch 807/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0243 - mae: 0.1138\n",
      "Epoch 808/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0237 - mae: 0.1129\n",
      "Epoch 809/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0235 - mae: 0.1121\n",
      "Epoch 810/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0235 - mae: 0.1120\n",
      "Epoch 811/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0234 - mae: 0.1118\n",
      "Epoch 812/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0234 - mae: 0.1122\n",
      "Epoch 813/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0231 - mae: 0.1112\n",
      "Epoch 814/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0233 - mae: 0.1112\n",
      "Epoch 815/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0240 - mae: 0.1143\n",
      "Epoch 816/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0238 - mae: 0.1116\n",
      "Epoch 817/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0274 - mae: 0.1222\n",
      "Epoch 818/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0251 - mae: 0.1174\n",
      "Epoch 819/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0239 - mae: 0.1132\n",
      "Epoch 820/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0240 - mae: 0.1137\n",
      "Epoch 821/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0233 - mae: 0.1121\n",
      "Epoch 822/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0235 - mae: 0.1127\n",
      "Epoch 823/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0249 - mae: 0.1166\n",
      "Epoch 824/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0263 - mae: 0.1189\n",
      "Epoch 825/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0245 - mae: 0.1142\n",
      "Epoch 826/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0238 - mae: 0.1129\n",
      "Epoch 827/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0232 - mae: 0.1113\n",
      "Epoch 828/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0233 - mae: 0.1119\n",
      "Epoch 829/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0243 - mae: 0.1154\n",
      "Epoch 830/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0231 - mae: 0.1108\n",
      "Epoch 831/2000\n",
      "2018/2018 [==============================] - 0s 90us/sample - loss: 0.0233 - mae: 0.1122\n",
      "Epoch 832/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0229 - mae: 0.1109\n",
      "Epoch 833/2000\n",
      "2018/2018 [==============================] - ETA: 0s - loss: 0.0246 - mae: 0.114 - 0s 99us/sample - loss: 0.0239 - mae: 0.1131\n",
      "Epoch 834/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.0232 - mae: 0.1110\n",
      "Epoch 835/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0230 - mae: 0.1111\n",
      "Epoch 836/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0227 - mae: 0.1097\n",
      "Epoch 837/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0233 - mae: 0.1113\n",
      "Epoch 838/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0223 - mae: 0.1090\n",
      "Epoch 839/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0250 - mae: 0.1168\n",
      "Epoch 840/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0264 - mae: 0.1145\n",
      "Epoch 841/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0242 - mae: 0.1131\n",
      "Epoch 842/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0232 - mae: 0.1121\n",
      "Epoch 843/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0224 - mae: 0.1088\n",
      "Epoch 844/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0227 - mae: 0.1101\n",
      "Epoch 845/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0226 - mae: 0.1090\n",
      "Epoch 846/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0251 - mae: 0.1166\n",
      "Epoch 847/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0229 - mae: 0.1112\n",
      "Epoch 848/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0455 - mae: 0.1349\n",
      "Epoch 849/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0278 - mae: 0.1228\n",
      "Epoch 850/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0262 - mae: 0.1187\n",
      "Epoch 851/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0249 - mae: 0.1143\n",
      "Epoch 852/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0240 - mae: 0.1124\n",
      "Epoch 853/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0239 - mae: 0.1119\n",
      "Epoch 854/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0242 - mae: 0.1143\n",
      "Epoch 855/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0237 - mae: 0.1114\n",
      "Epoch 856/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0241 - mae: 0.1132\n",
      "Epoch 857/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0230 - mae: 0.1095\n",
      "Epoch 858/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0229 - mae: 0.1093\n",
      "Epoch 859/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0227 - mae: 0.1089\n",
      "Epoch 860/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0230 - mae: 0.1102\n",
      "Epoch 861/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0231 - mae: 0.1100\n",
      "Epoch 862/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0231 - mae: 0.1108\n",
      "Epoch 863/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0229 - mae: 0.1102\n",
      "Epoch 864/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0220 - mae: 0.1068\n",
      "Epoch 865/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0229 - mae: 0.1093\n",
      "Epoch 866/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0221 - mae: 0.1072\n",
      "Epoch 867/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0222 - mae: 0.1075\n",
      "Epoch 868/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0219 - mae: 0.1062\n",
      "Epoch 869/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0230 - mae: 0.1089\n",
      "Epoch 870/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0229 - mae: 0.1096\n",
      "Epoch 871/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1068\n",
      "Epoch 872/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0223 - mae: 0.1075\n",
      "Epoch 873/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0218 - mae: 0.1065\n",
      "Epoch 874/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0217 - mae: 0.1054\n",
      "Epoch 875/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0234 - mae: 0.1114\n",
      "Epoch 876/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0219 - mae: 0.1071\n",
      "Epoch 877/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0221 - mae: 0.1074\n",
      "Epoch 878/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0217 - mae: 0.1058\n",
      "Epoch 879/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0216 - mae: 0.1051\n",
      "Epoch 880/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0223 - mae: 0.1077\n",
      "Epoch 881/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0216 - mae: 0.1054\n",
      "Epoch 882/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0215 - mae: 0.1058\n",
      "Epoch 883/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0214 - mae: 0.1063\n",
      "Epoch 884/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0238 - mae: 0.1105\n",
      "Epoch 885/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0360 - mae: 0.1221\n",
      "Epoch 886/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0296 - mae: 0.1238\n",
      "Epoch 887/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0287 - mae: 0.1240\n",
      "Epoch 888/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0248 - mae: 0.1165\n",
      "Epoch 889/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0237 - mae: 0.1124\n",
      "Epoch 890/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0240 - mae: 0.1150\n",
      "Epoch 891/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0234 - mae: 0.1126\n",
      "Epoch 892/2000\n",
      "2018/2018 [==============================] - 0s 91us/sample - loss: 0.0337 - mae: 0.1378\n",
      "Epoch 893/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0248 - mae: 0.1167\n",
      "Epoch 894/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0235 - mae: 0.1133\n",
      "Epoch 895/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0230 - mae: 0.1108\n",
      "Epoch 896/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0227 - mae: 0.1096\n",
      "Epoch 897/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0225 - mae: 0.1103\n",
      "Epoch 898/2000\n",
      "2018/2018 [==============================] - 0s 129us/sample - loss: 0.0232 - mae: 0.1118\n",
      "Epoch 899/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0223 - mae: 0.1090\n",
      "Epoch 900/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0233 - mae: 0.1133\n",
      "Epoch 901/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0239 - mae: 0.1144\n",
      "Epoch 902/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0220 - mae: 0.1082\n",
      "Epoch 903/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0219 - mae: 0.1088\n",
      "Epoch 904/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0220 - mae: 0.1087\n",
      "Epoch 905/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0223 - mae: 0.1089\n",
      "Epoch 906/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0246 - mae: 0.1166\n",
      "Epoch 907/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0235 - mae: 0.1129\n",
      "Epoch 908/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0233 - mae: 0.1124\n",
      "Epoch 909/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0235 - mae: 0.1127\n",
      "Epoch 910/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0218 - mae: 0.1085\n",
      "Epoch 911/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0221 - mae: 0.1092\n",
      "Epoch 912/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0216 - mae: 0.1071\n",
      "Epoch 913/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0215 - mae: 0.1077\n",
      "Epoch 914/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0227 - mae: 0.1114\n",
      "Epoch 915/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0224 - mae: 0.1094\n",
      "Epoch 916/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0214 - mae: 0.1067\n",
      "Epoch 917/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0218 - mae: 0.1079\n",
      "Epoch 918/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0217 - mae: 0.1066\n",
      "Epoch 919/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0215 - mae: 0.1074\n",
      "Epoch 920/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0214 - mae: 0.1069\n",
      "Epoch 921/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0214 - mae: 0.1068\n",
      "Epoch 922/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0219 - mae: 0.1079\n",
      "Epoch 923/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0216 - mae: 0.1081\n",
      "Epoch 924/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0209 - mae: 0.1049\n",
      "Epoch 925/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0213 - mae: 0.1059\n",
      "Epoch 926/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0227 - mae: 0.1108\n",
      "Epoch 927/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0224 - mae: 0.1095\n",
      "Epoch 928/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0221 - mae: 0.1093\n",
      "Epoch 929/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0253 - mae: 0.1186\n",
      "Epoch 930/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0215 - mae: 0.1070\n",
      "Epoch 931/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0223 - mae: 0.1098\n",
      "Epoch 932/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0219 - mae: 0.1078\n",
      "Epoch 933/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0219 - mae: 0.1074\n",
      "Epoch 934/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0221 - mae: 0.1086\n",
      "Epoch 935/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0215 - mae: 0.1054\n",
      "Epoch 936/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0213 - mae: 0.1061\n",
      "Epoch 937/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0212 - mae: 0.1060\n",
      "Epoch 938/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0213 - mae: 0.1074\n",
      "Epoch 939/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0206 - mae: 0.1040\n",
      "Epoch 940/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0202 - mae: 0.1029\n",
      "Epoch 941/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0214 - mae: 0.1052\n",
      "Epoch 942/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0223 - mae: 0.1085\n",
      "Epoch 943/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0215 - mae: 0.1070\n",
      "Epoch 944/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0222 - mae: 0.1075\n",
      "Epoch 945/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0214 - mae: 0.1057\n",
      "Epoch 946/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0209 - mae: 0.1046\n",
      "Epoch 947/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0213 - mae: 0.1062\n",
      "Epoch 948/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0232 - mae: 0.1119\n",
      "Epoch 949/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0215 - mae: 0.1071\n",
      "Epoch 950/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0220 - mae: 0.1079\n",
      "Epoch 951/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0222 - mae: 0.1083\n",
      "Epoch 952/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0219 - mae: 0.1075\n",
      "Epoch 953/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0210 - mae: 0.1062\n",
      "Epoch 954/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0213 - mae: 0.1057\n",
      "Epoch 955/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0212 - mae: 0.1077\n",
      "Epoch 956/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0203 - mae: 0.1037\n",
      "Epoch 957/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0215 - mae: 0.1071\n",
      "Epoch 958/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0211 - mae: 0.1054\n",
      "Epoch 959/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0217 - mae: 0.1066\n",
      "Epoch 960/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0212 - mae: 0.1057\n",
      "Epoch 961/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0221 - mae: 0.1088\n",
      "Epoch 962/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0219 - mae: 0.1073\n",
      "Epoch 963/2000\n",
      "2018/2018 [==============================] - 0s 94us/sample - loss: 0.0215 - mae: 0.1052\n",
      "Epoch 964/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0204 - mae: 0.1037\n",
      "Epoch 965/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0208 - mae: 0.1057\n",
      "Epoch 966/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0206 - mae: 0.1039\n",
      "Epoch 967/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0201 - mae: 0.1033\n",
      "Epoch 968/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0203 - mae: 0.1030\n",
      "Epoch 969/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0211 - mae: 0.1058\n",
      "Epoch 970/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0216 - mae: 0.1075\n",
      "Epoch 971/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0205 - mae: 0.1043\n",
      "Epoch 972/2000\n",
      "2018/2018 [==============================] - 0s 97us/sample - loss: 0.0217 - mae: 0.1084\n",
      "Epoch 973/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0222 - mae: 0.1091\n",
      "Epoch 974/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0201 - mae: 0.1035\n",
      "Epoch 975/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0204 - mae: 0.1034\n",
      "Epoch 976/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0201 - mae: 0.1038\n",
      "Epoch 977/2000\n",
      "2018/2018 [==============================] - 0s 91us/sample - loss: 0.0201 - mae: 0.1033\n",
      "Epoch 978/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0274 - mae: 0.1234\n",
      "Epoch 979/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0213 - mae: 0.1063\n",
      "Epoch 980/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.0211 - mae: 0.1062\n",
      "Epoch 981/2000\n",
      "2018/2018 [==============================] - 0s 91us/sample - loss: 0.0228 - mae: 0.1117\n",
      "Epoch 982/2000\n",
      "2018/2018 [==============================] - 0s 95us/sample - loss: 0.0206 - mae: 0.1044\n",
      "Epoch 983/2000\n",
      "2018/2018 [==============================] - 0s 107us/sample - loss: 0.0204 - mae: 0.1040\n",
      "Epoch 984/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0202 - mae: 0.1024\n",
      "Epoch 985/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0199 - mae: 0.1027\n",
      "Epoch 986/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0212 - mae: 0.1063\n",
      "Epoch 987/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0220 - mae: 0.1086\n",
      "Epoch 988/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0205 - mae: 0.1048\n",
      "Epoch 989/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0199 - mae: 0.1021\n",
      "Epoch 990/2000\n",
      "2018/2018 [==============================] - 0s 98us/sample - loss: 0.0200 - mae: 0.1029\n",
      "Epoch 991/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0207 - mae: 0.1047\n",
      "Epoch 992/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.0212 - mae: 0.1069\n",
      "Epoch 993/2000\n",
      "2018/2018 [==============================] - 0s 114us/sample - loss: 0.0201 - mae: 0.1035\n",
      "Epoch 994/2000\n",
      "2018/2018 [==============================] - 0s 110us/sample - loss: 0.0203 - mae: 0.1036\n",
      "Epoch 995/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0217 - mae: 0.1099\n",
      "Epoch 996/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0201 - mae: 0.1028\n",
      "Epoch 997/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0203 - mae: 0.1037\n",
      "Epoch 998/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0203 - mae: 0.1047\n",
      "Epoch 999/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0204 - mae: 0.1041\n",
      "Epoch 1000/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.1013\n",
      "Epoch 1001/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0194 - mae: 0.1008\n",
      "Epoch 1002/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0200 - mae: 0.1030\n",
      "Epoch 1003/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0200 - mae: 0.1033\n",
      "Epoch 1004/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0197 - mae: 0.1022\n",
      "Epoch 1005/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0199 - mae: 0.1016\n",
      "Epoch 1006/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0204 - mae: 0.1030\n",
      "Epoch 1007/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0198 - mae: 0.1014\n",
      "Epoch 1008/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0197 - mae: 0.1024\n",
      "Epoch 1009/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0198 - mae: 0.1020\n",
      "Epoch 1010/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0200 - mae: 0.1031\n",
      "Epoch 1011/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0201 - mae: 0.1034\n",
      "Epoch 1012/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0203 - mae: 0.1042\n",
      "Epoch 1013/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0209 - mae: 0.1063\n",
      "Epoch 1014/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0207 - mae: 0.1061\n",
      "Epoch 1015/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0197 - mae: 0.1018\n",
      "Epoch 1016/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0199 - mae: 0.1023\n",
      "Epoch 1017/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0217 - mae: 0.1066\n",
      "Epoch 1018/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0211 - mae: 0.1045\n",
      "Epoch 1019/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0206 - mae: 0.1043\n",
      "Epoch 1020/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0215 - mae: 0.1068\n",
      "Epoch 1021/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0248 - mae: 0.1165\n",
      "Epoch 1022/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0217 - mae: 0.1089\n",
      "Epoch 1023/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0202 - mae: 0.1027\n",
      "Epoch 1024/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0201 - mae: 0.1035\n",
      "Epoch 1025/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0197 - mae: 0.1009\n",
      "Epoch 1026/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0202 - mae: 0.1033\n",
      "Epoch 1027/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0199 - mae: 0.1027\n",
      "Epoch 1028/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0196 - mae: 0.1016\n",
      "Epoch 1029/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0209 - mae: 0.1058\n",
      "Epoch 1030/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0198 - mae: 0.1021\n",
      "Epoch 1031/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0200 - mae: 0.1033\n",
      "Epoch 1032/2000\n",
      "2018/2018 [==============================] - 0s 100us/sample - loss: 0.0199 - mae: 0.1029\n",
      "Epoch 1033/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0200 - mae: 0.1025\n",
      "Epoch 1034/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0192 - mae: 0.1004\n",
      "Epoch 1035/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0197 - mae: 0.1014\n",
      "Epoch 1036/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0207 - mae: 0.1046\n",
      "Epoch 1037/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0199 - mae: 0.1026\n",
      "Epoch 1038/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0198 - mae: 0.1019\n",
      "Epoch 1039/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0213 - mae: 0.1061\n",
      "Epoch 1040/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0200 - mae: 0.1028\n",
      "Epoch 1041/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0201 - mae: 0.1033\n",
      "Epoch 1042/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0197 - mae: 0.1025\n",
      "Epoch 1043/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0240 - mae: 0.1149\n",
      "Epoch 1044/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.1019\n",
      "Epoch 1045/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0192 - mae: 0.1003\n",
      "Epoch 1046/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0191 - mae: 0.0990\n",
      "Epoch 1047/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0192 - mae: 0.0998\n",
      "Epoch 1048/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0198 - mae: 0.1022\n",
      "Epoch 1049/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0189 - mae: 0.0993\n",
      "Epoch 1050/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0231 - mae: 0.1114\n",
      "Epoch 1051/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0202 - mae: 0.1037\n",
      "Epoch 1052/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0192 - mae: 0.1009\n",
      "Epoch 1053/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0197 - mae: 0.1031\n",
      "Epoch 1054/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0192 - mae: 0.0995\n",
      "Epoch 1055/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0205 - mae: 0.1044\n",
      "Epoch 1056/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0201 - mae: 0.1046\n",
      "Epoch 1057/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0193 - mae: 0.1011\n",
      "Epoch 1058/2000\n",
      "2018/2018 [==============================] - 0s 96us/sample - loss: 0.0198 - mae: 0.1032\n",
      "Epoch 1059/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0198 - mae: 0.1016\n",
      "Epoch 1060/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0197 - mae: 0.1018\n",
      "Epoch 1061/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0190 - mae: 0.0998\n",
      "Epoch 1062/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0189 - mae: 0.1002\n",
      "Epoch 1063/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0202 - mae: 0.1038\n",
      "Epoch 1064/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0200 - mae: 0.1029\n",
      "Epoch 1065/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0199 - mae: 0.1029\n",
      "Epoch 1066/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0209 - mae: 0.1048\n",
      "Epoch 1067/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0208 - mae: 0.1060\n",
      "Epoch 1068/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0193 - mae: 0.1008\n",
      "Epoch 1069/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0193 - mae: 0.1009\n",
      "Epoch 1070/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0204 - mae: 0.1047\n",
      "Epoch 1071/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0192 - mae: 0.1005\n",
      "Epoch 1072/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0192 - mae: 0.0999\n",
      "Epoch 1073/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0190 - mae: 0.0997\n",
      "Epoch 1074/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0191 - mae: 0.1000\n",
      "Epoch 1075/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0193 - mae: 0.1005\n",
      "Epoch 1076/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0187 - mae: 0.0990\n",
      "Epoch 1077/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0189 - mae: 0.0994\n",
      "Epoch 1078/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0195 - mae: 0.1013\n",
      "Epoch 1079/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0190 - mae: 0.0997\n",
      "Epoch 1080/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0197 - mae: 0.1020\n",
      "Epoch 1081/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0194 - mae: 0.1012\n",
      "Epoch 1082/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0189 - mae: 0.1000\n",
      "Epoch 1083/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0203 - mae: 0.1046\n",
      "Epoch 1084/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0212 - mae: 0.1063\n",
      "Epoch 1085/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0200 - mae: 0.1036\n",
      "Epoch 1086/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0195 - mae: 0.1011\n",
      "Epoch 1087/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0196 - mae: 0.1021\n",
      "Epoch 1088/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0187 - mae: 0.0987\n",
      "Epoch 1089/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0188 - mae: 0.0996\n",
      "Epoch 1090/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0184 - mae: 0.0985\n",
      "Epoch 1091/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0193 - mae: 0.1012\n",
      "Epoch 1092/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0200 - mae: 0.1028\n",
      "Epoch 1093/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0214 - mae: 0.1085\n",
      "Epoch 1094/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0194 - mae: 0.1026\n",
      "Epoch 1095/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0193 - mae: 0.1002\n",
      "Epoch 1096/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0196 - mae: 0.1021\n",
      "Epoch 1097/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0199 - mae: 0.1029\n",
      "Epoch 1098/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1024\n",
      "Epoch 1099/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0187 - mae: 0.0983\n",
      "Epoch 1100/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.1011\n",
      "Epoch 1101/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0185 - mae: 0.0979\n",
      "Epoch 1102/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1022\n",
      "Epoch 1103/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1009\n",
      "Epoch 1104/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0188 - mae: 0.0993\n",
      "Epoch 1105/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0194 - mae: 0.1014\n",
      "Epoch 1106/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0195 - mae: 0.1018\n",
      "Epoch 1107/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0196 - mae: 0.1016\n",
      "Epoch 1108/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0202 - mae: 0.1034\n",
      "Epoch 1109/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0196 - mae: 0.1022\n",
      "Epoch 1110/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0198 - mae: 0.1026\n",
      "Epoch 1111/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0187 - mae: 0.0992\n",
      "Epoch 1112/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0187 - mae: 0.0988\n",
      "Epoch 1113/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0187 - mae: 0.0988\n",
      "Epoch 1114/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0185 - mae: 0.0993\n",
      "Epoch 1115/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0519 - mae: 0.1077\n",
      "Epoch 1116/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0239 - mae: 0.1146\n",
      "Epoch 1117/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0235 - mae: 0.1145\n",
      "Epoch 1118/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0229 - mae: 0.1122\n",
      "Epoch 1119/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0205 - mae: 0.1049\n",
      "Epoch 1120/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0199 - mae: 0.1020\n",
      "Epoch 1121/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0197 - mae: 0.1012\n",
      "Epoch 1122/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0192 - mae: 0.1004\n",
      "Epoch 1123/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0199 - mae: 0.1028\n",
      "Epoch 1124/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0193 - mae: 0.1006\n",
      "Epoch 1125/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0192 - mae: 0.0998\n",
      "Epoch 1126/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0203 - mae: 0.1037\n",
      "Epoch 1127/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0194 - mae: 0.1014\n",
      "Epoch 1128/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0200 - mae: 0.1022\n",
      "Epoch 1129/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0210 - mae: 0.1061\n",
      "Epoch 1130/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0191 - mae: 0.0998\n",
      "Epoch 1131/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0189 - mae: 0.0992\n",
      "Epoch 1132/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0186 - mae: 0.0983\n",
      "Epoch 1133/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0210 - mae: 0.1052\n",
      "Epoch 1134/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0199 - mae: 0.1023\n",
      "Epoch 1135/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0208 - mae: 0.1059\n",
      "Epoch 1136/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0186 - mae: 0.0983\n",
      "Epoch 1137/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0246 - mae: 0.1150\n",
      "Epoch 1138/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0197 - mae: 0.1009\n",
      "Epoch 1139/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0186 - mae: 0.0978\n",
      "Epoch 1140/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0200 - mae: 0.1026\n",
      "Epoch 1141/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0186 - mae: 0.0982\n",
      "Epoch 1142/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0187 - mae: 0.0980\n",
      "Epoch 1143/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.0995\n",
      "Epoch 1144/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0193 - mae: 0.1002\n",
      "Epoch 1145/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0260 - mae: 0.1194\n",
      "Epoch 1146/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0208 - mae: 0.1048\n",
      "Epoch 1147/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0198 - mae: 0.1022\n",
      "Epoch 1148/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0207 - mae: 0.1049\n",
      "Epoch 1149/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0205 - mae: 0.1039\n",
      "Epoch 1150/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0196 - mae: 0.1009\n",
      "Epoch 1151/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0193 - mae: 0.1010\n",
      "Epoch 1152/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0191 - mae: 0.1003\n",
      "Epoch 1153/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0205 - mae: 0.1045\n",
      "Epoch 1154/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0190 - mae: 0.0991\n",
      "Epoch 1155/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1001\n",
      "Epoch 1156/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0192 - mae: 0.1010\n",
      "Epoch 1157/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0188 - mae: 0.0991\n",
      "Epoch 1158/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0188 - mae: 0.0992\n",
      "Epoch 1159/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.0990\n",
      "Epoch 1160/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0189 - mae: 0.0992\n",
      "Epoch 1161/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0186 - mae: 0.0993\n",
      "Epoch 1162/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0191 - mae: 0.0992\n",
      "Epoch 1163/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0186 - mae: 0.0996\n",
      "Epoch 1164/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0199 - mae: 0.1025\n",
      "Epoch 1165/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.1001\n",
      "Epoch 1166/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.1011\n",
      "Epoch 1167/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0186 - mae: 0.0987\n",
      "Epoch 1168/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.0990\n",
      "Epoch 1169/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0190 - mae: 0.1005\n",
      "Epoch 1170/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0982\n",
      "Epoch 1171/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0193 - mae: 0.1014\n",
      "Epoch 1172/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0185 - mae: 0.0975\n",
      "Epoch 1173/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0207 - mae: 0.1053\n",
      "Epoch 1174/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0192 - mae: 0.1001\n",
      "Epoch 1175/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0198 - mae: 0.1023\n",
      "Epoch 1176/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0187 - mae: 0.0987\n",
      "Epoch 1177/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1035\n",
      "Epoch 1178/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0184 - mae: 0.0981\n",
      "Epoch 1179/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0193 - mae: 0.1006\n",
      "Epoch 1180/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0197 - mae: 0.1020\n",
      "Epoch 1181/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0188 - mae: 0.0995\n",
      "Epoch 1182/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0966\n",
      "Epoch 1183/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0181 - mae: 0.0971\n",
      "Epoch 1184/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0260 - mae: 0.1213\n",
      "Epoch 1185/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0211 - mae: 0.1064\n",
      "Epoch 1186/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0200 - mae: 0.1033\n",
      "Epoch 1187/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0201 - mae: 0.1032\n",
      "Epoch 1188/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0208 - mae: 0.1058\n",
      "Epoch 1189/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1015\n",
      "Epoch 1190/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0198 - mae: 0.1022\n",
      "Epoch 1191/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0192 - mae: 0.1000\n",
      "Epoch 1192/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0191 - mae: 0.1000\n",
      "Epoch 1193/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0186 - mae: 0.0982\n",
      "Epoch 1194/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0192 - mae: 0.1004\n",
      "Epoch 1195/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.0995\n",
      "Epoch 1196/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0189 - mae: 0.0996\n",
      "Epoch 1197/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0188 - mae: 0.0993\n",
      "Epoch 1198/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0201 - mae: 0.1023\n",
      "Epoch 1199/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0188 - mae: 0.0990\n",
      "Epoch 1200/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0191 - mae: 0.1002\n",
      "Epoch 1201/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0243 - mae: 0.1158\n",
      "Epoch 1202/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0194 - mae: 0.1017\n",
      "Epoch 1203/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0193 - mae: 0.0995\n",
      "Epoch 1204/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0191 - mae: 0.1000\n",
      "Epoch 1205/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1003\n",
      "Epoch 1206/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0184 - mae: 0.0981\n",
      "Epoch 1207/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0186 - mae: 0.0986\n",
      "Epoch 1208/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0183 - mae: 0.0987\n",
      "Epoch 1209/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.0992\n",
      "Epoch 1210/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0186 - mae: 0.0996\n",
      "Epoch 1211/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0196 - mae: 0.1023\n",
      "Epoch 1212/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0189 - mae: 0.0993\n",
      "Epoch 1213/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0984\n",
      "Epoch 1214/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0199 - mae: 0.1028\n",
      "Epoch 1215/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0183 - mae: 0.0980\n",
      "Epoch 1216/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0187 - mae: 0.0994\n",
      "Epoch 1217/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1002\n",
      "Epoch 1218/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0181 - mae: 0.0972\n",
      "Epoch 1219/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0186 - mae: 0.0989\n",
      "Epoch 1220/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.0997\n",
      "Epoch 1221/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0181 - mae: 0.0966\n",
      "Epoch 1222/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0230 - mae: 0.1115\n",
      "Epoch 1223/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0194 - mae: 0.1006\n",
      "Epoch 1224/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0990\n",
      "Epoch 1225/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0188 - mae: 0.0997\n",
      "Epoch 1226/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0197 - mae: 0.1024\n",
      "Epoch 1227/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0188 - mae: 0.0996\n",
      "Epoch 1228/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0182 - mae: 0.0969\n",
      "Epoch 1229/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0188 - mae: 0.1001\n",
      "Epoch 1230/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0305 - mae: 0.1336\n",
      "Epoch 1231/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0222 - mae: 0.1102\n",
      "Epoch 1232/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0191 - mae: 0.0999\n",
      "Epoch 1233/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0188 - mae: 0.0992\n",
      "Epoch 1234/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0962\n",
      "Epoch 1235/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0981\n",
      "Epoch 1236/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0182 - mae: 0.0978\n",
      "Epoch 1237/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0186 - mae: 0.0983\n",
      "Epoch 1238/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0185 - mae: 0.0988\n",
      "Epoch 1239/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0188 - mae: 0.0998\n",
      "Epoch 1240/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0188 - mae: 0.0989\n",
      "Epoch 1241/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0193 - mae: 0.1005\n",
      "Epoch 1242/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1012\n",
      "Epoch 1243/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0196 - mae: 0.1011\n",
      "Epoch 1244/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0184 - mae: 0.0987\n",
      "Epoch 1245/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0196 - mae: 0.1018\n",
      "Epoch 1246/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0200 - mae: 0.1036\n",
      "Epoch 1247/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0186 - mae: 0.0979\n",
      "Epoch 1248/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0200 - mae: 0.1034\n",
      "Epoch 1249/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0209 - mae: 0.1060\n",
      "Epoch 1250/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0187 - mae: 0.0984\n",
      "Epoch 1251/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0182 - mae: 0.0974\n",
      "Epoch 1252/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0185 - mae: 0.0987\n",
      "Epoch 1253/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0181 - mae: 0.0969\n",
      "Epoch 1254/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0188 - mae: 0.0996\n",
      "Epoch 1255/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0179 - mae: 0.0966\n",
      "Epoch 1256/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0178 - mae: 0.0961\n",
      "Epoch 1257/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0181 - mae: 0.0974\n",
      "Epoch 1258/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0186 - mae: 0.0993\n",
      "Epoch 1259/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0181 - mae: 0.0970\n",
      "Epoch 1260/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0179 - mae: 0.0969\n",
      "Epoch 1261/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0179 - mae: 0.0969\n",
      "Epoch 1262/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0185 - mae: 0.0989\n",
      "Epoch 1263/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0182 - mae: 0.0974\n",
      "Epoch 1264/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0182 - mae: 0.0980\n",
      "Epoch 1265/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0177 - mae: 0.0959\n",
      "Epoch 1266/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0181 - mae: 0.0977\n",
      "Epoch 1267/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0989\n",
      "Epoch 1268/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0965\n",
      "Epoch 1269/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0184 - mae: 0.0986\n",
      "Epoch 1270/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0183 - mae: 0.0982\n",
      "Epoch 1271/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0188 - mae: 0.1006\n",
      "Epoch 1272/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0185 - mae: 0.0990\n",
      "Epoch 1273/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1035\n",
      "Epoch 1274/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0188 - mae: 0.1001\n",
      "Epoch 1275/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0188 - mae: 0.0997\n",
      "Epoch 1276/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0187 - mae: 0.0991\n",
      "Epoch 1277/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0181 - mae: 0.0974\n",
      "Epoch 1278/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0176 - mae: 0.0962\n",
      "Epoch 1279/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0203 - mae: 0.1053\n",
      "Epoch 1280/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0186 - mae: 0.0997\n",
      "Epoch 1281/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0197 - mae: 0.1033\n",
      "Epoch 1282/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0197 - mae: 0.1024\n",
      "Epoch 1283/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1035\n",
      "Epoch 1284/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.1001\n",
      "Epoch 1285/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0188 - mae: 0.1002\n",
      "Epoch 1286/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0203 - mae: 0.1040\n",
      "Epoch 1287/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0407 - mae: 0.1545\n",
      "Epoch 1288/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0246 - mae: 0.1192\n",
      "Epoch 1289/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0218 - mae: 0.1093\n",
      "Epoch 1290/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0206 - mae: 0.1052\n",
      "Epoch 1291/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0217 - mae: 0.1082\n",
      "Epoch 1292/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0198 - mae: 0.1026\n",
      "Epoch 1293/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1012\n",
      "Epoch 1294/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0198 - mae: 0.1025\n",
      "Epoch 1295/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0187 - mae: 0.0995\n",
      "Epoch 1296/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0198 - mae: 0.1025\n",
      "Epoch 1297/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1042\n",
      "Epoch 1298/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0187 - mae: 0.0999\n",
      "Epoch 1299/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.1004\n",
      "Epoch 1300/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0976\n",
      "Epoch 1301/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0991\n",
      "Epoch 1302/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0187 - mae: 0.0998\n",
      "Epoch 1303/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0181 - mae: 0.0979\n",
      "Epoch 1304/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0185 - mae: 0.0984\n",
      "Epoch 1305/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0186 - mae: 0.0991\n",
      "Epoch 1306/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0185 - mae: 0.0996\n",
      "Epoch 1307/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0196 - mae: 0.1022\n",
      "Epoch 1308/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0187 - mae: 0.0994\n",
      "Epoch 1309/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0182 - mae: 0.0973\n",
      "Epoch 1310/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0176 - mae: 0.0961\n",
      "Epoch 1311/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0188 - mae: 0.1004\n",
      "Epoch 1312/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0176 - mae: 0.0965\n",
      "Epoch 1313/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0185 - mae: 0.0993\n",
      "Epoch 1314/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0181 - mae: 0.0979\n",
      "Epoch 1315/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0182 - mae: 0.0979\n",
      "Epoch 1316/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0174 - mae: 0.0953\n",
      "Epoch 1317/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0193 - mae: 0.1019\n",
      "Epoch 1318/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0219 - mae: 0.1088\n",
      "Epoch 1319/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0185 - mae: 0.0989\n",
      "Epoch 1320/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0180 - mae: 0.0976\n",
      "Epoch 1321/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0178 - mae: 0.0970\n",
      "Epoch 1322/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0175 - mae: 0.0952\n",
      "Epoch 1323/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0185 - mae: 0.0989\n",
      "Epoch 1324/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0179 - mae: 0.0976\n",
      "Epoch 1325/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0175 - mae: 0.0959\n",
      "Epoch 1326/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0185 - mae: 0.0989\n",
      "Epoch 1327/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0180 - mae: 0.0972\n",
      "Epoch 1328/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0181 - mae: 0.0976\n",
      "Epoch 1329/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0177 - mae: 0.0955\n",
      "Epoch 1330/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0195 - mae: 0.1021\n",
      "Epoch 1331/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0177 - mae: 0.0969\n",
      "Epoch 1332/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0171 - mae: 0.0944\n",
      "Epoch 1333/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0175 - mae: 0.0955\n",
      "Epoch 1334/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0180 - mae: 0.0980\n",
      "Epoch 1335/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0178 - mae: 0.0976\n",
      "Epoch 1336/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0198 - mae: 0.1030\n",
      "Epoch 1337/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0201 - mae: 0.1044\n",
      "Epoch 1338/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0178 - mae: 0.0974\n",
      "Epoch 1339/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0181 - mae: 0.0983\n",
      "Epoch 1340/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0180 - mae: 0.0976\n",
      "Epoch 1341/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0180 - mae: 0.0976\n",
      "Epoch 1342/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0235 - mae: 0.1131\n",
      "Epoch 1343/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0186 - mae: 0.0989\n",
      "Epoch 1344/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0180 - mae: 0.0979\n",
      "Epoch 1345/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0178 - mae: 0.0967\n",
      "Epoch 1346/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0182 - mae: 0.0978\n",
      "Epoch 1347/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0191 - mae: 0.1004\n",
      "Epoch 1348/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0177 - mae: 0.0966\n",
      "Epoch 1349/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0180 - mae: 0.0974\n",
      "Epoch 1350/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0173 - mae: 0.0953\n",
      "Epoch 1351/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0177 - mae: 0.0963\n",
      "Epoch 1352/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0172 - mae: 0.0949\n",
      "Epoch 1353/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0179 - mae: 0.0972\n",
      "Epoch 1354/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0177 - mae: 0.0972\n",
      "Epoch 1355/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0174 - mae: 0.0959\n",
      "Epoch 1356/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0177 - mae: 0.0966\n",
      "Epoch 1357/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0205 - mae: 0.1059\n",
      "Epoch 1358/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0183 - mae: 0.0984\n",
      "Epoch 1359/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.0998\n",
      "Epoch 1360/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0176 - mae: 0.0968\n",
      "Epoch 1361/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0186 - mae: 0.0996\n",
      "Epoch 1362/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0175 - mae: 0.0957\n",
      "Epoch 1363/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0178 - mae: 0.0965\n",
      "Epoch 1364/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0176 - mae: 0.0961\n",
      "Epoch 1365/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0181 - mae: 0.0983\n",
      "Epoch 1366/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0176 - mae: 0.0966\n",
      "Epoch 1367/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0176 - mae: 0.0967\n",
      "Epoch 1368/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0177 - mae: 0.0967\n",
      "Epoch 1369/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.1022\n",
      "Epoch 1370/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0183 - mae: 0.0993\n",
      "Epoch 1371/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0172 - mae: 0.0954\n",
      "Epoch 1372/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0174 - mae: 0.0959\n",
      "Epoch 1373/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0179 - mae: 0.0976\n",
      "Epoch 1374/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.1010\n",
      "Epoch 1375/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0176 - mae: 0.0965\n",
      "Epoch 1376/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0190 - mae: 0.1019\n",
      "Epoch 1377/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0177 - mae: 0.0969\n",
      "Epoch 1378/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0181 - mae: 0.0978\n",
      "Epoch 1379/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0184 - mae: 0.0982\n",
      "Epoch 1380/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0237 - mae: 0.1146\n",
      "Epoch 1381/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0212 - mae: 0.1062\n",
      "Epoch 1382/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1021\n",
      "Epoch 1383/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0186 - mae: 0.0994\n",
      "Epoch 1384/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0180 - mae: 0.0985\n",
      "Epoch 1385/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0180 - mae: 0.0973\n",
      "Epoch 1386/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.1006\n",
      "Epoch 1387/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0183 - mae: 0.0989\n",
      "Epoch 1388/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0177 - mae: 0.0969\n",
      "Epoch 1389/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0181 - mae: 0.0982\n",
      "Epoch 1390/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0176 - mae: 0.0969\n",
      "Epoch 1391/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0173 - mae: 0.0952\n",
      "Epoch 1392/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0177 - mae: 0.0969\n",
      "Epoch 1393/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0179 - mae: 0.0973\n",
      "Epoch 1394/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0181 - mae: 0.0981\n",
      "Epoch 1395/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0172 - mae: 0.0948\n",
      "Epoch 1396/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0182 - mae: 0.0985\n",
      "Epoch 1397/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0176 - mae: 0.0963\n",
      "Epoch 1398/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0177 - mae: 0.0968\n",
      "Epoch 1399/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0170 - mae: 0.0946\n",
      "Epoch 1400/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0180 - mae: 0.0970\n",
      "Epoch 1401/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0177 - mae: 0.0968\n",
      "Epoch 1402/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0178 - mae: 0.0971\n",
      "Epoch 1403/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0175 - mae: 0.0966\n",
      "Epoch 1404/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0176 - mae: 0.0967\n",
      "Epoch 1405/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0174 - mae: 0.0969\n",
      "Epoch 1406/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0174 - mae: 0.0953\n",
      "Epoch 1407/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0174 - mae: 0.0960\n",
      "Epoch 1408/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0179 - mae: 0.0970\n",
      "Epoch 1409/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0961\n",
      "Epoch 1410/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0179 - mae: 0.0982\n",
      "Epoch 1411/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0176 - mae: 0.0966\n",
      "Epoch 1412/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0177 - mae: 0.0965\n",
      "Epoch 1413/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0176 - mae: 0.0959\n",
      "Epoch 1414/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1045\n",
      "Epoch 1415/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0178 - mae: 0.0968\n",
      "Epoch 1416/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0179 - mae: 0.0979\n",
      "Epoch 1417/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0179 - mae: 0.0979\n",
      "Epoch 1418/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0960\n",
      "Epoch 1419/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0201 - mae: 0.1045\n",
      "Epoch 1420/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0184 - mae: 0.0982\n",
      "Epoch 1421/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0187 - mae: 0.0987\n",
      "Epoch 1422/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0181 - mae: 0.0972\n",
      "Epoch 1423/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0178 - mae: 0.0963\n",
      "Epoch 1424/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0176 - mae: 0.0954\n",
      "Epoch 1425/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0180 - mae: 0.0969\n",
      "Epoch 1426/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0175 - mae: 0.0951\n",
      "Epoch 1427/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0180 - mae: 0.0975\n",
      "Epoch 1428/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0180 - mae: 0.0965\n",
      "Epoch 1429/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0947\n",
      "Epoch 1430/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.1008\n",
      "Epoch 1431/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.0994\n",
      "Epoch 1432/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0179 - mae: 0.0965\n",
      "Epoch 1433/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0173 - mae: 0.0950\n",
      "Epoch 1434/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0186 - mae: 0.1001\n",
      "Epoch 1435/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0201 - mae: 0.1047\n",
      "Epoch 1436/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0172 - mae: 0.0948\n",
      "Epoch 1437/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0176 - mae: 0.0958\n",
      "Epoch 1438/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0179 - mae: 0.0986\n",
      "Epoch 1439/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0176 - mae: 0.0964\n",
      "Epoch 1440/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0171 - mae: 0.0939\n",
      "Epoch 1441/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0176 - mae: 0.0970\n",
      "Epoch 1442/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0176 - mae: 0.0952\n",
      "Epoch 1443/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0171 - mae: 0.0951\n",
      "Epoch 1444/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0186 - mae: 0.0993\n",
      "Epoch 1445/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0179 - mae: 0.0966\n",
      "Epoch 1446/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0172 - mae: 0.0947\n",
      "Epoch 1447/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0189 - mae: 0.1009\n",
      "Epoch 1448/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0207 - mae: 0.1056\n",
      "Epoch 1449/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0173 - mae: 0.0950\n",
      "Epoch 1450/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0172 - mae: 0.0949\n",
      "Epoch 1451/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0170 - mae: 0.0945\n",
      "Epoch 1452/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0192 - mae: 0.1022\n",
      "Epoch 1453/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0987\n",
      "Epoch 1454/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0175 - mae: 0.0960\n",
      "Epoch 1455/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0179 - mae: 0.0977\n",
      "Epoch 1456/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0173 - mae: 0.0956\n",
      "Epoch 1457/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0168 - mae: 0.0934\n",
      "Epoch 1458/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0171 - mae: 0.0953\n",
      "Epoch 1459/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0174 - mae: 0.0960\n",
      "Epoch 1460/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0182 - mae: 0.0979\n",
      "Epoch 1461/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0189 - mae: 0.1002\n",
      "Epoch 1462/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0186 - mae: 0.1005\n",
      "Epoch 1463/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0190 - mae: 0.1010\n",
      "Epoch 1464/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0177 - mae: 0.0967\n",
      "Epoch 1465/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0178 - mae: 0.0981\n",
      "Epoch 1466/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0178 - mae: 0.0973\n",
      "Epoch 1467/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0171 - mae: 0.0949\n",
      "Epoch 1468/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0171 - mae: 0.0946\n",
      "Epoch 1469/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0171 - mae: 0.0948\n",
      "Epoch 1470/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0193 - mae: 0.1025\n",
      "Epoch 1471/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0176 - mae: 0.0962\n",
      "Epoch 1472/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0172 - mae: 0.0951\n",
      "Epoch 1473/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0178 - mae: 0.0980\n",
      "Epoch 1474/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0963\n",
      "Epoch 1475/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0168 - mae: 0.0942\n",
      "Epoch 1476/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0176 - mae: 0.0973\n",
      "Epoch 1477/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0173 - mae: 0.0957\n",
      "Epoch 1478/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0174 - mae: 0.0959\n",
      "Epoch 1479/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0176 - mae: 0.0971\n",
      "Epoch 1480/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0171 - mae: 0.0941\n",
      "Epoch 1481/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0171 - mae: 0.0950\n",
      "Epoch 1482/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0180 - mae: 0.0981\n",
      "Epoch 1483/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0174 - mae: 0.0967\n",
      "Epoch 1484/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0174 - mae: 0.0959\n",
      "Epoch 1485/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0175 - mae: 0.0963\n",
      "Epoch 1486/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0175 - mae: 0.0964\n",
      "Epoch 1487/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0181 - mae: 0.0988\n",
      "Epoch 1488/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0179 - mae: 0.0977\n",
      "Epoch 1489/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0180 - mae: 0.0989\n",
      "Epoch 1490/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0185 - mae: 0.1001\n",
      "Epoch 1491/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0176 - mae: 0.0963\n",
      "Epoch 1492/2000\n",
      "2018/2018 [==============================] - 0s 63us/sample - loss: 0.0167 - mae: 0.0933\n",
      "Epoch 1493/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0167 - mae: 0.0936\n",
      "Epoch 1494/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0172 - mae: 0.0949\n",
      "Epoch 1495/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0167 - mae: 0.0932\n",
      "Epoch 1496/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0181 - mae: 0.0979\n",
      "Epoch 1497/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0172 - mae: 0.0953\n",
      "Epoch 1498/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0174 - mae: 0.0955\n",
      "Epoch 1499/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0169 - mae: 0.0949\n",
      "Epoch 1500/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0169 - mae: 0.0943\n",
      "Epoch 1501/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0175 - mae: 0.0960\n",
      "Epoch 1502/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0179 - mae: 0.0976\n",
      "Epoch 1503/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0172 - mae: 0.0958\n",
      "Epoch 1504/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0183 - mae: 0.0987\n",
      "Epoch 1505/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0191 - mae: 0.1009\n",
      "Epoch 1506/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0175 - mae: 0.0961\n",
      "Epoch 1507/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0170 - mae: 0.0946\n",
      "Epoch 1508/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0177 - mae: 0.0979\n",
      "Epoch 1509/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0184 - mae: 0.0997\n",
      "Epoch 1510/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0181 - mae: 0.0988\n",
      "Epoch 1511/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0181 - mae: 0.0987\n",
      "Epoch 1512/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0173 - mae: 0.0955\n",
      "Epoch 1513/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0170 - mae: 0.0940\n",
      "Epoch 1514/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0172 - mae: 0.0951\n",
      "Epoch 1515/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0171 - mae: 0.0948\n",
      "Epoch 1516/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0174 - mae: 0.0956\n",
      "Epoch 1517/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0170 - mae: 0.0949\n",
      "Epoch 1518/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0173 - mae: 0.0962\n",
      "Epoch 1519/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0174 - mae: 0.0967\n",
      "Epoch 1520/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0254 - mae: 0.1147\n",
      "Epoch 1521/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1033\n",
      "Epoch 1522/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0187 - mae: 0.0998\n",
      "Epoch 1523/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0184 - mae: 0.0986\n",
      "Epoch 1524/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0183 - mae: 0.0988\n",
      "Epoch 1525/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0181 - mae: 0.0983\n",
      "Epoch 1526/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0185 - mae: 0.0994\n",
      "Epoch 1527/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0178 - mae: 0.0972\n",
      "Epoch 1528/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0200 - mae: 0.1030\n",
      "Epoch 1529/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0182 - mae: 0.0990\n",
      "Epoch 1530/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0177 - mae: 0.0962\n",
      "Epoch 1531/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0177 - mae: 0.0964\n",
      "Epoch 1532/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0171 - mae: 0.0950\n",
      "Epoch 1533/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0176 - mae: 0.0952\n",
      "Epoch 1534/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0172 - mae: 0.0956\n",
      "Epoch 1535/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0169 - mae: 0.0942\n",
      "Epoch 1536/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0182 - mae: 0.0982\n",
      "Epoch 1537/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0193 - mae: 0.1013\n",
      "Epoch 1538/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0186 - mae: 0.0989\n",
      "Epoch 1539/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0172 - mae: 0.0948\n",
      "Epoch 1540/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0179 - mae: 0.0968\n",
      "Epoch 1541/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0172 - mae: 0.0946\n",
      "Epoch 1542/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0176 - mae: 0.0956\n",
      "Epoch 1543/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0177 - mae: 0.0965\n",
      "Epoch 1544/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0170 - mae: 0.0938\n",
      "Epoch 1545/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0171 - mae: 0.0946\n",
      "Epoch 1546/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0168 - mae: 0.0936\n",
      "Epoch 1547/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0170 - mae: 0.0946\n",
      "Epoch 1548/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0173 - mae: 0.0958\n",
      "Epoch 1549/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0186 - mae: 0.1001\n",
      "Epoch 1550/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0936\n",
      "Epoch 1551/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0171 - mae: 0.0951\n",
      "Epoch 1552/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0180 - mae: 0.0980\n",
      "Epoch 1553/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0171 - mae: 0.0947\n",
      "Epoch 1554/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0169 - mae: 0.0939\n",
      "Epoch 1555/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0167 - mae: 0.0932\n",
      "Epoch 1556/2000\n",
      "2018/2018 [==============================] - 0s 108us/sample - loss: 0.0168 - mae: 0.0935\n",
      "Epoch 1557/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0171 - mae: 0.0954\n",
      "Epoch 1558/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0977\n",
      "Epoch 1559/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0175 - mae: 0.0968\n",
      "Epoch 1560/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0176 - mae: 0.0960\n",
      "Epoch 1561/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0169 - mae: 0.0939\n",
      "Epoch 1562/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0171 - mae: 0.0957\n",
      "Epoch 1563/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0182 - mae: 0.0989\n",
      "Epoch 1564/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0171 - mae: 0.0947\n",
      "Epoch 1565/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0172 - mae: 0.0950\n",
      "Epoch 1566/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0170 - mae: 0.0948\n",
      "Epoch 1567/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0178 - mae: 0.0977\n",
      "Epoch 1568/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0182 - mae: 0.0979\n",
      "Epoch 1569/2000\n",
      "2018/2018 [==============================] - 0s 104us/sample - loss: 0.0171 - mae: 0.0950\n",
      "Epoch 1570/2000\n",
      "2018/2018 [==============================] - 0s 95us/sample - loss: 0.0174 - mae: 0.0952\n",
      "Epoch 1571/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.0169 - mae: 0.0948\n",
      "Epoch 1572/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0169 - mae: 0.0943\n",
      "Epoch 1573/2000\n",
      "2018/2018 [==============================] - 0s 91us/sample - loss: 0.0170 - mae: 0.0946\n",
      "Epoch 1574/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0168 - mae: 0.0941\n",
      "Epoch 1575/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0172 - mae: 0.0954\n",
      "Epoch 1576/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0175 - mae: 0.0961\n",
      "Epoch 1577/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0167 - mae: 0.0930\n",
      "Epoch 1578/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0169 - mae: 0.0948\n",
      "Epoch 1579/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0170 - mae: 0.0945\n",
      "Epoch 1580/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0169 - mae: 0.0946\n",
      "Epoch 1581/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0166 - mae: 0.0935\n",
      "Epoch 1582/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.0996\n",
      "Epoch 1583/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0172 - mae: 0.0957\n",
      "Epoch 1584/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0174 - mae: 0.0965\n",
      "Epoch 1585/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0176 - mae: 0.0967\n",
      "Epoch 1586/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0172 - mae: 0.0958\n",
      "Epoch 1587/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0171 - mae: 0.0951\n",
      "Epoch 1588/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0172 - mae: 0.0958\n",
      "Epoch 1589/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0163 - mae: 0.0927\n",
      "Epoch 1590/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0171 - mae: 0.0952\n",
      "Epoch 1591/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0182 - mae: 0.0992\n",
      "Epoch 1592/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0174 - mae: 0.0964\n",
      "Epoch 1593/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0178 - mae: 0.0966\n",
      "Epoch 1594/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0174 - mae: 0.0968\n",
      "Epoch 1595/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0169 - mae: 0.0944\n",
      "Epoch 1596/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0173 - mae: 0.0965\n",
      "Epoch 1597/2000\n",
      "2018/2018 [==============================] - 0s 93us/sample - loss: 0.0199 - mae: 0.1046\n",
      "Epoch 1598/2000\n",
      "2018/2018 [==============================] - 0s 115us/sample - loss: 0.0170 - mae: 0.0956\n",
      "Epoch 1599/2000\n",
      "2018/2018 [==============================] - 0s 104us/sample - loss: 0.0184 - mae: 0.0982\n",
      "Epoch 1600/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0210 - mae: 0.1052\n",
      "Epoch 1601/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0183 - mae: 0.0988\n",
      "Epoch 1602/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0175 - mae: 0.0955\n",
      "Epoch 1603/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0173 - mae: 0.0959\n",
      "Epoch 1604/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0167 - mae: 0.0941\n",
      "Epoch 1605/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0966\n",
      "Epoch 1606/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0169 - mae: 0.0940\n",
      "Epoch 1607/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0171 - mae: 0.0948\n",
      "Epoch 1608/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0176 - mae: 0.0976\n",
      "Epoch 1609/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0184 - mae: 0.0985\n",
      "Epoch 1610/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0172 - mae: 0.0957\n",
      "Epoch 1611/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0174 - mae: 0.0959\n",
      "Epoch 1612/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0171 - mae: 0.0947\n",
      "Epoch 1613/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0166 - mae: 0.0936\n",
      "Epoch 1614/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0171 - mae: 0.0955\n",
      "Epoch 1615/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3669 - mae: 0.1218\n",
      "Epoch 1616/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0219 - mae: 0.1102\n",
      "Epoch 1617/2000\n",
      "2018/2018 [==============================] - 0s 114us/sample - loss: 0.0214 - mae: 0.1093\n",
      "Epoch 1618/2000\n",
      "2018/2018 [==============================] - 0s 123us/sample - loss: 0.0196 - mae: 0.1033\n",
      "Epoch 1619/2000\n",
      "2018/2018 [==============================] - 0s 109us/sample - loss: 0.0193 - mae: 0.1030\n",
      "Epoch 1620/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0189 - mae: 0.1014\n",
      "Epoch 1621/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0190 - mae: 0.1008\n",
      "Epoch 1622/2000\n",
      "2018/2018 [==============================] - 0s 102us/sample - loss: 0.0203 - mae: 0.1049\n",
      "Epoch 1623/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0191 - mae: 0.1016\n",
      "Epoch 1624/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0188 - mae: 0.0996\n",
      "Epoch 1625/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0186 - mae: 0.0998\n",
      "Epoch 1626/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0191 - mae: 0.1009\n",
      "Epoch 1627/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0195 - mae: 0.1024\n",
      "Epoch 1628/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0188 - mae: 0.1004\n",
      "Epoch 1629/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0189 - mae: 0.1007\n",
      "Epoch 1630/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0183 - mae: 0.0996\n",
      "Epoch 1631/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0986\n",
      "Epoch 1632/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1021\n",
      "Epoch 1633/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0178 - mae: 0.0964\n",
      "Epoch 1634/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0199 - mae: 0.1042\n",
      "Epoch 1635/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0185 - mae: 0.0997\n",
      "Epoch 1636/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0193 - mae: 0.1015\n",
      "Epoch 1637/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0209 - mae: 0.1071\n",
      "Epoch 1638/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0193 - mae: 0.1023\n",
      "Epoch 1639/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0187 - mae: 0.0996\n",
      "Epoch 1640/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0177 - mae: 0.0965\n",
      "Epoch 1641/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0177 - mae: 0.0969\n",
      "Epoch 1642/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0182 - mae: 0.0985\n",
      "Epoch 1643/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0177 - mae: 0.0968\n",
      "Epoch 1644/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0191 - mae: 0.1003\n",
      "Epoch 1645/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.1011\n",
      "Epoch 1646/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0182 - mae: 0.0986\n",
      "Epoch 1647/2000\n",
      "2018/2018 [==============================] - 0s 93us/sample - loss: 0.0178 - mae: 0.0966\n",
      "Epoch 1648/2000\n",
      "2018/2018 [==============================] - 0s 97us/sample - loss: 0.0178 - mae: 0.0971\n",
      "Epoch 1649/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0185 - mae: 0.0993\n",
      "Epoch 1650/2000\n",
      "2018/2018 [==============================] - 0s 101us/sample - loss: 0.0185 - mae: 0.0997\n",
      "Epoch 1651/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0178 - mae: 0.0964\n",
      "Epoch 1652/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0180 - mae: 0.0978\n",
      "Epoch 1653/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0184 - mae: 0.0998\n",
      "Epoch 1654/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0180 - mae: 0.0972\n",
      "Epoch 1655/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0202 - mae: 0.1051\n",
      "Epoch 1656/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0186 - mae: 0.0991\n",
      "Epoch 1657/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0186 - mae: 0.0994\n",
      "Epoch 1658/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0969\n",
      "Epoch 1659/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0176 - mae: 0.0961\n",
      "Epoch 1660/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0183 - mae: 0.0985\n",
      "Epoch 1661/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0184 - mae: 0.0999\n",
      "Epoch 1662/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0178 - mae: 0.0961\n",
      "Epoch 1663/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0175 - mae: 0.0962\n",
      "Epoch 1664/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0177 - mae: 0.0958\n",
      "Epoch 1665/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0179 - mae: 0.0974\n",
      "Epoch 1666/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0184 - mae: 0.0978\n",
      "Epoch 1667/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0176 - mae: 0.0959\n",
      "Epoch 1668/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0977\n",
      "Epoch 1669/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0176 - mae: 0.0967\n",
      "Epoch 1670/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0178 - mae: 0.0969\n",
      "Epoch 1671/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0176 - mae: 0.0962\n",
      "Epoch 1672/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0187 - mae: 0.0997\n",
      "Epoch 1673/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0171 - mae: 0.0944\n",
      "Epoch 1674/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0179 - mae: 0.0969\n",
      "Epoch 1675/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0176 - mae: 0.0955\n",
      "Epoch 1676/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0185 - mae: 0.0988\n",
      "Epoch 1677/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0179 - mae: 0.0965\n",
      "Epoch 1678/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0207 - mae: 0.1046\n",
      "Epoch 1679/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0178 - mae: 0.0957\n",
      "Epoch 1680/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0178 - mae: 0.0969\n",
      "Epoch 1681/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0194 - mae: 0.1019\n",
      "Epoch 1682/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0179 - mae: 0.0972\n",
      "Epoch 1683/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0176 - mae: 0.0965\n",
      "Epoch 1684/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0176 - mae: 0.0959\n",
      "Epoch 1685/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0173 - mae: 0.0946\n",
      "Epoch 1686/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0182 - mae: 0.0984\n",
      "Epoch 1687/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0175 - mae: 0.0962\n",
      "Epoch 1688/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0199 - mae: 0.1038\n",
      "Epoch 1689/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0174 - mae: 0.0957\n",
      "Epoch 1690/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0181 - mae: 0.0977\n",
      "Epoch 1691/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0174 - mae: 0.0956\n",
      "Epoch 1692/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0971\n",
      "Epoch 1693/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0174 - mae: 0.0957\n",
      "Epoch 1694/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0192 - mae: 0.1021\n",
      "Epoch 1695/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0170 - mae: 0.0947\n",
      "Epoch 1696/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0177 - mae: 0.0959\n",
      "Epoch 1697/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0174 - mae: 0.0953\n",
      "Epoch 1698/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0176 - mae: 0.0959\n",
      "Epoch 1699/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0174 - mae: 0.0955\n",
      "Epoch 1700/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0174 - mae: 0.0955\n",
      "Epoch 1701/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0171 - mae: 0.0944\n",
      "Epoch 1702/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0171 - mae: 0.0945\n",
      "Epoch 1703/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0983\n",
      "Epoch 1704/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0171 - mae: 0.0949\n",
      "Epoch 1705/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0171 - mae: 0.0949\n",
      "Epoch 1706/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0172 - mae: 0.0945\n",
      "Epoch 1707/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0179 - mae: 0.0969\n",
      "Epoch 1708/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0178 - mae: 0.0971\n",
      "Epoch 1709/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0175 - mae: 0.0952\n",
      "Epoch 1710/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0175 - mae: 0.0957\n",
      "Epoch 1711/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0169 - mae: 0.0939\n",
      "Epoch 1712/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0187 - mae: 0.0998\n",
      "Epoch 1713/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0172 - mae: 0.0956\n",
      "Epoch 1714/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0174 - mae: 0.0958\n",
      "Epoch 1715/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0174 - mae: 0.0962\n",
      "Epoch 1716/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0172 - mae: 0.0957\n",
      "Epoch 1717/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0173 - mae: 0.0958\n",
      "Epoch 1718/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0167 - mae: 0.0931\n",
      "Epoch 1719/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0193 - mae: 0.1024\n",
      "Epoch 1720/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0169 - mae: 0.0942\n",
      "Epoch 1721/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0184 - mae: 0.0990\n",
      "Epoch 1722/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0194 - mae: 0.1018\n",
      "Epoch 1723/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0192 - mae: 0.1024\n",
      "Epoch 1724/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0176 - mae: 0.0955\n",
      "Epoch 1725/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0172 - mae: 0.0954\n",
      "Epoch 1726/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0172 - mae: 0.0958\n",
      "Epoch 1727/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0182 - mae: 0.0985\n",
      "Epoch 1728/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0169 - mae: 0.0939\n",
      "Epoch 1729/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0170 - mae: 0.0945\n",
      "Epoch 1730/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0170 - mae: 0.0941\n",
      "Epoch 1731/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0167 - mae: 0.0932\n",
      "Epoch 1732/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0170 - mae: 0.0946\n",
      "Epoch 1733/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0179 - mae: 0.0982\n",
      "Epoch 1734/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0185 - mae: 0.0998\n",
      "Epoch 1735/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0197 - mae: 0.1028\n",
      "Epoch 1736/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0957\n",
      "Epoch 1737/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0176 - mae: 0.0969\n",
      "Epoch 1738/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0932\n",
      "Epoch 1739/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0175 - mae: 0.0957\n",
      "Epoch 1740/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0176 - mae: 0.0972\n",
      "Epoch 1741/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0174 - mae: 0.0954\n",
      "Epoch 1742/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0170 - mae: 0.0940\n",
      "Epoch 1743/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0169 - mae: 0.0938\n",
      "Epoch 1744/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0184 - mae: 0.0993\n",
      "Epoch 1745/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0169 - mae: 0.0939\n",
      "Epoch 1746/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0167 - mae: 0.0933\n",
      "Epoch 1747/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0170 - mae: 0.0938\n",
      "Epoch 1748/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0170 - mae: 0.0940\n",
      "Epoch 1749/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0169 - mae: 0.0939\n",
      "Epoch 1750/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0172 - mae: 0.0949\n",
      "Epoch 1751/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0166 - mae: 0.0933\n",
      "Epoch 1752/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0168 - mae: 0.0936\n",
      "Epoch 1753/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0192 - mae: 0.1004\n",
      "Epoch 1754/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0202 - mae: 0.1043\n",
      "Epoch 1755/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0192 - mae: 0.1017\n",
      "Epoch 1756/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0961\n",
      "Epoch 1757/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0183 - mae: 0.0983\n",
      "Epoch 1758/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0183 - mae: 0.0990\n",
      "Epoch 1759/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0172 - mae: 0.0955\n",
      "Epoch 1760/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0172 - mae: 0.0956\n",
      "Epoch 1761/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0195 - mae: 0.1034\n",
      "Epoch 1762/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0170 - mae: 0.0937\n",
      "Epoch 1763/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0173 - mae: 0.0954\n",
      "Epoch 1764/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0168 - mae: 0.0941\n",
      "Epoch 1765/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0168 - mae: 0.0942\n",
      "Epoch 1766/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0167 - mae: 0.0933\n",
      "Epoch 1767/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0164 - mae: 0.0922\n",
      "Epoch 1768/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0165 - mae: 0.0931\n",
      "Epoch 1769/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0173 - mae: 0.0949\n",
      "Epoch 1770/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0950\n",
      "Epoch 1771/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0168 - mae: 0.0933\n",
      "Epoch 1772/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0169 - mae: 0.0946\n",
      "Epoch 1773/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0166 - mae: 0.0929\n",
      "Epoch 1774/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0178 - mae: 0.0982\n",
      "Epoch 1775/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0993\n",
      "Epoch 1776/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0167 - mae: 0.0940\n",
      "Epoch 1777/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0189 - mae: 0.1007\n",
      "Epoch 1778/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0183 - mae: 0.0989\n",
      "Epoch 1779/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0166 - mae: 0.0935\n",
      "Epoch 1780/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0169 - mae: 0.0948\n",
      "Epoch 1781/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0166 - mae: 0.0926\n",
      "Epoch 1782/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0166 - mae: 0.0935\n",
      "Epoch 1783/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0170 - mae: 0.0954\n",
      "Epoch 1784/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0177 - mae: 0.0972\n",
      "Epoch 1785/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0196 - mae: 0.1036\n",
      "Epoch 1786/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0171 - mae: 0.0950\n",
      "Epoch 1787/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0174 - mae: 0.0949\n",
      "Epoch 1788/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0173 - mae: 0.0951\n",
      "Epoch 1789/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0166 - mae: 0.0933\n",
      "Epoch 1790/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0166 - mae: 0.0930\n",
      "Epoch 1791/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0164 - mae: 0.0927\n",
      "Epoch 1792/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0171 - mae: 0.0950\n",
      "Epoch 1793/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0172 - mae: 0.0951\n",
      "Epoch 1794/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0170 - mae: 0.0945\n",
      "Epoch 1795/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0196 - mae: 0.1024\n",
      "Epoch 1796/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0173 - mae: 0.0948\n",
      "Epoch 1797/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0173 - mae: 0.0961\n",
      "Epoch 1798/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0169 - mae: 0.0949\n",
      "Epoch 1799/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0188 - mae: 0.0997\n",
      "Epoch 1800/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0173 - mae: 0.0956\n",
      "Epoch 1801/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0168 - mae: 0.0947\n",
      "Epoch 1802/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0171 - mae: 0.0948\n",
      "Epoch 1803/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0172 - mae: 0.0962\n",
      "Epoch 1804/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0179 - mae: 0.0986\n",
      "Epoch 1805/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0169 - mae: 0.0953\n",
      "Epoch 1806/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0166 - mae: 0.0934\n",
      "Epoch 1807/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0166 - mae: 0.0937\n",
      "Epoch 1808/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0175 - mae: 0.0972\n",
      "Epoch 1809/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0169 - mae: 0.0953\n",
      "Epoch 1810/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0175 - mae: 0.0967\n",
      "Epoch 1811/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0166 - mae: 0.0939\n",
      "Epoch 1812/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0168 - mae: 0.0944\n",
      "Epoch 1813/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0165 - mae: 0.0939\n",
      "Epoch 1814/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0168 - mae: 0.0940\n",
      "Epoch 1815/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0174 - mae: 0.0960\n",
      "Epoch 1816/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0163 - mae: 0.0926\n",
      "Epoch 1817/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0168 - mae: 0.0946\n",
      "Epoch 1818/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0166 - mae: 0.0933\n",
      "Epoch 1819/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0173 - mae: 0.0961\n",
      "Epoch 1820/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0175 - mae: 0.0965\n",
      "Epoch 1821/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0167 - mae: 0.0941\n",
      "Epoch 1822/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0169 - mae: 0.0956\n",
      "Epoch 1823/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0172 - mae: 0.0961\n",
      "Epoch 1824/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0174 - mae: 0.0964\n",
      "Epoch 1825/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0163 - mae: 0.0927\n",
      "Epoch 1826/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0166 - mae: 0.0934\n",
      "Epoch 1827/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0164 - mae: 0.0922\n",
      "Epoch 1828/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0182 - mae: 0.0988\n",
      "Epoch 1829/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0168 - mae: 0.0942\n",
      "Epoch 1830/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0165 - mae: 0.0935\n",
      "Epoch 1831/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0170 - mae: 0.0946\n",
      "Epoch 1832/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0164 - mae: 0.0932\n",
      "Epoch 1833/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0169 - mae: 0.0949\n",
      "Epoch 1834/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0172 - mae: 0.0959\n",
      "Epoch 1835/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0169 - mae: 0.0950\n",
      "Epoch 1836/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0165 - mae: 0.0926\n",
      "Epoch 1837/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0164 - mae: 0.0926\n",
      "Epoch 1838/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.1027\n",
      "Epoch 1839/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0175 - mae: 0.0974\n",
      "Epoch 1840/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0186 - mae: 0.1007\n",
      "Epoch 1841/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0165 - mae: 0.0931\n",
      "Epoch 1842/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0200 - mae: 0.1026\n",
      "Epoch 1843/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1026\n",
      "Epoch 1844/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1025\n",
      "Epoch 1845/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0178 - mae: 0.0967\n",
      "Epoch 1846/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0177 - mae: 0.0972\n",
      "Epoch 1847/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0170 - mae: 0.0939\n",
      "Epoch 1848/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0180 - mae: 0.0984\n",
      "Epoch 1849/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1036\n",
      "Epoch 1850/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0173 - mae: 0.0963\n",
      "Epoch 1851/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0171 - mae: 0.0946\n",
      "Epoch 1852/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0173 - mae: 0.0948\n",
      "Epoch 1853/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0166 - mae: 0.0928\n",
      "Epoch 1854/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0168 - mae: 0.0949\n",
      "Epoch 1855/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0165 - mae: 0.0926\n",
      "Epoch 1856/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0162 - mae: 0.0916\n",
      "Epoch 1857/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0169 - mae: 0.0944\n",
      "Epoch 1858/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0180 - mae: 0.0978\n",
      "Epoch 1859/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0167 - mae: 0.0932\n",
      "Epoch 1860/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0165 - mae: 0.0927\n",
      "Epoch 1861/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0162 - mae: 0.0915\n",
      "Epoch 1862/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0167 - mae: 0.0944\n",
      "Epoch 1863/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0166 - mae: 0.0925\n",
      "Epoch 1864/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0172 - mae: 0.0958\n",
      "Epoch 1865/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0166 - mae: 0.0936\n",
      "Epoch 1866/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0167 - mae: 0.0941\n",
      "Epoch 1867/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0171 - mae: 0.0951\n",
      "Epoch 1868/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0164 - mae: 0.0931\n",
      "Epoch 1869/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0172 - mae: 0.0954\n",
      "Epoch 1870/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0171 - mae: 0.0949\n",
      "Epoch 1871/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0164 - mae: 0.0927\n",
      "Epoch 1872/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0173 - mae: 0.0963\n",
      "Epoch 1873/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0175 - mae: 0.0978\n",
      "Epoch 1874/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0179 - mae: 0.0981\n",
      "Epoch 1875/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0174 - mae: 0.0965\n",
      "Epoch 1876/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0173 - mae: 0.0965\n",
      "Epoch 1877/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0182 - mae: 0.0986\n",
      "Epoch 1878/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0176 - mae: 0.0962\n",
      "Epoch 1879/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0166 - mae: 0.0933\n",
      "Epoch 1880/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0169 - mae: 0.0946\n",
      "Epoch 1881/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0165 - mae: 0.0927\n",
      "Epoch 1882/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0164 - mae: 0.0927\n",
      "Epoch 1883/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0161 - mae: 0.0918\n",
      "Epoch 1884/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0165 - mae: 0.0934\n",
      "Epoch 1885/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0174 - mae: 0.0966\n",
      "Epoch 1886/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0174 - mae: 0.0961\n",
      "Epoch 1887/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0165 - mae: 0.0929\n",
      "Epoch 1888/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0165 - mae: 0.0938\n",
      "Epoch 1889/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0171 - mae: 0.0950\n",
      "Epoch 1890/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0172 - mae: 0.0954\n",
      "Epoch 1891/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0219 - mae: 0.1093\n",
      "Epoch 1892/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0188 - mae: 0.0997\n",
      "Epoch 1893/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0172 - mae: 0.0945\n",
      "Epoch 1894/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0175 - mae: 0.0964\n",
      "Epoch 1895/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0177 - mae: 0.0973\n",
      "Epoch 1896/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0183 - mae: 0.0995\n",
      "Epoch 1897/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0165 - mae: 0.0934\n",
      "Epoch 1898/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0167 - mae: 0.0940\n",
      "Epoch 1899/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0166 - mae: 0.0940\n",
      "Epoch 1900/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0165 - mae: 0.0928\n",
      "Epoch 1901/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0163 - mae: 0.0919\n",
      "Epoch 1902/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0179 - mae: 0.0988\n",
      "Epoch 1903/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0168 - mae: 0.0942\n",
      "Epoch 1904/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0161 - mae: 0.0924\n",
      "Epoch 1905/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0162 - mae: 0.0925\n",
      "Epoch 1906/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0182 - mae: 0.0991\n",
      "Epoch 1907/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0163 - mae: 0.0927\n",
      "Epoch 1908/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0163 - mae: 0.0925\n",
      "Epoch 1909/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0165 - mae: 0.0934\n",
      "Epoch 1910/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0171 - mae: 0.0949\n",
      "Epoch 1911/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0164 - mae: 0.0929\n",
      "Epoch 1912/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0162 - mae: 0.0928\n",
      "Epoch 1913/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0166 - mae: 0.0938\n",
      "Epoch 1914/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0165 - mae: 0.0935\n",
      "Epoch 1915/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0173 - mae: 0.0964\n",
      "Epoch 1916/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0169 - mae: 0.0944\n",
      "Epoch 1917/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0172 - mae: 0.0959\n",
      "Epoch 1918/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0167 - mae: 0.0939\n",
      "Epoch 1919/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0169 - mae: 0.0945\n",
      "Epoch 1920/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0162 - mae: 0.0924\n",
      "Epoch 1921/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0976\n",
      "Epoch 1922/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0192 - mae: 0.1018\n",
      "Epoch 1923/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0176 - mae: 0.0980\n",
      "Epoch 1924/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0180 - mae: 0.0988\n",
      "Epoch 1925/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0169 - mae: 0.0944\n",
      "Epoch 1926/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0161 - mae: 0.0919\n",
      "Epoch 1927/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0165 - mae: 0.0931\n",
      "Epoch 1928/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0162 - mae: 0.0914\n",
      "Epoch 1929/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0171 - mae: 0.0949\n",
      "Epoch 1930/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0162 - mae: 0.0919\n",
      "Epoch 1931/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0165 - mae: 0.0934\n",
      "Epoch 1932/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0161 - mae: 0.0912\n",
      "Epoch 1933/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0165 - mae: 0.0933\n",
      "Epoch 1934/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0168 - mae: 0.0945\n",
      "Epoch 1935/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0165 - mae: 0.0938\n",
      "Epoch 1936/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0170 - mae: 0.0949\n",
      "Epoch 1937/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0966\n",
      "Epoch 1938/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0971\n",
      "Epoch 1939/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0160 - mae: 0.0916\n",
      "Epoch 1940/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0171 - mae: 0.0954\n",
      "Epoch 1941/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0170 - mae: 0.0950\n",
      "Epoch 1942/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0165 - mae: 0.0922\n",
      "Epoch 1943/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0176 - mae: 0.0973\n",
      "Epoch 1944/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0167 - mae: 0.0947\n",
      "Epoch 1945/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0170 - mae: 0.0952\n",
      "Epoch 1946/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0162 - mae: 0.0919\n",
      "Epoch 1947/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0946\n",
      "Epoch 1948/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1051\n",
      "Epoch 1949/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0161 - mae: 0.0920\n",
      "Epoch 1950/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0162 - mae: 0.0926\n",
      "Epoch 1951/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0171 - mae: 0.0955\n",
      "Epoch 1952/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0168 - mae: 0.0958\n",
      "Epoch 1953/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0171 - mae: 0.0951\n",
      "Epoch 1954/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0168 - mae: 0.0943\n",
      "Epoch 1955/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0158 - mae: 0.0909\n",
      "Epoch 1956/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0167 - mae: 0.0949\n",
      "Epoch 1957/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0174 - mae: 0.0970\n",
      "Epoch 1958/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0162 - mae: 0.0928\n",
      "Epoch 1959/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0159 - mae: 0.0911\n",
      "Epoch 1960/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0163 - mae: 0.0924\n",
      "Epoch 1961/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0160 - mae: 0.0918\n",
      "Epoch 1962/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0185 - mae: 0.0990\n",
      "Epoch 1963/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0161 - mae: 0.0927\n",
      "Epoch 1964/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0170 - mae: 0.0953\n",
      "Epoch 1965/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0175 - mae: 0.0975\n",
      "Epoch 1966/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0163 - mae: 0.0931\n",
      "Epoch 1967/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0169 - mae: 0.0944\n",
      "Epoch 1968/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0208 - mae: 0.1074\n",
      "Epoch 1969/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0183 - mae: 0.0993\n",
      "Epoch 1970/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0178 - mae: 0.0985\n",
      "Epoch 1971/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0170 - mae: 0.0947\n",
      "Epoch 1972/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0173 - mae: 0.0957\n",
      "Epoch 1973/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0172 - mae: 0.0961\n",
      "Epoch 1974/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0176 - mae: 0.0975\n",
      "Epoch 1975/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0179 - mae: 0.0986\n",
      "Epoch 1976/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0176 - mae: 0.0978\n",
      "Epoch 1977/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0163 - mae: 0.0922\n",
      "Epoch 1978/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0168 - mae: 0.0946\n",
      "Epoch 1979/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0167 - mae: 0.0944\n",
      "Epoch 1980/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0167 - mae: 0.0947\n",
      "Epoch 1981/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0163 - mae: 0.0924\n",
      "Epoch 1982/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0169 - mae: 0.0948\n",
      "Epoch 1983/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0163 - mae: 0.0925\n",
      "Epoch 1984/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0169 - mae: 0.0949\n",
      "Epoch 1985/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0172 - mae: 0.0961\n",
      "Epoch 1986/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0175 - mae: 0.0970\n",
      "Epoch 1987/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0163 - mae: 0.0934\n",
      "Epoch 1988/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0166 - mae: 0.0940\n",
      "Epoch 1989/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0180 - mae: 0.0988\n",
      "Epoch 1990/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0165 - mae: 0.0934\n",
      "Epoch 1991/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0169 - mae: 0.0946\n",
      "Epoch 1992/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0176 - mae: 0.0973\n",
      "Epoch 1993/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0170 - mae: 0.0950\n",
      "Epoch 1994/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0164 - mae: 0.0924\n",
      "Epoch 1995/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0188 - mae: 0.1009\n",
      "Epoch 1996/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0170 - mae: 0.0955\n",
      "Epoch 1997/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0164 - mae: 0.0931\n",
      "Epoch 1998/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0165 - mae: 0.0937\n",
      "Epoch 1999/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0166 - mae: 0.0935\n",
      "Epoch 2000/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0162 - mae: 0.0930\n",
      "mae: 0.13858258724212646\n",
      "Overfit mae: 0.0922672227025032\n",
      "Train on 2018 samples\n",
      "Epoch 1/2000\n",
      "2018/2018 [==============================] - 1s 677us/sample - loss: 11021.3777 - mae: 26.7638\n",
      "Epoch 2/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 5206.0096 - mae: 16.6672\n",
      "Epoch 3/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 2893.6274 - mae: 11.5416\n",
      "Epoch 4/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 2424.8989 - mae: 9.9436\n",
      "Epoch 5/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 14245.6452 - mae: 29.3428\n",
      "Epoch 6/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 2306.0434 - mae: 13.3584\n",
      "Epoch 7/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 7639.4186 - mae: 13.4559\n",
      "Epoch 8/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 9435.9266 - mae: 21.4371\n",
      "Epoch 9/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 4457.5944 - mae: 12.5252\n",
      "Epoch 10/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 4035.2784 - mae: 13.7023\n",
      "Epoch 11/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 775.4955 - mae: 6.6606\n",
      "Epoch 12/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 696.5772 - mae: 5.9302\n",
      "Epoch 13/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 505.8517 - mae: 5.0020\n",
      "Epoch 14/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 709.7228 - mae: 4.9986\n",
      "Epoch 15/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 2292.8892 - mae: 7.6963\n",
      "Epoch 16/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 1234.5379 - mae: 7.6576\n",
      "Epoch 17/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 1044.5307 - mae: 5.4151\n",
      "Epoch 18/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 1796.7942 - mae: 9.1749\n",
      "Epoch 19/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 641.1335 - mae: 5.5045\n",
      "Epoch 20/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 4260.1662 - mae: 10.4279\n",
      "Epoch 21/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 9057.0655 - mae: 15.2311\n",
      "Epoch 22/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 19239.6121 - mae: 23.2180\n",
      "Epoch 23/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 4125.6989 - mae: 13.3315\n",
      "Epoch 24/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 2257.8534 - mae: 6.2428\n",
      "Epoch 25/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 535.1032 - mae: 5.3715\n",
      "Epoch 26/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 1628.6290 - mae: 7.1363\n",
      "Epoch 27/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 73us/sample - loss: 2836.8755 - mae: 6.1448\n",
      "Epoch 28/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 5270.3432 - mae: 12.7186\n",
      "Epoch 29/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 457.0748 - mae: 5.2938\n",
      "Epoch 30/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 640.1681 - mae: 4.3394\n",
      "Epoch 31/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 444.0787 - mae: 3.6039\n",
      "Epoch 32/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 179.5282 - mae: 2.7369\n",
      "Epoch 33/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 329.3743 - mae: 3.7784\n",
      "Epoch 34/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 536.5245 - mae: 5.0948\n",
      "Epoch 35/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 1218.1589 - mae: 6.1212\n",
      "Epoch 36/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 782.7951 - mae: 5.3984\n",
      "Epoch 37/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 789.4636 - mae: 5.1375\n",
      "Epoch 38/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 814.3784 - mae: 4.8915\n",
      "Epoch 39/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 763.8569 - mae: 3.9290\n",
      "Epoch 40/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 2515.6309 - mae: 8.1628\n",
      "Epoch 41/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 663.0123 - mae: 4.0155\n",
      "Epoch 42/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 1381.4408 - mae: 5.6741\n",
      "Epoch 43/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 1050.6044 - mae: 6.0514\n",
      "Epoch 44/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 5009.7438 - mae: 11.7575\n",
      "Epoch 45/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 2483.3685 - mae: 6.1226\n",
      "Epoch 46/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 12330.2942 - mae: 12.1849\n",
      "Epoch 47/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 1535.3640 - mae: 6.0897\n",
      "Epoch 48/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 790.9615 - mae: 5.4794\n",
      "Epoch 49/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 530.7407 - mae: 4.6399\n",
      "Epoch 50/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 86.3281 - mae: 2.6686\n",
      "Epoch 51/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 51.3819 - mae: 1.9932\n",
      "Epoch 52/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 41.3406 - mae: 1.7860\n",
      "Epoch 53/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 32.3807 - mae: 1.6957\n",
      "Epoch 54/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 27.6662 - mae: 1.6537\n",
      "Epoch 55/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 36.4259 - mae: 1.7457\n",
      "Epoch 56/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 42.3619 - mae: 1.7383\n",
      "Epoch 57/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 26.3586 - mae: 1.5745\n",
      "Epoch 58/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 33.4212 - mae: 1.6312\n",
      "Epoch 59/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 42.9017 - mae: 1.7123\n",
      "Epoch 60/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 53.4971 - mae: 1.8033\n",
      "Epoch 61/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 18.3036 - mae: 1.4391\n",
      "Epoch 62/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 36.2549 - mae: 1.6587\n",
      "Epoch 63/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 45.7859 - mae: 1.7045\n",
      "Epoch 64/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 99.4626 - mae: 2.0903\n",
      "Epoch 65/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 187.0450 - mae: 2.5242\n",
      "Epoch 66/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 58.3427 - mae: 1.6755\n",
      "Epoch 67/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 20.3431 - mae: 1.5993\n",
      "Epoch 68/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 22.8693 - mae: 1.4987\n",
      "Epoch 69/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 22.7493 - mae: 1.6326\n",
      "Epoch 70/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 34.8370 - mae: 1.5782\n",
      "Epoch 71/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 29.0536 - mae: 1.5185\n",
      "Epoch 72/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 32.9410 - mae: 1.5184\n",
      "Epoch 73/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 30.2035 - mae: 1.4442\n",
      "Epoch 74/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 28.6796 - mae: 1.3751\n",
      "Epoch 75/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 18.6286 - mae: 1.3085\n",
      "Epoch 76/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 48.0530 - mae: 1.3753\n",
      "Epoch 77/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 77.2032 - mae: 1.5625\n",
      "Epoch 78/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 352.1578 - mae: 2.3802\n",
      "Epoch 79/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 90.8935 - mae: 1.9070\n",
      "Epoch 80/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 66.0213 - mae: 1.6226\n",
      "Epoch 81/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 24.3511 - mae: 1.5065\n",
      "Epoch 82/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 18.2051 - mae: 1.2615\n",
      "Epoch 83/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 77.3686 - mae: 1.5621\n",
      "Epoch 84/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 169.9399 - mae: 1.8071\n",
      "Epoch 85/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 132.7617 - mae: 1.6141\n",
      "Epoch 86/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 62.1698 - mae: 1.5214\n",
      "Epoch 87/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 98.4497 - mae: 1.5496\n",
      "Epoch 88/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 101.6786 - mae: 1.8692\n",
      "Epoch 89/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 172.7538 - mae: 2.4156\n",
      "Epoch 90/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 167.2966 - mae: 1.8439\n",
      "Epoch 91/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 98.1364 - mae: 1.6283\n",
      "Epoch 92/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 109.7411 - mae: 1.8058\n",
      "Epoch 93/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 122.8167 - mae: 1.4276\n",
      "Epoch 94/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 280.6941 - mae: 1.9106\n",
      "Epoch 95/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 239.0562 - mae: 2.1514\n",
      "Epoch 96/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 214.3885 - mae: 2.2409\n",
      "Epoch 97/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 183.4134 - mae: 2.4576\n",
      "Epoch 98/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 107.7565 - mae: 1.9542\n",
      "Epoch 99/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 44.2617 - mae: 1.4359\n",
      "Epoch 100/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 76.0041 - mae: 1.5175\n",
      "Epoch 101/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 35.9809 - mae: 1.3127\n",
      "Epoch 102/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 23.4798 - mae: 1.2538\n",
      "Epoch 103/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 16.5750 - mae: 1.1207\n",
      "Epoch 104/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 11.8434 - mae: 1.0390\n",
      "Epoch 105/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 67us/sample - loss: 14.4920 - mae: 1.0583\n",
      "Epoch 106/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 14.0995 - mae: 1.0913\n",
      "Epoch 107/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 11.7027 - mae: 1.0296\n",
      "Epoch 108/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 10.2412 - mae: 0.9865\n",
      "Epoch 109/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 10.0599 - mae: 0.9323\n",
      "Epoch 110/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 10.6885 - mae: 0.9607\n",
      "Epoch 111/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 9.4019 - mae: 0.9343\n",
      "Epoch 112/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 9.4648 - mae: 0.9260\n",
      "Epoch 113/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 8.9543 - mae: 0.8931\n",
      "Epoch 114/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 6.6039 - mae: 0.8424\n",
      "Epoch 115/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 13.1069 - mae: 0.9532\n",
      "Epoch 116/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 13.8447 - mae: 1.0900\n",
      "Epoch 117/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 16.9289 - mae: 1.1246\n",
      "Epoch 118/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 1328.4234 - mae: 5.0861\n",
      "Epoch 119/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 377.0271 - mae: 3.7470\n",
      "Epoch 120/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 39.1545 - mae: 1.6619\n",
      "Epoch 121/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 42.3235 - mae: 1.6315\n",
      "Epoch 122/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 11.7153 - mae: 1.2904\n",
      "Epoch 123/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 9.4068 - mae: 1.1216\n",
      "Epoch 124/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 13.7818 - mae: 1.1245\n",
      "Epoch 125/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 21.1944 - mae: 1.2791\n",
      "Epoch 126/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 188.1525 - mae: 2.0800\n",
      "Epoch 127/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 6.9081 - mae: 1.0009\n",
      "Epoch 128/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 8.5755 - mae: 0.9260\n",
      "Epoch 129/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 12.0794 - mae: 0.9792\n",
      "Epoch 130/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 12.3852 - mae: 0.9538\n",
      "Epoch 131/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 4.7017 - mae: 0.7822\n",
      "Epoch 132/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 4.0454 - mae: 0.6838\n",
      "Epoch 133/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 4.3080 - mae: 0.7197\n",
      "Epoch 134/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 4.9266 - mae: 0.7129\n",
      "Epoch 135/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 2.2061 - mae: 0.6120\n",
      "Epoch 136/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 2.7377 - mae: 0.6124\n",
      "Epoch 137/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 2.2783 - mae: 0.6007\n",
      "Epoch 138/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 2.6652 - mae: 0.5941\n",
      "Epoch 139/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 2.4012 - mae: 0.5779\n",
      "Epoch 140/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 1.9503 - mae: 0.5492\n",
      "Epoch 141/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 2.2073 - mae: 0.5747\n",
      "Epoch 142/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 1.9120 - mae: 0.5398\n",
      "Epoch 143/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 1.6391 - mae: 0.5311\n",
      "Epoch 144/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 1.6212 - mae: 0.5218\n",
      "Epoch 145/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 1.7205 - mae: 0.5184\n",
      "Epoch 146/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 1.3676 - mae: 0.4962\n",
      "Epoch 147/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 1.3666 - mae: 0.4853\n",
      "Epoch 148/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 1.3947 - mae: 0.4857\n",
      "Epoch 149/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 1.5868 - mae: 0.4940\n",
      "Epoch 150/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 1.5228 - mae: 0.4759\n",
      "Epoch 151/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 2.2350 - mae: 0.5019\n",
      "Epoch 152/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 3.0423 - mae: 0.4952\n",
      "Epoch 153/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 5.7877 - mae: 0.5020\n",
      "Epoch 154/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 3.1259 - mae: 0.5031\n",
      "Epoch 155/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 1.2302 - mae: 0.4537\n",
      "Epoch 156/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 1.1596 - mae: 0.4447\n",
      "Epoch 157/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 1.5166 - mae: 0.4672\n",
      "Epoch 158/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 1.2655 - mae: 0.4391\n",
      "Epoch 159/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 2.3302 - mae: 0.4805\n",
      "Epoch 160/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 2.4013 - mae: 0.5269\n",
      "Epoch 161/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 2.5869 - mae: 0.4725\n",
      "Epoch 162/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 1.4387 - mae: 0.4371\n",
      "Epoch 163/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 17.2459 - mae: 0.7514\n",
      "Epoch 164/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 13.9584 - mae: 0.7205\n",
      "Epoch 165/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 26.6595 - mae: 0.9564\n",
      "Epoch 166/2000\n",
      "2018/2018 [==============================] - 0s 103us/sample - loss: 8.3570 - mae: 0.6539\n",
      "Epoch 167/2000\n",
      "2018/2018 [==============================] - 0s 100us/sample - loss: 7.9523 - mae: 0.7623\n",
      "Epoch 168/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 4.3342 - mae: 0.6041\n",
      "Epoch 169/2000\n",
      "2018/2018 [==============================] - 0s 116us/sample - loss: 1.6685 - mae: 0.4093\n",
      "Epoch 170/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 1.6669 - mae: 0.4701\n",
      "Epoch 171/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 1.0679 - mae: 0.3817\n",
      "Epoch 172/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 1.4763 - mae: 0.4137\n",
      "Epoch 173/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 1.2663 - mae: 0.3787\n",
      "Epoch 174/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 1.2569 - mae: 0.3797\n",
      "Epoch 175/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.9039 - mae: 0.3536\n",
      "Epoch 176/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.8777 - mae: 0.3245\n",
      "Epoch 177/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.8915 - mae: 0.3354\n",
      "Epoch 178/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.8638 - mae: 0.3015\n",
      "Epoch 179/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 1.1599 - mae: 0.3547\n",
      "Epoch 180/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.7601 - mae: 0.3086\n",
      "Epoch 181/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.9245 - mae: 0.3165\n",
      "Epoch 182/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.9188 - mae: 0.3104\n",
      "Epoch 183/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.7828 - mae: 0.2847\n",
      "Epoch 184/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.8597 - mae: 0.2929\n",
      "Epoch 185/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.7172 - mae: 0.2793\n",
      "Epoch 186/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.6675 - mae: 0.2673\n",
      "Epoch 187/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.7299 - mae: 0.2695\n",
      "Epoch 188/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.7873 - mae: 0.2775\n",
      "Epoch 189/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.7568 - mae: 0.2682\n",
      "Epoch 190/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 1.2900 - mae: 0.3049\n",
      "Epoch 191/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.9763 - mae: 0.2873\n",
      "Epoch 192/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 1.0745 - mae: 0.3083\n",
      "Epoch 193/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.9277 - mae: 0.3120\n",
      "Epoch 194/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.6321 - mae: 0.2548\n",
      "Epoch 195/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.8125 - mae: 0.2699\n",
      "Epoch 196/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.5956 - mae: 0.2448\n",
      "Epoch 197/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.6554 - mae: 0.2477\n",
      "Epoch 198/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.7919 - mae: 0.2644\n",
      "Epoch 199/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.5998 - mae: 0.2494\n",
      "Epoch 200/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.7232 - mae: 0.2753\n",
      "Epoch 201/2000\n",
      "2018/2018 [==============================] - 0s 102us/sample - loss: 1.3034 - mae: 0.3381\n",
      "Epoch 202/2000\n",
      "2018/2018 [==============================] - 0s 133us/sample - loss: 0.6243 - mae: 0.2453\n",
      "Epoch 203/2000\n",
      "2018/2018 [==============================] - 0s 99us/sample - loss: 0.5999 - mae: 0.2457\n",
      "Epoch 204/2000\n",
      "2018/2018 [==============================] - 0s 106us/sample - loss: 0.5771 - mae: 0.2340\n",
      "Epoch 205/2000\n",
      "2018/2018 [==============================] - 0s 90us/sample - loss: 0.6227 - mae: 0.2525\n",
      "Epoch 206/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.7203 - mae: 0.2638\n",
      "Epoch 207/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5971 - mae: 0.2467\n",
      "Epoch 208/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.7386 - mae: 0.2819\n",
      "Epoch 209/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.6143 - mae: 0.2385\n",
      "Epoch 210/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.5483 - mae: 0.2269\n",
      "Epoch 211/2000\n",
      "2018/2018 [==============================] - 0s 101us/sample - loss: 0.5591 - mae: 0.2366\n",
      "Epoch 212/2000\n",
      "2018/2018 [==============================] - 0s 119us/sample - loss: 0.6009 - mae: 0.2435\n",
      "Epoch 213/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.5297 - mae: 0.2246\n",
      "Epoch 214/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.5829 - mae: 0.2348\n",
      "Epoch 215/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 1.1135 - mae: 0.3297\n",
      "Epoch 216/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.6491 - mae: 0.2503\n",
      "Epoch 217/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.6276 - mae: 0.2530\n",
      "Epoch 218/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.6286 - mae: 0.2519\n",
      "Epoch 219/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.8444 - mae: 0.2930\n",
      "Epoch 220/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.5460 - mae: 0.2363\n",
      "Epoch 221/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.5710 - mae: 0.2348\n",
      "Epoch 222/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.5207 - mae: 0.2165\n",
      "Epoch 223/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.6839 - mae: 0.2637\n",
      "Epoch 224/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.7760 - mae: 0.2617\n",
      "Epoch 225/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.5327 - mae: 0.2218\n",
      "Epoch 226/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.5500 - mae: 0.2272\n",
      "Epoch 227/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.5101 - mae: 0.2170\n",
      "Epoch 228/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.6023 - mae: 0.2370\n",
      "Epoch 229/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.5214 - mae: 0.2216\n",
      "Epoch 230/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.5426 - mae: 0.2275\n",
      "Epoch 231/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5836 - mae: 0.2378\n",
      "Epoch 232/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.5035 - mae: 0.2160\n",
      "Epoch 233/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.5124 - mae: 0.2116\n",
      "Epoch 234/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.5237 - mae: 0.2137\n",
      "Epoch 235/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.5238 - mae: 0.2139\n",
      "Epoch 236/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 2.9736 - mae: 0.4982\n",
      "Epoch 237/2000\n",
      "2018/2018 [==============================] - 0s 109us/sample - loss: 0.5771 - mae: 0.2424\n",
      "Epoch 238/2000\n",
      "2018/2018 [==============================] - 0s 113us/sample - loss: 0.5047 - mae: 0.2266\n",
      "Epoch 239/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.5017 - mae: 0.2191\n",
      "Epoch 240/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.5222 - mae: 0.2205\n",
      "Epoch 241/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.5400 - mae: 0.2224\n",
      "Epoch 242/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.4769 - mae: 0.2072\n",
      "Epoch 243/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.4806 - mae: 0.2072\n",
      "Epoch 244/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.4837 - mae: 0.2077\n",
      "Epoch 245/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.4813 - mae: 0.2090\n",
      "Epoch 246/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.4717 - mae: 0.2029\n",
      "Epoch 247/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.4716 - mae: 0.2015\n",
      "Epoch 248/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4740 - mae: 0.2029\n",
      "Epoch 249/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4831 - mae: 0.2026\n",
      "Epoch 250/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5846 - mae: 0.2390\n",
      "Epoch 251/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 1.0113 - mae: 0.3115\n",
      "Epoch 252/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.4817 - mae: 0.2061\n",
      "Epoch 253/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.4707 - mae: 0.2032\n",
      "Epoch 254/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4759 - mae: 0.2026\n",
      "Epoch 255/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.4748 - mae: 0.2021\n",
      "Epoch 256/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.5288 - mae: 0.2211\n",
      "Epoch 257/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4852 - mae: 0.2168\n",
      "Epoch 258/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.4536 - mae: 0.1958\n",
      "Epoch 259/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4545 - mae: 0.1964\n",
      "Epoch 260/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4572 - mae: 0.1989\n",
      "Epoch 261/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.4706 - mae: 0.2041\n",
      "Epoch 262/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.4535 - mae: 0.1987\n",
      "Epoch 263/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.4468 - mae: 0.1945\n",
      "Epoch 264/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.4984 - mae: 0.2064\n",
      "Epoch 265/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.4474 - mae: 0.1960\n",
      "Epoch 266/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.4461 - mae: 0.1955\n",
      "Epoch 267/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4433 - mae: 0.1932\n",
      "Epoch 268/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4425 - mae: 0.1931\n",
      "Epoch 269/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.4464 - mae: 0.1934\n",
      "Epoch 270/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4394 - mae: 0.1935\n",
      "Epoch 271/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4391 - mae: 0.1944\n",
      "Epoch 272/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.4399 - mae: 0.1943\n",
      "Epoch 273/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4390 - mae: 0.1937\n",
      "Epoch 274/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.4371 - mae: 0.1938\n",
      "Epoch 275/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4300 - mae: 0.1902\n",
      "Epoch 276/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4568 - mae: 0.1951\n",
      "Epoch 277/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4263 - mae: 0.1888\n",
      "Epoch 278/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4307 - mae: 0.1917\n",
      "Epoch 279/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4387 - mae: 0.1987\n",
      "Epoch 280/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4403 - mae: 0.1966\n",
      "Epoch 281/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.4617 - mae: 0.2139\n",
      "Epoch 282/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.4689 - mae: 0.2089\n",
      "Epoch 283/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.4202 - mae: 0.1898\n",
      "Epoch 284/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.4172 - mae: 0.1894\n",
      "Epoch 285/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.4222 - mae: 0.1903\n",
      "Epoch 286/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.4229 - mae: 0.1962\n",
      "Epoch 287/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4143 - mae: 0.1895\n",
      "Epoch 288/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4398 - mae: 0.2010\n",
      "Epoch 289/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.4135 - mae: 0.1884\n",
      "Epoch 290/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4098 - mae: 0.1861\n",
      "Epoch 291/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.6842 - mae: 0.2686\n",
      "Epoch 292/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.4824 - mae: 0.2441\n",
      "Epoch 293/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.4223 - mae: 0.2060\n",
      "Epoch 294/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.4120 - mae: 0.1940\n",
      "Epoch 295/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.4008 - mae: 0.1849\n",
      "Epoch 296/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.3986 - mae: 0.1843\n",
      "Epoch 297/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.3961 - mae: 0.1829\n",
      "Epoch 298/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.3947 - mae: 0.1840\n",
      "Epoch 299/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.3987 - mae: 0.1919\n",
      "Epoch 300/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3924 - mae: 0.1846\n",
      "Epoch 301/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.3893 - mae: 0.1817\n",
      "Epoch 302/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.3887 - mae: 0.1830\n",
      "Epoch 303/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.4304 - mae: 0.2036\n",
      "Epoch 304/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.3877 - mae: 0.1859\n",
      "Epoch 305/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.3828 - mae: 0.1808\n",
      "Epoch 306/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.3812 - mae: 0.1812\n",
      "Epoch 307/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.3791 - mae: 0.1793\n",
      "Epoch 308/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3789 - mae: 0.1817\n",
      "Epoch 309/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3754 - mae: 0.1787\n",
      "Epoch 310/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.3739 - mae: 0.1788\n",
      "Epoch 311/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.3719 - mae: 0.1776\n",
      "Epoch 312/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.3697 - mae: 0.1771\n",
      "Epoch 313/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.3679 - mae: 0.1765\n",
      "Epoch 314/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.3665 - mae: 0.1762\n",
      "Epoch 315/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.3649 - mae: 0.1771\n",
      "Epoch 316/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.3623 - mae: 0.1751\n",
      "Epoch 317/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.3622 - mae: 0.1778\n",
      "Epoch 318/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.3591 - mae: 0.1757\n",
      "Epoch 319/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.3585 - mae: 0.1768\n",
      "Epoch 320/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3558 - mae: 0.1757\n",
      "Epoch 321/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.3539 - mae: 0.1752\n",
      "Epoch 322/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.3510 - mae: 0.1735\n",
      "Epoch 323/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3531 - mae: 0.1771\n",
      "Epoch 324/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.3492 - mae: 0.1769\n",
      "Epoch 325/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.3457 - mae: 0.1730\n",
      "Epoch 326/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.3598 - mae: 0.1878\n",
      "Epoch 327/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3444 - mae: 0.1768\n",
      "Epoch 328/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3843 - mae: 0.2004\n",
      "Epoch 329/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 1.9326 - mae: 0.2392\n",
      "Epoch 330/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.4343 - mae: 0.1990\n",
      "Epoch 331/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3455 - mae: 0.1859\n",
      "Epoch 332/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.3432 - mae: 0.1878\n",
      "Epoch 333/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.3401 - mae: 0.1852\n",
      "Epoch 334/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.3377 - mae: 0.1838\n",
      "Epoch 335/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.3346 - mae: 0.1819\n",
      "Epoch 336/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.3324 - mae: 0.1802\n",
      "Epoch 337/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3300 - mae: 0.1793\n",
      "Epoch 338/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.3283 - mae: 0.1791\n",
      "Epoch 339/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 1s 513us/sample - loss: 0.3269 - mae: 0.1794\n",
      "Epoch 340/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3253 - mae: 0.1802\n",
      "Epoch 341/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.3223 - mae: 0.1767\n",
      "Epoch 342/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.3206 - mae: 0.1777\n",
      "Epoch 343/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.3190 - mae: 0.1774\n",
      "Epoch 344/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.3166 - mae: 0.1755\n",
      "Epoch 345/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.3160 - mae: 0.1796\n",
      "Epoch 346/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3135 - mae: 0.1769\n",
      "Epoch 347/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.3112 - mae: 0.1752\n",
      "Epoch 348/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.3088 - mae: 0.1734\n",
      "Epoch 349/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3063 - mae: 0.1722\n",
      "Epoch 350/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.3052 - mae: 0.1744\n",
      "Epoch 351/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.3028 - mae: 0.1715\n",
      "Epoch 352/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3010 - mae: 0.1721\n",
      "Epoch 353/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.2992 - mae: 0.1721\n",
      "Epoch 354/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.2979 - mae: 0.1730\n",
      "Epoch 355/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.2951 - mae: 0.1710\n",
      "Epoch 356/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.2931 - mae: 0.1705\n",
      "Epoch 357/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.2930 - mae: 0.1740\n",
      "Epoch 358/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.2918 - mae: 0.1741\n",
      "Epoch 359/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.2884 - mae: 0.1720\n",
      "Epoch 360/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.2855 - mae: 0.1699\n",
      "Epoch 361/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.2839 - mae: 0.1692\n",
      "Epoch 362/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.2838 - mae: 0.1732\n",
      "Epoch 363/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.2802 - mae: 0.1697\n",
      "Epoch 364/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.2779 - mae: 0.1681\n",
      "Epoch 365/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.2764 - mae: 0.1689\n",
      "Epoch 366/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.2766 - mae: 0.1730\n",
      "Epoch 367/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.2757 - mae: 0.1750\n",
      "Epoch 368/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.2715 - mae: 0.1695\n",
      "Epoch 369/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.2683 - mae: 0.1675\n",
      "Epoch 370/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.2684 - mae: 0.1698\n",
      "Epoch 371/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.2665 - mae: 0.1697\n",
      "Epoch 372/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.2629 - mae: 0.1663\n",
      "Epoch 373/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.2604 - mae: 0.1655\n",
      "Epoch 374/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.2595 - mae: 0.1681\n",
      "Epoch 375/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.2572 - mae: 0.1661\n",
      "Epoch 376/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.2541 - mae: 0.1630\n",
      "Epoch 377/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.2537 - mae: 0.1657\n",
      "Epoch 378/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.2513 - mae: 0.1654\n",
      "Epoch 379/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.2506 - mae: 0.1682\n",
      "Epoch 380/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.2475 - mae: 0.1644\n",
      "Epoch 381/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.2453 - mae: 0.1637\n",
      "Epoch 382/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.2429 - mae: 0.1632\n",
      "Epoch 383/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.2424 - mae: 0.1657\n",
      "Epoch 384/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.2404 - mae: 0.1658\n",
      "Epoch 385/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.2384 - mae: 0.1648\n",
      "Epoch 386/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.2356 - mae: 0.1630\n",
      "Epoch 387/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.2340 - mae: 0.1638\n",
      "Epoch 388/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.2345 - mae: 0.1662\n",
      "Epoch 389/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.2298 - mae: 0.1645\n",
      "Epoch 390/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.2280 - mae: 0.1626\n",
      "Epoch 391/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.2271 - mae: 0.1654\n",
      "Epoch 392/2000\n",
      "2018/2018 [==============================] - 0s 124us/sample - loss: 0.2244 - mae: 0.1626\n",
      "Epoch 393/2000\n",
      "2018/2018 [==============================] - 0s 91us/sample - loss: 0.2225 - mae: 0.1622\n",
      "Epoch 394/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.2220 - mae: 0.1666\n",
      "Epoch 395/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.2178 - mae: 0.1612\n",
      "Epoch 396/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.2165 - mae: 0.1637\n",
      "Epoch 397/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.2140 - mae: 0.1613\n",
      "Epoch 398/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.2115 - mae: 0.1602\n",
      "Epoch 399/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.2285 - mae: 0.1955\n",
      "Epoch 400/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.2191 - mae: 0.1849\n",
      "Epoch 401/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.2150 - mae: 0.1815\n",
      "Epoch 402/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.2155 - mae: 0.1834\n",
      "Epoch 403/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.2113 - mae: 0.1806\n",
      "Epoch 404/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.2073 - mae: 0.1766\n",
      "Epoch 405/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.2039 - mae: 0.1738\n",
      "Epoch 406/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.2026 - mae: 0.1726\n",
      "Epoch 407/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.1974 - mae: 0.1674\n",
      "Epoch 408/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.1939 - mae: 0.1635\n",
      "Epoch 409/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.1924 - mae: 0.1648\n",
      "Epoch 410/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.1904 - mae: 0.1634\n",
      "Epoch 411/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.1877 - mae: 0.1621\n",
      "Epoch 412/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.1854 - mae: 0.1611\n",
      "Epoch 413/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.1849 - mae: 0.1648\n",
      "Epoch 414/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.1816 - mae: 0.1617\n",
      "Epoch 415/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.1804 - mae: 0.1624\n",
      "Epoch 416/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.1787 - mae: 0.1594\n",
      "Epoch 417/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1787 - mae: 0.1675\n",
      "Epoch 418/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.1759 - mae: 0.1650\n",
      "Epoch 419/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.1718 - mae: 0.1604\n",
      "Epoch 420/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.1699 - mae: 0.1601\n",
      "Epoch 421/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.1688 - mae: 0.1632\n",
      "Epoch 422/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1800 - mae: 0.1849\n",
      "Epoch 423/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.1676 - mae: 0.1673\n",
      "Epoch 424/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.1637 - mae: 0.1625\n",
      "Epoch 425/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.1605 - mae: 0.1604\n",
      "Epoch 426/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1599 - mae: 0.1630\n",
      "Epoch 427/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.1558 - mae: 0.1582\n",
      "Epoch 428/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.1542 - mae: 0.1593\n",
      "Epoch 429/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.1508 - mae: 0.1556\n",
      "Epoch 430/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.1502 - mae: 0.1589\n",
      "Epoch 431/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.1478 - mae: 0.1566\n",
      "Epoch 432/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1470 - mae: 0.1586\n",
      "Epoch 433/2000\n",
      "2018/2018 [==============================] - 1s 316us/sample - loss: 0.1432 - mae: 0.1542\n",
      "Epoch 434/2000\n",
      "2018/2018 [==============================] - 0s 226us/sample - loss: 0.1413 - mae: 0.1539\n",
      "Epoch 435/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.1399 - mae: 0.1551\n",
      "Epoch 436/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1370 - mae: 0.1516\n",
      "Epoch 437/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.1354 - mae: 0.1522\n",
      "Epoch 438/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.1336 - mae: 0.1522\n",
      "Epoch 439/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.1323 - mae: 0.1530\n",
      "Epoch 440/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.1310 - mae: 0.1548\n",
      "Epoch 441/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.1306 - mae: 0.1583\n",
      "Epoch 442/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.1260 - mae: 0.1525\n",
      "Epoch 443/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.1244 - mae: 0.1515\n",
      "Epoch 444/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.1226 - mae: 0.1513\n",
      "Epoch 445/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.1214 - mae: 0.1521\n",
      "Epoch 446/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.1243 - mae: 0.1623\n",
      "Epoch 447/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.1184 - mae: 0.1535\n",
      "Epoch 448/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.1153 - mae: 0.1498\n",
      "Epoch 449/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.1128 - mae: 0.1479\n",
      "Epoch 450/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.1161 - mae: 0.1556\n",
      "Epoch 451/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.1136 - mae: 0.1568\n",
      "Epoch 452/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.1102 - mae: 0.1523\n",
      "Epoch 453/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.1080 - mae: 0.1487\n",
      "Epoch 454/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.1063 - mae: 0.1500\n",
      "Epoch 455/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.1043 - mae: 0.1491\n",
      "Epoch 456/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.1052 - mae: 0.1523\n",
      "Epoch 457/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.1032 - mae: 0.1520\n",
      "Epoch 458/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.1011 - mae: 0.1500\n",
      "Epoch 459/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.1093 - mae: 0.1714\n",
      "Epoch 460/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0977 - mae: 0.1501\n",
      "Epoch 461/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0962 - mae: 0.1495\n",
      "Epoch 462/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0961 - mae: 0.1529\n",
      "Epoch 463/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0944 - mae: 0.1534\n",
      "Epoch 464/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0936 - mae: 0.1512\n",
      "Epoch 465/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0917 - mae: 0.1516\n",
      "Epoch 466/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0880 - mae: 0.1472\n",
      "Epoch 467/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0868 - mae: 0.1468\n",
      "Epoch 468/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0846 - mae: 0.1444\n",
      "Epoch 469/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0874 - mae: 0.1515\n",
      "Epoch 470/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0838 - mae: 0.1469\n",
      "Epoch 471/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0824 - mae: 0.1487\n",
      "Epoch 472/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0797 - mae: 0.1440\n",
      "Epoch 473/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0790 - mae: 0.1444\n",
      "Epoch 474/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0774 - mae: 0.1436\n",
      "Epoch 475/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0753 - mae: 0.1407\n",
      "Epoch 476/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0750 - mae: 0.1428\n",
      "Epoch 477/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0746 - mae: 0.1420\n",
      "Epoch 478/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0725 - mae: 0.1409\n",
      "Epoch 479/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0725 - mae: 0.1436\n",
      "Epoch 480/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0701 - mae: 0.1394\n",
      "Epoch 481/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0687 - mae: 0.1394\n",
      "Epoch 482/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0680 - mae: 0.1401\n",
      "Epoch 483/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0680 - mae: 0.1433\n",
      "Epoch 484/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0760 - mae: 0.1537\n",
      "Epoch 485/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0708 - mae: 0.1534\n",
      "Epoch 486/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0663 - mae: 0.1434\n",
      "Epoch 487/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0638 - mae: 0.1382\n",
      "Epoch 488/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0630 - mae: 0.1388\n",
      "Epoch 489/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0619 - mae: 0.1386\n",
      "Epoch 490/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0609 - mae: 0.1376\n",
      "Epoch 491/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0597 - mae: 0.1363\n",
      "Epoch 492/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0608 - mae: 0.1416\n",
      "Epoch 493/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0575 - mae: 0.1354\n",
      "Epoch 494/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0579 - mae: 0.1368\n",
      "Epoch 495/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0557 - mae: 0.1347\n",
      "Epoch 496/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0552 - mae: 0.1349\n",
      "Epoch 497/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0554 - mae: 0.1356\n",
      "Epoch 498/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0546 - mae: 0.1365\n",
      "Epoch 499/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0523 - mae: 0.1314\n",
      "Epoch 500/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0513 - mae: 0.1310\n",
      "Epoch 501/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0781 - mae: 0.1630\n",
      "Epoch 502/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0597 - mae: 0.1477\n",
      "Epoch 503/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0607 - mae: 0.1532\n",
      "Epoch 504/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0574 - mae: 0.1464\n",
      "Epoch 505/2000\n",
      "2018/2018 [==============================] - 1s 290us/sample - loss: 0.0538 - mae: 0.1400\n",
      "Epoch 506/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0512 - mae: 0.1366\n",
      "Epoch 507/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0538 - mae: 0.1436\n",
      "Epoch 508/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0510 - mae: 0.1397\n",
      "Epoch 509/2000\n",
      "2018/2018 [==============================] - 1s 317us/sample - loss: 0.0504 - mae: 0.1400\n",
      "Epoch 510/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0482 - mae: 0.1343\n",
      "Epoch 511/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0468 - mae: 0.1317\n",
      "Epoch 512/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0463 - mae: 0.1326\n",
      "Epoch 513/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0448 - mae: 0.1300\n",
      "Epoch 514/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0442 - mae: 0.1296\n",
      "Epoch 515/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0434 - mae: 0.1285\n",
      "Epoch 516/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0455 - mae: 0.1330\n",
      "Epoch 517/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0438 - mae: 0.1305\n",
      "Epoch 518/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0447 - mae: 0.1346\n",
      "Epoch 519/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0427 - mae: 0.1308\n",
      "Epoch 520/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0443 - mae: 0.1357\n",
      "Epoch 521/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.2817 - mae: 0.1485\n",
      "Epoch 522/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0443 - mae: 0.1329\n",
      "Epoch 523/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0443 - mae: 0.1344\n",
      "Epoch 524/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0427 - mae: 0.1314\n",
      "Epoch 525/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0418 - mae: 0.1297\n",
      "Epoch 526/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0414 - mae: 0.1294\n",
      "Epoch 527/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0408 - mae: 0.1300\n",
      "Epoch 528/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0416 - mae: 0.1313\n",
      "Epoch 529/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0406 - mae: 0.1299\n",
      "Epoch 530/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0405 - mae: 0.1302\n",
      "Epoch 531/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0394 - mae: 0.1282\n",
      "Epoch 532/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0435 - mae: 0.1432\n",
      "Epoch 533/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0396 - mae: 0.1302\n",
      "Epoch 534/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0398 - mae: 0.1302\n",
      "Epoch 535/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0390 - mae: 0.1281\n",
      "Epoch 536/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0395 - mae: 0.1314\n",
      "Epoch 537/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0372 - mae: 0.1262\n",
      "Epoch 538/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0371 - mae: 0.1268\n",
      "Epoch 539/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0365 - mae: 0.1258\n",
      "Epoch 540/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0361 - mae: 0.1247\n",
      "Epoch 541/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0362 - mae: 0.1256\n",
      "Epoch 542/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0372 - mae: 0.1288\n",
      "Epoch 543/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0352 - mae: 0.1242\n",
      "Epoch 544/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0351 - mae: 0.1249\n",
      "Epoch 545/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0349 - mae: 0.1250\n",
      "Epoch 546/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0361 - mae: 0.1286\n",
      "Epoch 547/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0346 - mae: 0.1246\n",
      "Epoch 548/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0336 - mae: 0.1232\n",
      "Epoch 549/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0344 - mae: 0.1253\n",
      "Epoch 550/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0379 - mae: 0.1337\n",
      "Epoch 551/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0333 - mae: 0.1238\n",
      "Epoch 552/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0331 - mae: 0.1241\n",
      "Epoch 553/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0335 - mae: 0.1249\n",
      "Epoch 554/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0333 - mae: 0.1252\n",
      "Epoch 555/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0338 - mae: 0.1261\n",
      "Epoch 556/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0317 - mae: 0.1214\n",
      "Epoch 557/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0376 - mae: 0.1341\n",
      "Epoch 558/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0331 - mae: 0.1249\n",
      "Epoch 559/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0339 - mae: 0.1280\n",
      "Epoch 560/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0341 - mae: 0.1285\n",
      "Epoch 561/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0311 - mae: 0.1215\n",
      "Epoch 562/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0333 - mae: 0.1277\n",
      "Epoch 563/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0316 - mae: 0.1236\n",
      "Epoch 564/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0315 - mae: 0.1232\n",
      "Epoch 565/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0316 - mae: 0.1233\n",
      "Epoch 566/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0310 - mae: 0.1221\n",
      "Epoch 567/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0316 - mae: 0.1243\n",
      "Epoch 568/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0320 - mae: 0.1261\n",
      "Epoch 569/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0301 - mae: 0.1202\n",
      "Epoch 570/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0323 - mae: 0.1266\n",
      "Epoch 571/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0294 - mae: 0.1199\n",
      "Epoch 572/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0292 - mae: 0.1194\n",
      "Epoch 573/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0316 - mae: 0.1257\n",
      "Epoch 574/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0305 - mae: 0.1233\n",
      "Epoch 575/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0297 - mae: 0.1223\n",
      "Epoch 576/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0333 - mae: 0.1286\n",
      "Epoch 577/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0293 - mae: 0.1204\n",
      "Epoch 578/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0350 - mae: 0.1346\n",
      "Epoch 579/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0291 - mae: 0.1207\n",
      "Epoch 580/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0319 - mae: 0.1292\n",
      "Epoch 581/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0335 - mae: 0.1313\n",
      "Epoch 582/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0297 - mae: 0.1237\n",
      "Epoch 583/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0288 - mae: 0.1199\n",
      "Epoch 584/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0277 - mae: 0.1179\n",
      "Epoch 585/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0281 - mae: 0.1188\n",
      "Epoch 586/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0282 - mae: 0.1205\n",
      "Epoch 587/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0282 - mae: 0.1190\n",
      "Epoch 588/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0282 - mae: 0.1197\n",
      "Epoch 589/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0274 - mae: 0.1181\n",
      "Epoch 590/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0270 - mae: 0.1152\n",
      "Epoch 591/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0273 - mae: 0.1176\n",
      "Epoch 592/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0291 - mae: 0.1235\n",
      "Epoch 593/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0263 - mae: 0.1164\n",
      "Epoch 594/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0267 - mae: 0.1163\n",
      "Epoch 595/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0268 - mae: 0.1179\n",
      "Epoch 596/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0278 - mae: 0.1197\n",
      "Epoch 597/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0275 - mae: 0.1186\n",
      "Epoch 598/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0563 - mae: 0.1502\n",
      "Epoch 599/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0355 - mae: 0.1356\n",
      "Epoch 600/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0345 - mae: 0.1344\n",
      "Epoch 601/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0333 - mae: 0.1328\n",
      "Epoch 602/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0318 - mae: 0.1294\n",
      "Epoch 603/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0314 - mae: 0.1279\n",
      "Epoch 604/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0306 - mae: 0.1269\n",
      "Epoch 605/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0296 - mae: 0.1243\n",
      "Epoch 606/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0296 - mae: 0.1240\n",
      "Epoch 607/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0315 - mae: 0.1293\n",
      "Epoch 608/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0299 - mae: 0.1249\n",
      "Epoch 609/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0299 - mae: 0.1258\n",
      "Epoch 610/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0295 - mae: 0.1246\n",
      "Epoch 611/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0283 - mae: 0.1208\n",
      "Epoch 612/2000\n",
      "2018/2018 [==============================] - 1s 288us/sample - loss: 0.0343 - mae: 0.1363\n",
      "Epoch 613/2000\n",
      "2018/2018 [==============================] - 0s 203us/sample - loss: 0.0284 - mae: 0.1220\n",
      "Epoch 614/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0279 - mae: 0.1198\n",
      "Epoch 615/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0272 - mae: 0.1180\n",
      "Epoch 616/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0291 - mae: 0.1236\n",
      "Epoch 617/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0281 - mae: 0.1211\n",
      "Epoch 618/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0272 - mae: 0.1183\n",
      "Epoch 619/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0296 - mae: 0.1250\n",
      "Epoch 620/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0294 - mae: 0.1248\n",
      "Epoch 621/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0279 - mae: 0.1213\n",
      "Epoch 622/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0271 - mae: 0.1198\n",
      "Epoch 623/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0261 - mae: 0.1157\n",
      "Epoch 624/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0316 - mae: 0.1300\n",
      "Epoch 625/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0302 - mae: 0.1248\n",
      "Epoch 626/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0284 - mae: 0.1211\n",
      "Epoch 627/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0271 - mae: 0.1173\n",
      "Epoch 628/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0275 - mae: 0.1192\n",
      "Epoch 629/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0274 - mae: 0.1188\n",
      "Epoch 630/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0289 - mae: 0.1230\n",
      "Epoch 631/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0267 - mae: 0.1181\n",
      "Epoch 632/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0262 - mae: 0.1154\n",
      "Epoch 633/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0290 - mae: 0.1252\n",
      "Epoch 634/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0269 - mae: 0.1181\n",
      "Epoch 635/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0265 - mae: 0.1175\n",
      "Epoch 636/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0263 - mae: 0.1173\n",
      "Epoch 637/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0250 - mae: 0.1134\n",
      "Epoch 638/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0262 - mae: 0.1170\n",
      "Epoch 639/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0247 - mae: 0.1127\n",
      "Epoch 640/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0280 - mae: 0.1215\n",
      "Epoch 641/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0253 - mae: 0.1150\n",
      "Epoch 642/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0255 - mae: 0.1162\n",
      "Epoch 643/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0254 - mae: 0.1150\n",
      "Epoch 644/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0242 - mae: 0.1118\n",
      "Epoch 645/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0281 - mae: 0.1233\n",
      "Epoch 646/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0243 - mae: 0.1131\n",
      "Epoch 647/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0242 - mae: 0.1124\n",
      "Epoch 648/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0246 - mae: 0.1139\n",
      "Epoch 649/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0241 - mae: 0.1127\n",
      "Epoch 650/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0269 - mae: 0.1199\n",
      "Epoch 651/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0235 - mae: 0.1101\n",
      "Epoch 652/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0237 - mae: 0.1118\n",
      "Epoch 653/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0237 - mae: 0.1116\n",
      "Epoch 654/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0237 - mae: 0.1110\n",
      "Epoch 655/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0235 - mae: 0.1112\n",
      "Epoch 656/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0228 - mae: 0.1093\n",
      "Epoch 657/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0234 - mae: 0.1107\n",
      "Epoch 658/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0231 - mae: 0.1101\n",
      "Epoch 659/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0237 - mae: 0.1117\n",
      "Epoch 660/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0232 - mae: 0.1110\n",
      "Epoch 661/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0239 - mae: 0.1113\n",
      "Epoch 662/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0238 - mae: 0.1122\n",
      "Epoch 663/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0234 - mae: 0.1106\n",
      "Epoch 664/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0225 - mae: 0.1092\n",
      "Epoch 665/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0233 - mae: 0.1110\n",
      "Epoch 666/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0240 - mae: 0.1142\n",
      "Epoch 667/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0231 - mae: 0.1107\n",
      "Epoch 668/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0223 - mae: 0.1074\n",
      "Epoch 669/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0262 - mae: 0.1162\n",
      "Epoch 670/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0522 - mae: 0.1221\n",
      "Epoch 671/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0288 - mae: 0.1228\n",
      "Epoch 672/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0280 - mae: 0.1220\n",
      "Epoch 673/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0283 - mae: 0.1230\n",
      "Epoch 674/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0258 - mae: 0.1172\n",
      "Epoch 675/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0268 - mae: 0.1205\n",
      "Epoch 676/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0284 - mae: 0.1247\n",
      "Epoch 677/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0281 - mae: 0.1240\n",
      "Epoch 678/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0249 - mae: 0.1140\n",
      "Epoch 679/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0255 - mae: 0.1169\n",
      "Epoch 680/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0244 - mae: 0.1134\n",
      "Epoch 681/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0241 - mae: 0.1125\n",
      "Epoch 682/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0238 - mae: 0.1123\n",
      "Epoch 683/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0237 - mae: 0.1122\n",
      "Epoch 684/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0240 - mae: 0.1122\n",
      "Epoch 685/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0237 - mae: 0.1123\n",
      "Epoch 686/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0266 - mae: 0.1196\n",
      "Epoch 687/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0232 - mae: 0.1113\n",
      "Epoch 688/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0239 - mae: 0.1127\n",
      "Epoch 689/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0234 - mae: 0.1108\n",
      "Epoch 690/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0244 - mae: 0.1138\n",
      "Epoch 691/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0237 - mae: 0.1121\n",
      "Epoch 692/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0234 - mae: 0.1105\n",
      "Epoch 693/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0239 - mae: 0.1126\n",
      "Epoch 694/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0241 - mae: 0.1134\n",
      "Epoch 695/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0226 - mae: 0.1087\n",
      "Epoch 696/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0234 - mae: 0.1117\n",
      "Epoch 697/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0250 - mae: 0.1142\n",
      "Epoch 698/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0234 - mae: 0.1112\n",
      "Epoch 699/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0240 - mae: 0.1129\n",
      "Epoch 700/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0237 - mae: 0.1112\n",
      "Epoch 701/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0225 - mae: 0.1087\n",
      "Epoch 702/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0232 - mae: 0.1102\n",
      "Epoch 703/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0227 - mae: 0.1095\n",
      "Epoch 704/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0227 - mae: 0.1102\n",
      "Epoch 705/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0230 - mae: 0.1101\n",
      "Epoch 706/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0241 - mae: 0.1144\n",
      "Epoch 707/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0226 - mae: 0.1093\n",
      "Epoch 708/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0230 - mae: 0.1100\n",
      "Epoch 709/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0232 - mae: 0.1101\n",
      "Epoch 710/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0227 - mae: 0.1077\n",
      "Epoch 711/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0229 - mae: 0.1087\n",
      "Epoch 712/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0231 - mae: 0.1104\n",
      "Epoch 713/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0230 - mae: 0.1100\n",
      "Epoch 714/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0219 - mae: 0.1070\n",
      "Epoch 715/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1072\n",
      "Epoch 716/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0220 - mae: 0.1077\n",
      "Epoch 717/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0221 - mae: 0.1077\n",
      "Epoch 718/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0228 - mae: 0.1101\n",
      "Epoch 719/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0227 - mae: 0.1093\n",
      "Epoch 720/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0222 - mae: 0.1074\n",
      "Epoch 721/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0234 - mae: 0.1109\n",
      "Epoch 722/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0219 - mae: 0.1064\n",
      "Epoch 723/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0226 - mae: 0.1089\n",
      "Epoch 724/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0223 - mae: 0.1080\n",
      "Epoch 725/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0217 - mae: 0.1070\n",
      "Epoch 726/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0227 - mae: 0.1093\n",
      "Epoch 727/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0215 - mae: 0.1058\n",
      "Epoch 728/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0225 - mae: 0.1098\n",
      "Epoch 729/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0233 - mae: 0.1116\n",
      "Epoch 730/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0225 - mae: 0.1089\n",
      "Epoch 731/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0217 - mae: 0.1057\n",
      "Epoch 732/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0214 - mae: 0.1064\n",
      "Epoch 733/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0219 - mae: 0.1065\n",
      "Epoch 734/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0227 - mae: 0.1093\n",
      "Epoch 735/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0219 - mae: 0.1071\n",
      "Epoch 736/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0224 - mae: 0.1085\n",
      "Epoch 737/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0216 - mae: 0.1069\n",
      "Epoch 738/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0217 - mae: 0.1068\n",
      "Epoch 739/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0267 - mae: 0.1214\n",
      "Epoch 740/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0247 - mae: 0.1131\n",
      "Epoch 741/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0231 - mae: 0.1088\n",
      "Epoch 742/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0228 - mae: 0.1083\n",
      "Epoch 743/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0229 - mae: 0.1092\n",
      "Epoch 744/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0228 - mae: 0.1094\n",
      "Epoch 745/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0221 - mae: 0.1067\n",
      "Epoch 746/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0228 - mae: 0.1089\n",
      "Epoch 747/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0225 - mae: 0.1095\n",
      "Epoch 748/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0215 - mae: 0.1062\n",
      "Epoch 749/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0220 - mae: 0.1086\n",
      "Epoch 750/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0238 - mae: 0.1139\n",
      "Epoch 751/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0219 - mae: 0.1076\n",
      "Epoch 752/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0225 - mae: 0.1092\n",
      "Epoch 753/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0216 - mae: 0.1067\n",
      "Epoch 754/2000\n",
      "2018/2018 [==============================] - 0s 63us/sample - loss: 0.0232 - mae: 0.1116\n",
      "Epoch 755/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0214 - mae: 0.1069\n",
      "Epoch 756/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0242 - mae: 0.1141\n",
      "Epoch 757/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0234 - mae: 0.1112\n",
      "Epoch 758/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0222 - mae: 0.1074\n",
      "Epoch 759/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1079\n",
      "Epoch 760/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0217 - mae: 0.1067\n",
      "Epoch 761/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0219 - mae: 0.1068\n",
      "Epoch 762/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0215 - mae: 0.1064\n",
      "Epoch 763/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0209 - mae: 0.1041\n",
      "Epoch 764/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0227 - mae: 0.1096\n",
      "Epoch 765/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0215 - mae: 0.1065\n",
      "Epoch 766/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0220 - mae: 0.1068\n",
      "Epoch 767/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0229 - mae: 0.1092\n",
      "Epoch 768/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0211 - mae: 0.1049\n",
      "Epoch 769/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0211 - mae: 0.1052\n",
      "Epoch 770/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0221 - mae: 0.1071\n",
      "Epoch 771/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0229 - mae: 0.1095\n",
      "Epoch 772/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0211 - mae: 0.1049\n",
      "Epoch 773/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0208 - mae: 0.1051\n",
      "Epoch 774/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0212 - mae: 0.1058\n",
      "Epoch 775/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0215 - mae: 0.1063\n",
      "Epoch 776/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0218 - mae: 0.1066\n",
      "Epoch 777/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0210 - mae: 0.1058\n",
      "Epoch 778/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0215 - mae: 0.1063\n",
      "Epoch 779/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0208 - mae: 0.1046\n",
      "Epoch 780/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0225 - mae: 0.1093\n",
      "Epoch 781/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0211 - mae: 0.1061\n",
      "Epoch 782/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0215 - mae: 0.1062\n",
      "Epoch 783/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0241 - mae: 0.1132\n",
      "Epoch 784/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0212 - mae: 0.1059\n",
      "Epoch 785/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0212 - mae: 0.1061\n",
      "Epoch 786/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0209 - mae: 0.1057\n",
      "Epoch 787/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0208 - mae: 0.1054\n",
      "Epoch 788/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0207 - mae: 0.1043\n",
      "Epoch 789/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0210 - mae: 0.1050\n",
      "Epoch 790/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0206 - mae: 0.1044\n",
      "Epoch 791/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0203 - mae: 0.1029\n",
      "Epoch 792/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0203 - mae: 0.1034\n",
      "Epoch 793/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0205 - mae: 0.1041\n",
      "Epoch 794/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0200 - mae: 0.1025\n",
      "Epoch 795/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0212 - mae: 0.1066\n",
      "Epoch 796/2000\n",
      "2018/2018 [==============================] - 1s 251us/sample - loss: 0.0206 - mae: 0.1045\n",
      "Epoch 797/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0204 - mae: 0.1040\n",
      "Epoch 798/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0207 - mae: 0.1051\n",
      "Epoch 799/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0204 - mae: 0.1035\n",
      "Epoch 800/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0215 - mae: 0.1071\n",
      "Epoch 801/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0209 - mae: 0.1044\n",
      "Epoch 802/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0211 - mae: 0.1050\n",
      "Epoch 803/2000\n",
      "2018/2018 [==============================] - 0s 92us/sample - loss: 0.0217 - mae: 0.1075\n",
      "Epoch 804/2000\n",
      "2018/2018 [==============================] - 0s 168us/sample - loss: 0.0209 - mae: 0.1047\n",
      "Epoch 805/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0229 - mae: 0.1113\n",
      "Epoch 806/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0214 - mae: 0.1061\n",
      "Epoch 807/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0207 - mae: 0.1039\n",
      "Epoch 808/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0203 - mae: 0.1026\n",
      "Epoch 809/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0210 - mae: 0.1070\n",
      "Epoch 810/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0211 - mae: 0.1048\n",
      "Epoch 811/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0203 - mae: 0.1031\n",
      "Epoch 812/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0199 - mae: 0.1014\n",
      "Epoch 813/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0210 - mae: 0.1053\n",
      "Epoch 814/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0201 - mae: 0.1029\n",
      "Epoch 815/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0206 - mae: 0.1041\n",
      "Epoch 816/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0213 - mae: 0.1071\n",
      "Epoch 817/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0227 - mae: 0.1067\n",
      "Epoch 818/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0210 - mae: 0.1039\n",
      "Epoch 819/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0199 - mae: 0.1013\n",
      "Epoch 820/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0200 - mae: 0.1020\n",
      "Epoch 821/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0201 - mae: 0.1014\n",
      "Epoch 822/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0204 - mae: 0.1034\n",
      "Epoch 823/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0209 - mae: 0.1054\n",
      "Epoch 824/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1020\n",
      "Epoch 825/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0202 - mae: 0.1032\n",
      "Epoch 826/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0204 - mae: 0.1039\n",
      "Epoch 827/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0199 - mae: 0.1021\n",
      "Epoch 828/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0213 - mae: 0.1061\n",
      "Epoch 829/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0210 - mae: 0.1057\n",
      "Epoch 830/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0195 - mae: 0.1002\n",
      "Epoch 831/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0200 - mae: 0.1020\n",
      "Epoch 832/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0198 - mae: 0.1028\n",
      "Epoch 833/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0208 - mae: 0.1044\n",
      "Epoch 834/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0208 - mae: 0.1050\n",
      "Epoch 835/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0198 - mae: 0.1019\n",
      "Epoch 836/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0203 - mae: 0.1034\n",
      "Epoch 837/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0200 - mae: 0.1023\n",
      "Epoch 838/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1021\n",
      "Epoch 839/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0208 - mae: 0.1046\n",
      "Epoch 840/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0212 - mae: 0.1053\n",
      "Epoch 841/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0233 - mae: 0.1098\n",
      "Epoch 842/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0232 - mae: 0.1112\n",
      "Epoch 843/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0219 - mae: 0.1063\n",
      "Epoch 844/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0212 - mae: 0.1056\n",
      "Epoch 845/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0206 - mae: 0.1032\n",
      "Epoch 846/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0220 - mae: 0.1067\n",
      "Epoch 847/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0215 - mae: 0.1058\n",
      "Epoch 848/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0226 - mae: 0.1074\n",
      "Epoch 849/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0226 - mae: 0.1091\n",
      "Epoch 850/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0206 - mae: 0.1030\n",
      "Epoch 851/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0205 - mae: 0.1038\n",
      "Epoch 852/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0203 - mae: 0.1024\n",
      "Epoch 853/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0207 - mae: 0.1039\n",
      "Epoch 854/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0197 - mae: 0.1008\n",
      "Epoch 855/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0206 - mae: 0.1041\n",
      "Epoch 856/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0206 - mae: 0.1037\n",
      "Epoch 857/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0200 - mae: 0.1015\n",
      "Epoch 858/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0193 - mae: 0.1002\n",
      "Epoch 859/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0200 - mae: 0.1018\n",
      "Epoch 860/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.0989\n",
      "Epoch 861/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0206 - mae: 0.1043\n",
      "Epoch 862/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0205 - mae: 0.1031\n",
      "Epoch 863/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0231 - mae: 0.1103\n",
      "Epoch 864/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0238 - mae: 0.1132\n",
      "Epoch 865/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0224 - mae: 0.1083\n",
      "Epoch 866/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0214 - mae: 0.1059\n",
      "Epoch 867/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0213 - mae: 0.1061\n",
      "Epoch 868/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0217 - mae: 0.1059\n",
      "Epoch 869/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0204 - mae: 0.1030\n",
      "Epoch 870/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1023\n",
      "Epoch 871/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0208 - mae: 0.1047\n",
      "Epoch 872/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0203 - mae: 0.1033\n",
      "Epoch 873/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1022\n",
      "Epoch 874/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0202 - mae: 0.1031\n",
      "Epoch 875/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0220 - mae: 0.1086\n",
      "Epoch 876/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0203 - mae: 0.1040\n",
      "Epoch 877/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0206 - mae: 0.1046\n",
      "Epoch 878/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0201 - mae: 0.1031\n",
      "Epoch 879/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0215 - mae: 0.1075\n",
      "Epoch 880/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0206 - mae: 0.1052\n",
      "Epoch 881/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0198 - mae: 0.1015\n",
      "Epoch 882/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0198 - mae: 0.1021\n",
      "Epoch 883/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1014\n",
      "Epoch 884/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0237 - mae: 0.1150\n",
      "Epoch 885/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0201 - mae: 0.1026\n",
      "Epoch 886/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0194 - mae: 0.1011\n",
      "Epoch 887/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0203 - mae: 0.1033\n",
      "Epoch 888/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0195 - mae: 0.1012\n",
      "Epoch 889/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1022\n",
      "Epoch 890/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0199 - mae: 0.1030\n",
      "Epoch 891/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0196 - mae: 0.1010\n",
      "Epoch 892/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0193 - mae: 0.1002\n",
      "Epoch 893/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0193 - mae: 0.0998\n",
      "Epoch 894/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0190 - mae: 0.0999\n",
      "Epoch 895/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0214 - mae: 0.1064\n",
      "Epoch 896/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0204 - mae: 0.1029\n",
      "Epoch 897/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0198 - mae: 0.1005\n",
      "Epoch 898/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0205 - mae: 0.1034\n",
      "Epoch 899/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0192 - mae: 0.0999\n",
      "Epoch 900/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0197 - mae: 0.1018\n",
      "Epoch 901/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0212 - mae: 0.1065\n",
      "Epoch 902/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0194 - mae: 0.1002\n",
      "Epoch 903/2000\n",
      "2018/2018 [==============================] - 0s 246us/sample - loss: 0.0225 - mae: 0.1096\n",
      "Epoch 904/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0205 - mae: 0.1034\n",
      "Epoch 905/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0202 - mae: 0.1020\n",
      "Epoch 906/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0228 - mae: 0.1108\n",
      "Epoch 907/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0217 - mae: 0.1069\n",
      "Epoch 908/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0215 - mae: 0.1059\n",
      "Epoch 909/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0207 - mae: 0.1038\n",
      "Epoch 910/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0197 - mae: 0.1006\n",
      "Epoch 911/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0197 - mae: 0.1008\n",
      "Epoch 912/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0195 - mae: 0.1003\n",
      "Epoch 913/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1002\n",
      "Epoch 914/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0213 - mae: 0.1053\n",
      "Epoch 915/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0199 - mae: 0.1013\n",
      "Epoch 916/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0231 - mae: 0.1118\n",
      "Epoch 917/2000\n",
      "2018/2018 [==============================] - 0s 204us/sample - loss: 0.0232 - mae: 0.1077\n",
      "Epoch 918/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0240 - mae: 0.1128\n",
      "Epoch 919/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0213 - mae: 0.1049\n",
      "Epoch 920/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0233 - mae: 0.1105\n",
      "Epoch 921/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0219 - mae: 0.1060\n",
      "Epoch 922/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0205 - mae: 0.1025\n",
      "Epoch 923/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0203 - mae: 0.1019\n",
      "Epoch 924/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0207 - mae: 0.1030\n",
      "Epoch 925/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0207 - mae: 0.1049\n",
      "Epoch 926/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0235 - mae: 0.1131\n",
      "Epoch 927/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0208 - mae: 0.1041\n",
      "Epoch 928/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0204 - mae: 0.1033\n",
      "Epoch 929/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0241 - mae: 0.1153\n",
      "Epoch 930/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.0993\n",
      "Epoch 931/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0199 - mae: 0.1018\n",
      "Epoch 932/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0193 - mae: 0.1007\n",
      "Epoch 933/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0192 - mae: 0.0999\n",
      "Epoch 934/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0197 - mae: 0.1017\n",
      "Epoch 935/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0190 - mae: 0.0992\n",
      "Epoch 936/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0189 - mae: 0.0995\n",
      "Epoch 937/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0190 - mae: 0.0988\n",
      "Epoch 938/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0217 - mae: 0.1082\n",
      "Epoch 939/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.0993\n",
      "Epoch 940/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0191 - mae: 0.0985\n",
      "Epoch 941/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0197 - mae: 0.1019\n",
      "Epoch 942/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.0996\n",
      "Epoch 943/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0185 - mae: 0.0982\n",
      "Epoch 944/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0194 - mae: 0.1012\n",
      "Epoch 945/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1010\n",
      "Epoch 946/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0191 - mae: 0.1003\n",
      "Epoch 947/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.0997\n",
      "Epoch 948/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0190 - mae: 0.0989\n",
      "Epoch 949/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0194 - mae: 0.1012\n",
      "Epoch 950/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0228 - mae: 0.1086\n",
      "Epoch 951/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1028\n",
      "Epoch 952/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0198 - mae: 0.1019\n",
      "Epoch 953/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0202 - mae: 0.1029\n",
      "Epoch 954/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0190 - mae: 0.0996\n",
      "Epoch 955/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0193 - mae: 0.1007\n",
      "Epoch 956/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0191 - mae: 0.0989\n",
      "Epoch 957/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0188 - mae: 0.0991\n",
      "Epoch 958/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0191 - mae: 0.0995\n",
      "Epoch 959/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0193 - mae: 0.1003\n",
      "Epoch 960/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0193 - mae: 0.1007\n",
      "Epoch 961/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1007\n",
      "Epoch 962/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0196 - mae: 0.1020\n",
      "Epoch 963/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0188 - mae: 0.0990\n",
      "Epoch 964/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0188 - mae: 0.0990\n",
      "Epoch 965/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0192 - mae: 0.1011\n",
      "Epoch 966/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0213 - mae: 0.1066\n",
      "Epoch 967/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0208 - mae: 0.1053\n",
      "Epoch 968/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0195 - mae: 0.1010\n",
      "Epoch 969/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0195 - mae: 0.1013\n",
      "Epoch 970/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0213 - mae: 0.1078\n",
      "Epoch 971/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0193 - mae: 0.1004\n",
      "Epoch 972/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0191 - mae: 0.1004\n",
      "Epoch 973/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0225 - mae: 0.1118\n",
      "Epoch 974/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0189 - mae: 0.0992\n",
      "Epoch 975/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0188 - mae: 0.0988\n",
      "Epoch 976/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0187 - mae: 0.0991\n",
      "Epoch 977/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0186 - mae: 0.0988\n",
      "Epoch 978/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0204 - mae: 0.1038\n",
      "Epoch 979/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0203 - mae: 0.1042\n",
      "Epoch 980/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0189 - mae: 0.0982\n",
      "Epoch 981/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0208 - mae: 0.1047\n",
      "Epoch 982/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0189 - mae: 0.0986\n",
      "Epoch 983/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0197 - mae: 0.1011\n",
      "Epoch 984/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0197 - mae: 0.1026\n",
      "Epoch 985/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1027\n",
      "Epoch 986/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0190 - mae: 0.1001\n",
      "Epoch 987/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0191 - mae: 0.1002\n",
      "Epoch 988/2000\n",
      "2018/2018 [==============================] - 0s 101us/sample - loss: 0.0189 - mae: 0.0990\n",
      "Epoch 989/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0186 - mae: 0.0978\n",
      "Epoch 990/2000\n",
      "2018/2018 [==============================] - 0s 111us/sample - loss: 0.0187 - mae: 0.0994\n",
      "Epoch 991/2000\n",
      "2018/2018 [==============================] - 0s 96us/sample - loss: 0.0193 - mae: 0.1008\n",
      "Epoch 992/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0984\n",
      "Epoch 993/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0186 - mae: 0.0975\n",
      "Epoch 994/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0185 - mae: 0.0976\n",
      "Epoch 995/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0202 - mae: 0.1025\n",
      "Epoch 996/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1080\n",
      "Epoch 997/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0206 - mae: 0.1030\n",
      "Epoch 998/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1030\n",
      "Epoch 999/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0193 - mae: 0.1010\n",
      "Epoch 1000/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0189 - mae: 0.0986\n",
      "Epoch 1001/2000\n",
      "2018/2018 [==============================] - 0s 216us/sample - loss: 0.0196 - mae: 0.1012\n",
      "Epoch 1002/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0193 - mae: 0.0992\n",
      "Epoch 1003/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0190 - mae: 0.0982\n",
      "Epoch 1004/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0188 - mae: 0.0977\n",
      "Epoch 1005/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0189 - mae: 0.0985\n",
      "Epoch 1006/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0191 - mae: 0.0983\n",
      "Epoch 1007/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0195 - mae: 0.1013\n",
      "Epoch 1008/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0201 - mae: 0.1020\n",
      "Epoch 1009/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0193 - mae: 0.0995\n",
      "Epoch 1010/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0229 - mae: 0.1094\n",
      "Epoch 1011/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0198 - mae: 0.1027\n",
      "Epoch 1012/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0206 - mae: 0.1045\n",
      "Epoch 1013/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0207 - mae: 0.1049\n",
      "Epoch 1014/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1036\n",
      "Epoch 1015/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1019\n",
      "Epoch 1016/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0218 - mae: 0.1086\n",
      "Epoch 1017/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1015\n",
      "Epoch 1018/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0191 - mae: 0.1003\n",
      "Epoch 1019/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1005\n",
      "Epoch 1020/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1039\n",
      "Epoch 1021/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0244 - mae: 0.1164\n",
      "Epoch 1022/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0192 - mae: 0.1009\n",
      "Epoch 1023/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0188 - mae: 0.0991\n",
      "Epoch 1024/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0191 - mae: 0.1000\n",
      "Epoch 1025/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0194 - mae: 0.1013\n",
      "Epoch 1026/2000\n",
      "2018/2018 [==============================] - 0s 137us/sample - loss: 0.0194 - mae: 0.1010\n",
      "Epoch 1027/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0187 - mae: 0.0993\n",
      "Epoch 1028/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0185 - mae: 0.0986\n",
      "Epoch 1029/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0198 - mae: 0.1034\n",
      "Epoch 1030/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0191 - mae: 0.1009\n",
      "Epoch 1031/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0214 - mae: 0.1072\n",
      "Epoch 1032/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0197 - mae: 0.1027\n",
      "Epoch 1033/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0205 - mae: 0.1027\n",
      "Epoch 1034/2000\n",
      "2018/2018 [==============================] - 0s 132us/sample - loss: 0.0194 - mae: 0.0995\n",
      "Epoch 1035/2000\n",
      "2018/2018 [==============================] - 0s 105us/sample - loss: 0.0198 - mae: 0.1007\n",
      "Epoch 1036/2000\n",
      "2018/2018 [==============================] - 0s 94us/sample - loss: 0.0207 - mae: 0.1040\n",
      "Epoch 1037/2000\n",
      "2018/2018 [==============================] - 0s 90us/sample - loss: 0.0191 - mae: 0.0995\n",
      "Epoch 1038/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0193 - mae: 0.1000\n",
      "Epoch 1039/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0192 - mae: 0.1003\n",
      "Epoch 1040/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0188 - mae: 0.0995\n",
      "Epoch 1041/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.0994\n",
      "Epoch 1042/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0191 - mae: 0.1006\n",
      "Epoch 1043/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0224 - mae: 0.1097\n",
      "Epoch 1044/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0199 - mae: 0.1029\n",
      "Epoch 1045/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0186 - mae: 0.0978\n",
      "Epoch 1046/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0971\n",
      "Epoch 1047/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0185 - mae: 0.0977\n",
      "Epoch 1048/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0191 - mae: 0.1001\n",
      "Epoch 1049/2000\n",
      "2018/2018 [==============================] - 0s 96us/sample - loss: 0.0194 - mae: 0.1012\n",
      "Epoch 1050/2000\n",
      "2018/2018 [==============================] - 0s 116us/sample - loss: 0.0182 - mae: 0.0970\n",
      "Epoch 1051/2000\n",
      "2018/2018 [==============================] - 0s 100us/sample - loss: 0.0196 - mae: 0.1016\n",
      "Epoch 1052/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0186 - mae: 0.0985\n",
      "Epoch 1053/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0186 - mae: 0.0989\n",
      "Epoch 1054/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0211 - mae: 0.1066\n",
      "Epoch 1055/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0200 - mae: 0.1028\n",
      "Epoch 1056/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.1005\n",
      "Epoch 1057/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0182 - mae: 0.0969\n",
      "Epoch 1058/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0188 - mae: 0.0995\n",
      "Epoch 1059/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0190 - mae: 0.0989\n",
      "Epoch 1060/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0197 - mae: 0.1026\n",
      "Epoch 1061/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0188 - mae: 0.0995\n",
      "Epoch 1062/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0204 - mae: 0.1031\n",
      "Epoch 1063/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0183 - mae: 0.0975\n",
      "Epoch 1064/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0199 - mae: 0.1030\n",
      "Epoch 1065/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0187 - mae: 0.0988\n",
      "Epoch 1066/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0996\n",
      "Epoch 1067/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0198 - mae: 0.1025\n",
      "Epoch 1068/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0182 - mae: 0.0956\n",
      "Epoch 1069/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0193 - mae: 0.1019\n",
      "Epoch 1070/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0191 - mae: 0.1010\n",
      "Epoch 1071/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0193 - mae: 0.1003\n",
      "Epoch 1072/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0198 - mae: 0.1036\n",
      "Epoch 1073/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0180 - mae: 0.0973\n",
      "Epoch 1074/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0182 - mae: 0.0968\n",
      "Epoch 1075/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0178 - mae: 0.0957\n",
      "Epoch 1076/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0185 - mae: 0.0977\n",
      "Epoch 1077/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0193 - mae: 0.1012\n",
      "Epoch 1078/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0183 - mae: 0.0975\n",
      "Epoch 1079/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0180 - mae: 0.0964\n",
      "Epoch 1080/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0185 - mae: 0.0978\n",
      "Epoch 1081/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0184 - mae: 0.0985\n",
      "Epoch 1082/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0183 - mae: 0.0976\n",
      "Epoch 1083/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0196 - mae: 0.1027\n",
      "Epoch 1084/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0199 - mae: 0.1020\n",
      "Epoch 1085/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0193 - mae: 0.1008\n",
      "Epoch 1086/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0183 - mae: 0.0979\n",
      "Epoch 1087/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0182 - mae: 0.0969\n",
      "Epoch 1088/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0986\n",
      "Epoch 1089/2000\n",
      "2018/2018 [==============================] - 0s 205us/sample - loss: 0.0183 - mae: 0.0975\n",
      "Epoch 1090/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0187 - mae: 0.0989\n",
      "Epoch 1091/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0183 - mae: 0.0980\n",
      "Epoch 1092/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0197 - mae: 0.1033\n",
      "Epoch 1093/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0189 - mae: 0.1003\n",
      "Epoch 1094/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0193 - mae: 0.1008\n",
      "Epoch 1095/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0190 - mae: 0.1003\n",
      "Epoch 1096/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0189 - mae: 0.1006\n",
      "Epoch 1097/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0184 - mae: 0.0985\n",
      "Epoch 1098/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0184 - mae: 0.0969\n",
      "Epoch 1099/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0186 - mae: 0.0989\n",
      "Epoch 1100/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0200 - mae: 0.1029\n",
      "Epoch 1101/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0190 - mae: 0.1007\n",
      "Epoch 1102/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.0981\n",
      "Epoch 1103/2000\n",
      "2018/2018 [==============================] - 0s 106us/sample - loss: 0.0205 - mae: 0.1063\n",
      "Epoch 1104/2000\n",
      "2018/2018 [==============================] - 0s 94us/sample - loss: 0.0188 - mae: 0.0994\n",
      "Epoch 1105/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0184 - mae: 0.0979\n",
      "Epoch 1106/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0181 - mae: 0.0970\n",
      "Epoch 1107/2000\n",
      "2018/2018 [==============================] - 0s 203us/sample - loss: 0.0186 - mae: 0.0988\n",
      "Epoch 1108/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0186 - mae: 0.0982\n",
      "Epoch 1109/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0188 - mae: 0.0997\n",
      "Epoch 1110/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0186 - mae: 0.0992\n",
      "Epoch 1111/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0182 - mae: 0.0973\n",
      "Epoch 1112/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0181 - mae: 0.0973\n",
      "Epoch 1113/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0186 - mae: 0.0986\n",
      "Epoch 1114/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0181 - mae: 0.0968\n",
      "Epoch 1115/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0183 - mae: 0.0986\n",
      "Epoch 1116/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0199 - mae: 0.1028\n",
      "Epoch 1117/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0187 - mae: 0.0993\n",
      "Epoch 1118/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.0989\n",
      "Epoch 1119/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0242 - mae: 0.1162\n",
      "Epoch 1120/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0206 - mae: 0.1036\n",
      "Epoch 1121/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0202 - mae: 0.1026\n",
      "Epoch 1122/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0189 - mae: 0.0990\n",
      "Epoch 1123/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0198 - mae: 0.1020\n",
      "Epoch 1124/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0184 - mae: 0.0976\n",
      "Epoch 1125/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0184 - mae: 0.0975\n",
      "Epoch 1126/2000\n",
      "2018/2018 [==============================] - 0s 131us/sample - loss: 0.0187 - mae: 0.0992\n",
      "Epoch 1127/2000\n",
      "2018/2018 [==============================] - 0s 115us/sample - loss: 0.0188 - mae: 0.0992\n",
      "Epoch 1128/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0184 - mae: 0.0980\n",
      "Epoch 1129/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0187 - mae: 0.1001\n",
      "Epoch 1130/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0182 - mae: 0.0977\n",
      "Epoch 1131/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0180 - mae: 0.0970\n",
      "Epoch 1132/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0179 - mae: 0.0962\n",
      "Epoch 1133/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.0994\n",
      "Epoch 1134/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0181 - mae: 0.0969\n",
      "Epoch 1135/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0185 - mae: 0.0988\n",
      "Epoch 1136/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0471 - mae: 0.1235\n",
      "Epoch 1137/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0292 - mae: 0.1269\n",
      "Epoch 1138/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0224 - mae: 0.1100\n",
      "Epoch 1139/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0212 - mae: 0.1059\n",
      "Epoch 1140/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0217 - mae: 0.1085\n",
      "Epoch 1141/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0216 - mae: 0.1082\n",
      "Epoch 1142/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0206 - mae: 0.1050\n",
      "Epoch 1143/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0210 - mae: 0.1049\n",
      "Epoch 1144/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0215 - mae: 0.1075\n",
      "Epoch 1145/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0204 - mae: 0.1037\n",
      "Epoch 1146/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0201 - mae: 0.1034\n",
      "Epoch 1147/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0200 - mae: 0.1029\n",
      "Epoch 1148/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0202 - mae: 0.1041\n",
      "Epoch 1149/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0219 - mae: 0.1086\n",
      "Epoch 1150/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0198 - mae: 0.1025\n",
      "Epoch 1151/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0196 - mae: 0.1012\n",
      "Epoch 1152/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0194 - mae: 0.1014\n",
      "Epoch 1153/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0207 - mae: 0.1036\n",
      "Epoch 1154/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0195 - mae: 0.1016\n",
      "Epoch 1155/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0205 - mae: 0.1056\n",
      "Epoch 1156/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0194 - mae: 0.1026\n",
      "Epoch 1157/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0197 - mae: 0.1016\n",
      "Epoch 1158/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0188 - mae: 0.0996\n",
      "Epoch 1159/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0186 - mae: 0.0992\n",
      "Epoch 1160/2000\n",
      "2018/2018 [==============================] - 0s 185us/sample - loss: 0.0190 - mae: 0.0997\n",
      "Epoch 1161/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0190 - mae: 0.1003\n",
      "Epoch 1162/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0186 - mae: 0.0992\n",
      "Epoch 1163/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0186 - mae: 0.0989\n",
      "Epoch 1164/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0187 - mae: 0.0987\n",
      "Epoch 1165/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1009\n",
      "Epoch 1166/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0184 - mae: 0.0986\n",
      "Epoch 1167/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0186 - mae: 0.0988\n",
      "Epoch 1168/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0185 - mae: 0.0977\n",
      "Epoch 1169/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0182 - mae: 0.0978\n",
      "Epoch 1170/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0187 - mae: 0.0989\n",
      "Epoch 1171/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.1004\n",
      "Epoch 1172/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0191 - mae: 0.1003\n",
      "Epoch 1173/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0187 - mae: 0.0991\n",
      "Epoch 1174/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0186 - mae: 0.0986\n",
      "Epoch 1175/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.0998\n",
      "Epoch 1176/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0188 - mae: 0.0989\n",
      "Epoch 1177/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0208 - mae: 0.1068\n",
      "Epoch 1178/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0188 - mae: 0.0992\n",
      "Epoch 1179/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0183 - mae: 0.0981\n",
      "Epoch 1180/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0190 - mae: 0.1000\n",
      "Epoch 1181/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0192 - mae: 0.1009\n",
      "Epoch 1182/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0193 - mae: 0.1013\n",
      "Epoch 1183/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0183 - mae: 0.0974\n",
      "Epoch 1184/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0195 - mae: 0.1017\n",
      "Epoch 1185/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.0982\n",
      "Epoch 1186/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0183 - mae: 0.0967\n",
      "Epoch 1187/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0190 - mae: 0.1007\n",
      "Epoch 1188/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0187 - mae: 0.0988\n",
      "Epoch 1189/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0184 - mae: 0.0979\n",
      "Epoch 1190/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0185 - mae: 0.0990\n",
      "Epoch 1191/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0184 - mae: 0.0986\n",
      "Epoch 1192/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0179 - mae: 0.0965\n",
      "Epoch 1193/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0189 - mae: 0.0999\n",
      "Epoch 1194/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0183 - mae: 0.0978\n",
      "Epoch 1195/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0981\n",
      "Epoch 1196/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0183 - mae: 0.0985\n",
      "Epoch 1197/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0196 - mae: 0.1024\n",
      "Epoch 1198/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0189 - mae: 0.1007\n",
      "Epoch 1199/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0181 - mae: 0.0975\n",
      "Epoch 1200/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0180 - mae: 0.0963\n",
      "Epoch 1201/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0200 - mae: 0.1033\n",
      "Epoch 1202/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0191 - mae: 0.0996\n",
      "Epoch 1203/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0186 - mae: 0.0991\n",
      "Epoch 1204/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0994\n",
      "Epoch 1205/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0187 - mae: 0.0994\n",
      "Epoch 1206/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0184 - mae: 0.0981\n",
      "Epoch 1207/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0181 - mae: 0.0968\n",
      "Epoch 1208/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0178 - mae: 0.0960\n",
      "Epoch 1209/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0184 - mae: 0.0979\n",
      "Epoch 1210/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0187 - mae: 0.1000\n",
      "Epoch 1211/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0184 - mae: 0.0982\n",
      "Epoch 1212/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0181 - mae: 0.0969\n",
      "Epoch 1213/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0177 - mae: 0.0957\n",
      "Epoch 1214/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0971\n",
      "Epoch 1215/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0183 - mae: 0.0977\n",
      "Epoch 1216/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0977\n",
      "Epoch 1217/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0191 - mae: 0.0999\n",
      "Epoch 1218/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0179 - mae: 0.0968\n",
      "Epoch 1219/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0189 - mae: 0.1007\n",
      "Epoch 1220/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0212 - mae: 0.1081\n",
      "Epoch 1221/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0177 - mae: 0.0957\n",
      "Epoch 1222/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0244 - mae: 0.1167\n",
      "Epoch 1223/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0183 - mae: 0.0979\n",
      "Epoch 1224/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0182 - mae: 0.0971\n",
      "Epoch 1225/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0185 - mae: 0.0983\n",
      "Epoch 1226/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0176 - mae: 0.0954\n",
      "Epoch 1227/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0179 - mae: 0.0976\n",
      "Epoch 1228/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0177 - mae: 0.0965\n",
      "Epoch 1229/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0181 - mae: 0.0982\n",
      "Epoch 1230/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0180 - mae: 0.0973\n",
      "Epoch 1231/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0191 - mae: 0.1007\n",
      "Epoch 1232/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0182 - mae: 0.0978\n",
      "Epoch 1233/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0179 - mae: 0.0971\n",
      "Epoch 1234/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0178 - mae: 0.0969\n",
      "Epoch 1235/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0176 - mae: 0.0957\n",
      "Epoch 1236/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0181 - mae: 0.0977\n",
      "Epoch 1237/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0179 - mae: 0.0965\n",
      "Epoch 1238/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0181 - mae: 0.0975\n",
      "Epoch 1239/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0980\n",
      "Epoch 1240/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0191 - mae: 0.1011\n",
      "Epoch 1241/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0176 - mae: 0.0947\n",
      "Epoch 1242/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0183 - mae: 0.0979\n",
      "Epoch 1243/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0179 - mae: 0.0963\n",
      "Epoch 1244/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0180 - mae: 0.0970\n",
      "Epoch 1245/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0197 - mae: 0.1037\n",
      "Epoch 1246/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0196 - mae: 0.1021\n",
      "Epoch 1247/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0189 - mae: 0.0993\n",
      "Epoch 1248/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0191 - mae: 0.1019\n",
      "Epoch 1249/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0195 - mae: 0.1034\n",
      "Epoch 1250/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0180 - mae: 0.0976\n",
      "Epoch 1251/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0189 - mae: 0.0997\n",
      "Epoch 1252/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0185 - mae: 0.0986\n",
      "Epoch 1253/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0178 - mae: 0.0962\n",
      "Epoch 1254/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0194 - mae: 0.1013\n",
      "Epoch 1255/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0186 - mae: 0.0989\n",
      "Epoch 1256/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0183 - mae: 0.0981\n",
      "Epoch 1257/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0181 - mae: 0.0968\n",
      "Epoch 1258/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0984\n",
      "Epoch 1259/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0987\n",
      "Epoch 1260/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0186 - mae: 0.0998\n",
      "Epoch 1261/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0174 - mae: 0.0948\n",
      "Epoch 1262/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0178 - mae: 0.0974\n",
      "Epoch 1263/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0187 - mae: 0.0993\n",
      "Epoch 1264/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0177 - mae: 0.0961\n",
      "Epoch 1265/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0182 - mae: 0.0972\n",
      "Epoch 1266/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0179 - mae: 0.0963\n",
      "Epoch 1267/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0194 - mae: 0.1018\n",
      "Epoch 1268/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0178 - mae: 0.0964\n",
      "Epoch 1269/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0176 - mae: 0.0959\n",
      "Epoch 1270/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0177 - mae: 0.0967\n",
      "Epoch 1271/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0177 - mae: 0.0958\n",
      "Epoch 1272/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0184 - mae: 0.0987\n",
      "Epoch 1273/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0217 - mae: 0.1090\n",
      "Epoch 1274/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0196 - mae: 0.1016\n",
      "Epoch 1275/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0193 - mae: 0.1004\n",
      "Epoch 1276/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0193 - mae: 0.1002\n",
      "Epoch 1277/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0190 - mae: 0.1005\n",
      "Epoch 1278/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0186 - mae: 0.0998\n",
      "Epoch 1279/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0180 - mae: 0.0966\n",
      "Epoch 1280/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0178 - mae: 0.0964\n",
      "Epoch 1281/2000\n",
      "2018/2018 [==============================] - 0s 113us/sample - loss: 0.0173 - mae: 0.0946\n",
      "Epoch 1282/2000\n",
      "2018/2018 [==============================] - 0s 109us/sample - loss: 0.0180 - mae: 0.0970\n",
      "Epoch 1283/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0181 - mae: 0.0972\n",
      "Epoch 1284/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0178 - mae: 0.0970\n",
      "Epoch 1285/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0181 - mae: 0.0969\n",
      "Epoch 1286/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0177 - mae: 0.0967\n",
      "Epoch 1287/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0176 - mae: 0.0959\n",
      "Epoch 1288/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0173 - mae: 0.0948\n",
      "Epoch 1289/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0185 - mae: 0.0981\n",
      "Epoch 1290/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0179 - mae: 0.0962\n",
      "Epoch 1291/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0186 - mae: 0.0994\n",
      "Epoch 1292/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0201 - mae: 0.1047\n",
      "Epoch 1293/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0247 - mae: 0.1116\n",
      "Epoch 1294/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0210 - mae: 0.1046\n",
      "Epoch 1295/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0203 - mae: 0.1033\n",
      "Epoch 1296/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0189 - mae: 0.0984\n",
      "Epoch 1297/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.0995\n",
      "Epoch 1298/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0193 - mae: 0.1012\n",
      "Epoch 1299/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0182 - mae: 0.0976\n",
      "Epoch 1300/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0183 - mae: 0.0979\n",
      "Epoch 1301/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0185 - mae: 0.0983\n",
      "Epoch 1302/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0177 - mae: 0.0951\n",
      "Epoch 1303/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0176 - mae: 0.0966\n",
      "Epoch 1304/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0184 - mae: 0.0982\n",
      "Epoch 1305/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0185 - mae: 0.0989\n",
      "Epoch 1306/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.0984\n",
      "Epoch 1307/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0197 - mae: 0.1022\n",
      "Epoch 1308/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0181 - mae: 0.0970\n",
      "Epoch 1309/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0188 - mae: 0.0993\n",
      "Epoch 1310/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0181 - mae: 0.0979\n",
      "Epoch 1311/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0176 - mae: 0.0953\n",
      "Epoch 1312/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0175 - mae: 0.0953\n",
      "Epoch 1313/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0181 - mae: 0.0977\n",
      "Epoch 1314/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0187 - mae: 0.1000\n",
      "Epoch 1315/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0178 - mae: 0.0961\n",
      "Epoch 1316/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0177 - mae: 0.0964\n",
      "Epoch 1317/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0183 - mae: 0.0987\n",
      "Epoch 1318/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0197 - mae: 0.1021\n",
      "Epoch 1319/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.0999\n",
      "Epoch 1320/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0183 - mae: 0.0989\n",
      "Epoch 1321/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0181 - mae: 0.0971\n",
      "Epoch 1322/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0180 - mae: 0.0978\n",
      "Epoch 1323/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0183 - mae: 0.0981\n",
      "Epoch 1324/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0184 - mae: 0.0984\n",
      "Epoch 1325/2000\n",
      "2018/2018 [==============================] - ETA: 0s - loss: 0.0181 - mae: 0.097 - 0s 99us/sample - loss: 0.0180 - mae: 0.0974\n",
      "Epoch 1326/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0175 - mae: 0.0957\n",
      "Epoch 1327/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0966\n",
      "Epoch 1328/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0188 - mae: 0.0996\n",
      "Epoch 1329/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0173 - mae: 0.0944\n",
      "Epoch 1330/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0216 - mae: 0.1082\n",
      "Epoch 1331/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0175 - mae: 0.0959\n",
      "Epoch 1332/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0172 - mae: 0.0943\n",
      "Epoch 1333/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0952\n",
      "Epoch 1334/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0171 - mae: 0.0940\n",
      "Epoch 1335/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0182 - mae: 0.0973\n",
      "Epoch 1336/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0188 - mae: 0.1004\n",
      "Epoch 1337/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0191 - mae: 0.1009\n",
      "Epoch 1338/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0175 - mae: 0.0949\n",
      "Epoch 1339/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0172 - mae: 0.0943\n",
      "Epoch 1340/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0177 - mae: 0.0957\n",
      "Epoch 1341/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0179 - mae: 0.0975\n",
      "Epoch 1342/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0182 - mae: 0.0972\n",
      "Epoch 1343/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0950\n",
      "Epoch 1344/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0179 - mae: 0.0970\n",
      "Epoch 1345/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0182 - mae: 0.0976\n",
      "Epoch 1346/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0189 - mae: 0.0998\n",
      "Epoch 1347/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0961\n",
      "Epoch 1348/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0177 - mae: 0.0969\n",
      "Epoch 1349/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0182 - mae: 0.0986\n",
      "Epoch 1350/2000\n",
      "2018/2018 [==============================] - 0s 176us/sample - loss: 0.0178 - mae: 0.0961\n",
      "Epoch 1351/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0175 - mae: 0.0945\n",
      "Epoch 1352/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0175 - mae: 0.0951\n",
      "Epoch 1353/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0187 - mae: 0.0997\n",
      "Epoch 1354/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0176 - mae: 0.0959\n",
      "Epoch 1355/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0177 - mae: 0.0961\n",
      "Epoch 1356/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.0999\n",
      "Epoch 1357/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0222 - mae: 0.1101\n",
      "Epoch 1358/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0184 - mae: 0.0979\n",
      "Epoch 1359/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0257 - mae: 0.1154\n",
      "Epoch 1360/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0213 - mae: 0.1064\n",
      "Epoch 1361/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0188 - mae: 0.0988\n",
      "Epoch 1362/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0193 - mae: 0.1007\n",
      "Epoch 1363/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0185 - mae: 0.0984\n",
      "Epoch 1364/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0179 - mae: 0.0964\n",
      "Epoch 1365/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0191 - mae: 0.1008\n",
      "Epoch 1366/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0176 - mae: 0.0957\n",
      "Epoch 1367/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0177 - mae: 0.0958\n",
      "Epoch 1368/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0176 - mae: 0.0957\n",
      "Epoch 1369/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0194 - mae: 0.1022\n",
      "Epoch 1370/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.0986\n",
      "Epoch 1371/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0185 - mae: 0.1002\n",
      "Epoch 1372/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0178 - mae: 0.0969\n",
      "Epoch 1373/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0178 - mae: 0.0963\n",
      "Epoch 1374/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0174 - mae: 0.0958\n",
      "Epoch 1375/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0173 - mae: 0.0951\n",
      "Epoch 1376/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0175 - mae: 0.0972\n",
      "Epoch 1377/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0172 - mae: 0.0946\n",
      "Epoch 1378/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0172 - mae: 0.0952\n",
      "Epoch 1379/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0183 - mae: 0.0986\n",
      "Epoch 1380/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0171 - mae: 0.0941\n",
      "Epoch 1381/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0175 - mae: 0.0958\n",
      "Epoch 1382/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0172 - mae: 0.0942\n",
      "Epoch 1383/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0171 - mae: 0.0948\n",
      "Epoch 1384/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0179 - mae: 0.0977\n",
      "Epoch 1385/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0180 - mae: 0.0975\n",
      "Epoch 1386/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0196 - mae: 0.1029\n",
      "Epoch 1387/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0179 - mae: 0.0967\n",
      "Epoch 1388/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0189 - mae: 0.1002\n",
      "Epoch 1389/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0971\n",
      "Epoch 1390/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0171 - mae: 0.0942\n",
      "Epoch 1391/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0180 - mae: 0.0987\n",
      "Epoch 1392/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0175 - mae: 0.0961\n",
      "Epoch 1393/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0238 - mae: 0.1156\n",
      "Epoch 1394/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0188 - mae: 0.1000\n",
      "Epoch 1395/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0174 - mae: 0.0960\n",
      "Epoch 1396/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0172 - mae: 0.0951\n",
      "Epoch 1397/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0174 - mae: 0.0951\n",
      "Epoch 1398/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0175 - mae: 0.0953\n",
      "Epoch 1399/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0174 - mae: 0.0962\n",
      "Epoch 1400/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0962\n",
      "Epoch 1401/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0179 - mae: 0.0971\n",
      "Epoch 1402/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0193 - mae: 0.1026\n",
      "Epoch 1403/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0174 - mae: 0.0949\n",
      "Epoch 1404/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0966\n",
      "Epoch 1405/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0173 - mae: 0.0946\n",
      "Epoch 1406/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0170 - mae: 0.0938\n",
      "Epoch 1407/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0170 - mae: 0.0941\n",
      "Epoch 1408/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0176 - mae: 0.0952\n",
      "Epoch 1409/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0177 - mae: 0.0968\n",
      "Epoch 1410/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0971\n",
      "Epoch 1411/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0173 - mae: 0.0946\n",
      "Epoch 1412/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.1006\n",
      "Epoch 1413/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0174 - mae: 0.0949\n",
      "Epoch 1414/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0177 - mae: 0.0967\n",
      "Epoch 1415/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0168 - mae: 0.0932\n",
      "Epoch 1416/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0174 - mae: 0.0955\n",
      "Epoch 1417/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0181 - mae: 0.0974\n",
      "Epoch 1418/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0179 - mae: 0.0974\n",
      "Epoch 1419/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0175 - mae: 0.0954\n",
      "Epoch 1420/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0169 - mae: 0.0939\n",
      "Epoch 1421/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0175 - mae: 0.0953\n",
      "Epoch 1422/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0178 - mae: 0.0964\n",
      "Epoch 1423/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0971\n",
      "Epoch 1424/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0174 - mae: 0.0951\n",
      "Epoch 1425/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0172 - mae: 0.0953\n",
      "Epoch 1426/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0179 - mae: 0.0980\n",
      "Epoch 1427/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0174 - mae: 0.0958\n",
      "Epoch 1428/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0176 - mae: 0.0959\n",
      "Epoch 1429/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0172 - mae: 0.0943\n",
      "Epoch 1430/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0170 - mae: 0.0949\n",
      "Epoch 1431/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0173 - mae: 0.0957\n",
      "Epoch 1432/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0175 - mae: 0.0960\n",
      "Epoch 1433/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0169 - mae: 0.0939\n",
      "Epoch 1434/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0170 - mae: 0.0940\n",
      "Epoch 1435/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0187 - mae: 0.0989\n",
      "Epoch 1436/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0176 - mae: 0.0966\n",
      "Epoch 1437/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0178 - mae: 0.0961\n",
      "Epoch 1438/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0174 - mae: 0.0957\n",
      "Epoch 1439/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0336 - mae: 0.1415\n",
      "Epoch 1440/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0211 - mae: 0.1072\n",
      "Epoch 1441/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0189 - mae: 0.0999\n",
      "Epoch 1442/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0187 - mae: 0.0979\n",
      "Epoch 1443/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0183 - mae: 0.0972\n",
      "Epoch 1444/2000\n",
      "2018/2018 [==============================] - 1s 336us/sample - loss: 0.0181 - mae: 0.0968\n",
      "Epoch 1445/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0178 - mae: 0.0963\n",
      "Epoch 1446/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0175 - mae: 0.0949\n",
      "Epoch 1447/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0222 - mae: 0.1101\n",
      "Epoch 1448/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0182 - mae: 0.0975\n",
      "Epoch 1449/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0176 - mae: 0.0961\n",
      "Epoch 1450/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0176 - mae: 0.0963\n",
      "Epoch 1451/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0177 - mae: 0.0958\n",
      "Epoch 1452/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.1012\n",
      "Epoch 1453/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0181 - mae: 0.0985\n",
      "Epoch 1454/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0183 - mae: 0.0981\n",
      "Epoch 1455/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0174 - mae: 0.0965\n",
      "Epoch 1456/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0172 - mae: 0.0951\n",
      "Epoch 1457/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0173 - mae: 0.0953\n",
      "Epoch 1458/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0172 - mae: 0.0955\n",
      "Epoch 1459/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0181 - mae: 0.0995\n",
      "Epoch 1460/2000\n",
      "2018/2018 [==============================] - 1s 397us/sample - loss: 0.0174 - mae: 0.0960\n",
      "Epoch 1461/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0169 - mae: 0.0945\n",
      "Epoch 1462/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0175 - mae: 0.0965\n",
      "Epoch 1463/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.0994\n",
      "Epoch 1464/2000\n",
      "2018/2018 [==============================] - 1s 462us/sample - loss: 0.0184 - mae: 0.0993\n",
      "Epoch 1465/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0173 - mae: 0.0955\n",
      "Epoch 1466/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0181 - mae: 0.0972\n",
      "Epoch 1467/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0175 - mae: 0.0963\n",
      "Epoch 1468/2000\n",
      "2018/2018 [==============================] - 1s 289us/sample - loss: 0.0178 - mae: 0.0970\n",
      "Epoch 1469/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0183 - mae: 0.0978\n",
      "Epoch 1470/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0182 - mae: 0.0982\n",
      "Epoch 1471/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0170 - mae: 0.0937\n",
      "Epoch 1472/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0173 - mae: 0.0954\n",
      "Epoch 1473/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0176 - mae: 0.0962\n",
      "Epoch 1474/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0176 - mae: 0.0956\n",
      "Epoch 1475/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0172 - mae: 0.0950\n",
      "Epoch 1476/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0173 - mae: 0.0967\n",
      "Epoch 1477/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0174 - mae: 0.0960\n",
      "Epoch 1478/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0184 - mae: 0.0997\n",
      "Epoch 1479/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0178 - mae: 0.0964\n",
      "Epoch 1480/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0964\n",
      "Epoch 1481/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0182 - mae: 0.0984\n",
      "Epoch 1482/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0174 - mae: 0.0957\n",
      "Epoch 1483/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0172 - mae: 0.0946\n",
      "Epoch 1484/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0174 - mae: 0.0956\n",
      "Epoch 1485/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0169 - mae: 0.0945\n",
      "Epoch 1486/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0175 - mae: 0.0959\n",
      "Epoch 1487/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0173 - mae: 0.0951\n",
      "Epoch 1488/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0177 - mae: 0.0971\n",
      "Epoch 1489/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0172 - mae: 0.0947\n",
      "Epoch 1490/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0211 - mae: 0.1083\n",
      "Epoch 1491/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0173 - mae: 0.09530s - loss: 0.0176 - mae: 0.096\n",
      "Epoch 1492/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0168 - mae: 0.0941\n",
      "Epoch 1493/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0167 - mae: 0.0926\n",
      "Epoch 1494/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0171 - mae: 0.0947\n",
      "Epoch 1495/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0172 - mae: 0.0947\n",
      "Epoch 1496/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0169 - mae: 0.0943\n",
      "Epoch 1497/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0168 - mae: 0.0935\n",
      "Epoch 1498/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0176 - mae: 0.0967\n",
      "Epoch 1499/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0179 - mae: 0.0981\n",
      "Epoch 1500/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0171 - mae: 0.0945\n",
      "Epoch 1501/2000\n",
      "2018/2018 [==============================] - 1s 274us/sample - loss: 0.0172 - mae: 0.0947\n",
      "Epoch 1502/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0170 - mae: 0.0943\n",
      "Epoch 1503/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0167 - mae: 0.0930\n",
      "Epoch 1504/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0171 - mae: 0.0944\n",
      "Epoch 1505/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0177 - mae: 0.0978\n",
      "Epoch 1506/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0170 - mae: 0.0943\n",
      "Epoch 1507/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0171 - mae: 0.0948\n",
      "Epoch 1508/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0176 - mae: 0.0969\n",
      "Epoch 1509/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0174 - mae: 0.0970\n",
      "Epoch 1510/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0179 - mae: 0.0972\n",
      "Epoch 1511/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0183 - mae: 0.0997\n",
      "Epoch 1512/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0179 - mae: 0.0971\n",
      "Epoch 1513/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0180 - mae: 0.0974\n",
      "Epoch 1514/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0170 - mae: 0.0939\n",
      "Epoch 1515/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0172 - mae: 0.0955\n",
      "Epoch 1516/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0173 - mae: 0.0952\n",
      "Epoch 1517/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0171 - mae: 0.0949\n",
      "Epoch 1518/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0173 - mae: 0.0955\n",
      "Epoch 1519/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0175 - mae: 0.0973\n",
      "Epoch 1520/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0172 - mae: 0.0940\n",
      "Epoch 1521/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0177 - mae: 0.0959\n",
      "Epoch 1522/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0170 - mae: 0.0935\n",
      "Epoch 1523/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0168 - mae: 0.0934\n",
      "Epoch 1524/2000\n",
      "2018/2018 [==============================] - 1s 293us/sample - loss: 0.0178 - mae: 0.0968\n",
      "Epoch 1525/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0199 - mae: 0.1025\n",
      "Epoch 1526/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0191 - mae: 0.1001\n",
      "Epoch 1527/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0190 - mae: 0.1000\n",
      "Epoch 1528/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0200 - mae: 0.1044\n",
      "Epoch 1529/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0186 - mae: 0.0997\n",
      "Epoch 1530/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0171 - mae: 0.0951\n",
      "Epoch 1531/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0954\n",
      "Epoch 1532/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0167 - mae: 0.0941\n",
      "Epoch 1533/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0176 - mae: 0.0963\n",
      "Epoch 1534/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0933\n",
      "Epoch 1535/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0170 - mae: 0.0942\n",
      "Epoch 1536/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0183 - mae: 0.0987\n",
      "Epoch 1537/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0173 - mae: 0.0955\n",
      "Epoch 1538/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0173 - mae: 0.0954\n",
      "Epoch 1539/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0179 - mae: 0.0967\n",
      "Epoch 1540/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0173 - mae: 0.0952\n",
      "Epoch 1541/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0930\n",
      "Epoch 1542/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0169 - mae: 0.0938\n",
      "Epoch 1543/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0174 - mae: 0.0956\n",
      "Epoch 1544/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0172 - mae: 0.0956\n",
      "Epoch 1545/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0181 - mae: 0.0980\n",
      "Epoch 1546/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0171 - mae: 0.0953\n",
      "Epoch 1547/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0173 - mae: 0.0958\n",
      "Epoch 1548/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0166 - mae: 0.0923\n",
      "Epoch 1549/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0173 - mae: 0.0950\n",
      "Epoch 1550/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0173 - mae: 0.0956\n",
      "Epoch 1551/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0192 - mae: 0.1028\n",
      "Epoch 1552/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0175 - mae: 0.0955\n",
      "Epoch 1553/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0188 - mae: 0.1000\n",
      "Epoch 1554/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0983\n",
      "Epoch 1555/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0174 - mae: 0.0964\n",
      "Epoch 1556/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0168 - mae: 0.0936\n",
      "Epoch 1557/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0167 - mae: 0.0932\n",
      "Epoch 1558/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0177 - mae: 0.0964\n",
      "Epoch 1559/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0968\n",
      "Epoch 1560/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0169 - mae: 0.0943\n",
      "Epoch 1561/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0172 - mae: 0.0938\n",
      "Epoch 1562/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0170 - mae: 0.0940\n",
      "Epoch 1563/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0194 - mae: 0.1023\n",
      "Epoch 1564/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0173 - mae: 0.0954\n",
      "Epoch 1565/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0170 - mae: 0.0941\n",
      "Epoch 1566/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0167 - mae: 0.0928\n",
      "Epoch 1567/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0167 - mae: 0.0925\n",
      "Epoch 1568/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0989\n",
      "Epoch 1569/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0164 - mae: 0.0917\n",
      "Epoch 1570/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0167 - mae: 0.0930\n",
      "Epoch 1571/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0166 - mae: 0.0929\n",
      "Epoch 1572/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0951\n",
      "Epoch 1573/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0171 - mae: 0.0944\n",
      "Epoch 1574/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0934\n",
      "Epoch 1575/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0942\n",
      "Epoch 1576/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0169 - mae: 0.0935\n",
      "Epoch 1577/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0166 - mae: 0.0925\n",
      "Epoch 1578/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0170 - mae: 0.0946\n",
      "Epoch 1579/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0168 - mae: 0.0945\n",
      "Epoch 1580/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0164 - mae: 0.0916\n",
      "Epoch 1581/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0167 - mae: 0.0932\n",
      "Epoch 1582/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0168 - mae: 0.0933\n",
      "Epoch 1583/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0182 - mae: 0.0985\n",
      "Epoch 1584/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0178 - mae: 0.0976\n",
      "Epoch 1585/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0171 - mae: 0.0941\n",
      "Epoch 1586/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.1004\n",
      "Epoch 1587/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0173 - mae: 0.0949\n",
      "Epoch 1588/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0166 - mae: 0.0936\n",
      "Epoch 1589/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0169 - mae: 0.0940\n",
      "Epoch 1590/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0166 - mae: 0.0936\n",
      "Epoch 1591/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0169 - mae: 0.0935\n",
      "Epoch 1592/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0171 - mae: 0.0945\n",
      "Epoch 1593/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0185 - mae: 0.1000\n",
      "Epoch 1594/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0190 - mae: 0.1011\n",
      "Epoch 1595/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0176 - mae: 0.0963\n",
      "Epoch 1596/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0168 - mae: 0.0943\n",
      "Epoch 1597/2000\n",
      "2018/2018 [==============================] - 1s 261us/sample - loss: 0.0171 - mae: 0.0959\n",
      "Epoch 1598/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0176 - mae: 0.0973\n",
      "Epoch 1599/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0175 - mae: 0.0957\n",
      "Epoch 1600/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0166 - mae: 0.0939\n",
      "Epoch 1601/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0168 - mae: 0.0935\n",
      "Epoch 1602/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0172 - mae: 0.0952\n",
      "Epoch 1603/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0175 - mae: 0.0963\n",
      "Epoch 1604/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0168 - mae: 0.0933\n",
      "Epoch 1605/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0170 - mae: 0.0948\n",
      "Epoch 1606/2000\n",
      "2018/2018 [==============================] - 0s 105us/sample - loss: 0.0169 - mae: 0.0950\n",
      "Epoch 1607/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0172 - mae: 0.0943\n",
      "Epoch 1608/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0173 - mae: 0.0961\n",
      "Epoch 1609/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0165 - mae: 0.0917\n",
      "Epoch 1610/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0165 - mae: 0.0929\n",
      "Epoch 1611/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0166 - mae: 0.0934\n",
      "Epoch 1612/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0174 - mae: 0.0949\n",
      "Epoch 1613/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0166 - mae: 0.0928\n",
      "Epoch 1614/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0963\n",
      "Epoch 1615/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0177 - mae: 0.0973\n",
      "Epoch 1616/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0185 - mae: 0.0996\n",
      "Epoch 1617/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0184 - mae: 0.0990\n",
      "Epoch 1618/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0164 - mae: 0.0916\n",
      "Epoch 1619/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0169 - mae: 0.0931\n",
      "Epoch 1620/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0167 - mae: 0.0938\n",
      "Epoch 1621/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0165 - mae: 0.0928\n",
      "Epoch 1622/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0179 - mae: 0.0976\n",
      "Epoch 1623/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0171 - mae: 0.0944\n",
      "Epoch 1624/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0955\n",
      "Epoch 1625/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0171 - mae: 0.0948\n",
      "Epoch 1626/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0179 - mae: 0.0985\n",
      "Epoch 1627/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0168 - mae: 0.0934\n",
      "Epoch 1628/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0938\n",
      "Epoch 1629/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0171 - mae: 0.0947\n",
      "Epoch 1630/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0166 - mae: 0.0922\n",
      "Epoch 1631/2000\n",
      "2018/2018 [==============================] - 1s 289us/sample - loss: 0.0167 - mae: 0.0937\n",
      "Epoch 1632/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0177 - mae: 0.0968\n",
      "Epoch 1633/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0163 - mae: 0.0919\n",
      "Epoch 1634/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0164 - mae: 0.0925\n",
      "Epoch 1635/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0172 - mae: 0.0949\n",
      "Epoch 1636/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0168 - mae: 0.0939\n",
      "Epoch 1637/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0169 - mae: 0.0949\n",
      "Epoch 1638/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0166 - mae: 0.0943\n",
      "Epoch 1639/2000\n",
      "2018/2018 [==============================] - 1s 280us/sample - loss: 0.0164 - mae: 0.0924\n",
      "Epoch 1640/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0176 - mae: 0.0960\n",
      "Epoch 1641/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0166 - mae: 0.0927\n",
      "Epoch 1642/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0163 - mae: 0.0924\n",
      "Epoch 1643/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0169 - mae: 0.0935\n",
      "Epoch 1644/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0173 - mae: 0.0964\n",
      "Epoch 1645/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1016\n",
      "Epoch 1646/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0166 - mae: 0.0931\n",
      "Epoch 1647/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0165 - mae: 0.0923\n",
      "Epoch 1648/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0163 - mae: 0.0923\n",
      "Epoch 1649/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0166 - mae: 0.0933\n",
      "Epoch 1650/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0161 - mae: 0.0917\n",
      "Epoch 1651/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0164 - mae: 0.0916\n",
      "Epoch 1652/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0198 - mae: 0.1033\n",
      "Epoch 1653/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0191 - mae: 0.1027\n",
      "Epoch 1654/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0168 - mae: 0.0938\n",
      "Epoch 1655/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0167 - mae: 0.0945\n",
      "Epoch 1656/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0172 - mae: 0.0951\n",
      "Epoch 1657/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0188 - mae: 0.1007\n",
      "Epoch 1658/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0169 - mae: 0.0945\n",
      "Epoch 1659/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0179 - mae: 0.0977\n",
      "Epoch 1660/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0178 - mae: 0.0967\n",
      "Epoch 1661/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0173 - mae: 0.0959\n",
      "Epoch 1662/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0169 - mae: 0.0937\n",
      "Epoch 1663/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0168 - mae: 0.0942\n",
      "Epoch 1664/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0164 - mae: 0.0927\n",
      "Epoch 1665/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0170 - mae: 0.0946\n",
      "Epoch 1666/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0173 - mae: 0.0956\n",
      "Epoch 1667/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0171 - mae: 0.0954\n",
      "Epoch 1668/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0171 - mae: 0.0951\n",
      "Epoch 1669/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0162 - mae: 0.0923\n",
      "Epoch 1670/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0162 - mae: 0.0922\n",
      "Epoch 1671/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0166 - mae: 0.0930\n",
      "Epoch 1672/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0172 - mae: 0.0950\n",
      "Epoch 1673/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0165 - mae: 0.0926\n",
      "Epoch 1674/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0165 - mae: 0.0925\n",
      "Epoch 1675/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0168 - mae: 0.0938\n",
      "Epoch 1676/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0172 - mae: 0.0944\n",
      "Epoch 1677/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0165 - mae: 0.0922\n",
      "Epoch 1678/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0190 - mae: 0.1014\n",
      "Epoch 1679/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0162 - mae: 0.0912\n",
      "Epoch 1680/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0167 - mae: 0.0929\n",
      "Epoch 1681/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0162 - mae: 0.0915\n",
      "Epoch 1682/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0164 - mae: 0.0921\n",
      "Epoch 1683/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0171 - mae: 0.0949\n",
      "Epoch 1684/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0164 - mae: 0.0926\n",
      "Epoch 1685/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0162 - mae: 0.0924\n",
      "Epoch 1686/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0197 - mae: 0.1032\n",
      "Epoch 1687/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0176 - mae: 0.0969\n",
      "Epoch 1688/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0163 - mae: 0.0924\n",
      "Epoch 1689/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0174 - mae: 0.0955\n",
      "Epoch 1690/2000\n",
      "2018/2018 [==============================] - 1s 291us/sample - loss: 0.0176 - mae: 0.0972\n",
      "Epoch 1691/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0190 - mae: 0.0993\n",
      "Epoch 1692/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0180 - mae: 0.0970\n",
      "Epoch 1693/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0196 - mae: 0.1039\n",
      "Epoch 1694/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0178 - mae: 0.0964\n",
      "Epoch 1695/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0171 - mae: 0.0949\n",
      "Epoch 1696/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0180 - mae: 0.0983\n",
      "Epoch 1697/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0166 - mae: 0.0929\n",
      "Epoch 1698/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0166 - mae: 0.0933\n",
      "Epoch 1699/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0170 - mae: 0.0941\n",
      "Epoch 1700/2000\n",
      "2018/2018 [==============================] - 0s 64us/sample - loss: 0.0163 - mae: 0.0915\n",
      "Epoch 1701/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0160 - mae: 0.0914\n",
      "Epoch 1702/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0166 - mae: 0.0931\n",
      "Epoch 1703/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0169 - mae: 0.0939\n",
      "Epoch 1704/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0164 - mae: 0.0919\n",
      "Epoch 1705/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0165 - mae: 0.0918\n",
      "Epoch 1706/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0168 - mae: 0.0939\n",
      "Epoch 1707/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0164 - mae: 0.0922\n",
      "Epoch 1708/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0175 - mae: 0.0966\n",
      "Epoch 1709/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0172 - mae: 0.0958\n",
      "Epoch 1710/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0171 - mae: 0.0950\n",
      "Epoch 1711/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0165 - mae: 0.0930\n",
      "Epoch 1712/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0165 - mae: 0.0933\n",
      "Epoch 1713/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0169 - mae: 0.0939\n",
      "Epoch 1714/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0164 - mae: 0.0925\n",
      "Epoch 1715/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0163 - mae: 0.0924\n",
      "Epoch 1716/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0160 - mae: 0.0911\n",
      "Epoch 1717/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0178 - mae: 0.0983\n",
      "Epoch 1718/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0176 - mae: 0.0962\n",
      "Epoch 1719/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0174 - mae: 0.0966\n",
      "Epoch 1720/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0168 - mae: 0.0939\n",
      "Epoch 1721/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0173 - mae: 0.0970\n",
      "Epoch 1722/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0172 - mae: 0.0953\n",
      "Epoch 1723/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0168 - mae: 0.0947\n",
      "Epoch 1724/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0162 - mae: 0.0918\n",
      "Epoch 1725/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0171 - mae: 0.0947\n",
      "Epoch 1726/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0175 - mae: 0.0971\n",
      "Epoch 1727/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0170 - mae: 0.0946\n",
      "Epoch 1728/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0165 - mae: 0.0925\n",
      "Epoch 1729/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0157 - mae: 0.0897\n",
      "Epoch 1730/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0160 - mae: 0.0915\n",
      "Epoch 1731/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0162 - mae: 0.0921\n",
      "Epoch 1732/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0165 - mae: 0.0940\n",
      "Epoch 1733/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0198 - mae: 0.1044\n",
      "Epoch 1734/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0177 - mae: 0.0963\n",
      "Epoch 1735/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0165 - mae: 0.0934\n",
      "Epoch 1736/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0161 - mae: 0.0911\n",
      "Epoch 1737/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0942\n",
      "Epoch 1738/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0164 - mae: 0.0929\n",
      "Epoch 1739/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0163 - mae: 0.0927\n",
      "Epoch 1740/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0164 - mae: 0.0926\n",
      "Epoch 1741/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0165 - mae: 0.0925\n",
      "Epoch 1742/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0164 - mae: 0.0931\n",
      "Epoch 1743/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0163 - mae: 0.0919\n",
      "Epoch 1744/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0983\n",
      "Epoch 1745/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0163 - mae: 0.0922\n",
      "Epoch 1746/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0936\n",
      "Epoch 1747/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0162 - mae: 0.0920\n",
      "Epoch 1748/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0170 - mae: 0.0950\n",
      "Epoch 1749/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0164 - mae: 0.0919\n",
      "Epoch 1750/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0161 - mae: 0.0917\n",
      "Epoch 1751/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0166 - mae: 0.0931\n",
      "Epoch 1752/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0175 - mae: 0.0954\n",
      "Epoch 1753/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0165 - mae: 0.0929\n",
      "Epoch 1754/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0163 - mae: 0.0924\n",
      "Epoch 1755/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0174 - mae: 0.0958\n",
      "Epoch 1756/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0162 - mae: 0.0914\n",
      "Epoch 1757/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0172 - mae: 0.0943\n",
      "Epoch 1758/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0168 - mae: 0.0947\n",
      "Epoch 1759/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0160 - mae: 0.0915\n",
      "Epoch 1760/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0164 - mae: 0.0920\n",
      "Epoch 1761/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0175 - mae: 0.0970\n",
      "Epoch 1762/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0166 - mae: 0.0925\n",
      "Epoch 1763/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0184 - mae: 0.0985\n",
      "Epoch 1764/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0248 - mae: 0.1085\n",
      "Epoch 1765/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0209 - mae: 0.1053\n",
      "Epoch 1766/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0192 - mae: 0.1009\n",
      "Epoch 1767/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0205 - mae: 0.1011\n",
      "Epoch 1768/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0186 - mae: 0.0986\n",
      "Epoch 1769/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0182 - mae: 0.0983\n",
      "Epoch 1770/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0178 - mae: 0.0966\n",
      "Epoch 1771/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0173 - mae: 0.0949\n",
      "Epoch 1772/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0172 - mae: 0.0954\n",
      "Epoch 1773/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0170 - mae: 0.0938\n",
      "Epoch 1774/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0180 - mae: 0.0985\n",
      "Epoch 1775/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0170 - mae: 0.0938\n",
      "Epoch 1776/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0167 - mae: 0.0930\n",
      "Epoch 1777/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.1007\n",
      "Epoch 1778/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0183 - mae: 0.0983\n",
      "Epoch 1779/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0172 - mae: 0.0955\n",
      "Epoch 1780/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0163 - mae: 0.0923\n",
      "Epoch 1781/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0170 - mae: 0.0946\n",
      "Epoch 1782/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0165 - mae: 0.0934\n",
      "Epoch 1783/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0170 - mae: 0.0953\n",
      "Epoch 1784/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0164 - mae: 0.0932\n",
      "Epoch 1785/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0177 - mae: 0.0974\n",
      "Epoch 1786/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0163 - mae: 0.0919\n",
      "Epoch 1787/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0162 - mae: 0.0915\n",
      "Epoch 1788/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0169 - mae: 0.0943\n",
      "Epoch 1789/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0159 - mae: 0.0911\n",
      "Epoch 1790/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0164 - mae: 0.0931\n",
      "Epoch 1791/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0163 - mae: 0.0926\n",
      "Epoch 1792/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0159 - mae: 0.0906\n",
      "Epoch 1793/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0931\n",
      "Epoch 1794/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0161 - mae: 0.0913\n",
      "Epoch 1795/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0181 - mae: 0.0992\n",
      "Epoch 1796/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0176 - mae: 0.0970\n",
      "Epoch 1797/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0160 - mae: 0.0913\n",
      "Epoch 1798/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0168 - mae: 0.0951\n",
      "Epoch 1799/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0160 - mae: 0.0918\n",
      "Epoch 1800/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0162 - mae: 0.0926\n",
      "Epoch 1801/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0163 - mae: 0.0929\n",
      "Epoch 1802/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0164 - mae: 0.0927\n",
      "Epoch 1803/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0166 - mae: 0.0941\n",
      "Epoch 1804/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0972\n",
      "Epoch 1805/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0164 - mae: 0.0931\n",
      "Epoch 1806/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0165 - mae: 0.0926\n",
      "Epoch 1807/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0168 - mae: 0.0952\n",
      "Epoch 1808/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0183 - mae: 0.0991\n",
      "Epoch 1809/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0957\n",
      "Epoch 1810/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0172 - mae: 0.0955\n",
      "Epoch 1811/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0164 - mae: 0.0926\n",
      "Epoch 1812/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0165 - mae: 0.0931\n",
      "Epoch 1813/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0160 - mae: 0.0915\n",
      "Epoch 1814/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0165 - mae: 0.0928\n",
      "Epoch 1815/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0157 - mae: 0.0904\n",
      "Epoch 1816/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0164 - mae: 0.0928\n",
      "Epoch 1817/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0165 - mae: 0.0939\n",
      "Epoch 1818/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0159 - mae: 0.0911\n",
      "Epoch 1819/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0163 - mae: 0.0926\n",
      "Epoch 1820/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0167 - mae: 0.0935\n",
      "Epoch 1821/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0169 - mae: 0.0945\n",
      "Epoch 1822/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0163 - mae: 0.0925\n",
      "Epoch 1823/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0162 - mae: 0.0917\n",
      "Epoch 1824/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0166 - mae: 0.0934\n",
      "Epoch 1825/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0163 - mae: 0.0925\n",
      "Epoch 1826/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0161 - mae: 0.0918\n",
      "Epoch 1827/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0164 - mae: 0.0934\n",
      "Epoch 1828/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0159 - mae: 0.0909\n",
      "Epoch 1829/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0167 - mae: 0.0944\n",
      "Epoch 1830/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0163 - mae: 0.0920\n",
      "Epoch 1831/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0166 - mae: 0.0929\n",
      "Epoch 1832/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0160 - mae: 0.0911\n",
      "Epoch 1833/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0161 - mae: 0.0913\n",
      "Epoch 1834/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0163 - mae: 0.0918\n",
      "Epoch 1835/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0172 - mae: 0.0948\n",
      "Epoch 1836/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0162 - mae: 0.0924\n",
      "Epoch 1837/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0163 - mae: 0.0926\n",
      "Epoch 1838/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0176 - mae: 0.0965\n",
      "Epoch 1839/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0165 - mae: 0.0935\n",
      "Epoch 1840/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0160 - mae: 0.0916\n",
      "Epoch 1841/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0171 - mae: 0.0958\n",
      "Epoch 1842/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0934\n",
      "Epoch 1843/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0164 - mae: 0.0925\n",
      "Epoch 1844/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0180 - mae: 0.0988\n",
      "Epoch 1845/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0939\n",
      "Epoch 1846/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0162 - mae: 0.0924\n",
      "Epoch 1847/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0202 - mae: 0.1039\n",
      "Epoch 1848/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0194 - mae: 0.1018\n",
      "Epoch 1849/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0204 - mae: 0.1047\n",
      "Epoch 1850/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0178 - mae: 0.0968\n",
      "Epoch 1851/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0169 - mae: 0.0933\n",
      "Epoch 1852/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0169 - mae: 0.0937\n",
      "Epoch 1853/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0165 - mae: 0.0921\n",
      "Epoch 1854/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0166 - mae: 0.0933\n",
      "Epoch 1855/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0163 - mae: 0.0921\n",
      "Epoch 1856/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0164 - mae: 0.0927\n",
      "Epoch 1857/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0164 - mae: 0.0928\n",
      "Epoch 1858/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0160 - mae: 0.0910\n",
      "Epoch 1859/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0158 - mae: 0.0903\n",
      "Epoch 1860/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0163 - mae: 0.0922\n",
      "Epoch 1861/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0163 - mae: 0.0918\n",
      "Epoch 1862/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0166 - mae: 0.0934\n",
      "Epoch 1863/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0171 - mae: 0.0959\n",
      "Epoch 1864/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0160 - mae: 0.0915\n",
      "Epoch 1865/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0162 - mae: 0.0923\n",
      "Epoch 1866/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0936\n",
      "Epoch 1867/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0170 - mae: 0.0947\n",
      "Epoch 1868/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0172 - mae: 0.0943\n",
      "Epoch 1869/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0941\n",
      "Epoch 1870/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0167 - mae: 0.0942\n",
      "Epoch 1871/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0956\n",
      "Epoch 1872/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0167 - mae: 0.0943\n",
      "Epoch 1873/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0164 - mae: 0.0924\n",
      "Epoch 1874/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0159 - mae: 0.0909\n",
      "Epoch 1875/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0167 - mae: 0.0933\n",
      "Epoch 1876/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0171 - mae: 0.0956\n",
      "Epoch 1877/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0163 - mae: 0.0927\n",
      "Epoch 1878/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0170 - mae: 0.0956\n",
      "Epoch 1879/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0165 - mae: 0.0932\n",
      "Epoch 1880/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0159 - mae: 0.0915\n",
      "Epoch 1881/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0159 - mae: 0.0909\n",
      "Epoch 1882/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0165 - mae: 0.0927\n",
      "Epoch 1883/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0162 - mae: 0.0926\n",
      "Epoch 1884/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0164 - mae: 0.0921\n",
      "Epoch 1885/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0188 - mae: 0.1006\n",
      "Epoch 1886/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0183 - mae: 0.0990\n",
      "Epoch 1887/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0163 - mae: 0.0922\n",
      "Epoch 1888/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0163 - mae: 0.0924\n",
      "Epoch 1889/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0185 - mae: 0.0999\n",
      "Epoch 1890/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0160 - mae: 0.0919\n",
      "Epoch 1891/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0159 - mae: 0.0912\n",
      "Epoch 1892/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0170 - mae: 0.0940\n",
      "Epoch 1893/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0165 - mae: 0.0933\n",
      "Epoch 1894/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0175 - mae: 0.0969\n",
      "Epoch 1895/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0163 - mae: 0.0925\n",
      "Epoch 1896/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0159 - mae: 0.0912\n",
      "Epoch 1897/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0155 - mae: 0.0892\n",
      "Epoch 1898/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0163 - mae: 0.0927\n",
      "Epoch 1899/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0159 - mae: 0.0917\n",
      "Epoch 1900/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0154 - mae: 0.0891\n",
      "Epoch 1901/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0192 - mae: 0.0999\n",
      "Epoch 1902/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0174 - mae: 0.0975\n",
      "Epoch 1903/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0165 - mae: 0.0923\n",
      "Epoch 1904/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0165 - mae: 0.0935\n",
      "Epoch 1905/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0162 - mae: 0.0916\n",
      "Epoch 1906/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0162 - mae: 0.0922\n",
      "Epoch 1907/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0173 - mae: 0.0963\n",
      "Epoch 1908/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0165 - mae: 0.0937\n",
      "Epoch 1909/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0160 - mae: 0.0907\n",
      "Epoch 1910/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0182 - mae: 0.0972\n",
      "Epoch 1911/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 0.0172 - mae: 0.0933\n",
      "Epoch 1912/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0177 - mae: 0.0955\n",
      "Epoch 1913/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0181 - mae: 0.0966\n",
      "Epoch 1914/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0170 - mae: 0.0947\n",
      "Epoch 1915/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0937\n",
      "Epoch 1916/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0161 - mae: 0.0921\n",
      "Epoch 1917/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0165 - mae: 0.0933\n",
      "Epoch 1918/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0157 - mae: 0.0905\n",
      "Epoch 1919/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0167 - mae: 0.0932\n",
      "Epoch 1920/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0160 - mae: 0.0917\n",
      "Epoch 1921/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0157 - mae: 0.0904\n",
      "Epoch 1922/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0159 - mae: 0.0911\n",
      "Epoch 1923/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0178 - mae: 0.0976\n",
      "Epoch 1924/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0160 - mae: 0.0903\n",
      "Epoch 1925/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0156 - mae: 0.0906\n",
      "Epoch 1926/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0162 - mae: 0.0912\n",
      "Epoch 1927/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0163 - mae: 0.0918\n",
      "Epoch 1928/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0174 - mae: 0.0965\n",
      "Epoch 1929/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0172 - mae: 0.0952\n",
      "Epoch 1930/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0155 - mae: 0.0898\n",
      "Epoch 1931/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0176 - mae: 0.0959\n",
      "Epoch 1932/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0188 - mae: 0.1008\n",
      "Epoch 1933/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0161 - mae: 0.0909\n",
      "Epoch 1934/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0169 - mae: 0.0950\n",
      "Epoch 1935/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0162 - mae: 0.0916\n",
      "Epoch 1936/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0161 - mae: 0.0915\n",
      "Epoch 1937/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0166 - mae: 0.0934\n",
      "Epoch 1938/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0165 - mae: 0.0924\n",
      "Epoch 1939/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0162 - mae: 0.0918\n",
      "Epoch 1940/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0160 - mae: 0.0914\n",
      "Epoch 1941/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0925\n",
      "Epoch 1942/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0171 - mae: 0.0945\n",
      "Epoch 1943/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0160 - mae: 0.0908\n",
      "Epoch 1944/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0164 - mae: 0.0929\n",
      "Epoch 1945/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0160 - mae: 0.0907\n",
      "Epoch 1946/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0162 - mae: 0.0917\n",
      "Epoch 1947/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0169 - mae: 0.0939\n",
      "Epoch 1948/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0161 - mae: 0.0917\n",
      "Epoch 1949/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0160 - mae: 0.0918\n",
      "Epoch 1950/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0162 - mae: 0.0914\n",
      "Epoch 1951/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0166 - mae: 0.0938\n",
      "Epoch 1952/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0171 - mae: 0.0953\n",
      "Epoch 1953/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0167 - mae: 0.0942\n",
      "Epoch 1954/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0160 - mae: 0.0913\n",
      "Epoch 1955/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0156 - mae: 0.0903\n",
      "Epoch 1956/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0163 - mae: 0.0929\n",
      "Epoch 1957/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0165 - mae: 0.0938\n",
      "Epoch 1958/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0160 - mae: 0.0910\n",
      "Epoch 1959/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0162 - mae: 0.0920\n",
      "Epoch 1960/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0159 - mae: 0.0915\n",
      "Epoch 1961/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0160 - mae: 0.0917\n",
      "Epoch 1962/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0176 - mae: 0.0963\n",
      "Epoch 1963/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0160 - mae: 0.0915\n",
      "Epoch 1964/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0177 - mae: 0.0959\n",
      "Epoch 1965/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0172 - mae: 0.0952\n",
      "Epoch 1966/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0164 - mae: 0.0930\n",
      "Epoch 1967/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0162 - mae: 0.0925\n",
      "Epoch 1968/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0164 - mae: 0.0928\n",
      "Epoch 1969/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0161 - mae: 0.0923\n",
      "Epoch 1970/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0160 - mae: 0.0926\n",
      "Epoch 1971/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0159 - mae: 0.0909\n",
      "Epoch 1972/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0161 - mae: 0.0916\n",
      "Epoch 1973/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0158 - mae: 0.0899\n",
      "Epoch 1974/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0162 - mae: 0.0922\n",
      "Epoch 1975/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0164 - mae: 0.0927\n",
      "Epoch 1976/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0159 - mae: 0.0915\n",
      "Epoch 1977/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0156 - mae: 0.0897\n",
      "Epoch 1978/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0401 - mae: 0.1541\n",
      "Epoch 1979/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0235 - mae: 0.1138\n",
      "Epoch 1980/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0194 - mae: 0.1018\n",
      "Epoch 1981/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0185 - mae: 0.0987\n",
      "Epoch 1982/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0181 - mae: 0.0979\n",
      "Epoch 1983/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0179 - mae: 0.0965\n",
      "Epoch 1984/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0171 - mae: 0.0950\n",
      "Epoch 1985/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0177 - mae: 0.0958\n",
      "Epoch 1986/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0174 - mae: 0.0952\n",
      "Epoch 1987/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0183 - mae: 0.0991\n",
      "Epoch 1988/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0175 - mae: 0.0964\n",
      "Epoch 1989/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0167 - mae: 0.0936\n",
      "Epoch 1990/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0166 - mae: 0.0931\n",
      "Epoch 1991/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0164 - mae: 0.0925\n",
      "Epoch 1992/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0272 - mae: 0.1238\n",
      "Epoch 1993/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 0.0182 - mae: 0.0985\n",
      "Epoch 1994/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0170 - mae: 0.0942\n",
      "Epoch 1995/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0180 - mae: 0.0979\n",
      "Epoch 1996/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0168 - mae: 0.0938\n",
      "Epoch 1997/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0163 - mae: 0.0922\n",
      "Epoch 1998/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 0.0169 - mae: 0.0943\n",
      "Epoch 1999/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0163 - mae: 0.0925\n",
      "Epoch 2000/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0166 - mae: 0.0932\n",
      "mae: 0.11122877150774002\n",
      "Overfit mae: 0.09043572098016739\n",
      "Train on 2018 samples\n",
      "Epoch 1/2000\n",
      "2018/2018 [==============================] - 1s 714us/sample - loss: 3952.2910 - mae: 13.8420\n",
      "Epoch 2/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 5798.9094 - mae: 15.8888\n",
      "Epoch 3/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 24945.8814 - mae: 27.2851\n",
      "Epoch 4/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 20992.7650 - mae: 21.0395\n",
      "Epoch 5/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 4074.5903 - mae: 10.2185\n",
      "Epoch 6/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 6550.5459 - mae: 10.8616\n",
      "Epoch 7/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 3363.4320 - mae: 13.2691\n",
      "Epoch 8/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 6070.8759 - mae: 13.6170\n",
      "Epoch 9/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 22122.7055 - mae: 19.2617\n",
      "Epoch 10/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 5057.1428 - mae: 13.3965\n",
      "Epoch 11/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 15155.1499 - mae: 21.8068\n",
      "Epoch 12/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 6637.3250 - mae: 12.9663\n",
      "Epoch 13/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 9458.3625 - mae: 17.1829\n",
      "Epoch 14/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 4716.4272 - mae: 9.9089\n",
      "Epoch 15/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 3826.1433 - mae: 11.4468\n",
      "Epoch 16/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 7960.5194 - mae: 11.1012\n",
      "Epoch 17/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 10030.5257 - mae: 12.0555\n",
      "Epoch 18/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 2875.0606 - mae: 8.5428\n",
      "Epoch 19/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 27014.9106 - mae: 17.2538\n",
      "Epoch 20/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 27279.1215 - mae: 18.1630\n",
      "Epoch 21/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 19833.9356 - mae: 17.3439\n",
      "Epoch 22/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 9367.6912 - mae: 12.8930\n",
      "Epoch 23/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 2672.2189 - mae: 6.2860\n",
      "Epoch 24/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 277.5244 - mae: 4.1977\n",
      "Epoch 25/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 130.3161 - mae: 3.0572\n",
      "Epoch 26/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 93.7103 - mae: 2.7809\n",
      "Epoch 27/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 89.0377 - mae: 2.6805\n",
      "Epoch 28/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 98.0099 - mae: 2.4782\n",
      "Epoch 29/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 60.1550 - mae: 2.4180\n",
      "Epoch 30/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 39.4593 - mae: 2.2459\n",
      "Epoch 31/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 67.9146 - mae: 2.1812\n",
      "Epoch 32/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 45.1557 - mae: 1.9844\n",
      "Epoch 33/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 32.9788 - mae: 1.8585\n",
      "Epoch 34/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 40.4417 - mae: 1.8857\n",
      "Epoch 35/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 61.5246 - mae: 2.0163\n",
      "Epoch 36/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 31.9102 - mae: 1.8121\n",
      "Epoch 37/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 28.7900 - mae: 1.7696\n",
      "Epoch 38/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 81.1892 - mae: 1.9842\n",
      "Epoch 39/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 38.8622 - mae: 1.7782\n",
      "Epoch 40/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 77.4388 - mae: 1.9201\n",
      "Epoch 41/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 85.7397 - mae: 1.8789\n",
      "Epoch 42/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 69.4480 - mae: 1.9057\n",
      "Epoch 43/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 106.3039 - mae: 1.8767\n",
      "Epoch 44/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 186.8607 - mae: 2.1375\n",
      "Epoch 45/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 209.1010 - mae: 1.9190\n",
      "Epoch 46/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 572.7021 - mae: 3.3023\n",
      "Epoch 47/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 263.2229 - mae: 2.2154\n",
      "Epoch 48/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 811.3128 - mae: 4.8185\n",
      "Epoch 49/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 911.6156 - mae: 4.2579\n",
      "Epoch 50/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 707.2650 - mae: 3.0623\n",
      "Epoch 51/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 1615.8262 - mae: 7.7062\n",
      "Epoch 52/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 75us/sample - loss: 2350.6670 - mae: 6.9751\n",
      "Epoch 53/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 397.0943 - mae: 3.5099\n",
      "Epoch 54/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 326.7992 - mae: 3.4743\n",
      "Epoch 55/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 501.2351 - mae: 4.6464\n",
      "Epoch 56/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 839.0134 - mae: 4.9689\n",
      "Epoch 57/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 1999.2044 - mae: 5.6210\n",
      "Epoch 58/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 162.5639 - mae: 2.5778\n",
      "Epoch 59/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 98.8777 - mae: 1.9918\n",
      "Epoch 60/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 996.8953 - mae: 3.6259\n",
      "Epoch 61/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 382.3983 - mae: 3.0801\n",
      "Epoch 62/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 771.8558 - mae: 3.8469\n",
      "Epoch 63/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 198.3199 - mae: 2.7531\n",
      "Epoch 64/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 107.8207 - mae: 2.0322\n",
      "Epoch 65/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 849.5229 - mae: 3.7410\n",
      "Epoch 66/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 11174.0390 - mae: 9.2351\n",
      "Epoch 67/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 321.9229 - mae: 4.3391\n",
      "Epoch 68/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 99.9731 - mae: 2.3901\n",
      "Epoch 69/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 43.4295 - mae: 1.7427\n",
      "Epoch 70/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 27.0832 - mae: 1.4431\n",
      "Epoch 71/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 25.5677 - mae: 1.4116\n",
      "Epoch 72/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 26.5114 - mae: 1.3058\n",
      "Epoch 73/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 20.7737 - mae: 1.2935\n",
      "Epoch 74/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 42.6933 - mae: 1.3571\n",
      "Epoch 75/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 30.9968 - mae: 1.2565\n",
      "Epoch 76/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 23.7489 - mae: 1.2020\n",
      "Epoch 77/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 22.3237 - mae: 1.1967\n",
      "Epoch 78/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 39.5305 - mae: 1.3579\n",
      "Epoch 79/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 22.9231 - mae: 1.0926\n",
      "Epoch 80/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 12.1493 - mae: 1.0442\n",
      "Epoch 81/2000\n",
      "2018/2018 [==============================] - 0s 136us/sample - loss: 11.6103 - mae: 1.0267\n",
      "Epoch 82/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 23.3161 - mae: 1.1065\n",
      "Epoch 83/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 62.0501 - mae: 1.4216\n",
      "Epoch 84/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 40.0330 - mae: 1.2154\n",
      "Epoch 85/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 23.3541 - mae: 1.0866\n",
      "Epoch 86/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 17.2546 - mae: 1.0105\n",
      "Epoch 87/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 24.8476 - mae: 1.0145\n",
      "Epoch 88/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 11.8088 - mae: 0.9688\n",
      "Epoch 89/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 10.8250 - mae: 0.9168\n",
      "Epoch 90/2000\n",
      "2018/2018 [==============================] - 0s 98us/sample - loss: 19.7933 - mae: 1.0158\n",
      "Epoch 91/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 15.1395 - mae: 0.9491\n",
      "Epoch 92/2000\n",
      "2018/2018 [==============================] - 0s 90us/sample - loss: 48.1524 - mae: 1.2867\n",
      "Epoch 93/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 63.6526 - mae: 1.2404\n",
      "Epoch 94/2000\n",
      "2018/2018 [==============================] - 0s 97us/sample - loss: 575.9527 - mae: 2.9415\n",
      "Epoch 95/2000\n",
      "2018/2018 [==============================] - 0s 113us/sample - loss: 698.0694 - mae: 4.2034\n",
      "Epoch 96/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 1076.4545 - mae: 3.5724\n",
      "Epoch 97/2000\n",
      "2018/2018 [==============================] - 0s 112us/sample - loss: 506.3223 - mae: 4.6799\n",
      "Epoch 98/2000\n",
      "2018/2018 [==============================] - 0s 137us/sample - loss: 4925.8401 - mae: 8.9004\n",
      "Epoch 99/2000\n",
      "2018/2018 [==============================] - 0s 109us/sample - loss: 679.6063 - mae: 4.0158\n",
      "Epoch 100/2000\n",
      "2018/2018 [==============================] - 0s 98us/sample - loss: 493.3601 - mae: 2.5031\n",
      "Epoch 101/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 1378.5763 - mae: 3.2718\n",
      "Epoch 102/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 86.1439 - mae: 1.6186\n",
      "Epoch 103/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 33.3734 - mae: 1.2990\n",
      "Epoch 104/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 28.6614 - mae: 1.1894\n",
      "Epoch 105/2000\n",
      "2018/2018 [==============================] - 0s 130us/sample - loss: 23.2576 - mae: 1.2103\n",
      "Epoch 106/2000\n",
      "2018/2018 [==============================] - 0s 106us/sample - loss: 21.1343 - mae: 1.1374\n",
      "Epoch 107/2000\n",
      "2018/2018 [==============================] - 0s 95us/sample - loss: 16.1085 - mae: 1.0743\n",
      "Epoch 108/2000\n",
      "2018/2018 [==============================] - 0s 96us/sample - loss: 7.8802 - mae: 0.9485\n",
      "Epoch 109/2000\n",
      "2018/2018 [==============================] - 0s 100us/sample - loss: 10.3231 - mae: 0.9687\n",
      "Epoch 110/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 15.2863 - mae: 0.9578\n",
      "Epoch 111/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 4.1723 - mae: 0.8175\n",
      "Epoch 112/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 5.6818 - mae: 0.8381\n",
      "Epoch 113/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 6.2566 - mae: 0.8216\n",
      "Epoch 114/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 3.2563 - mae: 0.7793\n",
      "Epoch 115/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 4.4494 - mae: 0.7905\n",
      "Epoch 116/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 4.4417 - mae: 0.7705\n",
      "Epoch 117/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 3.1354 - mae: 0.7474\n",
      "Epoch 118/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 2.5985 - mae: 0.7160\n",
      "Epoch 119/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 3.4233 - mae: 0.7157\n",
      "Epoch 120/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 2.5707 - mae: 0.6943\n",
      "Epoch 121/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 3.4298 - mae: 0.7139\n",
      "Epoch 122/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 3.4343 - mae: 0.7053\n",
      "Epoch 123/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 2.7841 - mae: 0.7057\n",
      "Epoch 124/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 2.6908 - mae: 0.6745\n",
      "Epoch 125/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 3.4838 - mae: 0.7687\n",
      "Epoch 126/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 2.7099 - mae: 0.6798\n",
      "Epoch 127/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 3.4588 - mae: 0.6771\n",
      "Epoch 128/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 3.2539 - mae: 0.6617\n",
      "Epoch 129/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 3.7340 - mae: 0.6555\n",
      "Epoch 130/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 76us/sample - loss: 8.8315 - mae: 0.7659\n",
      "Epoch 131/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 10.4447 - mae: 0.7244\n",
      "Epoch 132/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 23.7488 - mae: 0.7979\n",
      "Epoch 133/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 20.1276 - mae: 0.8222\n",
      "Epoch 134/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 44.8002 - mae: 1.0889\n",
      "Epoch 135/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 57.2604 - mae: 1.1434\n",
      "Epoch 136/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 103.7552 - mae: 1.1772\n",
      "Epoch 137/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 93.9459 - mae: 1.2646\n",
      "Epoch 138/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 31.5475 - mae: 0.9995\n",
      "Epoch 139/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 14.8819 - mae: 0.8806\n",
      "Epoch 140/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 25.5155 - mae: 0.9406\n",
      "Epoch 141/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 56.8358 - mae: 1.1231\n",
      "Epoch 142/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 426.6216 - mae: 2.2720\n",
      "Epoch 143/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 391.7381 - mae: 2.6782\n",
      "Epoch 144/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 88.4728 - mae: 1.7775\n",
      "Epoch 145/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 57.6567 - mae: 1.6565\n",
      "Epoch 146/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 362.8403 - mae: 3.4143\n",
      "Epoch 147/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 993.9068 - mae: 3.9846\n",
      "Epoch 148/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 156.2486 - mae: 2.3621\n",
      "Epoch 149/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 288.4489 - mae: 2.9150\n",
      "Epoch 150/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 217.1559 - mae: 2.3417\n",
      "Epoch 151/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 74.5097 - mae: 1.8387\n",
      "Epoch 152/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 60.8176 - mae: 1.6094\n",
      "Epoch 153/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 19.1738 - mae: 1.0435\n",
      "Epoch 154/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 10.8359 - mae: 0.8586\n",
      "Epoch 155/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 6.7522 - mae: 0.7692\n",
      "Epoch 156/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 5.1400 - mae: 0.7052\n",
      "Epoch 157/2000\n",
      "2018/2018 [==============================] - 0s 232us/sample - loss: 4.0328 - mae: 0.6532\n",
      "Epoch 158/2000\n",
      "2018/2018 [==============================] - 0s 65us/sample - loss: 3.2978 - mae: 0.6159\n",
      "Epoch 159/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 2.8400 - mae: 0.5872\n",
      "Epoch 160/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 2.4331 - mae: 0.5661\n",
      "Epoch 161/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 2.1615 - mae: 0.5432\n",
      "Epoch 162/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 1.9552 - mae: 0.5268\n",
      "Epoch 163/2000\n",
      "2018/2018 [==============================] - 0s 66us/sample - loss: 1.8021 - mae: 0.5103\n",
      "Epoch 164/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 1.6682 - mae: 0.4944\n",
      "Epoch 165/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 1.5438 - mae: 0.4799\n",
      "Epoch 166/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 1.4364 - mae: 0.4676\n",
      "Epoch 167/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 1.3628 - mae: 0.4581\n",
      "Epoch 168/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 1.2759 - mae: 0.4443\n",
      "Epoch 169/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 1.2218 - mae: 0.4356\n",
      "Epoch 170/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 1.1707 - mae: 0.4282\n",
      "Epoch 171/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 1.1278 - mae: 0.4189\n",
      "Epoch 172/2000\n",
      "2018/2018 [==============================] - 0s 67us/sample - loss: 1.0899 - mae: 0.4113\n",
      "Epoch 173/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 1.0695 - mae: 0.4057\n",
      "Epoch 174/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 1.0460 - mae: 0.4002\n",
      "Epoch 175/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 1.0065 - mae: 0.3923\n",
      "Epoch 176/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 1.0008 - mae: 0.3876\n",
      "Epoch 177/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 1.0163 - mae: 0.3877\n",
      "Epoch 178/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 1.0646 - mae: 0.3879\n",
      "Epoch 179/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 1.0838 - mae: 0.3841\n",
      "Epoch 180/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 1.2482 - mae: 0.3900\n",
      "Epoch 181/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 1.4472 - mae: 0.3991\n",
      "Epoch 182/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 1.3602 - mae: 0.3816\n",
      "Epoch 183/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 2.0779 - mae: 0.3911\n",
      "Epoch 184/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 1.9695 - mae: 0.3839\n",
      "Epoch 185/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 2.7813 - mae: 0.4022\n",
      "Epoch 186/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 6.3446 - mae: 0.4989\n",
      "Epoch 187/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 4.9035 - mae: 0.4403\n",
      "Epoch 188/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 4.8424 - mae: 0.4598\n",
      "Epoch 189/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.9782 - mae: 0.3616\n",
      "Epoch 190/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.8463 - mae: 0.3304\n",
      "Epoch 191/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.8425 - mae: 0.3234\n",
      "Epoch 192/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.8512 - mae: 0.3200\n",
      "Epoch 193/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.9127 - mae: 0.3141\n",
      "Epoch 194/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 1.1257 - mae: 0.3269\n",
      "Epoch 195/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 1.8258 - mae: 0.3383\n",
      "Epoch 196/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 2.7312 - mae: 0.3413\n",
      "Epoch 197/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 6.6935 - mae: 0.3792\n",
      "Epoch 198/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 3.2134 - mae: 0.3941\n",
      "Epoch 199/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 1.5456 - mae: 0.3521\n",
      "Epoch 200/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 1.3675 - mae: 0.3410\n",
      "Epoch 201/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.8678 - mae: 0.3176\n",
      "Epoch 202/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.8163 - mae: 0.3036\n",
      "Epoch 203/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.7922 - mae: 0.2950\n",
      "Epoch 204/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.7789 - mae: 0.2925\n",
      "Epoch 205/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.7740 - mae: 0.2914\n",
      "Epoch 206/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.7846 - mae: 0.2896\n",
      "Epoch 207/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.7749 - mae: 0.2884\n",
      "Epoch 208/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.8178 - mae: 0.2901\n",
      "Epoch 209/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.8991 - mae: 0.2993\n",
      "Epoch 210/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 1.1124 - mae: 0.3064\n",
      "Epoch 211/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 1.4149 - mae: 0.3148\n",
      "Epoch 212/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.8452 - mae: 0.2857\n",
      "Epoch 213/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 1.0174 - mae: 0.2955\n",
      "Epoch 214/2000\n",
      "2018/2018 [==============================] - 0s 113us/sample - loss: 1.3959 - mae: 0.3119\n",
      "Epoch 215/2000\n",
      "2018/2018 [==============================] - 0s 107us/sample - loss: 5.1438 - mae: 0.4331\n",
      "Epoch 216/2000\n",
      "2018/2018 [==============================] - 0s 101us/sample - loss: 6.4139 - mae: 0.4879\n",
      "Epoch 217/2000\n",
      "2018/2018 [==============================] - 0s 106us/sample - loss: 1.3743 - mae: 0.3505\n",
      "Epoch 218/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 1.1647 - mae: 0.3330\n",
      "Epoch 219/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 1.1912 - mae: 0.3303\n",
      "Epoch 220/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 1.2168 - mae: 0.3436\n",
      "Epoch 221/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 1.1697 - mae: 0.3333\n",
      "Epoch 222/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 1.3126 - mae: 0.3551\n",
      "Epoch 223/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 1.7703 - mae: 0.3645\n",
      "Epoch 224/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 1.7198 - mae: 0.3645\n",
      "Epoch 225/2000\n",
      "2018/2018 [==============================] - 0s 98us/sample - loss: 2.6630 - mae: 0.4223\n",
      "Epoch 226/2000\n",
      "2018/2018 [==============================] - 0s 124us/sample - loss: 2.3589 - mae: 0.3736\n",
      "Epoch 227/2000\n",
      "2018/2018 [==============================] - 0s 155us/sample - loss: 1.5417 - mae: 0.3461\n",
      "Epoch 228/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.7988 - mae: 0.2766\n",
      "Epoch 229/2000\n",
      "2018/2018 [==============================] - 0s 94us/sample - loss: 0.6783 - mae: 0.2650\n",
      "Epoch 230/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.6323 - mae: 0.2511\n",
      "Epoch 231/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.6055 - mae: 0.2418\n",
      "Epoch 232/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.6029 - mae: 0.2414\n",
      "Epoch 233/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.5980 - mae: 0.2368\n",
      "Epoch 234/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.5945 - mae: 0.2349\n",
      "Epoch 235/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.5918 - mae: 0.2335\n",
      "Epoch 236/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.5918 - mae: 0.2335\n",
      "Epoch 237/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.5910 - mae: 0.2326\n",
      "Epoch 238/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.5934 - mae: 0.2313\n",
      "Epoch 239/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.5926 - mae: 0.2313\n",
      "Epoch 240/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.5882 - mae: 0.2311\n",
      "Epoch 241/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.6067 - mae: 0.2351\n",
      "Epoch 242/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.6602 - mae: 0.2451\n",
      "Epoch 243/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.6119 - mae: 0.2368\n",
      "Epoch 244/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.6200 - mae: 0.2377\n",
      "Epoch 245/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.6233 - mae: 0.2408\n",
      "Epoch 246/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.6151 - mae: 0.2348\n",
      "Epoch 247/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.6388 - mae: 0.2406\n",
      "Epoch 248/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.6217 - mae: 0.2364\n",
      "Epoch 249/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.6531 - mae: 0.2337\n",
      "Epoch 250/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.6030 - mae: 0.2323\n",
      "Epoch 251/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.5728 - mae: 0.2251\n",
      "Epoch 252/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.5666 - mae: 0.2221\n",
      "Epoch 253/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.5751 - mae: 0.2246\n",
      "Epoch 254/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.6144 - mae: 0.2324\n",
      "Epoch 255/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.7084 - mae: 0.2374\n",
      "Epoch 256/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.9110 - mae: 0.2756\n",
      "Epoch 257/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 1.3066 - mae: 0.3102\n",
      "Epoch 258/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 1.0265 - mae: 0.2668\n",
      "Epoch 259/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.7220 - mae: 0.2912\n",
      "Epoch 260/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.5658 - mae: 0.2285\n",
      "Epoch 261/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.5576 - mae: 0.2210\n",
      "Epoch 262/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.5469 - mae: 0.2131\n",
      "Epoch 263/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.5506 - mae: 0.2137\n",
      "Epoch 264/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.5570 - mae: 0.2161\n",
      "Epoch 265/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.5483 - mae: 0.2137\n",
      "Epoch 266/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5547 - mae: 0.2161\n",
      "Epoch 267/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5464 - mae: 0.2135\n",
      "Epoch 268/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.5449 - mae: 0.2098\n",
      "Epoch 269/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5467 - mae: 0.2112\n",
      "Epoch 270/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5549 - mae: 0.2172\n",
      "Epoch 271/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.5394 - mae: 0.2096\n",
      "Epoch 272/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.7366 - mae: 0.2352\n",
      "Epoch 273/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.5540 - mae: 0.2177\n",
      "Epoch 274/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.5598 - mae: 0.2182\n",
      "Epoch 275/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5518 - mae: 0.2160\n",
      "Epoch 276/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5726 - mae: 0.2220\n",
      "Epoch 277/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5798 - mae: 0.2185\n",
      "Epoch 278/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.6249 - mae: 0.2272\n",
      "Epoch 279/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5727 - mae: 0.2221\n",
      "Epoch 280/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5558 - mae: 0.2136\n",
      "Epoch 281/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5335 - mae: 0.2112\n",
      "Epoch 282/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.5535 - mae: 0.2213\n",
      "Epoch 283/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.5198 - mae: 0.2048\n",
      "Epoch 284/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.5210 - mae: 0.2061\n",
      "Epoch 285/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5227 - mae: 0.2055\n",
      "Epoch 286/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.5210 - mae: 0.2057\n",
      "Epoch 287/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.5141 - mae: 0.1995\n",
      "Epoch 288/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5119 - mae: 0.2013\n",
      "Epoch 289/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.5138 - mae: 0.2026\n",
      "Epoch 290/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.5119 - mae: 0.2022\n",
      "Epoch 291/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5095 - mae: 0.2021\n",
      "Epoch 292/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.5047 - mae: 0.1990\n",
      "Epoch 293/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.5041 - mae: 0.1997\n",
      "Epoch 294/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.5020 - mae: 0.1992\n",
      "Epoch 295/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.5094 - mae: 0.2027\n",
      "Epoch 296/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.5075 - mae: 0.1995\n",
      "Epoch 297/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4946 - mae: 0.1952\n",
      "Epoch 298/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4947 - mae: 0.1960\n",
      "Epoch 299/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4923 - mae: 0.1961\n",
      "Epoch 300/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4911 - mae: 0.1957\n",
      "Epoch 301/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4940 - mae: 0.1983\n",
      "Epoch 302/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.4874 - mae: 0.1948\n",
      "Epoch 303/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.5136 - mae: 0.2086\n",
      "Epoch 304/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.4888 - mae: 0.1991\n",
      "Epoch 305/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.4877 - mae: 0.1986\n",
      "Epoch 306/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5110 - mae: 0.2161\n",
      "Epoch 307/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5416 - mae: 0.2316\n",
      "Epoch 308/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5383 - mae: 0.2196\n",
      "Epoch 309/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.5143 - mae: 0.2178\n",
      "Epoch 310/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.4851 - mae: 0.2008\n",
      "Epoch 311/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4889 - mae: 0.2050\n",
      "Epoch 312/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4779 - mae: 0.2009\n",
      "Epoch 313/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.5431 - mae: 0.2340\n",
      "Epoch 314/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.4973 - mae: 0.2204\n",
      "Epoch 315/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.4985 - mae: 0.2162\n",
      "Epoch 316/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5866 - mae: 0.2698\n",
      "Epoch 317/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.6524 - mae: 0.2801\n",
      "Epoch 318/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.5943 - mae: 0.2542\n",
      "Epoch 319/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4945 - mae: 0.2260\n",
      "Epoch 320/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4723 - mae: 0.2126\n",
      "Epoch 321/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.4704 - mae: 0.2120\n",
      "Epoch 322/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4632 - mae: 0.2043\n",
      "Epoch 323/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.4632 - mae: 0.2074\n",
      "Epoch 324/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.4962 - mae: 0.2213\n",
      "Epoch 325/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.4555 - mae: 0.2025\n",
      "Epoch 326/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.4508 - mae: 0.2001\n",
      "Epoch 327/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.4691 - mae: 0.2143\n",
      "Epoch 328/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.7213 - mae: 0.2756\n",
      "Epoch 329/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.9401 - mae: 0.3372\n",
      "Epoch 330/2000\n",
      "2018/2018 [==============================] - 0s 119us/sample - loss: 1.2074 - mae: 0.3667\n",
      "Epoch 331/2000\n",
      "2018/2018 [==============================] - 0s 99us/sample - loss: 1.1420 - mae: 0.3134\n",
      "Epoch 332/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.8774 - mae: 0.2663\n",
      "Epoch 333/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 1.4639 - mae: 0.3272\n",
      "Epoch 334/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.7839 - mae: 0.2683\n",
      "Epoch 335/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.4891 - mae: 0.2317\n",
      "Epoch 336/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.4618 - mae: 0.2253\n",
      "Epoch 337/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.4708 - mae: 0.2283\n",
      "Epoch 338/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.4595 - mae: 0.2239\n",
      "Epoch 339/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.4474 - mae: 0.2208\n",
      "Epoch 340/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.4413 - mae: 0.2187\n",
      "Epoch 341/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.4391 - mae: 0.2179\n",
      "Epoch 342/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.4371 - mae: 0.2170\n",
      "Epoch 343/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.4349 - mae: 0.2166\n",
      "Epoch 344/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.4334 - mae: 0.2165\n",
      "Epoch 345/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.4328 - mae: 0.2176\n",
      "Epoch 346/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.4302 - mae: 0.2167\n",
      "Epoch 347/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.4320 - mae: 0.2172\n",
      "Epoch 348/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.4304 - mae: 0.2178\n",
      "Epoch 349/2000\n",
      "2018/2018 [==============================] - 0s 91us/sample - loss: 0.4310 - mae: 0.2200\n",
      "Epoch 350/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.4230 - mae: 0.2159\n",
      "Epoch 351/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.4203 - mae: 0.2143\n",
      "Epoch 352/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.4193 - mae: 0.2155\n",
      "Epoch 353/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.4195 - mae: 0.2165\n",
      "Epoch 354/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.4174 - mae: 0.2163\n",
      "Epoch 355/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.4175 - mae: 0.2160\n",
      "Epoch 356/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.4122 - mae: 0.2146\n",
      "Epoch 357/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.4143 - mae: 0.2172\n",
      "Epoch 358/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.4104 - mae: 0.2171\n",
      "Epoch 359/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.4323 - mae: 0.2243\n",
      "Epoch 360/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.4110 - mae: 0.2204\n",
      "Epoch 361/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.4019 - mae: 0.2145\n",
      "Epoch 362/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.3994 - mae: 0.2136\n",
      "Epoch 363/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.3976 - mae: 0.2133\n",
      "Epoch 364/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.3957 - mae: 0.2133\n",
      "Epoch 365/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3934 - mae: 0.2125\n",
      "Epoch 366/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.3909 - mae: 0.2124\n",
      "Epoch 367/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3888 - mae: 0.2121\n",
      "Epoch 368/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3869 - mae: 0.2119\n",
      "Epoch 369/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3995 - mae: 0.2174\n",
      "Epoch 370/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.4047 - mae: 0.2208\n",
      "Epoch 371/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.3892 - mae: 0.2175\n",
      "Epoch 372/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.3830 - mae: 0.2154\n",
      "Epoch 373/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3799 - mae: 0.2143\n",
      "Epoch 374/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3768 - mae: 0.2145\n",
      "Epoch 375/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3868 - mae: 0.2177\n",
      "Epoch 376/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3836 - mae: 0.2169\n",
      "Epoch 377/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4270 - mae: 0.2301\n",
      "Epoch 378/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.4631 - mae: 0.2367\n",
      "Epoch 379/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3897 - mae: 0.2255\n",
      "Epoch 380/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.4225 - mae: 0.2261\n",
      "Epoch 381/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.3631 - mae: 0.2191\n",
      "Epoch 382/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.3640 - mae: 0.2187\n",
      "Epoch 383/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.4225 - mae: 0.2304\n",
      "Epoch 384/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.3580 - mae: 0.2199\n",
      "Epoch 385/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3588 - mae: 0.2197\n",
      "Epoch 386/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3509 - mae: 0.2171\n",
      "Epoch 387/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3512 - mae: 0.2183\n",
      "Epoch 388/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3535 - mae: 0.2193\n",
      "Epoch 389/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3436 - mae: 0.2163\n",
      "Epoch 390/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3416 - mae: 0.2164\n",
      "Epoch 391/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.3386 - mae: 0.2152\n",
      "Epoch 392/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.3367 - mae: 0.2147\n",
      "Epoch 393/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.3335 - mae: 0.2145\n",
      "Epoch 394/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.3315 - mae: 0.2143\n",
      "Epoch 395/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3283 - mae: 0.2131\n",
      "Epoch 396/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3256 - mae: 0.2129\n",
      "Epoch 397/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3234 - mae: 0.2126\n",
      "Epoch 398/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3208 - mae: 0.2124\n",
      "Epoch 399/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3195 - mae: 0.2136\n",
      "Epoch 400/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3178 - mae: 0.2133\n",
      "Epoch 401/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3278 - mae: 0.2170\n",
      "Epoch 402/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.3629 - mae: 0.2243\n",
      "Epoch 403/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.3251 - mae: 0.2191\n",
      "Epoch 404/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.3554 - mae: 0.2191\n",
      "Epoch 405/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3574 - mae: 0.2258\n",
      "Epoch 406/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3243 - mae: 0.2218\n",
      "Epoch 407/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.3029 - mae: 0.2142\n",
      "Epoch 408/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3028 - mae: 0.2147\n",
      "Epoch 409/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3023 - mae: 0.2144\n",
      "Epoch 410/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.3063 - mae: 0.2157\n",
      "Epoch 411/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.2985 - mae: 0.2141\n",
      "Epoch 412/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.2889 - mae: 0.2104\n",
      "Epoch 413/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.2818 - mae: 0.2060\n",
      "Epoch 414/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.2782 - mae: 0.2039\n",
      "Epoch 415/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.2755 - mae: 0.2028\n",
      "Epoch 416/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.2728 - mae: 0.2021\n",
      "Epoch 417/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.2696 - mae: 0.2008\n",
      "Epoch 418/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.2667 - mae: 0.1999\n",
      "Epoch 419/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.2647 - mae: 0.1999\n",
      "Epoch 420/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.2619 - mae: 0.1993\n",
      "Epoch 421/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.2582 - mae: 0.1980\n",
      "Epoch 422/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.2563 - mae: 0.1972\n",
      "Epoch 423/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.2521 - mae: 0.1951\n",
      "Epoch 424/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.2497 - mae: 0.1946\n",
      "Epoch 425/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.2473 - mae: 0.1944\n",
      "Epoch 426/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.2440 - mae: 0.1936\n",
      "Epoch 427/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.2403 - mae: 0.1909\n",
      "Epoch 428/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.2383 - mae: 0.1909\n",
      "Epoch 429/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.2340 - mae: 0.1889\n",
      "Epoch 430/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.2313 - mae: 0.1881\n",
      "Epoch 431/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.2308 - mae: 0.1892\n",
      "Epoch 432/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.2273 - mae: 0.1878\n",
      "Epoch 433/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.2267 - mae: 0.1885\n",
      "Epoch 434/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.2247 - mae: 0.1907\n",
      "Epoch 435/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.2189 - mae: 0.1872\n",
      "Epoch 436/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.2155 - mae: 0.1859\n",
      "Epoch 437/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.2127 - mae: 0.1855\n",
      "Epoch 438/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.2101 - mae: 0.1842\n",
      "Epoch 439/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.2092 - mae: 0.1859\n",
      "Epoch 440/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.2095 - mae: 0.1867\n",
      "Epoch 441/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.2029 - mae: 0.1840\n",
      "Epoch 442/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.2010 - mae: 0.1837\n",
      "Epoch 443/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.2022 - mae: 0.1864\n",
      "Epoch 444/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.2024 - mae: 0.1877\n",
      "Epoch 445/2000\n",
      "2018/2018 [==============================] - 0s 113us/sample - loss: 0.1935 - mae: 0.1840\n",
      "Epoch 446/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.1906 - mae: 0.1838\n",
      "Epoch 447/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.1888 - mae: 0.1836\n",
      "Epoch 448/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.1884 - mae: 0.1842\n",
      "Epoch 449/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.1841 - mae: 0.1826\n",
      "Epoch 450/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.1807 - mae: 0.1820\n",
      "Epoch 451/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.1775 - mae: 0.1809\n",
      "Epoch 452/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.1746 - mae: 0.1808\n",
      "Epoch 453/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.1729 - mae: 0.1812\n",
      "Epoch 454/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.1702 - mae: 0.1805\n",
      "Epoch 455/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.1689 - mae: 0.1817\n",
      "Epoch 456/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.1656 - mae: 0.1808\n",
      "Epoch 457/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.1632 - mae: 0.1802\n",
      "Epoch 458/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.1609 - mae: 0.1802\n",
      "Epoch 459/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.1584 - mae: 0.1790\n",
      "Epoch 460/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.1556 - mae: 0.1781\n",
      "Epoch 461/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.1533 - mae: 0.1786\n",
      "Epoch 462/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.1514 - mae: 0.1787\n",
      "Epoch 463/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1529 - mae: 0.1816\n",
      "Epoch 464/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.1492 - mae: 0.1812\n",
      "Epoch 465/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.1472 - mae: 0.1823\n",
      "Epoch 466/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.1453 - mae: 0.1825\n",
      "Epoch 467/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.1428 - mae: 0.1826\n",
      "Epoch 468/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.1431 - mae: 0.1852\n",
      "Epoch 469/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.1394 - mae: 0.1835\n",
      "Epoch 470/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.1378 - mae: 0.1827\n",
      "Epoch 471/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.1352 - mae: 0.1823\n",
      "Epoch 472/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.1321 - mae: 0.1827\n",
      "Epoch 473/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1300 - mae: 0.1813\n",
      "Epoch 474/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1268 - mae: 0.1800\n",
      "Epoch 475/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.1253 - mae: 0.1808\n",
      "Epoch 476/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.1226 - mae: 0.1777\n",
      "Epoch 477/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1205 - mae: 0.1777\n",
      "Epoch 478/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.1224 - mae: 0.1792\n",
      "Epoch 479/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.1166 - mae: 0.1751\n",
      "Epoch 480/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.1137 - mae: 0.1748\n",
      "Epoch 481/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.1129 - mae: 0.1757\n",
      "Epoch 482/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.1107 - mae: 0.1758\n",
      "Epoch 483/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.1074 - mae: 0.1728\n",
      "Epoch 484/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.1054 - mae: 0.1720\n",
      "Epoch 485/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.1036 - mae: 0.1723\n",
      "Epoch 486/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.1017 - mae: 0.1715\n",
      "Epoch 487/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0994 - mae: 0.1702\n",
      "Epoch 488/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0973 - mae: 0.1686\n",
      "Epoch 489/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0952 - mae: 0.1692\n",
      "Epoch 490/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0934 - mae: 0.1683\n",
      "Epoch 491/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0918 - mae: 0.1676\n",
      "Epoch 492/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0907 - mae: 0.1685\n",
      "Epoch 493/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0883 - mae: 0.1661\n",
      "Epoch 494/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0870 - mae: 0.1666\n",
      "Epoch 495/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0852 - mae: 0.1665\n",
      "Epoch 496/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0837 - mae: 0.1658\n",
      "Epoch 497/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0822 - mae: 0.1658\n",
      "Epoch 498/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0810 - mae: 0.1660\n",
      "Epoch 499/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0949 - mae: 0.1855\n",
      "Epoch 500/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0838 - mae: 0.1777\n",
      "Epoch 501/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0809 - mae: 0.1734\n",
      "Epoch 502/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0789 - mae: 0.1705\n",
      "Epoch 503/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0771 - mae: 0.1691\n",
      "Epoch 504/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0754 - mae: 0.1690\n",
      "Epoch 505/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0738 - mae: 0.1668\n",
      "Epoch 506/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0722 - mae: 0.1660\n",
      "Epoch 507/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0717 - mae: 0.1672\n",
      "Epoch 508/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0699 - mae: 0.1654\n",
      "Epoch 509/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0687 - mae: 0.1653\n",
      "Epoch 510/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0675 - mae: 0.1650\n",
      "Epoch 511/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0669 - mae: 0.1664\n",
      "Epoch 512/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0657 - mae: 0.1664\n",
      "Epoch 513/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0646 - mae: 0.1649\n",
      "Epoch 514/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0632 - mae: 0.1637\n",
      "Epoch 515/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0627 - mae: 0.1648\n",
      "Epoch 516/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0613 - mae: 0.1632\n",
      "Epoch 517/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0606 - mae: 0.1635\n",
      "Epoch 518/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0598 - mae: 0.1639\n",
      "Epoch 519/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0590 - mae: 0.1638\n",
      "Epoch 520/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0580 - mae: 0.1633\n",
      "Epoch 521/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0572 - mae: 0.1622\n",
      "Epoch 522/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0566 - mae: 0.1627\n",
      "Epoch 523/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0557 - mae: 0.1623\n",
      "Epoch 524/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0553 - mae: 0.1630\n",
      "Epoch 525/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0544 - mae: 0.1619\n",
      "Epoch 526/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0538 - mae: 0.1620\n",
      "Epoch 527/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0532 - mae: 0.1621\n",
      "Epoch 528/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0522 - mae: 0.1614\n",
      "Epoch 529/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0522 - mae: 0.1625\n",
      "Epoch 530/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0516 - mae: 0.1632\n",
      "Epoch 531/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0505 - mae: 0.1627\n",
      "Epoch 532/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0498 - mae: 0.1611\n",
      "Epoch 533/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0492 - mae: 0.1607\n",
      "Epoch 534/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0487 - mae: 0.1604\n",
      "Epoch 535/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0484 - mae: 0.1599\n",
      "Epoch 536/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0485 - mae: 0.1611\n",
      "Epoch 537/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0477 - mae: 0.1599\n",
      "Epoch 538/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0475 - mae: 0.1606\n",
      "Epoch 539/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0470 - mae: 0.1598\n",
      "Epoch 540/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0466 - mae: 0.1595\n",
      "Epoch 541/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0464 - mae: 0.1600\n",
      "Epoch 542/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0463 - mae: 0.1605\n",
      "Epoch 543/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0457 - mae: 0.1595\n",
      "Epoch 544/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0455 - mae: 0.1595\n",
      "Epoch 545/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0452 - mae: 0.1588\n",
      "Epoch 546/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0448 - mae: 0.1587\n",
      "Epoch 547/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0446 - mae: 0.1586\n",
      "Epoch 548/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0449 - mae: 0.1593\n",
      "Epoch 549/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0447 - mae: 0.1599\n",
      "Epoch 550/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0444 - mae: 0.1602\n",
      "Epoch 551/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0437 - mae: 0.1579\n",
      "Epoch 552/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0435 - mae: 0.1583\n",
      "Epoch 553/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0439 - mae: 0.1599\n",
      "Epoch 554/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0440 - mae: 0.1600\n",
      "Epoch 555/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0431 - mae: 0.1576\n",
      "Epoch 556/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0430 - mae: 0.1583\n",
      "Epoch 557/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0437 - mae: 0.1607\n",
      "Epoch 558/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0427 - mae: 0.1584\n",
      "Epoch 559/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0430 - mae: 0.1588\n",
      "Epoch 560/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0431 - mae: 0.1598\n",
      "Epoch 561/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0423 - mae: 0.1580\n",
      "Epoch 562/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0423 - mae: 0.1579\n",
      "Epoch 563/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0423 - mae: 0.1582\n",
      "Epoch 564/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0417 - mae: 0.1565\n",
      "Epoch 565/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0417 - mae: 0.1564\n",
      "Epoch 566/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0414 - mae: 0.1553\n",
      "Epoch 567/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0417 - mae: 0.1564\n",
      "Epoch 568/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0411 - mae: 0.1557\n",
      "Epoch 569/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0510 - mae: 0.1609\n",
      "Epoch 570/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0426 - mae: 0.1560\n",
      "Epoch 571/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0423 - mae: 0.1567\n",
      "Epoch 572/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0422 - mae: 0.1558\n",
      "Epoch 573/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0412 - mae: 0.1534\n",
      "Epoch 574/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0419 - mae: 0.1558\n",
      "Epoch 575/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0409 - mae: 0.1534\n",
      "Epoch 576/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0414 - mae: 0.1551\n",
      "Epoch 577/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0411 - mae: 0.1546\n",
      "Epoch 578/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0406 - mae: 0.1534\n",
      "Epoch 579/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0405 - mae: 0.1529\n",
      "Epoch 580/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0403 - mae: 0.1530\n",
      "Epoch 581/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0419 - mae: 0.1548\n",
      "Epoch 582/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0402 - mae: 0.1531\n",
      "Epoch 583/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0401 - mae: 0.1517\n",
      "Epoch 584/2000\n",
      "2018/2018 [==============================] - 0s 91us/sample - loss: 0.0400 - mae: 0.1511\n",
      "Epoch 585/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.0409 - mae: 0.1543\n",
      "Epoch 586/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0396 - mae: 0.1508\n",
      "Epoch 587/2000\n",
      "2018/2018 [==============================] - 0s 93us/sample - loss: 0.0396 - mae: 0.1504\n",
      "Epoch 588/2000\n",
      "2018/2018 [==============================] - 0s 95us/sample - loss: 0.0395 - mae: 0.1512\n",
      "Epoch 589/2000\n",
      "2018/2018 [==============================] - 0s 92us/sample - loss: 0.0394 - mae: 0.1508\n",
      "Epoch 590/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0398 - mae: 0.1507\n",
      "Epoch 591/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.0400 - mae: 0.1528\n",
      "Epoch 592/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0392 - mae: 0.1503\n",
      "Epoch 593/2000\n",
      "2018/2018 [==============================] - 0s 94us/sample - loss: 0.0391 - mae: 0.1497\n",
      "Epoch 594/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.0392 - mae: 0.1509\n",
      "Epoch 595/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0389 - mae: 0.1491\n",
      "Epoch 596/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0383 - mae: 0.1483\n",
      "Epoch 597/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0390 - mae: 0.1494\n",
      "Epoch 598/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 93us/sample - loss: 0.0385 - mae: 0.1486\n",
      "Epoch 599/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.0388 - mae: 0.1484\n",
      "Epoch 600/2000\n",
      "2018/2018 [==============================] - 0s 94us/sample - loss: 0.0386 - mae: 0.1485\n",
      "Epoch 601/2000\n",
      "2018/2018 [==============================] - 0s 92us/sample - loss: 0.0381 - mae: 0.1476\n",
      "Epoch 602/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0386 - mae: 0.1496\n",
      "Epoch 603/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0385 - mae: 0.1495\n",
      "Epoch 604/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0376 - mae: 0.1470\n",
      "Epoch 605/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0378 - mae: 0.1471\n",
      "Epoch 606/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0376 - mae: 0.1461\n",
      "Epoch 607/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0375 - mae: 0.1462\n",
      "Epoch 608/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0377 - mae: 0.1473\n",
      "Epoch 609/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0380 - mae: 0.1480\n",
      "Epoch 610/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0375 - mae: 0.1461\n",
      "Epoch 611/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0373 - mae: 0.1451\n",
      "Epoch 612/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0368 - mae: 0.1456\n",
      "Epoch 613/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0367 - mae: 0.1445\n",
      "Epoch 614/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0367 - mae: 0.1453\n",
      "Epoch 615/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0362 - mae: 0.1444\n",
      "Epoch 616/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0364 - mae: 0.1446\n",
      "Epoch 617/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0370 - mae: 0.1456\n",
      "Epoch 618/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0384 - mae: 0.1450\n",
      "Epoch 619/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0390 - mae: 0.1485\n",
      "Epoch 620/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0364 - mae: 0.1441\n",
      "Epoch 621/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0371 - mae: 0.1473\n",
      "Epoch 622/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0359 - mae: 0.1443\n",
      "Epoch 623/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0364 - mae: 0.1441\n",
      "Epoch 624/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0358 - mae: 0.1441\n",
      "Epoch 625/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0359 - mae: 0.1442\n",
      "Epoch 626/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0354 - mae: 0.1426\n",
      "Epoch 627/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0363 - mae: 0.1452\n",
      "Epoch 628/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0355 - mae: 0.1428\n",
      "Epoch 629/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0356 - mae: 0.1430\n",
      "Epoch 630/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0359 - mae: 0.1429\n",
      "Epoch 631/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0360 - mae: 0.1452\n",
      "Epoch 632/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0346 - mae: 0.1410\n",
      "Epoch 633/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0346 - mae: 0.1406\n",
      "Epoch 634/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0343 - mae: 0.1409\n",
      "Epoch 635/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0356 - mae: 0.1437\n",
      "Epoch 636/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0351 - mae: 0.1429\n",
      "Epoch 637/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0359 - mae: 0.1448\n",
      "Epoch 638/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0351 - mae: 0.1424\n",
      "Epoch 639/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0349 - mae: 0.1427\n",
      "Epoch 640/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0340 - mae: 0.1404\n",
      "Epoch 641/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0356 - mae: 0.1443\n",
      "Epoch 642/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0361 - mae: 0.1459\n",
      "Epoch 643/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0347 - mae: 0.1425\n",
      "Epoch 644/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0342 - mae: 0.1406\n",
      "Epoch 645/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0349 - mae: 0.1415\n",
      "Epoch 646/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0356 - mae: 0.1440\n",
      "Epoch 647/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0344 - mae: 0.1414\n",
      "Epoch 648/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0341 - mae: 0.1407\n",
      "Epoch 649/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0344 - mae: 0.1422\n",
      "Epoch 650/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0354 - mae: 0.1434\n",
      "Epoch 651/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0343 - mae: 0.1413\n",
      "Epoch 652/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0336 - mae: 0.1400\n",
      "Epoch 653/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0331 - mae: 0.1383\n",
      "Epoch 654/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0341 - mae: 0.1418\n",
      "Epoch 655/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0346 - mae: 0.1424\n",
      "Epoch 656/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0344 - mae: 0.1421\n",
      "Epoch 657/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0332 - mae: 0.1391\n",
      "Epoch 658/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0328 - mae: 0.1384\n",
      "Epoch 659/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0331 - mae: 0.1387\n",
      "Epoch 660/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0335 - mae: 0.1408\n",
      "Epoch 661/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0326 - mae: 0.1377\n",
      "Epoch 662/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0323 - mae: 0.1375\n",
      "Epoch 663/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0325 - mae: 0.1372\n",
      "Epoch 664/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0326 - mae: 0.1375\n",
      "Epoch 665/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0319 - mae: 0.1366\n",
      "Epoch 666/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0329 - mae: 0.1381\n",
      "Epoch 667/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0323 - mae: 0.1370\n",
      "Epoch 668/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0319 - mae: 0.1366\n",
      "Epoch 669/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0325 - mae: 0.1374\n",
      "Epoch 670/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0327 - mae: 0.1385\n",
      "Epoch 671/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0342 - mae: 0.1428\n",
      "Epoch 672/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0320 - mae: 0.1373\n",
      "Epoch 673/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0316 - mae: 0.1367\n",
      "Epoch 674/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0316 - mae: 0.1360\n",
      "Epoch 675/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0321 - mae: 0.1376\n",
      "Epoch 676/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0320 - mae: 0.1365\n",
      "Epoch 677/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0320 - mae: 0.1365\n",
      "Epoch 678/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0318 - mae: 0.1362\n",
      "Epoch 679/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0317 - mae: 0.1365\n",
      "Epoch 680/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0341 - mae: 0.1409\n",
      "Epoch 681/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0345 - mae: 0.1398\n",
      "Epoch 682/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0323 - mae: 0.1369\n",
      "Epoch 683/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0318 - mae: 0.1358\n",
      "Epoch 684/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0360 - mae: 0.1453\n",
      "Epoch 685/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0343 - mae: 0.1408\n",
      "Epoch 686/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0337 - mae: 0.1411\n",
      "Epoch 687/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0331 - mae: 0.1393\n",
      "Epoch 688/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0319 - mae: 0.1357\n",
      "Epoch 689/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0314 - mae: 0.1352\n",
      "Epoch 690/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0317 - mae: 0.1351\n",
      "Epoch 691/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0312 - mae: 0.1342\n",
      "Epoch 692/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0313 - mae: 0.1342\n",
      "Epoch 693/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0306 - mae: 0.1333\n",
      "Epoch 694/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0313 - mae: 0.1343\n",
      "Epoch 695/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0301 - mae: 0.1322\n",
      "Epoch 696/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0303 - mae: 0.1330\n",
      "Epoch 697/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0309 - mae: 0.1341\n",
      "Epoch 698/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0314 - mae: 0.1345\n",
      "Epoch 699/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0359 - mae: 0.1456\n",
      "Epoch 700/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0326 - mae: 0.1391\n",
      "Epoch 701/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0320 - mae: 0.1376\n",
      "Epoch 702/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0321 - mae: 0.1375\n",
      "Epoch 703/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0313 - mae: 0.1353\n",
      "Epoch 704/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0303 - mae: 0.1323\n",
      "Epoch 705/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0302 - mae: 0.1318\n",
      "Epoch 706/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0296 - mae: 0.1316\n",
      "Epoch 707/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0298 - mae: 0.1313\n",
      "Epoch 708/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0298 - mae: 0.1315\n",
      "Epoch 709/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0300 - mae: 0.1322\n",
      "Epoch 710/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0304 - mae: 0.1327\n",
      "Epoch 711/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0296 - mae: 0.1312\n",
      "Epoch 712/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0289 - mae: 0.1299\n",
      "Epoch 713/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0308 - mae: 0.1332\n",
      "Epoch 714/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0314 - mae: 0.1357\n",
      "Epoch 715/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0294 - mae: 0.1306\n",
      "Epoch 716/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0291 - mae: 0.1302\n",
      "Epoch 717/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0295 - mae: 0.1308\n",
      "Epoch 718/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0302 - mae: 0.1327\n",
      "Epoch 719/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0295 - mae: 0.1304\n",
      "Epoch 720/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0285 - mae: 0.1282\n",
      "Epoch 721/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0283 - mae: 0.1277\n",
      "Epoch 722/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0286 - mae: 0.1283\n",
      "Epoch 723/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0305 - mae: 0.1332\n",
      "Epoch 724/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0300 - mae: 0.1315\n",
      "Epoch 725/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0290 - mae: 0.1297\n",
      "Epoch 726/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0287 - mae: 0.1284\n",
      "Epoch 727/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0295 - mae: 0.1297\n",
      "Epoch 728/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0300 - mae: 0.1313\n",
      "Epoch 729/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0288 - mae: 0.1293\n",
      "Epoch 730/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0316 - mae: 0.1363\n",
      "Epoch 731/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0312 - mae: 0.1355\n",
      "Epoch 732/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0283 - mae: 0.1284\n",
      "Epoch 733/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0286 - mae: 0.1286\n",
      "Epoch 734/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0285 - mae: 0.1284\n",
      "Epoch 735/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0283 - mae: 0.1278\n",
      "Epoch 736/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0296 - mae: 0.1315\n",
      "Epoch 737/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0291 - mae: 0.1295\n",
      "Epoch 738/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0350 - mae: 0.1438\n",
      "Epoch 739/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0311 - mae: 0.1356\n",
      "Epoch 740/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0305 - mae: 0.1343\n",
      "Epoch 741/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0285 - mae: 0.1281\n",
      "Epoch 742/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0279 - mae: 0.1274\n",
      "Epoch 743/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0284 - mae: 0.1282\n",
      "Epoch 744/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0294 - mae: 0.1273\n",
      "Epoch 745/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0335 - mae: 0.1350\n",
      "Epoch 746/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0319 - mae: 0.1360\n",
      "Epoch 747/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0300 - mae: 0.1321\n",
      "Epoch 748/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0279 - mae: 0.1272\n",
      "Epoch 749/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0275 - mae: 0.1255\n",
      "Epoch 750/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0285 - mae: 0.1287\n",
      "Epoch 751/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0278 - mae: 0.1266\n",
      "Epoch 752/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0270 - mae: 0.1245\n",
      "Epoch 753/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0275 - mae: 0.1255\n",
      "Epoch 754/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0278 - mae: 0.1253\n",
      "Epoch 755/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0276 - mae: 0.1266\n",
      "Epoch 756/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0292 - mae: 0.1302\n",
      "Epoch 757/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0275 - mae: 0.1263\n",
      "Epoch 758/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0325 - mae: 0.1290\n",
      "Epoch 759/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0287 - mae: 0.1279\n",
      "Epoch 760/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0286 - mae: 0.1277\n",
      "Epoch 761/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0273 - mae: 0.1241\n",
      "Epoch 762/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0283 - mae: 0.1264\n",
      "Epoch 763/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0287 - mae: 0.1271\n",
      "Epoch 764/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0278 - mae: 0.1262\n",
      "Epoch 765/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0280 - mae: 0.1257\n",
      "Epoch 766/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0293 - mae: 0.1298\n",
      "Epoch 767/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0274 - mae: 0.1248\n",
      "Epoch 768/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0291 - mae: 0.1297\n",
      "Epoch 769/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0280 - mae: 0.1265\n",
      "Epoch 770/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0278 - mae: 0.1262\n",
      "Epoch 771/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0297 - mae: 0.1309\n",
      "Epoch 772/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0283 - mae: 0.1278\n",
      "Epoch 773/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0275 - mae: 0.1259\n",
      "Epoch 774/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0282 - mae: 0.1276\n",
      "Epoch 775/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0274 - mae: 0.1251\n",
      "Epoch 776/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0323 - mae: 0.1385\n",
      "Epoch 777/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0287 - mae: 0.1282\n",
      "Epoch 778/2000\n",
      "2018/2018 [==============================] - 0s 104us/sample - loss: 0.0273 - mae: 0.1248\n",
      "Epoch 779/2000\n",
      "2018/2018 [==============================] - 0s 93us/sample - loss: 0.0286 - mae: 0.1273\n",
      "Epoch 780/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0289 - mae: 0.1289\n",
      "Epoch 781/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0268 - mae: 0.1235\n",
      "Epoch 782/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.0267 - mae: 0.1235\n",
      "Epoch 783/2000\n",
      "2018/2018 [==============================] - 0s 127us/sample - loss: 0.0263 - mae: 0.1229\n",
      "Epoch 784/2000\n",
      "2018/2018 [==============================] - 0s 96us/sample - loss: 0.0257 - mae: 0.1207\n",
      "Epoch 785/2000\n",
      "2018/2018 [==============================] - 0s 144us/sample - loss: 0.0278 - mae: 0.1265\n",
      "Epoch 786/2000\n",
      "2018/2018 [==============================] - 0s 236us/sample - loss: 0.0266 - mae: 0.1225\n",
      "Epoch 787/2000\n",
      "2018/2018 [==============================] - 0s 109us/sample - loss: 0.0274 - mae: 0.1253\n",
      "Epoch 788/2000\n",
      "2018/2018 [==============================] - 0s 92us/sample - loss: 0.0263 - mae: 0.1231\n",
      "Epoch 789/2000\n",
      "2018/2018 [==============================] - 0s 90us/sample - loss: 0.0284 - mae: 0.1278\n",
      "Epoch 790/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0260 - mae: 0.1226\n",
      "Epoch 791/2000\n",
      "2018/2018 [==============================] - 0s 90us/sample - loss: 0.0259 - mae: 0.1209\n",
      "Epoch 792/2000\n",
      "2018/2018 [==============================] - 0s 91us/sample - loss: 0.0269 - mae: 0.1245\n",
      "Epoch 793/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0266 - mae: 0.1232\n",
      "Epoch 794/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0269 - mae: 0.1235\n",
      "Epoch 795/2000\n",
      "2018/2018 [==============================] - 0s 95us/sample - loss: 0.0294 - mae: 0.1298\n",
      "Epoch 796/2000\n",
      "2018/2018 [==============================] - 0s 90us/sample - loss: 0.0272 - mae: 0.1252\n",
      "Epoch 797/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0265 - mae: 0.1227\n",
      "Epoch 798/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0282 - mae: 0.1275\n",
      "Epoch 799/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0272 - mae: 0.1244\n",
      "Epoch 800/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0270 - mae: 0.1239\n",
      "Epoch 801/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0258 - mae: 0.1214\n",
      "Epoch 802/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0268 - mae: 0.1232\n",
      "Epoch 803/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0272 - mae: 0.1253\n",
      "Epoch 804/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.0271 - mae: 0.1242\n",
      "Epoch 805/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.0262 - mae: 0.1234\n",
      "Epoch 806/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0260 - mae: 0.1222\n",
      "Epoch 807/2000\n",
      "2018/2018 [==============================] - 0s 92us/sample - loss: 0.0266 - mae: 0.1228\n",
      "Epoch 808/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0274 - mae: 0.1254\n",
      "Epoch 809/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0270 - mae: 0.1249\n",
      "Epoch 810/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0264 - mae: 0.1230\n",
      "Epoch 811/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0269 - mae: 0.1244\n",
      "Epoch 812/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0260 - mae: 0.1211\n",
      "Epoch 813/2000\n",
      "2018/2018 [==============================] - 0s 121us/sample - loss: 0.0267 - mae: 0.1238\n",
      "Epoch 814/2000\n",
      "2018/2018 [==============================] - 0s 135us/sample - loss: 0.0257 - mae: 0.1204\n",
      "Epoch 815/2000\n",
      "2018/2018 [==============================] - 0s 90us/sample - loss: 0.0263 - mae: 0.1224\n",
      "Epoch 816/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0282 - mae: 0.1272\n",
      "Epoch 817/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0260 - mae: 0.1219\n",
      "Epoch 818/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0259 - mae: 0.1216\n",
      "Epoch 819/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0250 - mae: 0.1198\n",
      "Epoch 820/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0297 - mae: 0.1300\n",
      "Epoch 821/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0289 - mae: 0.1291\n",
      "Epoch 822/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0270 - mae: 0.1245\n",
      "Epoch 823/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0262 - mae: 0.1228\n",
      "Epoch 824/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0259 - mae: 0.1214\n",
      "Epoch 825/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0255 - mae: 0.1200\n",
      "Epoch 826/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0256 - mae: 0.1206\n",
      "Epoch 827/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0261 - mae: 0.1214\n",
      "Epoch 828/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0255 - mae: 0.1199\n",
      "Epoch 829/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0266 - mae: 0.1233\n",
      "Epoch 830/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0251 - mae: 0.1196\n",
      "Epoch 831/2000\n",
      "2018/2018 [==============================] - 0s 94us/sample - loss: 0.0386 - mae: 0.1237\n",
      "Epoch 832/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 104us/sample - loss: 0.0251 - mae: 0.1193\n",
      "Epoch 833/2000\n",
      "2018/2018 [==============================] - 0s 150us/sample - loss: 0.0273 - mae: 0.1244\n",
      "Epoch 834/2000\n",
      "2018/2018 [==============================] - 0s 93us/sample - loss: 0.0256 - mae: 0.1215\n",
      "Epoch 835/2000\n",
      "2018/2018 [==============================] - 0s 93us/sample - loss: 0.0255 - mae: 0.1207\n",
      "Epoch 836/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0294 - mae: 0.1294\n",
      "Epoch 837/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0283 - mae: 0.1270\n",
      "Epoch 838/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0259 - mae: 0.1214\n",
      "Epoch 839/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0257 - mae: 0.1213\n",
      "Epoch 840/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0268 - mae: 0.1222\n",
      "Epoch 841/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0270 - mae: 0.1238\n",
      "Epoch 842/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0254 - mae: 0.1199\n",
      "Epoch 843/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0253 - mae: 0.1198\n",
      "Epoch 844/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0261 - mae: 0.1231\n",
      "Epoch 845/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0253 - mae: 0.1198\n",
      "Epoch 846/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0279 - mae: 0.1259\n",
      "Epoch 847/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0285 - mae: 0.1284\n",
      "Epoch 848/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0271 - mae: 0.1249\n",
      "Epoch 849/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0273 - mae: 0.1257\n",
      "Epoch 850/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0429 - mae: 0.1593\n",
      "Epoch 851/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0308 - mae: 0.1345\n",
      "Epoch 852/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0273 - mae: 0.1256\n",
      "Epoch 853/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0273 - mae: 0.1260\n",
      "Epoch 854/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0260 - mae: 0.1226\n",
      "Epoch 855/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0255 - mae: 0.1201\n",
      "Epoch 856/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0250 - mae: 0.1196\n",
      "Epoch 857/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0261 - mae: 0.1215\n",
      "Epoch 858/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0305 - mae: 0.1320\n",
      "Epoch 859/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0282 - mae: 0.1289\n",
      "Epoch 860/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0265 - mae: 0.1239\n",
      "Epoch 861/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0254 - mae: 0.1206\n",
      "Epoch 862/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0252 - mae: 0.1214\n",
      "Epoch 863/2000\n",
      "2018/2018 [==============================] - 0s 116us/sample - loss: 0.0250 - mae: 0.1194\n",
      "Epoch 864/2000\n",
      "2018/2018 [==============================] - 0s 116us/sample - loss: 0.0250 - mae: 0.1192\n",
      "Epoch 865/2000\n",
      "2018/2018 [==============================] - 0s 159us/sample - loss: 0.0273 - mae: 0.1253\n",
      "Epoch 866/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0261 - mae: 0.1223\n",
      "Epoch 867/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0260 - mae: 0.1217\n",
      "Epoch 868/2000\n",
      "2018/2018 [==============================] - 0s 92us/sample - loss: 0.0283 - mae: 0.1275\n",
      "Epoch 869/2000\n",
      "2018/2018 [==============================] - 0s 151us/sample - loss: 0.0267 - mae: 0.1238\n",
      "Epoch 870/2000\n",
      "2018/2018 [==============================] - 0s 114us/sample - loss: 0.0259 - mae: 0.1206\n",
      "Epoch 871/2000\n",
      "2018/2018 [==============================] - 0s 97us/sample - loss: 0.0255 - mae: 0.1206\n",
      "Epoch 872/2000\n",
      "2018/2018 [==============================] - 0s 92us/sample - loss: 0.0254 - mae: 0.1201\n",
      "Epoch 873/2000\n",
      "2018/2018 [==============================] - 0s 90us/sample - loss: 0.0247 - mae: 0.1182\n",
      "Epoch 874/2000\n",
      "2018/2018 [==============================] - 0s 98us/sample - loss: 0.0293 - mae: 0.1274\n",
      "Epoch 875/2000\n",
      "2018/2018 [==============================] - 0s 117us/sample - loss: 0.0268 - mae: 0.1236\n",
      "Epoch 876/2000\n",
      "2018/2018 [==============================] - 0s 121us/sample - loss: 0.0265 - mae: 0.1232\n",
      "Epoch 877/2000\n",
      "2018/2018 [==============================] - 0s 127us/sample - loss: 0.0251 - mae: 0.1197\n",
      "Epoch 878/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0249 - mae: 0.1193\n",
      "Epoch 879/2000\n",
      "2018/2018 [==============================] - 0s 102us/sample - loss: 0.0270 - mae: 0.1238\n",
      "Epoch 880/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0249 - mae: 0.1195\n",
      "Epoch 881/2000\n",
      "2018/2018 [==============================] - 0s 91us/sample - loss: 0.0256 - mae: 0.1200\n",
      "Epoch 882/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.0244 - mae: 0.1177\n",
      "Epoch 883/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0258 - mae: 0.1209\n",
      "Epoch 884/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0262 - mae: 0.1229\n",
      "Epoch 885/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0247 - mae: 0.1185\n",
      "Epoch 886/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0251 - mae: 0.1196\n",
      "Epoch 887/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0255 - mae: 0.1204\n",
      "Epoch 888/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0248 - mae: 0.1182\n",
      "Epoch 889/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0277 - mae: 0.1255\n",
      "Epoch 890/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0247 - mae: 0.1193\n",
      "Epoch 891/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0242 - mae: 0.1170\n",
      "Epoch 892/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0251 - mae: 0.1193\n",
      "Epoch 893/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0251 - mae: 0.1189\n",
      "Epoch 894/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0271 - mae: 0.1233\n",
      "Epoch 895/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0270 - mae: 0.1245\n",
      "Epoch 896/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0248 - mae: 0.1183\n",
      "Epoch 897/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0245 - mae: 0.1182\n",
      "Epoch 898/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0264 - mae: 0.1237\n",
      "Epoch 899/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0245 - mae: 0.1181\n",
      "Epoch 900/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0248 - mae: 0.1187\n",
      "Epoch 901/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0263 - mae: 0.1231\n",
      "Epoch 902/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0259 - mae: 0.1205\n",
      "Epoch 903/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0274 - mae: 0.1258\n",
      "Epoch 904/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0282 - mae: 0.1275\n",
      "Epoch 905/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0250 - mae: 0.1192\n",
      "Epoch 906/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0264 - mae: 0.1232\n",
      "Epoch 907/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0272 - mae: 0.1248\n",
      "Epoch 908/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0282 - mae: 0.1281\n",
      "Epoch 909/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0263 - mae: 0.1220\n",
      "Epoch 910/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0257 - mae: 0.1224\n",
      "Epoch 911/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0246 - mae: 0.1183\n",
      "Epoch 912/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0246 - mae: 0.1192\n",
      "Epoch 913/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0246 - mae: 0.1183\n",
      "Epoch 914/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0243 - mae: 0.1175\n",
      "Epoch 915/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0251 - mae: 0.1206\n",
      "Epoch 916/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0254 - mae: 0.1204\n",
      "Epoch 917/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0274 - mae: 0.1243\n",
      "Epoch 918/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0291 - mae: 0.1299\n",
      "Epoch 919/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0268 - mae: 0.1235\n",
      "Epoch 920/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0265 - mae: 0.1229\n",
      "Epoch 921/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0249 - mae: 0.1202\n",
      "Epoch 922/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0250 - mae: 0.1204\n",
      "Epoch 923/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0245 - mae: 0.1183\n",
      "Epoch 924/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0240 - mae: 0.1173\n",
      "Epoch 925/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0238 - mae: 0.1165\n",
      "Epoch 926/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0250 - mae: 0.1200\n",
      "Epoch 927/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0248 - mae: 0.1191\n",
      "Epoch 928/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0295 - mae: 0.1300\n",
      "Epoch 929/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0279 - mae: 0.1282\n",
      "Epoch 930/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0257 - mae: 0.1219\n",
      "Epoch 931/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0241 - mae: 0.1174\n",
      "Epoch 932/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0242 - mae: 0.1172\n",
      "Epoch 933/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0253 - mae: 0.1203\n",
      "Epoch 934/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0248 - mae: 0.1197\n",
      "Epoch 935/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0241 - mae: 0.1166\n",
      "Epoch 936/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0286 - mae: 0.1267\n",
      "Epoch 937/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0252 - mae: 0.1206\n",
      "Epoch 938/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0239 - mae: 0.1169\n",
      "Epoch 939/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0249 - mae: 0.1205\n",
      "Epoch 940/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0241 - mae: 0.1168\n",
      "Epoch 941/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0253 - mae: 0.1200\n",
      "Epoch 942/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0241 - mae: 0.1173\n",
      "Epoch 943/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0243 - mae: 0.1172\n",
      "Epoch 944/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0240 - mae: 0.1171\n",
      "Epoch 945/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0256 - mae: 0.1207\n",
      "Epoch 946/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0235 - mae: 0.1159\n",
      "Epoch 947/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0246 - mae: 0.1176\n",
      "Epoch 948/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0235 - mae: 0.1153\n",
      "Epoch 949/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0243 - mae: 0.1178\n",
      "Epoch 950/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0234 - mae: 0.1153\n",
      "Epoch 951/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0262 - mae: 0.1222\n",
      "Epoch 952/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0243 - mae: 0.1192\n",
      "Epoch 953/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0249 - mae: 0.1189\n",
      "Epoch 954/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0249 - mae: 0.1185\n",
      "Epoch 955/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0252 - mae: 0.1204\n",
      "Epoch 956/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0243 - mae: 0.1181\n",
      "Epoch 957/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0242 - mae: 0.1172\n",
      "Epoch 958/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0244 - mae: 0.1180\n",
      "Epoch 959/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0599 - mae: 0.1240\n",
      "Epoch 960/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0252 - mae: 0.1197\n",
      "Epoch 961/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0253 - mae: 0.1204\n",
      "Epoch 962/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0249 - mae: 0.1195\n",
      "Epoch 963/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0255 - mae: 0.1216\n",
      "Epoch 964/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0246 - mae: 0.1180\n",
      "Epoch 965/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0254 - mae: 0.1203\n",
      "Epoch 966/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0262 - mae: 0.1222\n",
      "Epoch 967/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0248 - mae: 0.1195\n",
      "Epoch 968/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0246 - mae: 0.1186\n",
      "Epoch 969/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0297 - mae: 0.1273\n",
      "Epoch 970/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0264 - mae: 0.1233\n",
      "Epoch 971/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0241 - mae: 0.1172\n",
      "Epoch 972/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0246 - mae: 0.1192\n",
      "Epoch 973/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0243 - mae: 0.1172\n",
      "Epoch 974/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0239 - mae: 0.1162\n",
      "Epoch 975/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0256 - mae: 0.1216\n",
      "Epoch 976/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0242 - mae: 0.1183\n",
      "Epoch 977/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0238 - mae: 0.1170\n",
      "Epoch 978/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0249 - mae: 0.1188\n",
      "Epoch 979/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0240 - mae: 0.1165\n",
      "Epoch 980/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0244 - mae: 0.1182\n",
      "Epoch 981/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0254 - mae: 0.1203\n",
      "Epoch 982/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0244 - mae: 0.1177\n",
      "Epoch 983/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0268 - mae: 0.1233\n",
      "Epoch 984/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0265 - mae: 0.1241\n",
      "Epoch 985/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0255 - mae: 0.1201\n",
      "Epoch 986/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0239 - mae: 0.1166\n",
      "Epoch 987/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0242 - mae: 0.1180\n",
      "Epoch 988/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0272 - mae: 0.1237\n",
      "Epoch 989/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0250 - mae: 0.1199\n",
      "Epoch 990/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0241 - mae: 0.1180\n",
      "Epoch 991/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0246 - mae: 0.1187\n",
      "Epoch 992/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0246 - mae: 0.1190\n",
      "Epoch 993/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0237 - mae: 0.1169\n",
      "Epoch 994/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0254 - mae: 0.1203\n",
      "Epoch 995/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0247 - mae: 0.1200\n",
      "Epoch 996/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0246 - mae: 0.1198\n",
      "Epoch 997/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0509 - mae: 0.1767\n",
      "Epoch 998/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0415 - mae: 0.1601\n",
      "Epoch 999/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0368 - mae: 0.1487\n",
      "Epoch 1000/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0345 - mae: 0.1451\n",
      "Epoch 1001/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0331 - mae: 0.1418\n",
      "Epoch 1002/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0317 - mae: 0.1389\n",
      "Epoch 1003/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0318 - mae: 0.1404\n",
      "Epoch 1004/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0304 - mae: 0.1349\n",
      "Epoch 1005/2000\n",
      "2018/2018 [==============================] - 0s 130us/sample - loss: 0.0298 - mae: 0.1336\n",
      "Epoch 1006/2000\n",
      "2018/2018 [==============================] - 0s 94us/sample - loss: 0.0293 - mae: 0.1317\n",
      "Epoch 1007/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0309 - mae: 0.1353\n",
      "Epoch 1008/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.0313 - mae: 0.1360\n",
      "Epoch 1009/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0310 - mae: 0.1354\n",
      "Epoch 1010/2000\n",
      "2018/2018 [==============================] - 0s 92us/sample - loss: 0.0289 - mae: 0.1310\n",
      "Epoch 1011/2000\n",
      "2018/2018 [==============================] - 0s 90us/sample - loss: 0.0305 - mae: 0.1314\n",
      "Epoch 1012/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0274 - mae: 0.1273\n",
      "Epoch 1013/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0265 - mae: 0.1244\n",
      "Epoch 1014/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0267 - mae: 0.1251\n",
      "Epoch 1015/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0254 - mae: 0.1217\n",
      "Epoch 1016/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0271 - mae: 0.1252\n",
      "Epoch 1017/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0254 - mae: 0.1213\n",
      "Epoch 1018/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0255 - mae: 0.1205\n",
      "Epoch 1019/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0319 - mae: 0.1344\n",
      "Epoch 1020/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0355 - mae: 0.1421\n",
      "Epoch 1021/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0306 - mae: 0.1333\n",
      "Epoch 1022/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0290 - mae: 0.1292\n",
      "Epoch 1023/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0291 - mae: 0.1299\n",
      "Epoch 1024/2000\n",
      "2018/2018 [==============================] - 0s 124us/sample - loss: 0.0262 - mae: 0.1232\n",
      "Epoch 1025/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0267 - mae: 0.1237\n",
      "Epoch 1026/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0255 - mae: 0.1207\n",
      "Epoch 1027/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0271 - mae: 0.1242\n",
      "Epoch 1028/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0251 - mae: 0.1197\n",
      "Epoch 1029/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0263 - mae: 0.1230\n",
      "Epoch 1030/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0253 - mae: 0.1200\n",
      "Epoch 1031/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0251 - mae: 0.1198\n",
      "Epoch 1032/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0247 - mae: 0.1192\n",
      "Epoch 1033/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0242 - mae: 0.1178\n",
      "Epoch 1034/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0245 - mae: 0.1176\n",
      "Epoch 1035/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0258 - mae: 0.1212\n",
      "Epoch 1036/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0256 - mae: 0.1203\n",
      "Epoch 1037/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0256 - mae: 0.1205\n",
      "Epoch 1038/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0271 - mae: 0.1239\n",
      "Epoch 1039/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0260 - mae: 0.1207\n",
      "Epoch 1040/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0253 - mae: 0.1196\n",
      "Epoch 1041/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0284 - mae: 0.1285\n",
      "Epoch 1042/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0250 - mae: 0.1195\n",
      "Epoch 1043/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0265 - mae: 0.1232\n",
      "Epoch 1044/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0253 - mae: 0.1214\n",
      "Epoch 1045/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0253 - mae: 0.1188\n",
      "Epoch 1046/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0247 - mae: 0.1179\n",
      "Epoch 1047/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0290 - mae: 0.1284\n",
      "Epoch 1048/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0258 - mae: 0.1212\n",
      "Epoch 1049/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0249 - mae: 0.1182\n",
      "Epoch 1050/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0267 - mae: 0.1232\n",
      "Epoch 1051/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0263 - mae: 0.1225\n",
      "Epoch 1052/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0256 - mae: 0.1204\n",
      "Epoch 1053/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0257 - mae: 0.1206\n",
      "Epoch 1054/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0247 - mae: 0.1180\n",
      "Epoch 1055/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0246 - mae: 0.1180\n",
      "Epoch 1056/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0263 - mae: 0.1236\n",
      "Epoch 1057/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0259 - mae: 0.1224\n",
      "Epoch 1058/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0253 - mae: 0.1195\n",
      "Epoch 1059/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0248 - mae: 0.1182\n",
      "Epoch 1060/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0271 - mae: 0.1237\n",
      "Epoch 1061/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0269 - mae: 0.1249\n",
      "Epoch 1062/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0266 - mae: 0.1238\n",
      "Epoch 1063/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0268 - mae: 0.1228\n",
      "Epoch 1064/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0277 - mae: 0.1241\n",
      "Epoch 1065/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0270 - mae: 0.1235\n",
      "Epoch 1066/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0269 - mae: 0.1232\n",
      "Epoch 1067/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0281 - mae: 0.1273\n",
      "Epoch 1068/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0272 - mae: 0.1253\n",
      "Epoch 1069/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0305 - mae: 0.1321\n",
      "Epoch 1070/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0255 - mae: 0.1208\n",
      "Epoch 1071/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0248 - mae: 0.1194\n",
      "Epoch 1072/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0257 - mae: 0.1214\n",
      "Epoch 1073/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0262 - mae: 0.1216\n",
      "Epoch 1074/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0246 - mae: 0.1178\n",
      "Epoch 1075/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0259 - mae: 0.1208\n",
      "Epoch 1076/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0246 - mae: 0.1180\n",
      "Epoch 1077/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0248 - mae: 0.1178\n",
      "Epoch 1078/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0241 - mae: 0.1162\n",
      "Epoch 1079/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0253 - mae: 0.1186\n",
      "Epoch 1080/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0264 - mae: 0.1216\n",
      "Epoch 1081/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0253 - mae: 0.1193\n",
      "Epoch 1082/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0260 - mae: 0.1212\n",
      "Epoch 1083/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0245 - mae: 0.1168\n",
      "Epoch 1084/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0257 - mae: 0.1195\n",
      "Epoch 1085/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0242 - mae: 0.1160\n",
      "Epoch 1086/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0260 - mae: 0.1217\n",
      "Epoch 1087/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0242 - mae: 0.1169\n",
      "Epoch 1088/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0240 - mae: 0.1157\n",
      "Epoch 1089/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0241 - mae: 0.1154\n",
      "Epoch 1090/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0252 - mae: 0.1190\n",
      "Epoch 1091/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0276 - mae: 0.1241\n",
      "Epoch 1092/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0306 - mae: 0.1301\n",
      "Epoch 1093/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0279 - mae: 0.1267\n",
      "Epoch 1094/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0285 - mae: 0.1270\n",
      "Epoch 1095/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0300 - mae: 0.1293\n",
      "Epoch 1096/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0276 - mae: 0.1236\n",
      "Epoch 1097/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0268 - mae: 0.1236\n",
      "Epoch 1098/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0279 - mae: 0.1250\n",
      "Epoch 1099/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0269 - mae: 0.1223\n",
      "Epoch 1100/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0254 - mae: 0.1196\n",
      "Epoch 1101/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0251 - mae: 0.1186\n",
      "Epoch 1102/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0261 - mae: 0.1206\n",
      "Epoch 1103/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0253 - mae: 0.1179\n",
      "Epoch 1104/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0255 - mae: 0.1194\n",
      "Epoch 1105/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0280 - mae: 0.1249\n",
      "Epoch 1106/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0269 - mae: 0.1227\n",
      "Epoch 1107/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0257 - mae: 0.1190\n",
      "Epoch 1108/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0275 - mae: 0.1253\n",
      "Epoch 1109/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0249 - mae: 0.1174\n",
      "Epoch 1110/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0254 - mae: 0.1204\n",
      "Epoch 1111/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0283 - mae: 0.1261\n",
      "Epoch 1112/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0245 - mae: 0.1172\n",
      "Epoch 1113/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0285 - mae: 0.1266\n",
      "Epoch 1114/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0254 - mae: 0.1193\n",
      "Epoch 1115/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0238 - mae: 0.1154\n",
      "Epoch 1116/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0248 - mae: 0.1184\n",
      "Epoch 1117/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0240 - mae: 0.1164\n",
      "Epoch 1118/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0266 - mae: 0.1228\n",
      "Epoch 1119/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0265 - mae: 0.1224\n",
      "Epoch 1120/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0282 - mae: 0.1246\n",
      "Epoch 1121/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0347 - mae: 0.1413\n",
      "Epoch 1122/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0292 - mae: 0.1317\n",
      "Epoch 1123/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0262 - mae: 0.1235\n",
      "Epoch 1124/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0266 - mae: 0.1236\n",
      "Epoch 1125/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0287 - mae: 0.1282\n",
      "Epoch 1126/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0259 - mae: 0.1218\n",
      "Epoch 1127/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0249 - mae: 0.1189\n",
      "Epoch 1128/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0236 - mae: 0.1156\n",
      "Epoch 1129/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0237 - mae: 0.1145\n",
      "Epoch 1130/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0237 - mae: 0.1153\n",
      "Epoch 1131/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0243 - mae: 0.1178\n",
      "Epoch 1132/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0236 - mae: 0.1147\n",
      "Epoch 1133/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0238 - mae: 0.1158\n",
      "Epoch 1134/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0294 - mae: 0.1289\n",
      "Epoch 1135/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0273 - mae: 0.1260\n",
      "Epoch 1136/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0244 - mae: 0.1174\n",
      "Epoch 1137/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0355 - mae: 0.1313\n",
      "Epoch 1138/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0260 - mae: 0.1216\n",
      "Epoch 1139/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0243 - mae: 0.1170\n",
      "Epoch 1140/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0249 - mae: 0.1189\n",
      "Epoch 1141/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0241 - mae: 0.1160\n",
      "Epoch 1142/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0250 - mae: 0.1178\n",
      "Epoch 1143/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0254 - mae: 0.1191\n",
      "Epoch 1144/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0258 - mae: 0.1211\n",
      "Epoch 1145/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0241 - mae: 0.1165\n",
      "Epoch 1146/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0240 - mae: 0.1160\n",
      "Epoch 1147/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0239 - mae: 0.1157\n",
      "Epoch 1148/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0250 - mae: 0.1185\n",
      "Epoch 1149/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0236 - mae: 0.1147\n",
      "Epoch 1150/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0241 - mae: 0.1166\n",
      "Epoch 1151/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0241 - mae: 0.1165\n",
      "Epoch 1152/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0238 - mae: 0.1150\n",
      "Epoch 1153/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0236 - mae: 0.1143\n",
      "Epoch 1154/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0233 - mae: 0.1139\n",
      "Epoch 1155/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0243 - mae: 0.1164\n",
      "Epoch 1156/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0242 - mae: 0.1172\n",
      "Epoch 1157/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0244 - mae: 0.1170\n",
      "Epoch 1158/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0248 - mae: 0.1177\n",
      "Epoch 1159/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0239 - mae: 0.1160\n",
      "Epoch 1160/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0234 - mae: 0.1132\n",
      "Epoch 1161/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0246 - mae: 0.1177\n",
      "Epoch 1162/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0246 - mae: 0.1179\n",
      "Epoch 1163/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0243 - mae: 0.1167\n",
      "Epoch 1164/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0243 - mae: 0.1169\n",
      "Epoch 1165/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0246 - mae: 0.1186\n",
      "Epoch 1166/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0234 - mae: 0.1142\n",
      "Epoch 1167/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0242 - mae: 0.1166\n",
      "Epoch 1168/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0244 - mae: 0.1166\n",
      "Epoch 1169/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0232 - mae: 0.1144\n",
      "Epoch 1170/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0240 - mae: 0.1165\n",
      "Epoch 1171/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0239 - mae: 0.1159\n",
      "Epoch 1172/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0237 - mae: 0.1152\n",
      "Epoch 1173/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0240 - mae: 0.1152\n",
      "Epoch 1174/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0234 - mae: 0.1144\n",
      "Epoch 1175/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0242 - mae: 0.1174\n",
      "Epoch 1176/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0229 - mae: 0.1130\n",
      "Epoch 1177/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0234 - mae: 0.1152\n",
      "Epoch 1178/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0240 - mae: 0.1168\n",
      "Epoch 1179/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0234 - mae: 0.1148\n",
      "Epoch 1180/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0233 - mae: 0.1141\n",
      "Epoch 1181/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0236 - mae: 0.1151\n",
      "Epoch 1182/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0238 - mae: 0.1161\n",
      "Epoch 1183/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0241 - mae: 0.1172\n",
      "Epoch 1184/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0274 - mae: 0.1263\n",
      "Epoch 1185/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0234 - mae: 0.1151\n",
      "Epoch 1186/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0231 - mae: 0.1133\n",
      "Epoch 1187/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0232 - mae: 0.1152\n",
      "Epoch 1188/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0269 - mae: 0.1237\n",
      "Epoch 1189/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0235 - mae: 0.1157\n",
      "Epoch 1190/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0247 - mae: 0.1191\n",
      "Epoch 1191/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0242 - mae: 0.1173\n",
      "Epoch 1192/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0245 - mae: 0.1176\n",
      "Epoch 1193/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0245 - mae: 0.1190\n",
      "Epoch 1194/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0240 - mae: 0.1174\n",
      "Epoch 1195/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0236 - mae: 0.1161\n",
      "Epoch 1196/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0257 - mae: 0.1207\n",
      "Epoch 1197/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0240 - mae: 0.1171\n",
      "Epoch 1198/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0257 - mae: 0.1209\n",
      "Epoch 1199/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0232 - mae: 0.1155\n",
      "Epoch 1200/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0232 - mae: 0.1144\n",
      "Epoch 1201/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0248 - mae: 0.1193\n",
      "Epoch 1202/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0232 - mae: 0.1147\n",
      "Epoch 1203/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0313 - mae: 0.1346\n",
      "Epoch 1204/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0281 - mae: 0.1271\n",
      "Epoch 1205/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0253 - mae: 0.1192\n",
      "Epoch 1206/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0241 - mae: 0.1168\n",
      "Epoch 1207/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0230 - mae: 0.1139\n",
      "Epoch 1208/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0227 - mae: 0.1131\n",
      "Epoch 1209/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0235 - mae: 0.1154\n",
      "Epoch 1210/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0231 - mae: 0.1144\n",
      "Epoch 1211/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0237 - mae: 0.1166\n",
      "Epoch 1212/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0227 - mae: 0.1129\n",
      "Epoch 1213/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0258 - mae: 0.1207\n",
      "Epoch 1214/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0243 - mae: 0.1166\n",
      "Epoch 1215/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0235 - mae: 0.1156\n",
      "Epoch 1216/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0230 - mae: 0.1144\n",
      "Epoch 1217/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0235 - mae: 0.1153\n",
      "Epoch 1218/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0234 - mae: 0.1155\n",
      "Epoch 1219/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0225 - mae: 0.1128\n",
      "Epoch 1220/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0224 - mae: 0.1121\n",
      "Epoch 1221/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0233 - mae: 0.1146\n",
      "Epoch 1222/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0252 - mae: 0.1202\n",
      "Epoch 1223/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0228 - mae: 0.1123\n",
      "Epoch 1224/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0237 - mae: 0.1153\n",
      "Epoch 1225/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0239 - mae: 0.1164\n",
      "Epoch 1226/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0226 - mae: 0.1135\n",
      "Epoch 1227/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0233 - mae: 0.1150\n",
      "Epoch 1228/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0225 - mae: 0.1124\n",
      "Epoch 1229/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0227 - mae: 0.1133\n",
      "Epoch 1230/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0228 - mae: 0.1130\n",
      "Epoch 1231/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0236 - mae: 0.1157\n",
      "Epoch 1232/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0267 - mae: 0.1221\n",
      "Epoch 1233/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0263 - mae: 0.1227\n",
      "Epoch 1234/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0251 - mae: 0.1206\n",
      "Epoch 1235/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0232 - mae: 0.1142\n",
      "Epoch 1236/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0232 - mae: 0.1150\n",
      "Epoch 1237/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0240 - mae: 0.1165\n",
      "Epoch 1238/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0227 - mae: 0.1131\n",
      "Epoch 1239/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0231 - mae: 0.1140\n",
      "Epoch 1240/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0231 - mae: 0.1139\n",
      "Epoch 1241/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0236 - mae: 0.1152\n",
      "Epoch 1242/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0234 - mae: 0.1159\n",
      "Epoch 1243/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0232 - mae: 0.1139\n",
      "Epoch 1244/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0225 - mae: 0.1134\n",
      "Epoch 1245/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0233 - mae: 0.1150\n",
      "Epoch 1246/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0271 - mae: 0.1230\n",
      "Epoch 1247/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0261 - mae: 0.1231\n",
      "Epoch 1248/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0241 - mae: 0.1170\n",
      "Epoch 1249/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0261 - mae: 0.1212\n",
      "Epoch 1250/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0325 - mae: 0.1399\n",
      "Epoch 1251/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0273 - mae: 0.1256\n",
      "Epoch 1252/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0259 - mae: 0.1224\n",
      "Epoch 1253/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0250 - mae: 0.1187\n",
      "Epoch 1254/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0305 - mae: 0.1297\n",
      "Epoch 1255/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0253 - mae: 0.1222\n",
      "Epoch 1256/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0233 - mae: 0.1166\n",
      "Epoch 1257/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0254 - mae: 0.1206\n",
      "Epoch 1258/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0232 - mae: 0.1162\n",
      "Epoch 1259/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0235 - mae: 0.1159\n",
      "Epoch 1260/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0234 - mae: 0.1164\n",
      "Epoch 1261/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0238 - mae: 0.1166\n",
      "Epoch 1262/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0235 - mae: 0.1163\n",
      "Epoch 1263/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0237 - mae: 0.1173\n",
      "Epoch 1264/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0232 - mae: 0.1150\n",
      "Epoch 1265/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0228 - mae: 0.1141\n",
      "Epoch 1266/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0233 - mae: 0.1158\n",
      "Epoch 1267/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0232 - mae: 0.1158\n",
      "Epoch 1268/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0226 - mae: 0.1138\n",
      "Epoch 1269/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0226 - mae: 0.1131\n",
      "Epoch 1270/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0231 - mae: 0.1141\n",
      "Epoch 1271/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0224 - mae: 0.1127\n",
      "Epoch 1272/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0229 - mae: 0.1131\n",
      "Epoch 1273/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0239 - mae: 0.1163\n",
      "Epoch 1274/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0230 - mae: 0.1147\n",
      "Epoch 1275/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0226 - mae: 0.1131\n",
      "Epoch 1276/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0236 - mae: 0.1154\n",
      "Epoch 1277/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0231 - mae: 0.1146\n",
      "Epoch 1278/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0226 - mae: 0.1133\n",
      "Epoch 1279/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0237 - mae: 0.1157\n",
      "Epoch 1280/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0287 - mae: 0.1259\n",
      "Epoch 1281/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0291 - mae: 0.1267\n",
      "Epoch 1282/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0257 - mae: 0.1205\n",
      "Epoch 1283/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0227 - mae: 0.1134\n",
      "Epoch 1284/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0227 - mae: 0.1129\n",
      "Epoch 1285/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0229 - mae: 0.1131\n",
      "Epoch 1286/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0239 - mae: 0.1154\n",
      "Epoch 1287/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0242 - mae: 0.1174\n",
      "Epoch 1288/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0232 - mae: 0.1147\n",
      "Epoch 1289/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0226 - mae: 0.1130\n",
      "Epoch 1290/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0226 - mae: 0.1132\n",
      "Epoch 1291/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0239 - mae: 0.1159\n",
      "Epoch 1292/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0242 - mae: 0.1163\n",
      "Epoch 1293/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0236 - mae: 0.1156\n",
      "Epoch 1294/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0234 - mae: 0.1151\n",
      "Epoch 1295/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0232 - mae: 0.1147\n",
      "Epoch 1296/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0234 - mae: 0.1149\n",
      "Epoch 1297/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0227 - mae: 0.1138\n",
      "Epoch 1298/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0229 - mae: 0.1139\n",
      "Epoch 1299/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0221 - mae: 0.1118\n",
      "Epoch 1300/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0235 - mae: 0.1153\n",
      "Epoch 1301/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0271 - mae: 0.1243\n",
      "Epoch 1302/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0268 - mae: 0.1238\n",
      "Epoch 1303/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0237 - mae: 0.1161\n",
      "Epoch 1304/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0234 - mae: 0.1143\n",
      "Epoch 1305/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0225 - mae: 0.1141\n",
      "Epoch 1306/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0230 - mae: 0.1140\n",
      "Epoch 1307/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0233 - mae: 0.1146\n",
      "Epoch 1308/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0224 - mae: 0.1121\n",
      "Epoch 1309/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0227 - mae: 0.1138\n",
      "Epoch 1310/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0220 - mae: 0.1111\n",
      "Epoch 1311/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0248 - mae: 0.1183\n",
      "Epoch 1312/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0220 - mae: 0.1124\n",
      "Epoch 1313/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0219 - mae: 0.1109\n",
      "Epoch 1314/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0218 - mae: 0.1110\n",
      "Epoch 1315/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0218 - mae: 0.1104\n",
      "Epoch 1316/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0248 - mae: 0.1188\n",
      "Epoch 1317/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0237 - mae: 0.1166\n",
      "Epoch 1318/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0256 - mae: 0.1204\n",
      "Epoch 1319/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0232 - mae: 0.1149\n",
      "Epoch 1320/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0230 - mae: 0.1144\n",
      "Epoch 1321/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0228 - mae: 0.1133\n",
      "Epoch 1322/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0226 - mae: 0.1132\n",
      "Epoch 1323/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0226 - mae: 0.1135\n",
      "Epoch 1324/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0220 - mae: 0.1118\n",
      "Epoch 1325/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0224 - mae: 0.1133\n",
      "Epoch 1326/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0232 - mae: 0.1153\n",
      "Epoch 1327/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0231 - mae: 0.1145\n",
      "Epoch 1328/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0228 - mae: 0.1143\n",
      "Epoch 1329/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0224 - mae: 0.1122\n",
      "Epoch 1330/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0238 - mae: 0.1164\n",
      "Epoch 1331/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0238 - mae: 0.1171\n",
      "Epoch 1332/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0228 - mae: 0.1141\n",
      "Epoch 1333/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0227 - mae: 0.1133\n",
      "Epoch 1334/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0256 - mae: 0.1201\n",
      "Epoch 1335/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0241 - mae: 0.1174\n",
      "Epoch 1336/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0238 - mae: 0.1169\n",
      "Epoch 1337/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0236 - mae: 0.1158\n",
      "Epoch 1338/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0235 - mae: 0.1166\n",
      "Epoch 1339/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0222 - mae: 0.1120\n",
      "Epoch 1340/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0233 - mae: 0.1147\n",
      "Epoch 1341/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1124\n",
      "Epoch 1342/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1112\n",
      "Epoch 1343/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0237 - mae: 0.1146\n",
      "Epoch 1344/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0242 - mae: 0.1186\n",
      "Epoch 1345/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0244 - mae: 0.1180\n",
      "Epoch 1346/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0248 - mae: 0.1182\n",
      "Epoch 1347/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0236 - mae: 0.1162\n",
      "Epoch 1348/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0222 - mae: 0.1118\n",
      "Epoch 1349/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0229 - mae: 0.1144\n",
      "Epoch 1350/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0219 - mae: 0.1104\n",
      "Epoch 1351/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0220 - mae: 0.1117\n",
      "Epoch 1352/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0229 - mae: 0.1137\n",
      "Epoch 1353/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0263 - mae: 0.1160\n",
      "Epoch 1354/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0229 - mae: 0.1138\n",
      "Epoch 1355/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0232 - mae: 0.1141\n",
      "Epoch 1356/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0306 - mae: 0.1327\n",
      "Epoch 1357/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0285 - mae: 0.1276\n",
      "Epoch 1358/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0275 - mae: 0.1253\n",
      "Epoch 1359/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0245 - mae: 0.1170\n",
      "Epoch 1360/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0226 - mae: 0.1130\n",
      "Epoch 1361/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0228 - mae: 0.1142\n",
      "Epoch 1362/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0235 - mae: 0.1163\n",
      "Epoch 1363/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0224 - mae: 0.1126\n",
      "Epoch 1364/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0225 - mae: 0.1124\n",
      "Epoch 1365/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0221 - mae: 0.1115\n",
      "Epoch 1366/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0227 - mae: 0.1131\n",
      "Epoch 1367/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0220 - mae: 0.1115\n",
      "Epoch 1368/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0226 - mae: 0.1129\n",
      "Epoch 1369/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0225 - mae: 0.1129\n",
      "Epoch 1370/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0231 - mae: 0.1153\n",
      "Epoch 1371/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0221 - mae: 0.1116\n",
      "Epoch 1372/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0232 - mae: 0.1139\n",
      "Epoch 1373/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0224 - mae: 0.1138\n",
      "Epoch 1374/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0259 - mae: 0.1211\n",
      "Epoch 1375/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0234 - mae: 0.1155\n",
      "Epoch 1376/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0235 - mae: 0.1162\n",
      "Epoch 1377/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0231 - mae: 0.1147\n",
      "Epoch 1378/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0229 - mae: 0.1133\n",
      "Epoch 1379/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0230 - mae: 0.1147\n",
      "Epoch 1380/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0270 - mae: 0.1237\n",
      "Epoch 1381/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0283 - mae: 0.1265\n",
      "Epoch 1382/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0302 - mae: 0.1302\n",
      "Epoch 1383/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0249 - mae: 0.1199\n",
      "Epoch 1384/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0237 - mae: 0.1157\n",
      "Epoch 1385/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0229 - mae: 0.1135\n",
      "Epoch 1386/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0233 - mae: 0.1151\n",
      "Epoch 1387/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0237 - mae: 0.1153\n",
      "Epoch 1388/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0230 - mae: 0.1145\n",
      "Epoch 1389/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0234 - mae: 0.1159\n",
      "Epoch 1390/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0223 - mae: 0.1122\n",
      "Epoch 1391/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0222 - mae: 0.1128\n",
      "Epoch 1392/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0235 - mae: 0.1151\n",
      "Epoch 1393/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0238 - mae: 0.1157\n",
      "Epoch 1394/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0226 - mae: 0.1135\n",
      "Epoch 1395/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0231 - mae: 0.1144\n",
      "Epoch 1396/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0239 - mae: 0.1163\n",
      "Epoch 1397/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0227 - mae: 0.1139\n",
      "Epoch 1398/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0251 - mae: 0.1190\n",
      "Epoch 1399/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0221 - mae: 0.1112\n",
      "Epoch 1400/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0222 - mae: 0.1121\n",
      "Epoch 1401/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0220 - mae: 0.1114\n",
      "Epoch 1402/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0231 - mae: 0.1140\n",
      "Epoch 1403/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0220 - mae: 0.1120\n",
      "Epoch 1404/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0225 - mae: 0.1132\n",
      "Epoch 1405/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0216 - mae: 0.1101\n",
      "Epoch 1406/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0216 - mae: 0.1102\n",
      "Epoch 1407/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0216 - mae: 0.1102\n",
      "Epoch 1408/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0219 - mae: 0.1117\n",
      "Epoch 1409/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0231 - mae: 0.1152\n",
      "Epoch 1410/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0223 - mae: 0.1132\n",
      "Epoch 1411/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0214 - mae: 0.1105\n",
      "Epoch 1412/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0220 - mae: 0.1112\n",
      "Epoch 1413/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0242 - mae: 0.1170\n",
      "Epoch 1414/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0302 - mae: 0.1315\n",
      "Epoch 1415/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0298 - mae: 0.1316\n",
      "Epoch 1416/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0250 - mae: 0.1205\n",
      "Epoch 1417/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0231 - mae: 0.1147\n",
      "Epoch 1418/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0267 - mae: 0.1233\n",
      "Epoch 1419/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0277 - mae: 0.1280\n",
      "Epoch 1420/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0248 - mae: 0.1190\n",
      "Epoch 1421/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0245 - mae: 0.1192\n",
      "Epoch 1422/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0226 - mae: 0.1132\n",
      "Epoch 1423/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0228 - mae: 0.1146\n",
      "Epoch 1424/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0232 - mae: 0.1145\n",
      "Epoch 1425/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0223 - mae: 0.1133\n",
      "Epoch 1426/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0239 - mae: 0.1163\n",
      "Epoch 1427/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0228 - mae: 0.1134\n",
      "Epoch 1428/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0228 - mae: 0.1132\n",
      "Epoch 1429/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0223 - mae: 0.1122\n",
      "Epoch 1430/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0226 - mae: 0.1131\n",
      "Epoch 1431/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0240 - mae: 0.1167\n",
      "Epoch 1432/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0259 - mae: 0.1224\n",
      "Epoch 1433/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0220 - mae: 0.1117\n",
      "Epoch 1434/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0239 - mae: 0.1169\n",
      "Epoch 1435/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0223 - mae: 0.1127\n",
      "Epoch 1436/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1124\n",
      "Epoch 1437/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0222 - mae: 0.1124\n",
      "Epoch 1438/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0234 - mae: 0.1156\n",
      "Epoch 1439/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0251 - mae: 0.1189\n",
      "Epoch 1440/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0231 - mae: 0.1146\n",
      "Epoch 1441/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0242 - mae: 0.1168\n",
      "Epoch 1442/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0243 - mae: 0.1187\n",
      "Epoch 1443/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1122\n",
      "Epoch 1444/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0226 - mae: 0.1122\n",
      "Epoch 1445/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0233 - mae: 0.1142\n",
      "Epoch 1446/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0228 - mae: 0.1142\n",
      "Epoch 1447/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0220 - mae: 0.1114\n",
      "Epoch 1448/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0225 - mae: 0.1130\n",
      "Epoch 1449/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0221 - mae: 0.1118\n",
      "Epoch 1450/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0219 - mae: 0.1112\n",
      "Epoch 1451/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0216 - mae: 0.1113\n",
      "Epoch 1452/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0239 - mae: 0.1179\n",
      "Epoch 1453/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0240 - mae: 0.1165\n",
      "Epoch 1454/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0241 - mae: 0.1177\n",
      "Epoch 1455/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0228 - mae: 0.1135\n",
      "Epoch 1456/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0221 - mae: 0.1117\n",
      "Epoch 1457/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0220 - mae: 0.1127\n",
      "Epoch 1458/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0219 - mae: 0.1117\n",
      "Epoch 1459/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0221 - mae: 0.1122\n",
      "Epoch 1460/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0218 - mae: 0.1110\n",
      "Epoch 1461/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0224 - mae: 0.1129\n",
      "Epoch 1462/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0253 - mae: 0.1205\n",
      "Epoch 1463/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0222 - mae: 0.1125\n",
      "Epoch 1464/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0229 - mae: 0.1132\n",
      "Epoch 1465/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0221 - mae: 0.1126\n",
      "Epoch 1466/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0265 - mae: 0.1235\n",
      "Epoch 1467/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0242 - mae: 0.1175\n",
      "Epoch 1468/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0220 - mae: 0.1119\n",
      "Epoch 1469/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0217 - mae: 0.1107\n",
      "Epoch 1470/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0217 - mae: 0.1109\n",
      "Epoch 1471/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0230 - mae: 0.1145\n",
      "Epoch 1472/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0216 - mae: 0.1103\n",
      "Epoch 1473/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0240 - mae: 0.1155\n",
      "Epoch 1474/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0231 - mae: 0.1131\n",
      "Epoch 1475/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0250 - mae: 0.1193\n",
      "Epoch 1476/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0234 - mae: 0.1150\n",
      "Epoch 1477/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0234 - mae: 0.1145\n",
      "Epoch 1478/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0227 - mae: 0.1135\n",
      "Epoch 1479/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1122\n",
      "Epoch 1480/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0222 - mae: 0.1121\n",
      "Epoch 1481/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0224 - mae: 0.1120\n",
      "Epoch 1482/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1110\n",
      "Epoch 1483/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0216 - mae: 0.1103\n",
      "Epoch 1484/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0221 - mae: 0.1120\n",
      "Epoch 1485/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0234 - mae: 0.1147\n",
      "Epoch 1486/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0222 - mae: 0.1126\n",
      "Epoch 1487/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1131\n",
      "Epoch 1488/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0222 - mae: 0.1126\n",
      "Epoch 1489/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0228 - mae: 0.1135\n",
      "Epoch 1490/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0290 - mae: 0.1284\n",
      "Epoch 1491/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0276 - mae: 0.1274\n",
      "Epoch 1492/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0236 - mae: 0.1160\n",
      "Epoch 1493/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0225 - mae: 0.1132\n",
      "Epoch 1494/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0224 - mae: 0.1131\n",
      "Epoch 1495/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0232 - mae: 0.1137\n",
      "Epoch 1496/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0224 - mae: 0.1123\n",
      "Epoch 1497/2000\n",
      "2018/2018 [==============================] - 0s 107us/sample - loss: 0.0263 - mae: 0.1228\n",
      "Epoch 1498/2000\n",
      "2018/2018 [==============================] - 0s 102us/sample - loss: 0.0252 - mae: 0.1183\n",
      "Epoch 1499/2000\n",
      "2018/2018 [==============================] - 0s 92us/sample - loss: 0.0234 - mae: 0.1162\n",
      "Epoch 1500/2000\n",
      "2018/2018 [==============================] - 0s 127us/sample - loss: 0.0218 - mae: 0.1107\n",
      "Epoch 1501/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0253 - mae: 0.1189\n",
      "Epoch 1502/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0219 - mae: 0.1120\n",
      "Epoch 1503/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0234 - mae: 0.1151\n",
      "Epoch 1504/2000\n",
      "2018/2018 [==============================] - 0s 92us/sample - loss: 0.0215 - mae: 0.1111\n",
      "Epoch 1505/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0232 - mae: 0.1154\n",
      "Epoch 1506/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0219 - mae: 0.1115\n",
      "Epoch 1507/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0229 - mae: 0.1142\n",
      "Epoch 1508/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0226 - mae: 0.1140\n",
      "Epoch 1509/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0226 - mae: 0.1135\n",
      "Epoch 1510/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0230 - mae: 0.1138\n",
      "Epoch 1511/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0214 - mae: 0.1104\n",
      "Epoch 1512/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0235 - mae: 0.1150\n",
      "Epoch 1513/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0230 - mae: 0.1140\n",
      "Epoch 1514/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0221 - mae: 0.1122\n",
      "Epoch 1515/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.0227 - mae: 0.1130\n",
      "Epoch 1516/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0237 - mae: 0.1147\n",
      "Epoch 1517/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0235 - mae: 0.1158\n",
      "Epoch 1518/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0229 - mae: 0.1136\n",
      "Epoch 1519/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0214 - mae: 0.1104\n",
      "Epoch 1520/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0210 - mae: 0.1081\n",
      "Epoch 1521/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0242 - mae: 0.11870s - loss: 0.0239 - mae: 0.11\n",
      "Epoch 1522/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0212 - mae: 0.1093\n",
      "Epoch 1523/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.0244 - mae: 0.1175\n",
      "Epoch 1524/2000\n",
      "2018/2018 [==============================] - 0s 93us/sample - loss: 0.0225 - mae: 0.1122\n",
      "Epoch 1525/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0239 - mae: 0.1174\n",
      "Epoch 1526/2000\n",
      "2018/2018 [==============================] - 0s 124us/sample - loss: 0.0223 - mae: 0.1127\n",
      "Epoch 1527/2000\n",
      "2018/2018 [==============================] - 0s 112us/sample - loss: 0.0254 - mae: 0.1203\n",
      "Epoch 1528/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0257 - mae: 0.1227\n",
      "Epoch 1529/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0228 - mae: 0.1141\n",
      "Epoch 1530/2000\n",
      "2018/2018 [==============================] - 0s 91us/sample - loss: 0.0234 - mae: 0.1153\n",
      "Epoch 1531/2000\n",
      "2018/2018 [==============================] - 0s 115us/sample - loss: 0.0228 - mae: 0.1140\n",
      "Epoch 1532/2000\n",
      "2018/2018 [==============================] - 0s 94us/sample - loss: 0.0216 - mae: 0.1120\n",
      "Epoch 1533/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 91us/sample - loss: 0.0214 - mae: 0.1104\n",
      "Epoch 1534/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0259 - mae: 0.1216\n",
      "Epoch 1535/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0300 - mae: 0.1333\n",
      "Epoch 1536/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0274 - mae: 0.1268\n",
      "Epoch 1537/2000\n",
      "2018/2018 [==============================] - 0s 138us/sample - loss: 0.0269 - mae: 0.1250\n",
      "Epoch 1538/2000\n",
      "2018/2018 [==============================] - 0s 122us/sample - loss: 0.0262 - mae: 0.1226\n",
      "Epoch 1539/2000\n",
      "2018/2018 [==============================] - 0s 98us/sample - loss: 0.0251 - mae: 0.1183\n",
      "Epoch 1540/2000\n",
      "2018/2018 [==============================] - 0s 101us/sample - loss: 0.0232 - mae: 0.1141\n",
      "Epoch 1541/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0232 - mae: 0.1156\n",
      "Epoch 1542/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0218 - mae: 0.1123\n",
      "Epoch 1543/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0227 - mae: 0.1137\n",
      "Epoch 1544/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0246 - mae: 0.1192\n",
      "Epoch 1545/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0230 - mae: 0.1144\n",
      "Epoch 1546/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0221 - mae: 0.1118\n",
      "Epoch 1547/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0218 - mae: 0.1110\n",
      "Epoch 1548/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0221 - mae: 0.1118\n",
      "Epoch 1549/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0225 - mae: 0.1139\n",
      "Epoch 1550/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0218 - mae: 0.1117\n",
      "Epoch 1551/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0219 - mae: 0.1123\n",
      "Epoch 1552/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0229 - mae: 0.1127\n",
      "Epoch 1553/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0247 - mae: 0.1202\n",
      "Epoch 1554/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0223 - mae: 0.1134\n",
      "Epoch 1555/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1116\n",
      "Epoch 1556/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0218 - mae: 0.1120\n",
      "Epoch 1557/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0225 - mae: 0.1139\n",
      "Epoch 1558/2000\n",
      "2018/2018 [==============================] - 0s 121us/sample - loss: 0.0224 - mae: 0.1134\n",
      "Epoch 1559/2000\n",
      "2018/2018 [==============================] - 0s 105us/sample - loss: 0.0227 - mae: 0.1134\n",
      "Epoch 1560/2000\n",
      "2018/2018 [==============================] - 0s 109us/sample - loss: 0.0225 - mae: 0.1136\n",
      "Epoch 1561/2000\n",
      "2018/2018 [==============================] - 0s 98us/sample - loss: 0.0229 - mae: 0.1139\n",
      "Epoch 1562/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0219 - mae: 0.1114\n",
      "Epoch 1563/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0226 - mae: 0.1143\n",
      "Epoch 1564/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0227 - mae: 0.1134\n",
      "Epoch 1565/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0214 - mae: 0.1101\n",
      "Epoch 1566/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0220 - mae: 0.1115\n",
      "Epoch 1567/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0214 - mae: 0.1103\n",
      "Epoch 1568/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0254 - mae: 0.1206\n",
      "Epoch 1569/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0222 - mae: 0.1134\n",
      "Epoch 1570/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0214 - mae: 0.1102\n",
      "Epoch 1571/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0218 - mae: 0.1115\n",
      "Epoch 1572/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0236 - mae: 0.1166\n",
      "Epoch 1573/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1110\n",
      "Epoch 1574/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0219 - mae: 0.1124\n",
      "Epoch 1575/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0214 - mae: 0.1104\n",
      "Epoch 1576/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0230 - mae: 0.1145\n",
      "Epoch 1577/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0229 - mae: 0.1138\n",
      "Epoch 1578/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0224 - mae: 0.1129\n",
      "Epoch 1579/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0215 - mae: 0.1113\n",
      "Epoch 1580/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0214 - mae: 0.1097\n",
      "Epoch 1581/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0214 - mae: 0.1105\n",
      "Epoch 1582/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0215 - mae: 0.1105\n",
      "Epoch 1583/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0216 - mae: 0.1108\n",
      "Epoch 1584/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0216 - mae: 0.1119\n",
      "Epoch 1585/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0220 - mae: 0.1110\n",
      "Epoch 1586/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1124\n",
      "Epoch 1587/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0214 - mae: 0.1101\n",
      "Epoch 1588/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0222 - mae: 0.1128\n",
      "Epoch 1589/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0221 - mae: 0.1122\n",
      "Epoch 1590/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0225 - mae: 0.1135\n",
      "Epoch 1591/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0238 - mae: 0.1171\n",
      "Epoch 1592/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0239 - mae: 0.1169\n",
      "Epoch 1593/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0220 - mae: 0.1127\n",
      "Epoch 1594/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0219 - mae: 0.1116\n",
      "Epoch 1595/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0225 - mae: 0.1134\n",
      "Epoch 1596/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0222 - mae: 0.1124\n",
      "Epoch 1597/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0251 - mae: 0.1191\n",
      "Epoch 1598/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0241 - mae: 0.1172\n",
      "Epoch 1599/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0223 - mae: 0.1130\n",
      "Epoch 1600/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0226 - mae: 0.1136\n",
      "Epoch 1601/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0237 - mae: 0.1151\n",
      "Epoch 1602/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0245 - mae: 0.1180\n",
      "Epoch 1603/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0228 - mae: 0.1137\n",
      "Epoch 1604/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0214 - mae: 0.1101\n",
      "Epoch 1605/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0225 - mae: 0.1128\n",
      "Epoch 1606/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0238 - mae: 0.1169\n",
      "Epoch 1607/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0226 - mae: 0.1131\n",
      "Epoch 1608/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0216 - mae: 0.1113\n",
      "Epoch 1609/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0216 - mae: 0.1105\n",
      "Epoch 1610/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0214 - mae: 0.1099\n",
      "Epoch 1611/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0219 - mae: 0.1118\n",
      "Epoch 1612/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0238 - mae: 0.1153\n",
      "Epoch 1613/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0214 - mae: 0.1107\n",
      "Epoch 1614/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0224 - mae: 0.1126\n",
      "Epoch 1615/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0232 - mae: 0.1148\n",
      "Epoch 1616/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0213 - mae: 0.1104\n",
      "Epoch 1617/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0219 - mae: 0.1114\n",
      "Epoch 1618/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0215 - mae: 0.1112\n",
      "Epoch 1619/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0222 - mae: 0.1126\n",
      "Epoch 1620/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0218 - mae: 0.1112\n",
      "Epoch 1621/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0218 - mae: 0.1117\n",
      "Epoch 1622/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0215 - mae: 0.1106\n",
      "Epoch 1623/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0213 - mae: 0.1093\n",
      "Epoch 1624/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0212 - mae: 0.1098\n",
      "Epoch 1625/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0217 - mae: 0.1110\n",
      "Epoch 1626/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0211 - mae: 0.1098\n",
      "Epoch 1627/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0227 - mae: 0.1131\n",
      "Epoch 1628/2000\n",
      "2018/2018 [==============================] - 0s 68us/sample - loss: 0.0228 - mae: 0.1144\n",
      "Epoch 1629/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0209 - mae: 0.1094\n",
      "Epoch 1630/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0210 - mae: 0.1095\n",
      "Epoch 1631/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0216 - mae: 0.1110\n",
      "Epoch 1632/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0223 - mae: 0.1122\n",
      "Epoch 1633/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0209 - mae: 0.1087\n",
      "Epoch 1634/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0222 - mae: 0.1123\n",
      "Epoch 1635/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0228 - mae: 0.1138\n",
      "Epoch 1636/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0236 - mae: 0.1156\n",
      "Epoch 1637/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0222 - mae: 0.1123\n",
      "Epoch 1638/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0211 - mae: 0.1101\n",
      "Epoch 1639/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0217 - mae: 0.1112\n",
      "Epoch 1640/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0238 - mae: 0.1170\n",
      "Epoch 1641/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0227 - mae: 0.1130\n",
      "Epoch 1642/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0228 - mae: 0.1143\n",
      "Epoch 1643/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0217 - mae: 0.1108\n",
      "Epoch 1644/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0219 - mae: 0.1115\n",
      "Epoch 1645/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0224 - mae: 0.1128\n",
      "Epoch 1646/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0223 - mae: 0.1129\n",
      "Epoch 1647/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0215 - mae: 0.1101\n",
      "Epoch 1648/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0205 - mae: 0.1074\n",
      "Epoch 1649/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0213 - mae: 0.1099\n",
      "Epoch 1650/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0237 - mae: 0.1168\n",
      "Epoch 1651/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0267 - mae: 0.1249\n",
      "Epoch 1652/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0260 - mae: 0.1225\n",
      "Epoch 1653/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0218 - mae: 0.1113\n",
      "Epoch 1654/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0218 - mae: 0.1115\n",
      "Epoch 1655/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0239 - mae: 0.1183\n",
      "Epoch 1656/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0222 - mae: 0.1117\n",
      "Epoch 1657/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0244 - mae: 0.1181\n",
      "Epoch 1658/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0247 - mae: 0.1194\n",
      "Epoch 1659/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0228 - mae: 0.1139\n",
      "Epoch 1660/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0224 - mae: 0.1127\n",
      "Epoch 1661/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0236 - mae: 0.1170\n",
      "Epoch 1662/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0217 - mae: 0.1111\n",
      "Epoch 1663/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0211 - mae: 0.1097\n",
      "Epoch 1664/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0219 - mae: 0.1121\n",
      "Epoch 1665/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0223 - mae: 0.1124\n",
      "Epoch 1666/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0220 - mae: 0.1121\n",
      "Epoch 1667/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0223 - mae: 0.1132\n",
      "Epoch 1668/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0229 - mae: 0.1144\n",
      "Epoch 1669/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0222 - mae: 0.1129\n",
      "Epoch 1670/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0211 - mae: 0.1100\n",
      "Epoch 1671/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0217 - mae: 0.1103\n",
      "Epoch 1672/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0232 - mae: 0.1148\n",
      "Epoch 1673/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0218 - mae: 0.1114\n",
      "Epoch 1674/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0224 - mae: 0.1119\n",
      "Epoch 1675/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0215 - mae: 0.1113\n",
      "Epoch 1676/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0218 - mae: 0.1114\n",
      "Epoch 1677/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0221 - mae: 0.1110\n",
      "Epoch 1678/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0247 - mae: 0.1189\n",
      "Epoch 1679/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0235 - mae: 0.1152\n",
      "Epoch 1680/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0229 - mae: 0.1136\n",
      "Epoch 1681/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0259 - mae: 0.1211\n",
      "Epoch 1682/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0331 - mae: 0.1359\n",
      "Epoch 1683/2000\n",
      "2018/2018 [==============================] - 0s 101us/sample - loss: 0.0317 - mae: 0.1352\n",
      "Epoch 1684/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0304 - mae: 0.1329\n",
      "Epoch 1685/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0299 - mae: 0.1329\n",
      "Epoch 1686/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0287 - mae: 0.1296\n",
      "Epoch 1687/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0315 - mae: 0.1321\n",
      "Epoch 1688/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0341 - mae: 0.1397\n",
      "Epoch 1689/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0306 - mae: 0.1334\n",
      "Epoch 1690/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0296 - mae: 0.1303\n",
      "Epoch 1691/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0285 - mae: 0.1282\n",
      "Epoch 1692/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0301 - mae: 0.1331\n",
      "Epoch 1693/2000\n",
      "2018/2018 [==============================] - 0s 109us/sample - loss: 0.0297 - mae: 0.1314\n",
      "Epoch 1694/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0282 - mae: 0.1272\n",
      "Epoch 1695/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0283 - mae: 0.1260\n",
      "Epoch 1696/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0260 - mae: 0.1223\n",
      "Epoch 1697/2000\n",
      "2018/2018 [==============================] - 0s 151us/sample - loss: 0.0244 - mae: 0.1180\n",
      "Epoch 1698/2000\n",
      "2018/2018 [==============================] - 0s 115us/sample - loss: 0.0237 - mae: 0.1161\n",
      "Epoch 1699/2000\n",
      "2018/2018 [==============================] - 0s 99us/sample - loss: 0.0232 - mae: 0.1142\n",
      "Epoch 1700/2000\n",
      "2018/2018 [==============================] - 0s 101us/sample - loss: 0.0229 - mae: 0.1138\n",
      "Epoch 1701/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0226 - mae: 0.1130\n",
      "Epoch 1702/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0225 - mae: 0.1118\n",
      "Epoch 1703/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0231 - mae: 0.1157\n",
      "Epoch 1704/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0227 - mae: 0.1139\n",
      "Epoch 1705/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0221 - mae: 0.1119\n",
      "Epoch 1706/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0240 - mae: 0.1170\n",
      "Epoch 1707/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0218 - mae: 0.1115\n",
      "Epoch 1708/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0255 - mae: 0.1218\n",
      "Epoch 1709/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0242 - mae: 0.1174\n",
      "Epoch 1710/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0265 - mae: 0.1242\n",
      "Epoch 1711/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0235 - mae: 0.1167\n",
      "Epoch 1712/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0240 - mae: 0.1169\n",
      "Epoch 1713/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0233 - mae: 0.1152\n",
      "Epoch 1714/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0214 - mae: 0.1105\n",
      "Epoch 1715/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0216 - mae: 0.1112\n",
      "Epoch 1716/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0214 - mae: 0.1107\n",
      "Epoch 1717/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0223 - mae: 0.1136\n",
      "Epoch 1718/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0222 - mae: 0.1134\n",
      "Epoch 1719/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0224 - mae: 0.1129\n",
      "Epoch 1720/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0217 - mae: 0.1112\n",
      "Epoch 1721/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0237 - mae: 0.1165\n",
      "Epoch 1722/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0214 - mae: 0.1113\n",
      "Epoch 1723/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0214 - mae: 0.1104\n",
      "Epoch 1724/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0223 - mae: 0.1133\n",
      "Epoch 1725/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0216 - mae: 0.1106\n",
      "Epoch 1726/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0250 - mae: 0.1191\n",
      "Epoch 1727/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0225 - mae: 0.1136\n",
      "Epoch 1728/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0217 - mae: 0.1108\n",
      "Epoch 1729/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0214 - mae: 0.1112\n",
      "Epoch 1730/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0211 - mae: 0.1086\n",
      "Epoch 1731/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0215 - mae: 0.1107\n",
      "Epoch 1732/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0216 - mae: 0.1110\n",
      "Epoch 1733/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0211 - mae: 0.1102\n",
      "Epoch 1734/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0215 - mae: 0.1109\n",
      "Epoch 1735/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0214 - mae: 0.1101\n",
      "Epoch 1736/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0224 - mae: 0.1134\n",
      "Epoch 1737/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0212 - mae: 0.1103\n",
      "Epoch 1738/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0213 - mae: 0.1098\n",
      "Epoch 1739/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0213 - mae: 0.1099\n",
      "Epoch 1740/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0228 - mae: 0.1149\n",
      "Epoch 1741/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0224 - mae: 0.1140\n",
      "Epoch 1742/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0220 - mae: 0.1121\n",
      "Epoch 1743/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0212 - mae: 0.1093\n",
      "Epoch 1744/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0337 - mae: 0.1378\n",
      "Epoch 1745/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0301 - mae: 0.1339\n",
      "Epoch 1746/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0297 - mae: 0.1327\n",
      "Epoch 1747/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0270 - mae: 0.1259\n",
      "Epoch 1748/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0301 - mae: 0.1299\n",
      "Epoch 1749/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0258 - mae: 0.1221\n",
      "Epoch 1750/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0271 - mae: 0.1261\n",
      "Epoch 1751/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0257 - mae: 0.1224\n",
      "Epoch 1752/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0236 - mae: 0.1171\n",
      "Epoch 1753/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0238 - mae: 0.1161\n",
      "Epoch 1754/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0231 - mae: 0.1157\n",
      "Epoch 1755/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0700 - mae: 0.1210\n",
      "Epoch 1756/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0399 - mae: 0.1522\n",
      "Epoch 1757/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0308 - mae: 0.1321\n",
      "Epoch 1758/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0299 - mae: 0.1308\n",
      "Epoch 1759/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0292 - mae: 0.1296\n",
      "Epoch 1760/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0276 - mae: 0.1252\n",
      "Epoch 1761/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0275 - mae: 0.1258\n",
      "Epoch 1762/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0263 - mae: 0.1228\n",
      "Epoch 1763/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0259 - mae: 0.1217\n",
      "Epoch 1764/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0250 - mae: 0.1196\n",
      "Epoch 1765/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0248 - mae: 0.1188\n",
      "Epoch 1766/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0245 - mae: 0.1179\n",
      "Epoch 1767/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0253 - mae: 0.1207\n",
      "Epoch 1768/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0249 - mae: 0.1183\n",
      "Epoch 1769/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0258 - mae: 0.1204\n",
      "Epoch 1770/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0244 - mae: 0.1184\n",
      "Epoch 1771/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0255 - mae: 0.1181\n",
      "Epoch 1772/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0245 - mae: 0.1169\n",
      "Epoch 1773/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0241 - mae: 0.1164\n",
      "Epoch 1774/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0247 - mae: 0.1187\n",
      "Epoch 1775/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0240 - mae: 0.1161\n",
      "Epoch 1776/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0237 - mae: 0.1157\n",
      "Epoch 1777/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0250 - mae: 0.1194\n",
      "Epoch 1778/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0260 - mae: 0.1213\n",
      "Epoch 1779/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0450 - mae: 0.1198\n",
      "Epoch 1780/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0238 - mae: 0.1165\n",
      "Epoch 1781/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0237 - mae: 0.1153\n",
      "Epoch 1782/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0249 - mae: 0.1187\n",
      "Epoch 1783/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0241 - mae: 0.1172\n",
      "Epoch 1784/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0242 - mae: 0.1181\n",
      "Epoch 1785/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0242 - mae: 0.1171\n",
      "Epoch 1786/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0237 - mae: 0.1156\n",
      "Epoch 1787/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0234 - mae: 0.1150\n",
      "Epoch 1788/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0233 - mae: 0.1144\n",
      "Epoch 1789/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0234 - mae: 0.1145\n",
      "Epoch 1790/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0232 - mae: 0.1146\n",
      "Epoch 1791/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0231 - mae: 0.1157\n",
      "Epoch 1792/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0235 - mae: 0.1150\n",
      "Epoch 1793/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0234 - mae: 0.1150\n",
      "Epoch 1794/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0228 - mae: 0.1145\n",
      "Epoch 1795/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0225 - mae: 0.1133\n",
      "Epoch 1796/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0235 - mae: 0.1139\n",
      "Epoch 1797/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0229 - mae: 0.1146\n",
      "Epoch 1798/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0241 - mae: 0.1181\n",
      "Epoch 1799/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0228 - mae: 0.1144\n",
      "Epoch 1800/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0227 - mae: 0.1136\n",
      "Epoch 1801/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0228 - mae: 0.1135\n",
      "Epoch 1802/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0224 - mae: 0.1131\n",
      "Epoch 1803/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0224 - mae: 0.1137\n",
      "Epoch 1804/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0227 - mae: 0.1142\n",
      "Epoch 1805/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0230 - mae: 0.1142\n",
      "Epoch 1806/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0221 - mae: 0.1115\n",
      "Epoch 1807/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0228 - mae: 0.1146\n",
      "Epoch 1808/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0239 - mae: 0.1177\n",
      "Epoch 1809/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0243 - mae: 0.1181\n",
      "Epoch 1810/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0227 - mae: 0.1130\n",
      "Epoch 1811/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0227 - mae: 0.1146\n",
      "Epoch 1812/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0231 - mae: 0.1155\n",
      "Epoch 1813/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0230 - mae: 0.1148\n",
      "Epoch 1814/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0231 - mae: 0.1156\n",
      "Epoch 1815/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0223 - mae: 0.1134\n",
      "Epoch 1816/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0220 - mae: 0.1115\n",
      "Epoch 1817/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0225 - mae: 0.1138\n",
      "Epoch 1818/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0221 - mae: 0.1124\n",
      "Epoch 1819/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0229 - mae: 0.1140\n",
      "Epoch 1820/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0232 - mae: 0.1155\n",
      "Epoch 1821/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0220 - mae: 0.1120\n",
      "Epoch 1822/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0229 - mae: 0.1146\n",
      "Epoch 1823/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0227 - mae: 0.1145\n",
      "Epoch 1824/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0233 - mae: 0.1157\n",
      "Epoch 1825/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0224 - mae: 0.1132\n",
      "Epoch 1826/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0225 - mae: 0.1143\n",
      "Epoch 1827/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0227 - mae: 0.1146\n",
      "Epoch 1828/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0218 - mae: 0.1119\n",
      "Epoch 1829/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0230 - mae: 0.1156\n",
      "Epoch 1830/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0221 - mae: 0.1133\n",
      "Epoch 1831/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0224 - mae: 0.1141\n",
      "Epoch 1832/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0216 - mae: 0.1102\n",
      "Epoch 1833/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0217 - mae: 0.1113\n",
      "Epoch 1834/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0215 - mae: 0.1112\n",
      "Epoch 1835/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0216 - mae: 0.1111\n",
      "Epoch 1836/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0212 - mae: 0.1093\n",
      "Epoch 1837/2000\n",
      "2018/2018 [==============================] - 0s 86us/sample - loss: 0.0222 - mae: 0.1128\n",
      "Epoch 1838/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0220 - mae: 0.1124\n",
      "Epoch 1839/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0222 - mae: 0.1140\n",
      "Epoch 1840/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0234 - mae: 0.1164\n",
      "Epoch 1841/2000\n",
      "2018/2018 [==============================] - 0s 122us/sample - loss: 0.0254 - mae: 0.1203\n",
      "Epoch 1842/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0264 - mae: 0.1224\n",
      "Epoch 1843/2000\n",
      "2018/2018 [==============================] - 0s 93us/sample - loss: 0.0231 - mae: 0.1155\n",
      "Epoch 1844/2000\n",
      "2018/2018 [==============================] - 0s 110us/sample - loss: 0.0224 - mae: 0.1139\n",
      "Epoch 1845/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 96us/sample - loss: 0.0227 - mae: 0.1144\n",
      "Epoch 1846/2000\n",
      "2018/2018 [==============================] - 0s 89us/sample - loss: 0.0220 - mae: 0.1121\n",
      "Epoch 1847/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0275 - mae: 0.1249\n",
      "Epoch 1848/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0232 - mae: 0.1164\n",
      "Epoch 1849/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0219 - mae: 0.1124\n",
      "Epoch 1850/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0216 - mae: 0.1121\n",
      "Epoch 1851/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0229 - mae: 0.1146\n",
      "Epoch 1852/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0230 - mae: 0.1142\n",
      "Epoch 1853/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0216 - mae: 0.1111\n",
      "Epoch 1854/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0210 - mae: 0.1098\n",
      "Epoch 1855/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0222 - mae: 0.1132\n",
      "Epoch 1856/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0225 - mae: 0.1126\n",
      "Epoch 1857/2000\n",
      "2018/2018 [==============================] - 0s 87us/sample - loss: 0.0225 - mae: 0.1144\n",
      "Epoch 1858/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0219 - mae: 0.1128\n",
      "Epoch 1859/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0209 - mae: 0.1095\n",
      "Epoch 1860/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0211 - mae: 0.1101\n",
      "Epoch 1861/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0220 - mae: 0.1114\n",
      "Epoch 1862/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0229 - mae: 0.1150\n",
      "Epoch 1863/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0229 - mae: 0.1144\n",
      "Epoch 1864/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0308 - mae: 0.1237\n",
      "Epoch 1865/2000\n",
      "2018/2018 [==============================] - 0s 83us/sample - loss: 0.0221 - mae: 0.1116\n",
      "Epoch 1866/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0232 - mae: 0.1154\n",
      "Epoch 1867/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0216 - mae: 0.1113\n",
      "Epoch 1868/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0222 - mae: 0.1130\n",
      "Epoch 1869/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0216 - mae: 0.1111\n",
      "Epoch 1870/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0250 - mae: 0.1200\n",
      "Epoch 1871/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0229 - mae: 0.1155\n",
      "Epoch 1872/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0220 - mae: 0.1122\n",
      "Epoch 1873/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0217 - mae: 0.1122\n",
      "Epoch 1874/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0221 - mae: 0.1125\n",
      "Epoch 1875/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0233 - mae: 0.1161\n",
      "Epoch 1876/2000\n",
      "2018/2018 [==============================] - 0s 85us/sample - loss: 0.0317 - mae: 0.1361\n",
      "Epoch 1877/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0268 - mae: 0.1252\n",
      "Epoch 1878/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0265 - mae: 0.1232\n",
      "Epoch 1879/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0223 - mae: 0.1135\n",
      "Epoch 1880/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0219 - mae: 0.1126\n",
      "Epoch 1881/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0219 - mae: 0.1123\n",
      "Epoch 1882/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0212 - mae: 0.1105\n",
      "Epoch 1883/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0215 - mae: 0.1116\n",
      "Epoch 1884/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0226 - mae: 0.1139\n",
      "Epoch 1885/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0225 - mae: 0.1140\n",
      "Epoch 1886/2000\n",
      "2018/2018 [==============================] - 0s 84us/sample - loss: 0.0261 - mae: 0.1234\n",
      "Epoch 1887/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0218 - mae: 0.1118\n",
      "Epoch 1888/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0211 - mae: 0.1106\n",
      "Epoch 1889/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0212 - mae: 0.1103\n",
      "Epoch 1890/2000\n",
      "2018/2018 [==============================] - 0s 81us/sample - loss: 0.0215 - mae: 0.1115\n",
      "Epoch 1891/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0228 - mae: 0.1155\n",
      "Epoch 1892/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0223 - mae: 0.1126\n",
      "Epoch 1893/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0209 - mae: 0.1090\n",
      "Epoch 1894/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0207 - mae: 0.1090\n",
      "Epoch 1895/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0206 - mae: 0.1089\n",
      "Epoch 1896/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0215 - mae: 0.1110\n",
      "Epoch 1897/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0208 - mae: 0.1100\n",
      "Epoch 1898/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0219 - mae: 0.1120\n",
      "Epoch 1899/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0239 - mae: 0.1187\n",
      "Epoch 1900/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0219 - mae: 0.1126\n",
      "Epoch 1901/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0244 - mae: 0.1186\n",
      "Epoch 1902/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0224 - mae: 0.1144\n",
      "Epoch 1903/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0220 - mae: 0.1128\n",
      "Epoch 1904/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0222 - mae: 0.1139\n",
      "Epoch 1905/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1124\n",
      "Epoch 1906/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0217 - mae: 0.1117\n",
      "Epoch 1907/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0209 - mae: 0.1087\n",
      "Epoch 1908/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0216 - mae: 0.1106\n",
      "Epoch 1909/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0356 - mae: 0.1439\n",
      "Epoch 1910/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0283 - mae: 0.1306\n",
      "Epoch 1911/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0261 - mae: 0.1246\n",
      "Epoch 1912/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0250 - mae: 0.1211\n",
      "Epoch 1913/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0228 - mae: 0.1156\n",
      "Epoch 1914/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0228 - mae: 0.1154\n",
      "Epoch 1915/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0240 - mae: 0.1180\n",
      "Epoch 1916/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0220 - mae: 0.1127\n",
      "Epoch 1917/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0227 - mae: 0.1149\n",
      "Epoch 1918/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0215 - mae: 0.1116\n",
      "Epoch 1919/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0212 - mae: 0.1098\n",
      "Epoch 1920/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0212 - mae: 0.1103\n",
      "Epoch 1921/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0217 - mae: 0.1110\n",
      "Epoch 1922/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0216 - mae: 0.1114\n",
      "Epoch 1923/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0221 - mae: 0.1125\n",
      "Epoch 1924/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0221 - mae: 0.1130\n",
      "Epoch 1925/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1120\n",
      "Epoch 1926/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0235 - mae: 0.1144\n",
      "Epoch 1927/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0249 - mae: 0.1205\n",
      "Epoch 1928/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0232 - mae: 0.1159\n",
      "Epoch 1929/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0239 - mae: 0.1171\n",
      "Epoch 1930/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0463 - mae: 0.1561\n",
      "Epoch 1931/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0273 - mae: 0.1270\n",
      "Epoch 1932/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0235 - mae: 0.1172\n",
      "Epoch 1933/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0228 - mae: 0.1144\n",
      "Epoch 1934/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0223 - mae: 0.1124\n",
      "Epoch 1935/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0249 - mae: 0.1184\n",
      "Epoch 1936/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0220 - mae: 0.1115\n",
      "Epoch 1937/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0353 - mae: 0.1436\n",
      "Epoch 1938/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0254 - mae: 0.1214\n",
      "Epoch 1939/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0236 - mae: 0.1176\n",
      "Epoch 1940/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0234 - mae: 0.1163\n",
      "Epoch 1941/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0217 - mae: 0.1122\n",
      "Epoch 1942/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0221 - mae: 0.1132\n",
      "Epoch 1943/2000\n",
      "2018/2018 [==============================] - 0s 77us/sample - loss: 0.0285 - mae: 0.1276\n",
      "Epoch 1944/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0271 - mae: 0.1259\n",
      "Epoch 1945/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0253 - mae: 0.1214\n",
      "Epoch 1946/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0241 - mae: 0.1177\n",
      "Epoch 1947/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0233 - mae: 0.1157\n",
      "Epoch 1948/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0231 - mae: 0.1154\n",
      "Epoch 1949/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0228 - mae: 0.1143\n",
      "Epoch 1950/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0220 - mae: 0.1125\n",
      "Epoch 1951/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1125\n",
      "Epoch 1952/2000\n",
      "2018/2018 [==============================] - 0s 82us/sample - loss: 0.0249 - mae: 0.1194\n",
      "Epoch 1953/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0242 - mae: 0.1176\n",
      "Epoch 1954/2000\n",
      "2018/2018 [==============================] - 0s 78us/sample - loss: 0.0232 - mae: 0.1148\n",
      "Epoch 1955/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0226 - mae: 0.1137\n",
      "Epoch 1956/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0222 - mae: 0.1131\n",
      "Epoch 1957/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0233 - mae: 0.1156\n",
      "Epoch 1958/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0223 - mae: 0.1122\n",
      "Epoch 1959/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0216 - mae: 0.1112\n",
      "Epoch 1960/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0212 - mae: 0.1103\n",
      "Epoch 1961/2000\n",
      "2018/2018 [==============================] - 0s 70us/sample - loss: 0.0214 - mae: 0.1108\n",
      "Epoch 1962/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1119\n",
      "Epoch 1963/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0217 - mae: 0.1113\n",
      "Epoch 1964/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0221 - mae: 0.1114\n",
      "Epoch 1965/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0227 - mae: 0.1143\n",
      "Epoch 1966/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0239 - mae: 0.1177\n",
      "Epoch 1967/2000\n",
      "2018/2018 [==============================] - 0s 69us/sample - loss: 0.0210 - mae: 0.1102\n",
      "Epoch 1968/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0209 - mae: 0.1096\n",
      "Epoch 1969/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0211 - mae: 0.1097\n",
      "Epoch 1970/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0218 - mae: 0.1126\n",
      "Epoch 1971/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0207 - mae: 0.1095\n",
      "Epoch 1972/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0219 - mae: 0.1118\n",
      "Epoch 1973/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0220 - mae: 0.1135\n",
      "Epoch 1974/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0213 - mae: 0.1103\n",
      "Epoch 1975/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0220 - mae: 0.1125\n",
      "Epoch 1976/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0227 - mae: 0.1145\n",
      "Epoch 1977/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0217 - mae: 0.1113\n",
      "Epoch 1978/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0210 - mae: 0.1104\n",
      "Epoch 1979/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0211 - mae: 0.1098\n",
      "Epoch 1980/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0208 - mae: 0.1092\n",
      "Epoch 1981/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0215 - mae: 0.1108\n",
      "Epoch 1982/2000\n",
      "2018/2018 [==============================] - 0s 71us/sample - loss: 0.0216 - mae: 0.1114\n",
      "Epoch 1983/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0217 - mae: 0.1123\n",
      "Epoch 1984/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0221 - mae: 0.1131\n",
      "Epoch 1985/2000\n",
      "2018/2018 [==============================] - 0s 75us/sample - loss: 0.0220 - mae: 0.1126\n",
      "Epoch 1986/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0215 - mae: 0.1101\n",
      "Epoch 1987/2000\n",
      "2018/2018 [==============================] - 0s 76us/sample - loss: 0.0224 - mae: 0.1142\n",
      "Epoch 1988/2000\n",
      "2018/2018 [==============================] - 0s 79us/sample - loss: 0.0211 - mae: 0.1099\n",
      "Epoch 1989/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0236 - mae: 0.1174\n",
      "Epoch 1990/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0210 - mae: 0.1097\n",
      "Epoch 1991/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0209 - mae: 0.1092\n",
      "Epoch 1992/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0213 - mae: 0.1100\n",
      "Epoch 1993/2000\n",
      "2018/2018 [==============================] - 0s 73us/sample - loss: 0.0207 - mae: 0.1087\n",
      "Epoch 1994/2000\n",
      "2018/2018 [==============================] - 0s 74us/sample - loss: 0.0204 - mae: 0.1088\n",
      "Epoch 1995/2000\n",
      "2018/2018 [==============================] - 0s 72us/sample - loss: 0.0222 - mae: 0.1129\n",
      "Epoch 1996/2000\n",
      "2018/2018 [==============================] - 0s 80us/sample - loss: 0.0209 - mae: 0.1089\n",
      "Epoch 1997/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0211 - mae: 0.1108\n",
      "Epoch 1998/2000\n",
      "2018/2018 [==============================] - 0s 88us/sample - loss: 0.0216 - mae: 0.1111\n",
      "Epoch 1999/2000\n",
      "2018/2018 [==============================] - 0s 121us/sample - loss: 0.0219 - mae: 0.1126\n",
      "Epoch 2000/2000\n",
      "2018/2018 [==============================] - 0s 104us/sample - loss: 0.0222 - mae: 0.1129\n",
      "mae: 0.11770293861627579\n",
      "Overfit mae: 0.10932701826095581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2019 samples\n",
      "Epoch 1/2000\n",
      "2019/2019 [==============================] - 1s 636us/sample - loss: 34877.3281 - mae: 26.3559\n",
      "Epoch 2/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 2707.4368 - mae: 11.9398\n",
      "Epoch 3/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 1477.0022 - mae: 10.1110\n",
      "Epoch 4/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 2131.9067 - mae: 10.1947\n",
      "Epoch 5/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 1224.9525 - mae: 8.6344\n",
      "Epoch 6/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 1350.6781 - mae: 8.7132\n",
      "Epoch 7/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 2298.2214 - mae: 11.4389\n",
      "Epoch 8/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 2558.7925 - mae: 10.2683\n",
      "Epoch 9/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 3799.2135 - mae: 13.1791\n",
      "Epoch 10/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 740.9773 - mae: 8.2224\n",
      "Epoch 11/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 2356.1358 - mae: 8.5058\n",
      "Epoch 12/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 4311.4341 - mae: 9.4556\n",
      "Epoch 13/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 2748.8597 - mae: 11.0151\n",
      "Epoch 14/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 43672.8236 - mae: 33.5888\n",
      "Epoch 15/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 13829.4391 - mae: 26.4125\n",
      "Epoch 16/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 3107.7101 - mae: 9.6002\n",
      "Epoch 17/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 535.7117 - mae: 5.0847\n",
      "Epoch 18/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 499.8925 - mae: 4.7852\n",
      "Epoch 19/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 365.6951 - mae: 4.1817\n",
      "Epoch 20/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 108.7972 - mae: 3.3522\n",
      "Epoch 21/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 107.4475 - mae: 3.0990\n",
      "Epoch 22/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 166.2289 - mae: 3.6434\n",
      "Epoch 23/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 38.4786 - mae: 2.5536\n",
      "Epoch 24/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 48.3686 - mae: 2.5410\n",
      "Epoch 25/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 45.6326 - mae: 2.4720\n",
      "Epoch 26/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 82.2188 - mae: 2.8507\n",
      "Epoch 27/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 47.0287 - mae: 2.3994\n",
      "Epoch 28/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 43.2142 - mae: 2.3083\n",
      "Epoch 29/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 46.6591 - mae: 2.5172\n",
      "Epoch 30/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 33.3975 - mae: 2.2835\n",
      "Epoch 31/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 76.7680 - mae: 2.8082\n",
      "Epoch 32/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 111.5237 - mae: 2.5242\n",
      "Epoch 33/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 27.2384 - mae: 2.0963\n",
      "Epoch 34/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 13.4945 - mae: 1.7431\n",
      "Epoch 35/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 33.7899 - mae: 2.0475\n",
      "Epoch 36/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 18.3186 - mae: 1.7618\n",
      "Epoch 37/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 722.5395 - mae: 4.8829\n",
      "Epoch 38/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 295.8151 - mae: 4.4858\n",
      "Epoch 39/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 595.3032 - mae: 4.5023\n",
      "Epoch 40/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 2772.3838 - mae: 9.5095\n",
      "Epoch 41/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 6978.4629 - mae: 16.3788\n",
      "Epoch 42/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 3295.9272 - mae: 8.7698\n",
      "Epoch 43/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 329.4387 - mae: 3.6429\n",
      "Epoch 44/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 281.6718 - mae: 2.8978\n",
      "Epoch 45/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1852.9719 - mae: 5.7708\n",
      "Epoch 46/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 616.9431 - mae: 3.6945\n",
      "Epoch 47/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 489.2133 - mae: 3.8925\n",
      "Epoch 48/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 1874.7890 - mae: 6.6006\n",
      "Epoch 49/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 191.9777 - mae: 3.5138\n",
      "Epoch 50/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 132.1716 - mae: 2.5904\n",
      "Epoch 51/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 62.2720 - mae: 2.0894\n",
      "Epoch 52/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 116.4773 - mae: 2.5245\n",
      "Epoch 53/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 810.7466 - mae: 3.6628\n",
      "Epoch 54/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 48.4861 - mae: 1.9512\n",
      "Epoch 55/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 34.7186 - mae: 1.7333\n",
      "Epoch 56/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 89.1476 - mae: 2.3263\n",
      "Epoch 57/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 166.8361 - mae: 2.1839\n",
      "Epoch 58/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 40.4224 - mae: 1.8607\n",
      "Epoch 59/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 47.8942 - mae: 1.9105\n",
      "Epoch 60/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 59.1032 - mae: 1.7290\n",
      "Epoch 61/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 51.8093 - mae: 1.8447\n",
      "Epoch 62/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 155.7730 - mae: 2.4570\n",
      "Epoch 63/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 39.7852 - mae: 1.6020\n",
      "Epoch 64/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 21.1684 - mae: 1.3677\n",
      "Epoch 65/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 25.4917 - mae: 1.3534\n",
      "Epoch 66/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 17.9999 - mae: 1.3155\n",
      "Epoch 67/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 12.2622 - mae: 1.2840\n",
      "Epoch 68/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 78.6574 - mae: 1.9018\n",
      "Epoch 69/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 72.8649 - mae: 1.8832\n",
      "Epoch 70/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 23.0086 - mae: 1.5964\n",
      "Epoch 71/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 25.2313 - mae: 1.3965\n",
      "Epoch 72/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 10.5282 - mae: 1.2936\n",
      "Epoch 73/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 12.2394 - mae: 1.2070\n",
      "Epoch 74/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 43.4836 - mae: 1.6551\n",
      "Epoch 75/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 13.9142 - mae: 1.2688\n",
      "Epoch 76/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 47.1276 - mae: 1.5082\n",
      "Epoch 77/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 79.2578 - mae: 1.7116\n",
      "Epoch 78/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 73us/sample - loss: 23.4512 - mae: 1.4312\n",
      "Epoch 79/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 142.2750 - mae: 1.9331\n",
      "Epoch 80/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 3876.5305 - mae: 9.6856\n",
      "Epoch 81/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 925.8427 - mae: 5.7186\n",
      "Epoch 82/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 514.0832 - mae: 3.9473\n",
      "Epoch 83/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 69.6289 - mae: 2.2948\n",
      "Epoch 84/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 173.7602 - mae: 3.0143\n",
      "Epoch 85/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 42.0918 - mae: 1.8471\n",
      "Epoch 86/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 33.4598 - mae: 1.6600\n",
      "Epoch 87/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 18.4741 - mae: 1.3951\n",
      "Epoch 88/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 13.8254 - mae: 1.3034\n",
      "Epoch 89/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 14.2847 - mae: 1.2939\n",
      "Epoch 90/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 11.1917 - mae: 1.2148\n",
      "Epoch 91/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 16.5041 - mae: 1.3383\n",
      "Epoch 92/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 10.1044 - mae: 1.1556\n",
      "Epoch 93/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 16.7712 - mae: 1.2116\n",
      "Epoch 94/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 8.6222 - mae: 1.1072\n",
      "Epoch 95/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 8.2996 - mae: 1.1190\n",
      "Epoch 96/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 22.8363 - mae: 1.2783\n",
      "Epoch 97/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 212.0137 - mae: 2.1888\n",
      "Epoch 98/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 46.4796 - mae: 1.8159\n",
      "Epoch 99/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 115.4419 - mae: 2.0682\n",
      "Epoch 100/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 87.9228 - mae: 1.9507\n",
      "Epoch 101/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 286.2658 - mae: 2.3945\n",
      "Epoch 102/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 681.8865 - mae: 2.6885\n",
      "Epoch 103/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 163.0840 - mae: 2.3362\n",
      "Epoch 104/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 617.8238 - mae: 4.1552\n",
      "Epoch 105/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 912.3195 - mae: 4.1996\n",
      "Epoch 106/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 562.5291 - mae: 3.1109\n",
      "Epoch 107/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 90.6213 - mae: 1.8525\n",
      "Epoch 108/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 49.7395 - mae: 1.6459\n",
      "Epoch 109/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 15.6771 - mae: 1.1276\n",
      "Epoch 110/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 19.7846 - mae: 1.0725\n",
      "Epoch 111/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 28.8593 - mae: 1.2013\n",
      "Epoch 112/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 36.6184 - mae: 1.1874\n",
      "Epoch 113/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 9.7589 - mae: 0.9590\n",
      "Epoch 114/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 5.1286 - mae: 0.8308\n",
      "Epoch 115/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 4.4770 - mae: 0.8166\n",
      "Epoch 116/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 4.6209 - mae: 0.8177\n",
      "Epoch 117/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 3.5524 - mae: 0.7628\n",
      "Epoch 118/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 5.2952 - mae: 0.7778\n",
      "Epoch 119/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 6.4179 - mae: 0.8067\n",
      "Epoch 120/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 10.7444 - mae: 0.8331\n",
      "Epoch 121/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 14.8091 - mae: 0.9896\n",
      "Epoch 122/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 19.3361 - mae: 1.0542\n",
      "Epoch 123/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 123.8468 - mae: 2.3379\n",
      "Epoch 124/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 30.9714 - mae: 1.6859\n",
      "Epoch 125/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 22.0474 - mae: 1.4304\n",
      "Epoch 126/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 39.5947 - mae: 1.4184\n",
      "Epoch 127/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 174.3895 - mae: 1.7774\n",
      "Epoch 128/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 238.3558 - mae: 2.6812\n",
      "Epoch 129/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 151.2022 - mae: 2.4882\n",
      "Epoch 130/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 135.5500 - mae: 1.8367\n",
      "Epoch 131/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 60.5060 - mae: 1.6068\n",
      "Epoch 132/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 34.0824 - mae: 1.4337\n",
      "Epoch 133/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 20.1915 - mae: 1.1061\n",
      "Epoch 134/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 4.5215 - mae: 0.8472\n",
      "Epoch 135/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 4.0550 - mae: 0.7644\n",
      "Epoch 136/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 2.8117 - mae: 0.6883\n",
      "Epoch 137/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 2.8278 - mae: 0.6772\n",
      "Epoch 138/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 2.6202 - mae: 0.6501\n",
      "Epoch 139/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 2.1540 - mae: 0.6312\n",
      "Epoch 140/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 2.6441 - mae: 0.6346\n",
      "Epoch 141/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 2.2082 - mae: 0.6119\n",
      "Epoch 142/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 3.2177 - mae: 0.6405\n",
      "Epoch 143/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 2.3848 - mae: 0.6037\n",
      "Epoch 144/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 3.1086 - mae: 0.6569\n",
      "Epoch 145/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 5.9719 - mae: 0.7714\n",
      "Epoch 146/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 10.1922 - mae: 1.0871\n",
      "Epoch 147/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 5.7104 - mae: 0.7729\n",
      "Epoch 148/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 6.6842 - mae: 0.7350\n",
      "Epoch 149/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 15.3902 - mae: 1.0114\n",
      "Epoch 150/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 3.8217 - mae: 0.6543\n",
      "Epoch 151/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 2.2907 - mae: 0.5448\n",
      "Epoch 152/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 2.5712 - mae: 0.5443\n",
      "Epoch 153/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 1.6287 - mae: 0.4954\n",
      "Epoch 154/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 1.9137 - mae: 0.5313\n",
      "Epoch 155/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 2.2235 - mae: 0.5557\n",
      "Epoch 156/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 2.1055 - mae: 0.5304\n",
      "Epoch 157/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 3.6621 - mae: 0.5703\n",
      "Epoch 158/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 2.1463 - mae: 0.5356\n",
      "Epoch 159/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 31.8642 - mae: 1.5809\n",
      "Epoch 160/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 37.3075 - mae: 1.6894\n",
      "Epoch 161/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 45.2482 - mae: 1.4126\n",
      "Epoch 162/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 88.4707 - mae: 1.3535\n",
      "Epoch 163/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 98.2488 - mae: 2.3633\n",
      "Epoch 164/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 72.8891 - mae: 2.1730\n",
      "Epoch 165/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 64.8368 - mae: 1.4704\n",
      "Epoch 166/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 86.6882 - mae: 1.9912\n",
      "Epoch 167/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 33.1258 - mae: 1.0087\n",
      "Epoch 168/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 17.0597 - mae: 0.8373\n",
      "Epoch 169/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 22.3523 - mae: 0.8172\n",
      "Epoch 170/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 89.1983 - mae: 1.1198\n",
      "Epoch 171/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 10.4887 - mae: 0.8896\n",
      "Epoch 172/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 3.9279 - mae: 0.6158\n",
      "Epoch 173/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 5.4591 - mae: 0.5522\n",
      "Epoch 174/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1.2474 - mae: 0.4430\n",
      "Epoch 175/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 1.2446 - mae: 0.4042\n",
      "Epoch 176/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 1.1530 - mae: 0.3930\n",
      "Epoch 177/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 2.2187 - mae: 0.4240\n",
      "Epoch 178/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 1.0844 - mae: 0.3833\n",
      "Epoch 179/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.2025 - mae: 0.3942\n",
      "Epoch 180/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.0698 - mae: 0.3706\n",
      "Epoch 181/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.9280 - mae: 0.3532\n",
      "Epoch 182/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.9507 - mae: 0.3598\n",
      "Epoch 183/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.8678 - mae: 0.3395\n",
      "Epoch 184/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.8250 - mae: 0.3326\n",
      "Epoch 185/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.7776 - mae: 0.3245\n",
      "Epoch 186/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.8117 - mae: 0.3286\n",
      "Epoch 187/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.9877 - mae: 0.3661\n",
      "Epoch 188/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.7900 - mae: 0.3220\n",
      "Epoch 189/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.9205 - mae: 0.3458\n",
      "Epoch 190/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.9232 - mae: 0.3350\n",
      "Epoch 191/2000\n",
      "2019/2019 [==============================] - 0s 100us/sample - loss: 1.4763 - mae: 0.3873\n",
      "Epoch 192/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 2.6143 - mae: 0.4246\n",
      "Epoch 193/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 1.6176 - mae: 0.3972\n",
      "Epoch 194/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1.7834 - mae: 0.4137\n",
      "Epoch 195/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 1.6946 - mae: 0.3906\n",
      "Epoch 196/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 2.7345 - mae: 0.4291\n",
      "Epoch 197/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 2.7789 - mae: 0.4632\n",
      "Epoch 198/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 40.7684 - mae: 1.0485\n",
      "Epoch 199/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 7.5150 - mae: 0.5523\n",
      "Epoch 200/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 3.0624 - mae: 0.4496\n",
      "Epoch 201/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 100.2627 - mae: 0.8432\n",
      "Epoch 202/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 124.1816 - mae: 0.9913\n",
      "Epoch 203/2000\n",
      "2019/2019 [==============================] - 0s 102us/sample - loss: 4.2600 - mae: 0.4987\n",
      "Epoch 204/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 4.5222 - mae: 0.4703\n",
      "Epoch 205/2000\n",
      "2019/2019 [==============================] - 0s 97us/sample - loss: 3.9761 - mae: 0.5157\n",
      "Epoch 206/2000\n",
      "2019/2019 [==============================] - 0s 126us/sample - loss: 27.4334 - mae: 0.9326\n",
      "Epoch 207/2000\n",
      "2019/2019 [==============================] - 0s 105us/sample - loss: 23.2050 - mae: 0.9876\n",
      "Epoch 208/2000\n",
      "2019/2019 [==============================] - 0s 98us/sample - loss: 42.9445 - mae: 0.8768\n",
      "Epoch 209/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 35.5043 - mae: 1.5302\n",
      "Epoch 210/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 3.5742 - mae: 0.7206\n",
      "Epoch 211/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 1.3419 - mae: 0.4158\n",
      "Epoch 212/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.9242 - mae: 0.3608\n",
      "Epoch 213/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.8292 - mae: 0.3467\n",
      "Epoch 214/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.7681 - mae: 0.3289\n",
      "Epoch 215/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.6833 - mae: 0.3077\n",
      "Epoch 216/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.6848 - mae: 0.3029\n",
      "Epoch 217/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.6737 - mae: 0.2967\n",
      "Epoch 218/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.6522 - mae: 0.2897\n",
      "Epoch 219/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.6309 - mae: 0.2815\n",
      "Epoch 220/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.6143 - mae: 0.2757\n",
      "Epoch 221/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.6079 - mae: 0.2727\n",
      "Epoch 222/2000\n",
      "2019/2019 [==============================] - 0s 132us/sample - loss: 0.6126 - mae: 0.2723\n",
      "Epoch 223/2000\n",
      "2019/2019 [==============================] - 0s 96us/sample - loss: 0.6218 - mae: 0.2756\n",
      "Epoch 224/2000\n",
      "2019/2019 [==============================] - 0s 123us/sample - loss: 0.6093 - mae: 0.2692\n",
      "Epoch 225/2000\n",
      "2019/2019 [==============================] - 0s 98us/sample - loss: 0.6044 - mae: 0.2643\n",
      "Epoch 226/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.6422 - mae: 0.2729\n",
      "Epoch 227/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.8080 - mae: 0.3055\n",
      "Epoch 228/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.7337 - mae: 0.2952\n",
      "Epoch 229/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.6102 - mae: 0.2577\n",
      "Epoch 230/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.7308 - mae: 0.2808\n",
      "Epoch 231/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 1.1660 - mae: 0.3155\n",
      "Epoch 232/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 2.2067 - mae: 0.3775\n",
      "Epoch 233/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 2.0827 - mae: 0.3578\n",
      "Epoch 234/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 94us/sample - loss: 2.2284 - mae: 0.4388\n",
      "Epoch 235/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 1.9361 - mae: 0.4337\n",
      "Epoch 236/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 1.2159 - mae: 0.3098\n",
      "Epoch 237/2000\n",
      "2019/2019 [==============================] - 0s 120us/sample - loss: 1.4045 - mae: 0.3957\n",
      "Epoch 238/2000\n",
      "2019/2019 [==============================] - 0s 110us/sample - loss: 1.5308 - mae: 0.3559\n",
      "Epoch 239/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 1.4886 - mae: 0.3590\n",
      "Epoch 240/2000\n",
      "2019/2019 [==============================] - 0s 96us/sample - loss: 1.4127 - mae: 0.3320\n",
      "Epoch 241/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 1.4787 - mae: 0.3589\n",
      "Epoch 242/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 1.7509 - mae: 0.3929\n",
      "Epoch 243/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 1.2544 - mae: 0.3571\n",
      "Epoch 244/2000\n",
      "2019/2019 [==============================] - 0s 94us/sample - loss: 1.0621 - mae: 0.2929\n",
      "Epoch 245/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.8341 - mae: 0.2737\n",
      "Epoch 246/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.8135 - mae: 0.2967\n",
      "Epoch 247/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.6945 - mae: 0.2685\n",
      "Epoch 248/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.7993 - mae: 0.2858\n",
      "Epoch 249/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 1.0994 - mae: 0.3106\n",
      "Epoch 250/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 1.8202 - mae: 0.4182\n",
      "Epoch 251/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 1.8303 - mae: 0.3660\n",
      "Epoch 252/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 3.8279 - mae: 0.5536\n",
      "Epoch 253/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 2.5716 - mae: 0.5219\n",
      "Epoch 254/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.2634 - mae: 0.3856\n",
      "Epoch 255/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.8090 - mae: 0.3111\n",
      "Epoch 256/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.7131 - mae: 0.2857\n",
      "Epoch 257/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.6008 - mae: 0.2586\n",
      "Epoch 258/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.6473 - mae: 0.2712\n",
      "Epoch 259/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.7280 - mae: 0.2678\n",
      "Epoch 260/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.1117 - mae: 0.3131\n",
      "Epoch 261/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1.5045 - mae: 0.3317\n",
      "Epoch 262/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 2.2871 - mae: 0.4562\n",
      "Epoch 263/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 2.0092 - mae: 0.3779\n",
      "Epoch 264/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1.8217 - mae: 0.3540\n",
      "Epoch 265/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 2.1390 - mae: 0.5009\n",
      "Epoch 266/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.9574 - mae: 0.3428\n",
      "Epoch 267/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.6832 - mae: 0.3013\n",
      "Epoch 268/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5878 - mae: 0.2589\n",
      "Epoch 269/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5625 - mae: 0.2563\n",
      "Epoch 270/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5260 - mae: 0.2432\n",
      "Epoch 271/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5306 - mae: 0.2446\n",
      "Epoch 272/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5085 - mae: 0.2313\n",
      "Epoch 273/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4974 - mae: 0.2265\n",
      "Epoch 274/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4893 - mae: 0.2215\n",
      "Epoch 275/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.5035 - mae: 0.2278\n",
      "Epoch 276/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4869 - mae: 0.2203\n",
      "Epoch 277/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4865 - mae: 0.2196\n",
      "Epoch 278/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4848 - mae: 0.2180\n",
      "Epoch 279/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4834 - mae: 0.2197\n",
      "Epoch 280/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4841 - mae: 0.2185\n",
      "Epoch 281/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.4825 - mae: 0.2190\n",
      "Epoch 282/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.4764 - mae: 0.2143\n",
      "Epoch 283/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.4780 - mae: 0.2162\n",
      "Epoch 284/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4854 - mae: 0.2177\n",
      "Epoch 285/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4802 - mae: 0.2144\n",
      "Epoch 286/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4766 - mae: 0.2148\n",
      "Epoch 287/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5128 - mae: 0.2257\n",
      "Epoch 288/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.6302 - mae: 0.2391\n",
      "Epoch 289/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 2.5124 - mae: 0.4350\n",
      "Epoch 290/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 2.6522 - mae: 0.5115\n",
      "Epoch 291/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 4.4426 - mae: 0.4965\n",
      "Epoch 292/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 2.1616 - mae: 0.3915\n",
      "Epoch 293/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 1.4792 - mae: 0.3500\n",
      "Epoch 294/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 2.8437 - mae: 0.3459\n",
      "Epoch 295/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.3605 - mae: 0.3984\n",
      "Epoch 296/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 21.9194 - mae: 0.6477\n",
      "Epoch 297/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.7237 - mae: 0.3199\n",
      "Epoch 298/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 3.3614 - mae: 0.4889\n",
      "Epoch 299/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 2.6823 - mae: 0.4129\n",
      "Epoch 300/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.6701 - mae: 0.2874\n",
      "Epoch 301/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4975 - mae: 0.2506\n",
      "Epoch 302/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4644 - mae: 0.2422\n",
      "Epoch 303/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4526 - mae: 0.2321\n",
      "Epoch 304/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4474 - mae: 0.2261\n",
      "Epoch 305/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4424 - mae: 0.2223\n",
      "Epoch 306/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4393 - mae: 0.2184\n",
      "Epoch 307/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4367 - mae: 0.2161\n",
      "Epoch 308/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4346 - mae: 0.2144\n",
      "Epoch 309/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4328 - mae: 0.2133\n",
      "Epoch 310/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4309 - mae: 0.2114\n",
      "Epoch 311/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4293 - mae: 0.2109\n",
      "Epoch 312/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4276 - mae: 0.2095\n",
      "Epoch 313/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4260 - mae: 0.2084\n",
      "Epoch 314/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4247 - mae: 0.2076\n",
      "Epoch 315/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4230 - mae: 0.2068\n",
      "Epoch 316/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.4217 - mae: 0.2070\n",
      "Epoch 317/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4201 - mae: 0.2062\n",
      "Epoch 318/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4185 - mae: 0.2054\n",
      "Epoch 319/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4171 - mae: 0.2057\n",
      "Epoch 320/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4154 - mae: 0.2046\n",
      "Epoch 321/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4140 - mae: 0.2046\n",
      "Epoch 322/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4124 - mae: 0.2036\n",
      "Epoch 323/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4110 - mae: 0.2033\n",
      "Epoch 324/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.4095 - mae: 0.2028\n",
      "Epoch 325/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4079 - mae: 0.2026\n",
      "Epoch 326/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4077 - mae: 0.2026\n",
      "Epoch 327/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4823 - mae: 0.2154\n",
      "Epoch 328/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4049 - mae: 0.2037\n",
      "Epoch 329/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4022 - mae: 0.2017\n",
      "Epoch 330/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4004 - mae: 0.2005\n",
      "Epoch 331/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3990 - mae: 0.2007\n",
      "Epoch 332/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3971 - mae: 0.1996\n",
      "Epoch 333/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3954 - mae: 0.1991\n",
      "Epoch 334/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.3945 - mae: 0.1998\n",
      "Epoch 335/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3922 - mae: 0.1993\n",
      "Epoch 336/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3905 - mae: 0.1978\n",
      "Epoch 337/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.3889 - mae: 0.1986\n",
      "Epoch 338/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.3870 - mae: 0.1974\n",
      "Epoch 339/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.3852 - mae: 0.1970\n",
      "Epoch 340/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.3834 - mae: 0.1966\n",
      "Epoch 341/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3816 - mae: 0.1960\n",
      "Epoch 342/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.3799 - mae: 0.1956\n",
      "Epoch 343/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3783 - mae: 0.1954\n",
      "Epoch 344/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.3762 - mae: 0.1949\n",
      "Epoch 345/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.3742 - mae: 0.1939\n",
      "Epoch 346/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.3724 - mae: 0.1939\n",
      "Epoch 347/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.3702 - mae: 0.1927\n",
      "Epoch 348/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.3684 - mae: 0.1919\n",
      "Epoch 349/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.3669 - mae: 0.1921\n",
      "Epoch 350/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.3638 - mae: 0.1902\n",
      "Epoch 351/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.3622 - mae: 0.1896\n",
      "Epoch 352/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3600 - mae: 0.1880\n",
      "Epoch 353/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3587 - mae: 0.1889\n",
      "Epoch 354/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3561 - mae: 0.1885\n",
      "Epoch 355/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3542 - mae: 0.1872\n",
      "Epoch 356/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3525 - mae: 0.1868\n",
      "Epoch 357/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.3499 - mae: 0.1857\n",
      "Epoch 358/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.3484 - mae: 0.1856\n",
      "Epoch 359/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3464 - mae: 0.1853\n",
      "Epoch 360/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3502 - mae: 0.1929\n",
      "Epoch 361/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3428 - mae: 0.1846\n",
      "Epoch 362/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.3404 - mae: 0.1841\n",
      "Epoch 363/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3386 - mae: 0.1841\n",
      "Epoch 364/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3363 - mae: 0.1829\n",
      "Epoch 365/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3344 - mae: 0.1822\n",
      "Epoch 366/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3331 - mae: 0.1836\n",
      "Epoch 367/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.3308 - mae: 0.1823\n",
      "Epoch 368/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3284 - mae: 0.1816\n",
      "Epoch 369/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.3265 - mae: 0.1811\n",
      "Epoch 370/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3244 - mae: 0.1807\n",
      "Epoch 371/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3227 - mae: 0.1808\n",
      "Epoch 372/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3206 - mae: 0.1810\n",
      "Epoch 373/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.3176 - mae: 0.1789\n",
      "Epoch 374/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3156 - mae: 0.1792\n",
      "Epoch 375/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.3141 - mae: 0.1800\n",
      "Epoch 376/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3122 - mae: 0.1802\n",
      "Epoch 377/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3122 - mae: 0.1830\n",
      "Epoch 378/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3084 - mae: 0.1800\n",
      "Epoch 379/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3056 - mae: 0.1785\n",
      "Epoch 380/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3057 - mae: 0.1817\n",
      "Epoch 381/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3017 - mae: 0.1786\n",
      "Epoch 382/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3020 - mae: 0.1820\n",
      "Epoch 383/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2964 - mae: 0.1768\n",
      "Epoch 384/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2933 - mae: 0.1748\n",
      "Epoch 385/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2929 - mae: 0.1787\n",
      "Epoch 386/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.2908 - mae: 0.1766\n",
      "Epoch 387/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2876 - mae: 0.1752\n",
      "Epoch 388/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.2895 - mae: 0.1819\n",
      "Epoch 389/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2843 - mae: 0.1770\n",
      "Epoch 390/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2821 - mae: 0.1767\n",
      "Epoch 391/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2791 - mae: 0.1745\n",
      "Epoch 392/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2784 - mae: 0.1778\n",
      "Epoch 393/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2741 - mae: 0.1729\n",
      "Epoch 394/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2728 - mae: 0.1737\n",
      "Epoch 395/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2698 - mae: 0.1729\n",
      "Epoch 396/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2670 - mae: 0.1728\n",
      "Epoch 397/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.2644 - mae: 0.1716\n",
      "Epoch 398/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2633 - mae: 0.1723\n",
      "Epoch 399/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.2606 - mae: 0.1719\n",
      "Epoch 400/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2574 - mae: 0.1702\n",
      "Epoch 401/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2561 - mae: 0.1711\n",
      "Epoch 402/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2547 - mae: 0.1725\n",
      "Epoch 403/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2522 - mae: 0.1727\n",
      "Epoch 404/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2516 - mae: 0.1743\n",
      "Epoch 405/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2480 - mae: 0.1725\n",
      "Epoch 406/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2450 - mae: 0.1710\n",
      "Epoch 407/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2430 - mae: 0.1713\n",
      "Epoch 408/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.2401 - mae: 0.1703\n",
      "Epoch 409/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2376 - mae: 0.1695\n",
      "Epoch 410/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.2348 - mae: 0.1696\n",
      "Epoch 411/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2324 - mae: 0.1680\n",
      "Epoch 412/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2315 - mae: 0.1721\n",
      "Epoch 413/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2288 - mae: 0.1696\n",
      "Epoch 414/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2262 - mae: 0.1688\n",
      "Epoch 415/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2235 - mae: 0.1681\n",
      "Epoch 416/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2218 - mae: 0.1687\n",
      "Epoch 417/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2191 - mae: 0.1682\n",
      "Epoch 418/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2161 - mae: 0.1656\n",
      "Epoch 419/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.2144 - mae: 0.1679\n",
      "Epoch 420/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2112 - mae: 0.1648\n",
      "Epoch 421/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.2099 - mae: 0.1674\n",
      "Epoch 422/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2062 - mae: 0.1649\n",
      "Epoch 423/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2041 - mae: 0.1644\n",
      "Epoch 424/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2012 - mae: 0.1631\n",
      "Epoch 425/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1991 - mae: 0.1632\n",
      "Epoch 426/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1965 - mae: 0.1629\n",
      "Epoch 427/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1948 - mae: 0.1640\n",
      "Epoch 428/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1927 - mae: 0.1643\n",
      "Epoch 429/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1897 - mae: 0.1624\n",
      "Epoch 430/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1926 - mae: 0.1717\n",
      "Epoch 431/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1864 - mae: 0.1657\n",
      "Epoch 432/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1840 - mae: 0.1641\n",
      "Epoch 433/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1805 - mae: 0.1614\n",
      "Epoch 434/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1792 - mae: 0.1645\n",
      "Epoch 435/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1764 - mae: 0.1616\n",
      "Epoch 436/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1759 - mae: 0.1644\n",
      "Epoch 437/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1723 - mae: 0.1620\n",
      "Epoch 438/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1696 - mae: 0.1611\n",
      "Epoch 439/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1691 - mae: 0.1657\n",
      "Epoch 440/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1658 - mae: 0.1613\n",
      "Epoch 441/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1627 - mae: 0.1586\n",
      "Epoch 442/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1614 - mae: 0.1609\n",
      "Epoch 443/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1587 - mae: 0.1588\n",
      "Epoch 444/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1583 - mae: 0.1622\n",
      "Epoch 445/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1556 - mae: 0.1605\n",
      "Epoch 446/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1541 - mae: 0.1616\n",
      "Epoch 447/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1509 - mae: 0.1589\n",
      "Epoch 448/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1497 - mae: 0.1617\n",
      "Epoch 449/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1468 - mae: 0.1604\n",
      "Epoch 450/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1440 - mae: 0.1580\n",
      "Epoch 451/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1423 - mae: 0.1585\n",
      "Epoch 452/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1400 - mae: 0.1581\n",
      "Epoch 453/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1380 - mae: 0.1580\n",
      "Epoch 454/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1393 - mae: 0.1642\n",
      "Epoch 455/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1347 - mae: 0.1586\n",
      "Epoch 456/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1326 - mae: 0.1579\n",
      "Epoch 457/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1301 - mae: 0.1564\n",
      "Epoch 458/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1280 - mae: 0.1567\n",
      "Epoch 459/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1269 - mae: 0.1577\n",
      "Epoch 460/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1263 - mae: 0.1600\n",
      "Epoch 461/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1245 - mae: 0.1601\n",
      "Epoch 462/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1215 - mae: 0.1570\n",
      "Epoch 463/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1201 - mae: 0.1573\n",
      "Epoch 464/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1173 - mae: 0.1549\n",
      "Epoch 465/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1154 - mae: 0.1559\n",
      "Epoch 466/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1133 - mae: 0.1537\n",
      "Epoch 467/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1114 - mae: 0.1537\n",
      "Epoch 468/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1095 - mae: 0.1539\n",
      "Epoch 469/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1079 - mae: 0.1532\n",
      "Epoch 470/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1061 - mae: 0.1523\n",
      "Epoch 471/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1143 - mae: 0.1657\n",
      "Epoch 472/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1224 - mae: 0.1936\n",
      "Epoch 473/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1083 - mae: 0.1673\n",
      "Epoch 474/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1027 - mae: 0.1543\n",
      "Epoch 475/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1000 - mae: 0.1524\n",
      "Epoch 476/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0981 - mae: 0.1515\n",
      "Epoch 477/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0987 - mae: 0.1559\n",
      "Epoch 478/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0967 - mae: 0.1549\n",
      "Epoch 479/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0939 - mae: 0.1524\n",
      "Epoch 480/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1077 - mae: 0.1821\n",
      "Epoch 481/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1009 - mae: 0.1740\n",
      "Epoch 482/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0969 - mae: 0.1689\n",
      "Epoch 483/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0922 - mae: 0.1618\n",
      "Epoch 484/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0883 - mae: 0.1545\n",
      "Epoch 485/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0854 - mae: 0.1516\n",
      "Epoch 486/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0860 - mae: 0.1554\n",
      "Epoch 487/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0878 - mae: 0.1570\n",
      "Epoch 488/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0819 - mae: 0.1512\n",
      "Epoch 489/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0807 - mae: 0.1515\n",
      "Epoch 490/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0802 - mae: 0.1527\n",
      "Epoch 491/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0775 - mae: 0.1501\n",
      "Epoch 492/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0762 - mae: 0.1490\n",
      "Epoch 493/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0788 - mae: 0.1609\n",
      "Epoch 494/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0754 - mae: 0.1532\n",
      "Epoch 495/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0746 - mae: 0.1535\n",
      "Epoch 496/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0760 - mae: 0.1555\n",
      "Epoch 497/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0867 - mae: 0.1746\n",
      "Epoch 498/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0784 - mae: 0.1666\n",
      "Epoch 499/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0757 - mae: 0.1624\n",
      "Epoch 500/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0718 - mae: 0.1568\n",
      "Epoch 501/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0716 - mae: 0.1579\n",
      "Epoch 502/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0701 - mae: 0.1573\n",
      "Epoch 503/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0693 - mae: 0.1574\n",
      "Epoch 504/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0687 - mae: 0.1577\n",
      "Epoch 505/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0660 - mae: 0.1541\n",
      "Epoch 506/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0659 - mae: 0.1554\n",
      "Epoch 507/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0668 - mae: 0.1590\n",
      "Epoch 508/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0655 - mae: 0.1559\n",
      "Epoch 509/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0660 - mae: 0.1586\n",
      "Epoch 510/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0622 - mae: 0.1523\n",
      "Epoch 511/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0668 - mae: 0.1678\n",
      "Epoch 512/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0630 - mae: 0.1580\n",
      "Epoch 513/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0617 - mae: 0.1569\n",
      "Epoch 514/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0591 - mae: 0.1521\n",
      "Epoch 515/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0577 - mae: 0.1513\n",
      "Epoch 516/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0585 - mae: 0.1526\n",
      "Epoch 517/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0563 - mae: 0.1500\n",
      "Epoch 518/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0611 - mae: 0.1593\n",
      "Epoch 519/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0553 - mae: 0.1514\n",
      "Epoch 520/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0535 - mae: 0.1482\n",
      "Epoch 521/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0526 - mae: 0.1474\n",
      "Epoch 522/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0527 - mae: 0.1499\n",
      "Epoch 523/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0512 - mae: 0.1469\n",
      "Epoch 524/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0502 - mae: 0.1456\n",
      "Epoch 525/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0506 - mae: 0.1466\n",
      "Epoch 526/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0496 - mae: 0.1479\n",
      "Epoch 527/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0485 - mae: 0.1441\n",
      "Epoch 528/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0474 - mae: 0.1435\n",
      "Epoch 529/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0472 - mae: 0.1431\n",
      "Epoch 530/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0467 - mae: 0.1434\n",
      "Epoch 531/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0465 - mae: 0.1423\n",
      "Epoch 532/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0468 - mae: 0.1455\n",
      "Epoch 533/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0454 - mae: 0.1437\n",
      "Epoch 534/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0438 - mae: 0.1404\n",
      "Epoch 535/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0439 - mae: 0.1416\n",
      "Epoch 536/2000\n",
      "2019/2019 [==============================] - 0s 129us/sample - loss: 0.0430 - mae: 0.1406\n",
      "Epoch 537/2000\n",
      "2019/2019 [==============================] - 0s 105us/sample - loss: 0.0446 - mae: 0.1423\n",
      "Epoch 538/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0435 - mae: 0.1419\n",
      "Epoch 539/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0440 - mae: 0.1425\n",
      "Epoch 540/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0494 - mae: 0.1497\n",
      "Epoch 541/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0465 - mae: 0.1483\n",
      "Epoch 542/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0460 - mae: 0.1488\n",
      "Epoch 543/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0435 - mae: 0.1453\n",
      "Epoch 544/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0418 - mae: 0.1419\n",
      "Epoch 545/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0397 - mae: 0.1381\n",
      "Epoch 546/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0396 - mae: 0.1381\n",
      "Epoch 547/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0396 - mae: 0.1382\n",
      "Epoch 548/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0388 - mae: 0.1373\n",
      "Epoch 549/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0385 - mae: 0.1364\n",
      "Epoch 550/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0374 - mae: 0.1345\n",
      "Epoch 551/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0375 - mae: 0.1346\n",
      "Epoch 552/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0367 - mae: 0.1341\n",
      "Epoch 553/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0371 - mae: 0.1332\n",
      "Epoch 554/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0355 - mae: 0.1314\n",
      "Epoch 555/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0355 - mae: 0.1324\n",
      "Epoch 556/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0361 - mae: 0.1335\n",
      "Epoch 557/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0347 - mae: 0.1313\n",
      "Epoch 558/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0344 - mae: 0.1296\n",
      "Epoch 559/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0339 - mae: 0.1292\n",
      "Epoch 560/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0340 - mae: 0.1292\n",
      "Epoch 561/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0335 - mae: 0.1295\n",
      "Epoch 562/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0340 - mae: 0.1307\n",
      "Epoch 563/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0332 - mae: 0.1283\n",
      "Epoch 564/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0336 - mae: 0.1293\n",
      "Epoch 565/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0327 - mae: 0.1278\n",
      "Epoch 566/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0322 - mae: 0.1262\n",
      "Epoch 567/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0326 - mae: 0.1284\n",
      "Epoch 568/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0320 - mae: 0.1265\n",
      "Epoch 569/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0309 - mae: 0.1245\n",
      "Epoch 570/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0319 - mae: 0.1268\n",
      "Epoch 571/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0315 - mae: 0.1265\n",
      "Epoch 572/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0322 - mae: 0.1291\n",
      "Epoch 573/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0305 - mae: 0.1245\n",
      "Epoch 574/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0310 - mae: 0.1257\n",
      "Epoch 575/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0306 - mae: 0.1244\n",
      "Epoch 576/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0318 - mae: 0.1281\n",
      "Epoch 577/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0303 - mae: 0.1260\n",
      "Epoch 578/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0299 - mae: 0.1240\n",
      "Epoch 579/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0297 - mae: 0.1239\n",
      "Epoch 580/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0304 - mae: 0.1250\n",
      "Epoch 581/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0309 - mae: 0.1273\n",
      "Epoch 582/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0310 - mae: 0.1282\n",
      "Epoch 583/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0290 - mae: 0.1236\n",
      "Epoch 584/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0288 - mae: 0.1225\n",
      "Epoch 585/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0283 - mae: 0.1219\n",
      "Epoch 586/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0296 - mae: 0.1248\n",
      "Epoch 587/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0296 - mae: 0.1247\n",
      "Epoch 588/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0282 - mae: 0.1211\n",
      "Epoch 589/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0284 - mae: 0.1235\n",
      "Epoch 590/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0282 - mae: 0.1216\n",
      "Epoch 591/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0293 - mae: 0.1245\n",
      "Epoch 592/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0525 - mae: 0.1592\n",
      "Epoch 593/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0389 - mae: 0.1465\n",
      "Epoch 594/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0368 - mae: 0.1422\n",
      "Epoch 595/2000\n",
      "2019/2019 [==============================] - 0s 111us/sample - loss: 0.0354 - mae: 0.1402\n",
      "Epoch 596/2000\n",
      "2019/2019 [==============================] - 0s 104us/sample - loss: 0.0347 - mae: 0.1369\n",
      "Epoch 597/2000\n",
      "2019/2019 [==============================] - 0s 112us/sample - loss: 0.0344 - mae: 0.1386\n",
      "Epoch 598/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0428 - mae: 0.1537\n",
      "Epoch 599/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0334 - mae: 0.1354\n",
      "Epoch 600/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0316 - mae: 0.1301\n",
      "Epoch 601/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0309 - mae: 0.1298\n",
      "Epoch 602/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0303 - mae: 0.1271\n",
      "Epoch 603/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0297 - mae: 0.1264\n",
      "Epoch 604/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0302 - mae: 0.1270\n",
      "Epoch 605/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0300 - mae: 0.1249\n",
      "Epoch 606/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0295 - mae: 0.1239\n",
      "Epoch 607/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0280 - mae: 0.1205\n",
      "Epoch 608/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0283 - mae: 0.1216\n",
      "Epoch 609/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0281 - mae: 0.1205\n",
      "Epoch 610/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0282 - mae: 0.1213\n",
      "Epoch 611/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0312 - mae: 0.1206\n",
      "Epoch 612/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0316 - mae: 0.1308\n",
      "Epoch 613/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0293 - mae: 0.1246\n",
      "Epoch 614/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0281 - mae: 0.1213\n",
      "Epoch 615/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0292 - mae: 0.1242\n",
      "Epoch 616/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0273 - mae: 0.1189\n",
      "Epoch 617/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0275 - mae: 0.1191\n",
      "Epoch 618/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0277 - mae: 0.1198\n",
      "Epoch 619/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0280 - mae: 0.1213\n",
      "Epoch 620/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0269 - mae: 0.1180\n",
      "Epoch 621/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0269 - mae: 0.1172\n",
      "Epoch 622/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0268 - mae: 0.1169\n",
      "Epoch 623/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0272 - mae: 0.1188\n",
      "Epoch 624/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0265 - mae: 0.1166\n",
      "Epoch 625/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0280 - mae: 0.1217\n",
      "Epoch 626/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0266 - mae: 0.1167\n",
      "Epoch 627/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0261 - mae: 0.1147\n",
      "Epoch 628/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0283 - mae: 0.1226\n",
      "Epoch 629/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0275 - mae: 0.1201\n",
      "Epoch 630/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0276 - mae: 0.1208\n",
      "Epoch 631/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0262 - mae: 0.1162\n",
      "Epoch 632/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0253 - mae: 0.1137\n",
      "Epoch 633/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0257 - mae: 0.1138\n",
      "Epoch 634/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0257 - mae: 0.1142\n",
      "Epoch 635/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0255 - mae: 0.1148\n",
      "Epoch 636/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0256 - mae: 0.1142\n",
      "Epoch 637/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0258 - mae: 0.1158\n",
      "Epoch 638/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0282 - mae: 0.1188\n",
      "Epoch 639/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0252 - mae: 0.1133\n",
      "Epoch 640/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0275 - mae: 0.1186\n",
      "Epoch 641/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0272 - mae: 0.1187\n",
      "Epoch 642/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0261 - mae: 0.1160\n",
      "Epoch 643/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0288 - mae: 0.1193\n",
      "Epoch 644/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0272 - mae: 0.1208\n",
      "Epoch 645/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0261 - mae: 0.1159\n",
      "Epoch 646/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0277 - mae: 0.1217\n",
      "Epoch 647/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0275 - mae: 0.1163\n",
      "Epoch 648/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0259 - mae: 0.1154\n",
      "Epoch 649/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0260 - mae: 0.1155\n",
      "Epoch 650/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0257 - mae: 0.1147\n",
      "Epoch 651/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0258 - mae: 0.1160\n",
      "Epoch 652/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0250 - mae: 0.1134\n",
      "Epoch 653/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0246 - mae: 0.1113\n",
      "Epoch 654/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0281 - mae: 0.1197\n",
      "Epoch 655/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0254 - mae: 0.1140\n",
      "Epoch 656/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0276 - mae: 0.1203\n",
      "Epoch 657/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0273 - mae: 0.1202\n",
      "Epoch 658/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0265 - mae: 0.1174\n",
      "Epoch 659/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0280 - mae: 0.1213\n",
      "Epoch 660/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0335 - mae: 0.1343\n",
      "Epoch 661/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0282 - mae: 0.1209\n",
      "Epoch 662/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0259 - mae: 0.1152\n",
      "Epoch 663/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0265 - mae: 0.1160\n",
      "Epoch 664/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0258 - mae: 0.1145\n",
      "Epoch 665/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0255 - mae: 0.1142\n",
      "Epoch 666/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0249 - mae: 0.1124\n",
      "Epoch 667/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0249 - mae: 0.1127\n",
      "Epoch 668/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0246 - mae: 0.1115\n",
      "Epoch 669/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0253 - mae: 0.1148\n",
      "Epoch 670/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0248 - mae: 0.1124\n",
      "Epoch 671/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0267 - mae: 0.1182\n",
      "Epoch 672/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0247 - mae: 0.1120\n",
      "Epoch 673/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0244 - mae: 0.1105\n",
      "Epoch 674/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0247 - mae: 0.1123\n",
      "Epoch 675/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0244 - mae: 0.1122\n",
      "Epoch 676/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0250 - mae: 0.1133\n",
      "Epoch 677/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0240 - mae: 0.1102\n",
      "Epoch 678/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0243 - mae: 0.1109\n",
      "Epoch 679/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0237 - mae: 0.1092\n",
      "Epoch 680/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0241 - mae: 0.1107\n",
      "Epoch 681/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0247 - mae: 0.1134\n",
      "Epoch 682/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0241 - mae: 0.1105\n",
      "Epoch 683/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0239 - mae: 0.1104\n",
      "Epoch 684/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0244 - mae: 0.1123\n",
      "Epoch 685/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0238 - mae: 0.1099\n",
      "Epoch 686/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0251 - mae: 0.1146\n",
      "Epoch 687/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0236 - mae: 0.1103\n",
      "Epoch 688/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0240 - mae: 0.1107\n",
      "Epoch 689/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0244 - mae: 0.1127\n",
      "Epoch 690/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0238 - mae: 0.1094\n",
      "Epoch 691/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0231 - mae: 0.1079\n",
      "Epoch 692/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0232 - mae: 0.1087\n",
      "Epoch 693/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0241 - mae: 0.1106\n",
      "Epoch 694/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0244 - mae: 0.1119\n",
      "Epoch 695/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0233 - mae: 0.1085\n",
      "Epoch 696/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0246 - mae: 0.1117\n",
      "Epoch 697/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0263 - mae: 0.1174\n",
      "Epoch 698/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0250 - mae: 0.1128\n",
      "Epoch 699/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0244 - mae: 0.1120\n",
      "Epoch 700/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0236 - mae: 0.1095\n",
      "Epoch 701/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0232 - mae: 0.1082\n",
      "Epoch 702/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0237 - mae: 0.1104\n",
      "Epoch 703/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0227 - mae: 0.1070\n",
      "Epoch 704/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0281 - mae: 0.1179\n",
      "Epoch 705/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0252 - mae: 0.1139\n",
      "Epoch 706/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0248 - mae: 0.1125\n",
      "Epoch 707/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0252 - mae: 0.1154\n",
      "Epoch 708/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0244 - mae: 0.1127\n",
      "Epoch 709/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0237 - mae: 0.1094\n",
      "Epoch 710/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0237 - mae: 0.1109\n",
      "Epoch 711/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0245 - mae: 0.1130\n",
      "Epoch 712/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0236 - mae: 0.1103\n",
      "Epoch 713/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0236 - mae: 0.1100\n",
      "Epoch 714/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0256 - mae: 0.1154\n",
      "Epoch 715/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0228 - mae: 0.1071\n",
      "Epoch 716/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0259 - mae: 0.1133\n",
      "Epoch 717/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0249 - mae: 0.1136\n",
      "Epoch 718/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0243 - mae: 0.1118\n",
      "Epoch 719/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0239 - mae: 0.1108\n",
      "Epoch 720/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0235 - mae: 0.1098\n",
      "Epoch 721/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0225 - mae: 0.1069\n",
      "Epoch 722/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0230 - mae: 0.1080\n",
      "Epoch 723/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0229 - mae: 0.1074\n",
      "Epoch 724/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0226 - mae: 0.1071\n",
      "Epoch 725/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0237 - mae: 0.1113\n",
      "Epoch 726/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0230 - mae: 0.1080\n",
      "Epoch 727/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0228 - mae: 0.1086\n",
      "Epoch 728/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0238 - mae: 0.1119\n",
      "Epoch 729/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0229 - mae: 0.1080\n",
      "Epoch 730/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0249 - mae: 0.1131\n",
      "Epoch 731/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0233 - mae: 0.1090\n",
      "Epoch 732/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0247 - mae: 0.1141\n",
      "Epoch 733/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0228 - mae: 0.1082\n",
      "Epoch 734/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0230 - mae: 0.1086\n",
      "Epoch 735/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0226 - mae: 0.1069\n",
      "Epoch 736/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0241 - mae: 0.1117\n",
      "Epoch 737/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0235 - mae: 0.1095\n",
      "Epoch 738/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0229 - mae: 0.1085\n",
      "Epoch 739/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0240 - mae: 0.1120\n",
      "Epoch 740/2000\n",
      "2019/2019 [==============================] - 0s 143us/sample - loss: 0.0225 - mae: 0.1068\n",
      "Epoch 741/2000\n",
      "2019/2019 [==============================] - 0s 124us/sample - loss: 0.0228 - mae: 0.1077\n",
      "Epoch 742/2000\n",
      "2019/2019 [==============================] - 0s 95us/sample - loss: 0.0229 - mae: 0.1086\n",
      "Epoch 743/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0223 - mae: 0.1065\n",
      "Epoch 744/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0235 - mae: 0.1098\n",
      "Epoch 745/2000\n",
      "2019/2019 [==============================] - 0s 99us/sample - loss: 0.0231 - mae: 0.1095\n",
      "Epoch 746/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0228 - mae: 0.1081\n",
      "Epoch 747/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0224 - mae: 0.1060\n",
      "Epoch 748/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0236 - mae: 0.1101\n",
      "Epoch 749/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0230 - mae: 0.1093\n",
      "Epoch 750/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0220 - mae: 0.1059\n",
      "Epoch 751/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0223 - mae: 0.1070\n",
      "Epoch 752/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0231 - mae: 0.1087\n",
      "Epoch 753/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0223 - mae: 0.1069\n",
      "Epoch 754/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0227 - mae: 0.1068\n",
      "Epoch 755/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0225 - mae: 0.1066\n",
      "Epoch 756/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0225 - mae: 0.1063\n",
      "Epoch 757/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0337 - mae: 0.1356\n",
      "Epoch 758/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0257 - mae: 0.1171\n",
      "Epoch 759/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0233 - mae: 0.1099\n",
      "Epoch 760/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0244 - mae: 0.1138\n",
      "Epoch 761/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0231 - mae: 0.1095\n",
      "Epoch 762/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0237 - mae: 0.1111\n",
      "Epoch 763/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0223 - mae: 0.1065\n",
      "Epoch 764/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0233 - mae: 0.1111\n",
      "Epoch 765/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0221 - mae: 0.1070\n",
      "Epoch 766/2000\n",
      "2019/2019 [==============================] - 0s 94us/sample - loss: 0.0230 - mae: 0.1090\n",
      "Epoch 767/2000\n",
      "2019/2019 [==============================] - 0s 100us/sample - loss: 0.0227 - mae: 0.1078\n",
      "Epoch 768/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0229 - mae: 0.1093\n",
      "Epoch 769/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0224 - mae: 0.1071\n",
      "Epoch 770/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0218 - mae: 0.1058\n",
      "Epoch 771/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0228 - mae: 0.1078\n",
      "Epoch 772/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0221 - mae: 0.1064\n",
      "Epoch 773/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0214 - mae: 0.1049\n",
      "Epoch 774/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1067\n",
      "Epoch 775/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0221 - mae: 0.1061\n",
      "Epoch 776/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0226 - mae: 0.1075\n",
      "Epoch 777/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0221 - mae: 0.1066\n",
      "Epoch 778/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0218 - mae: 0.1066\n",
      "Epoch 779/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0212 - mae: 0.1044\n",
      "Epoch 780/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0223 - mae: 0.1073\n",
      "Epoch 781/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0230 - mae: 0.1090\n",
      "Epoch 782/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0229 - mae: 0.1093\n",
      "Epoch 783/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0222 - mae: 0.1072\n",
      "Epoch 784/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0222 - mae: 0.1059\n",
      "Epoch 785/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0228 - mae: 0.1096\n",
      "Epoch 786/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0216 - mae: 0.1056\n",
      "Epoch 787/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0232 - mae: 0.1100\n",
      "Epoch 788/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0233 - mae: 0.1100\n",
      "Epoch 789/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0314 - mae: 0.1314\n",
      "Epoch 790/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0260 - mae: 0.1161\n",
      "Epoch 791/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0236 - mae: 0.1106\n",
      "Epoch 792/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0235 - mae: 0.1114\n",
      "Epoch 793/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0258 - mae: 0.1153\n",
      "Epoch 794/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0233 - mae: 0.1094\n",
      "Epoch 795/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0250 - mae: 0.1127\n",
      "Epoch 796/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0234 - mae: 0.1104\n",
      "Epoch 797/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0231 - mae: 0.1100\n",
      "Epoch 798/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0262 - mae: 0.1182\n",
      "Epoch 799/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0232 - mae: 0.1098\n",
      "Epoch 800/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0220 - mae: 0.1061\n",
      "Epoch 801/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0235 - mae: 0.1116\n",
      "Epoch 802/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0224 - mae: 0.1081\n",
      "Epoch 803/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0227 - mae: 0.1084\n",
      "Epoch 804/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0226 - mae: 0.1080\n",
      "Epoch 805/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0220 - mae: 0.1067\n",
      "Epoch 806/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0220 - mae: 0.1083\n",
      "Epoch 807/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0216 - mae: 0.1063\n",
      "Epoch 808/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0221 - mae: 0.1077\n",
      "Epoch 809/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0217 - mae: 0.1064\n",
      "Epoch 810/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0213 - mae: 0.1052\n",
      "Epoch 811/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0219 - mae: 0.1057\n",
      "Epoch 812/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0236 - mae: 0.1108\n",
      "Epoch 813/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0221 - mae: 0.1074\n",
      "Epoch 814/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0233 - mae: 0.1113\n",
      "Epoch 815/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0218 - mae: 0.1075\n",
      "Epoch 816/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0219 - mae: 0.1066\n",
      "Epoch 817/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0222 - mae: 0.1075\n",
      "Epoch 818/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0215 - mae: 0.1054\n",
      "Epoch 819/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0211 - mae: 0.1040\n",
      "Epoch 820/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0211 - mae: 0.1042\n",
      "Epoch 821/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0223 - mae: 0.1088\n",
      "Epoch 822/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0219 - mae: 0.1067\n",
      "Epoch 823/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0209 - mae: 0.1037\n",
      "Epoch 824/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0209 - mae: 0.1052\n",
      "Epoch 825/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0218 - mae: 0.1078\n",
      "Epoch 826/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0232 - mae: 0.1104\n",
      "Epoch 827/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0210 - mae: 0.1036\n",
      "Epoch 828/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0225 - mae: 0.1084\n",
      "Epoch 829/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0225 - mae: 0.1073\n",
      "Epoch 830/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0218 - mae: 0.1056\n",
      "Epoch 831/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0211 - mae: 0.1040\n",
      "Epoch 832/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0217 - mae: 0.1060\n",
      "Epoch 833/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0213 - mae: 0.1041\n",
      "Epoch 834/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0228 - mae: 0.1088\n",
      "Epoch 835/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0222 - mae: 0.1086\n",
      "Epoch 836/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0219 - mae: 0.1065\n",
      "Epoch 837/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0224 - mae: 0.1079\n",
      "Epoch 838/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0231 - mae: 0.1106\n",
      "Epoch 839/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0212 - mae: 0.1042\n",
      "Epoch 840/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0222 - mae: 0.1081\n",
      "Epoch 841/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0212 - mae: 0.1047\n",
      "Epoch 842/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0214 - mae: 0.1054\n",
      "Epoch 843/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0223 - mae: 0.1070\n",
      "Epoch 844/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0244 - mae: 0.1128\n",
      "Epoch 845/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0216 - mae: 0.1052\n",
      "Epoch 846/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0213 - mae: 0.1050\n",
      "Epoch 847/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0212 - mae: 0.1045\n",
      "Epoch 848/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0210 - mae: 0.1043\n",
      "Epoch 849/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0217 - mae: 0.1058\n",
      "Epoch 850/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0220 - mae: 0.1061\n",
      "Epoch 851/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0274 - mae: 0.1227\n",
      "Epoch 852/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0227 - mae: 0.1101\n",
      "Epoch 853/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0223 - mae: 0.1077\n",
      "Epoch 854/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0217 - mae: 0.1065\n",
      "Epoch 855/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0214 - mae: 0.1057\n",
      "Epoch 856/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0212 - mae: 0.1046\n",
      "Epoch 857/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0225 - mae: 0.1082\n",
      "Epoch 858/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0223 - mae: 0.1077\n",
      "Epoch 859/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0222 - mae: 0.1082\n",
      "Epoch 860/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0216 - mae: 0.1055\n",
      "Epoch 861/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0222 - mae: 0.1063\n",
      "Epoch 862/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0221 - mae: 0.1077\n",
      "Epoch 863/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0209 - mae: 0.1032\n",
      "Epoch 864/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0219 - mae: 0.1054\n",
      "Epoch 865/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0219 - mae: 0.1071\n",
      "Epoch 866/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0218 - mae: 0.1067\n",
      "Epoch 867/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0212 - mae: 0.1042\n",
      "Epoch 868/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0212 - mae: 0.1055\n",
      "Epoch 869/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0219 - mae: 0.1067\n",
      "Epoch 870/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0224 - mae: 0.1078\n",
      "Epoch 871/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0208 - mae: 0.1037\n",
      "Epoch 872/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0216 - mae: 0.1062\n",
      "Epoch 873/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0217 - mae: 0.1064\n",
      "Epoch 874/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0220 - mae: 0.1066\n",
      "Epoch 875/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0218 - mae: 0.1066\n",
      "Epoch 876/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0206 - mae: 0.1026\n",
      "Epoch 877/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0214 - mae: 0.1043\n",
      "Epoch 878/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0208 - mae: 0.1032\n",
      "Epoch 879/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0214 - mae: 0.1052\n",
      "Epoch 880/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0209 - mae: 0.1035\n",
      "Epoch 881/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0208 - mae: 0.1033\n",
      "Epoch 882/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0204 - mae: 0.1020\n",
      "Epoch 883/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0219 - mae: 0.1076\n",
      "Epoch 884/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0233 - mae: 0.1103\n",
      "Epoch 885/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0240 - mae: 0.1124\n",
      "Epoch 886/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0223 - mae: 0.1077\n",
      "Epoch 887/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0218 - mae: 0.1066\n",
      "Epoch 888/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0231 - mae: 0.1108\n",
      "Epoch 889/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0217 - mae: 0.1066\n",
      "Epoch 890/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0216 - mae: 0.1063\n",
      "Epoch 891/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0220 - mae: 0.1083\n",
      "Epoch 892/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0210 - mae: 0.1044\n",
      "Epoch 893/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0218 - mae: 0.1065\n",
      "Epoch 894/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0218 - mae: 0.1066\n",
      "Epoch 895/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0206 - mae: 0.1025\n",
      "Epoch 896/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0207 - mae: 0.1035\n",
      "Epoch 897/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0204 - mae: 0.1030\n",
      "Epoch 898/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0220 - mae: 0.1065\n",
      "Epoch 899/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0230 - mae: 0.1089\n",
      "Epoch 900/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0226 - mae: 0.1093\n",
      "Epoch 901/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0216 - mae: 0.1058\n",
      "Epoch 902/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0223 - mae: 0.1077\n",
      "Epoch 903/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0217 - mae: 0.1067\n",
      "Epoch 904/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0230 - mae: 0.1103\n",
      "Epoch 905/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0216 - mae: 0.1065\n",
      "Epoch 906/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0211 - mae: 0.1061\n",
      "Epoch 907/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0211 - mae: 0.1052\n",
      "Epoch 908/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0205 - mae: 0.1028\n",
      "Epoch 909/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0224 - mae: 0.1082\n",
      "Epoch 910/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0211 - mae: 0.1049\n",
      "Epoch 911/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0209 - mae: 0.1045\n",
      "Epoch 912/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0217 - mae: 0.1067\n",
      "Epoch 913/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0204 - mae: 0.1025\n",
      "Epoch 914/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0206 - mae: 0.1034\n",
      "Epoch 915/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0211 - mae: 0.1033\n",
      "Epoch 916/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0226 - mae: 0.1081\n",
      "Epoch 917/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0206 - mae: 0.1031\n",
      "Epoch 918/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0211 - mae: 0.1045\n",
      "Epoch 919/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0201 - mae: 0.1016\n",
      "Epoch 920/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0200 - mae: 0.1017\n",
      "Epoch 921/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0220 - mae: 0.1080\n",
      "Epoch 922/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0219 - mae: 0.1067\n",
      "Epoch 923/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0208 - mae: 0.1032\n",
      "Epoch 924/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0235 - mae: 0.1038\n",
      "Epoch 925/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0239 - mae: 0.1114\n",
      "Epoch 926/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0232 - mae: 0.1112\n",
      "Epoch 927/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0219 - mae: 0.1073\n",
      "Epoch 928/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0223 - mae: 0.1082\n",
      "Epoch 929/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0206 - mae: 0.1047\n",
      "Epoch 930/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0206 - mae: 0.1024\n",
      "Epoch 931/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0216 - mae: 0.1057\n",
      "Epoch 932/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0201 - mae: 0.1021\n",
      "Epoch 933/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0206 - mae: 0.1028\n",
      "Epoch 934/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0205 - mae: 0.1030\n",
      "Epoch 935/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0217 - mae: 0.1064\n",
      "Epoch 936/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0203 - mae: 0.1019\n",
      "Epoch 937/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0223 - mae: 0.1084\n",
      "Epoch 938/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0210 - mae: 0.1054\n",
      "Epoch 939/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0202 - mae: 0.1006\n",
      "Epoch 940/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0208 - mae: 0.1045\n",
      "Epoch 941/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0204 - mae: 0.1027\n",
      "Epoch 942/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0202 - mae: 0.1014\n",
      "Epoch 943/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0214 - mae: 0.1061\n",
      "Epoch 944/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0200 - mae: 0.1013\n",
      "Epoch 945/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0204 - mae: 0.1030\n",
      "Epoch 946/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0205 - mae: 0.1030\n",
      "Epoch 947/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0211 - mae: 0.1051\n",
      "Epoch 948/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0204 - mae: 0.1024\n",
      "Epoch 949/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.0992\n",
      "Epoch 950/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0199 - mae: 0.1016\n",
      "Epoch 951/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0211 - mae: 0.1051\n",
      "Epoch 952/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0194 - mae: 0.1001\n",
      "Epoch 953/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0198 - mae: 0.1006\n",
      "Epoch 954/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0226 - mae: 0.1092\n",
      "Epoch 955/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0202 - mae: 0.1025\n",
      "Epoch 956/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0200 - mae: 0.1022\n",
      "Epoch 957/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0203 - mae: 0.1017\n",
      "Epoch 958/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0203 - mae: 0.1024\n",
      "Epoch 959/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0218 - mae: 0.1055\n",
      "Epoch 960/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0212 - mae: 0.1052\n",
      "Epoch 961/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0205 - mae: 0.1032\n",
      "Epoch 962/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0205 - mae: 0.1029\n",
      "Epoch 963/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0197 - mae: 0.1008\n",
      "Epoch 964/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0213 - mae: 0.1062\n",
      "Epoch 965/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0210 - mae: 0.1060\n",
      "Epoch 966/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0210 - mae: 0.1050\n",
      "Epoch 967/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0192 - mae: 0.0993\n",
      "Epoch 968/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0209 - mae: 0.1044\n",
      "Epoch 969/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0220 - mae: 0.1087\n",
      "Epoch 970/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0194 - mae: 0.0996\n",
      "Epoch 971/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0199 - mae: 0.1020\n",
      "Epoch 972/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0200 - mae: 0.1019\n",
      "Epoch 973/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0200 - mae: 0.1028\n",
      "Epoch 974/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0197 - mae: 0.1003\n",
      "Epoch 975/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0197 - mae: 0.1014\n",
      "Epoch 976/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0208 - mae: 0.1035\n",
      "Epoch 977/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0199 - mae: 0.1012\n",
      "Epoch 978/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0204 - mae: 0.1029\n",
      "Epoch 979/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0208 - mae: 0.1039\n",
      "Epoch 980/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0209 - mae: 0.1042\n",
      "Epoch 981/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0205 - mae: 0.1024\n",
      "Epoch 982/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0209 - mae: 0.1033\n",
      "Epoch 983/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1062\n",
      "Epoch 984/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0204 - mae: 0.1025\n",
      "Epoch 985/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0203 - mae: 0.1021\n",
      "Epoch 986/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0199 - mae: 0.1012\n",
      "Epoch 987/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0207 - mae: 0.1040\n",
      "Epoch 988/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0214 - mae: 0.1050\n",
      "Epoch 989/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0209 - mae: 0.1048\n",
      "Epoch 990/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0203 - mae: 0.1019\n",
      "Epoch 991/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0197 - mae: 0.1004\n",
      "Epoch 992/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0196 - mae: 0.0995\n",
      "Epoch 993/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0202 - mae: 0.1020\n",
      "Epoch 994/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0215 - mae: 0.1056\n",
      "Epoch 995/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0196 - mae: 0.1005\n",
      "Epoch 996/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0196 - mae: 0.1012\n",
      "Epoch 997/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0206 - mae: 0.1043\n",
      "Epoch 998/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0197 - mae: 0.1011\n",
      "Epoch 999/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0193 - mae: 0.0995\n",
      "Epoch 1000/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0205 - mae: 0.1040\n",
      "Epoch 1001/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0215 - mae: 0.1068\n",
      "Epoch 1002/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0204 - mae: 0.1036\n",
      "Epoch 1003/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0204 - mae: 0.1031\n",
      "Epoch 1004/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0206 - mae: 0.1036\n",
      "Epoch 1005/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0194 - mae: 0.1004\n",
      "Epoch 1006/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0208 - mae: 0.1049\n",
      "Epoch 1007/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0206 - mae: 0.1036\n",
      "Epoch 1008/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0246 - mae: 0.1162\n",
      "Epoch 1009/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0209 - mae: 0.1051\n",
      "Epoch 1010/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0215 - mae: 0.1050\n",
      "Epoch 1011/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0211 - mae: 0.1042\n",
      "Epoch 1012/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0271 - mae: 0.1190\n",
      "Epoch 1013/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0248 - mae: 0.1135\n",
      "Epoch 1014/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0240 - mae: 0.1141\n",
      "Epoch 1015/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1069\n",
      "Epoch 1016/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0210 - mae: 0.1040\n",
      "Epoch 1017/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0212 - mae: 0.1054\n",
      "Epoch 1018/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0221 - mae: 0.1078\n",
      "Epoch 1019/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0205 - mae: 0.1029\n",
      "Epoch 1020/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0204 - mae: 0.1023\n",
      "Epoch 1021/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0214 - mae: 0.1065\n",
      "Epoch 1022/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0225 - mae: 0.1090\n",
      "Epoch 1023/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0217 - mae: 0.1063\n",
      "Epoch 1024/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0203 - mae: 0.1025\n",
      "Epoch 1025/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0223 - mae: 0.1061\n",
      "Epoch 1026/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0218 - mae: 0.1074\n",
      "Epoch 1027/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0203 - mae: 0.1028\n",
      "Epoch 1028/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0206 - mae: 0.1036\n",
      "Epoch 1029/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0214 - mae: 0.1063\n",
      "Epoch 1030/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0208 - mae: 0.1047\n",
      "Epoch 1031/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0207 - mae: 0.1039\n",
      "Epoch 1032/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0210 - mae: 0.1048\n",
      "Epoch 1033/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0204 - mae: 0.1044\n",
      "Epoch 1034/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0239 - mae: 0.1138\n",
      "Epoch 1035/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1069\n",
      "Epoch 1036/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0215 - mae: 0.1060\n",
      "Epoch 1037/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0222 - mae: 0.1084\n",
      "Epoch 1038/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0213 - mae: 0.1057\n",
      "Epoch 1039/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0213 - mae: 0.1051\n",
      "Epoch 1040/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0207 - mae: 0.1051\n",
      "Epoch 1041/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0212 - mae: 0.1048\n",
      "Epoch 1042/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0223 - mae: 0.1093\n",
      "Epoch 1043/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0199 - mae: 0.1019\n",
      "Epoch 1044/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0200 - mae: 0.1027\n",
      "Epoch 1045/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0202 - mae: 0.1024\n",
      "Epoch 1046/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0207 - mae: 0.1039\n",
      "Epoch 1047/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0198 - mae: 0.1018\n",
      "Epoch 1048/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0211 - mae: 0.1058\n",
      "Epoch 1049/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0201 - mae: 0.1034\n",
      "Epoch 1050/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0205 - mae: 0.1041\n",
      "Epoch 1051/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0228 - mae: 0.1110\n",
      "Epoch 1052/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0234 - mae: 0.1115\n",
      "Epoch 1053/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0196 - mae: 0.1006\n",
      "Epoch 1054/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0206 - mae: 0.1043\n",
      "Epoch 1055/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0213 - mae: 0.1064\n",
      "Epoch 1056/2000\n",
      "2019/2019 [==============================] - 0s 127us/sample - loss: 0.0197 - mae: 0.1019\n",
      "Epoch 1057/2000\n",
      "2019/2019 [==============================] - 0s 105us/sample - loss: 0.0201 - mae: 0.1021\n",
      "Epoch 1058/2000\n",
      "2019/2019 [==============================] - 0s 126us/sample - loss: 0.0212 - mae: 0.1054s - loss: 0.0211 - mae: 0.1\n",
      "Epoch 1059/2000\n",
      "2019/2019 [==============================] - 0s 142us/sample - loss: 0.0200 - mae: 0.1029\n",
      "Epoch 1060/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0210 - mae: 0.1051\n",
      "Epoch 1061/2000\n",
      "2019/2019 [==============================] - 0s 99us/sample - loss: 0.0203 - mae: 0.1036\n",
      "Epoch 1062/2000\n",
      "2019/2019 [==============================] - 0s 106us/sample - loss: 0.0202 - mae: 0.1030\n",
      "Epoch 1063/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0205 - mae: 0.1041\n",
      "Epoch 1064/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0196 - mae: 0.1015\n",
      "Epoch 1065/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0192 - mae: 0.0998\n",
      "Epoch 1066/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0193 - mae: 0.1001\n",
      "Epoch 1067/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0196 - mae: 0.1010\n",
      "Epoch 1068/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0192 - mae: 0.1002\n",
      "Epoch 1069/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0194 - mae: 0.1004\n",
      "Epoch 1070/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0194 - mae: 0.1002\n",
      "Epoch 1071/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0207 - mae: 0.1042\n",
      "Epoch 1072/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0204 - mae: 0.1034\n",
      "Epoch 1073/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0228 - mae: 0.1097\n",
      "Epoch 1074/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0198 - mae: 0.1022\n",
      "Epoch 1075/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0192 - mae: 0.1010\n",
      "Epoch 1076/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0196 - mae: 0.1017\n",
      "Epoch 1077/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0210 - mae: 0.1049\n",
      "Epoch 1078/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0200 - mae: 0.1023\n",
      "Epoch 1079/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0191 - mae: 0.0994\n",
      "Epoch 1080/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0210 - mae: 0.1053\n",
      "Epoch 1081/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0196 - mae: 0.1017\n",
      "Epoch 1082/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0187 - mae: 0.0976\n",
      "Epoch 1083/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0190 - mae: 0.1004\n",
      "Epoch 1084/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0201 - mae: 0.1022\n",
      "Epoch 1085/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0200 - mae: 0.1025\n",
      "Epoch 1086/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0197 - mae: 0.1017\n",
      "Epoch 1087/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0199 - mae: 0.1017\n",
      "Epoch 1088/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0249 - mae: 0.1130\n",
      "Epoch 1089/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0229 - mae: 0.1110\n",
      "Epoch 1090/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0209 - mae: 0.1051\n",
      "Epoch 1091/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0207 - mae: 0.1054\n",
      "Epoch 1092/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0196 - mae: 0.1011\n",
      "Epoch 1093/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0197 - mae: 0.1010\n",
      "Epoch 1094/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0192 - mae: 0.1005\n",
      "Epoch 1095/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0200 - mae: 0.1015\n",
      "Epoch 1096/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0195 - mae: 0.1015\n",
      "Epoch 1097/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0201 - mae: 0.1040\n",
      "Epoch 1098/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0201 - mae: 0.1035\n",
      "Epoch 1099/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0202 - mae: 0.1034\n",
      "Epoch 1100/2000\n",
      "2019/2019 [==============================] - 0s 117us/sample - loss: 0.0195 - mae: 0.1009\n",
      "Epoch 1101/2000\n",
      "2019/2019 [==============================] - 0s 129us/sample - loss: 0.0195 - mae: 0.1017\n",
      "Epoch 1102/2000\n",
      "2019/2019 [==============================] - 0s 92us/sample - loss: 0.0233 - mae: 0.1115\n",
      "Epoch 1103/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0202 - mae: 0.1032\n",
      "Epoch 1104/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0204 - mae: 0.1045\n",
      "Epoch 1105/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0212 - mae: 0.1062\n",
      "Epoch 1106/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0195 - mae: 0.1007\n",
      "Epoch 1107/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0194 - mae: 0.1012\n",
      "Epoch 1108/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0198 - mae: 0.1012\n",
      "Epoch 1109/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0211 - mae: 0.1058\n",
      "Epoch 1110/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0204 - mae: 0.1049\n",
      "Epoch 1111/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0196 - mae: 0.1020\n",
      "Epoch 1112/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0215 - mae: 0.1070\n",
      "Epoch 1113/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0192 - mae: 0.1011\n",
      "Epoch 1114/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0202 - mae: 0.1036\n",
      "Epoch 1115/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.1009\n",
      "Epoch 1116/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0204 - mae: 0.1042\n",
      "Epoch 1117/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0195 - mae: 0.1007\n",
      "Epoch 1118/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0191 - mae: 0.1002\n",
      "Epoch 1119/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0194 - mae: 0.1012\n",
      "Epoch 1120/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0187 - mae: 0.0991\n",
      "Epoch 1121/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0191 - mae: 0.1003\n",
      "Epoch 1122/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0190 - mae: 0.1000\n",
      "Epoch 1123/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0201 - mae: 0.1026\n",
      "Epoch 1124/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0216 - mae: 0.1081\n",
      "Epoch 1125/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0187 - mae: 0.0987\n",
      "Epoch 1126/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0201 - mae: 0.1023\n",
      "Epoch 1127/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0196 - mae: 0.1000\n",
      "Epoch 1128/2000\n",
      "2019/2019 [==============================] - 0s 97us/sample - loss: 0.0198 - mae: 0.1028\n",
      "Epoch 1129/2000\n",
      "2019/2019 [==============================] - 0s 106us/sample - loss: 0.0197 - mae: 0.1025\n",
      "Epoch 1130/2000\n",
      "2019/2019 [==============================] - 0s 119us/sample - loss: 0.0199 - mae: 0.1028\n",
      "Epoch 1131/2000\n",
      "2019/2019 [==============================] - 0s 114us/sample - loss: 0.0191 - mae: 0.0991\n",
      "Epoch 1132/2000\n",
      "2019/2019 [==============================] - 0s 110us/sample - loss: 0.0193 - mae: 0.1011\n",
      "Epoch 1133/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0201 - mae: 0.1028\n",
      "Epoch 1134/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0195 - mae: 0.1017\n",
      "Epoch 1135/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0191 - mae: 0.1006\n",
      "Epoch 1136/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0199 - mae: 0.1026\n",
      "Epoch 1137/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0189 - mae: 0.0994\n",
      "Epoch 1138/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0192 - mae: 0.1005\n",
      "Epoch 1139/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0198 - mae: 0.1029\n",
      "Epoch 1140/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0194 - mae: 0.1008\n",
      "Epoch 1141/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0188 - mae: 0.0991\n",
      "Epoch 1142/2000\n",
      "2019/2019 [==============================] - 0s 131us/sample - loss: 0.0193 - mae: 0.1009\n",
      "Epoch 1143/2000\n",
      "2019/2019 [==============================] - 0s 121us/sample - loss: 0.0197 - mae: 0.1023\n",
      "Epoch 1144/2000\n",
      "2019/2019 [==============================] - 0s 105us/sample - loss: 0.0190 - mae: 0.1003\n",
      "Epoch 1145/2000\n",
      "2019/2019 [==============================] - 0s 94us/sample - loss: 0.0193 - mae: 0.1003\n",
      "Epoch 1146/2000\n",
      "2019/2019 [==============================] - 0s 98us/sample - loss: 0.0184 - mae: 0.0978\n",
      "Epoch 1147/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0181 - mae: 0.0968\n",
      "Epoch 1148/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0182 - mae: 0.0972\n",
      "Epoch 1149/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0197 - mae: 0.1019\n",
      "Epoch 1150/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0219 - mae: 0.1071\n",
      "Epoch 1151/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0210 - mae: 0.1049\n",
      "Epoch 1152/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0194 - mae: 0.1017\n",
      "Epoch 1153/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0216 - mae: 0.1062\n",
      "Epoch 1154/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0203 - mae: 0.1030\n",
      "Epoch 1155/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0203 - mae: 0.1025\n",
      "Epoch 1156/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0184 - mae: 0.0980\n",
      "Epoch 1157/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0193 - mae: 0.1006\n",
      "Epoch 1158/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0195 - mae: 0.1008\n",
      "Epoch 1159/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0196 - mae: 0.1013\n",
      "Epoch 1160/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0197 - mae: 0.1009\n",
      "Epoch 1161/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0196 - mae: 0.1011\n",
      "Epoch 1162/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0210 - mae: 0.1050\n",
      "Epoch 1163/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0222 - mae: 0.1093\n",
      "Epoch 1164/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0205 - mae: 0.1034\n",
      "Epoch 1165/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0190 - mae: 0.1002\n",
      "Epoch 1166/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.1014\n",
      "Epoch 1167/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0191 - mae: 0.0994\n",
      "Epoch 1168/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.0992\n",
      "Epoch 1169/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0191 - mae: 0.0993\n",
      "Epoch 1170/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0203 - mae: 0.1026\n",
      "Epoch 1171/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0193 - mae: 0.0999\n",
      "Epoch 1172/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0202 - mae: 0.1033\n",
      "Epoch 1173/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0190 - mae: 0.0993\n",
      "Epoch 1174/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.1014\n",
      "Epoch 1175/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0189 - mae: 0.0996\n",
      "Epoch 1176/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0187 - mae: 0.0988\n",
      "Epoch 1177/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.0988\n",
      "Epoch 1178/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0200 - mae: 0.1026\n",
      "Epoch 1179/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0190 - mae: 0.0985\n",
      "Epoch 1180/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0191 - mae: 0.0989\n",
      "Epoch 1181/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0195 - mae: 0.1015\n",
      "Epoch 1182/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0198 - mae: 0.1016\n",
      "Epoch 1183/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0203 - mae: 0.1033\n",
      "Epoch 1184/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0200 - mae: 0.1035\n",
      "Epoch 1185/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0202 - mae: 0.1026\n",
      "Epoch 1186/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0194 - mae: 0.1016\n",
      "Epoch 1187/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0188 - mae: 0.0991\n",
      "Epoch 1188/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0988\n",
      "Epoch 1189/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0188 - mae: 0.0988\n",
      "Epoch 1190/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0188 - mae: 0.0996\n",
      "Epoch 1191/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0976\n",
      "Epoch 1192/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0191 - mae: 0.0999\n",
      "Epoch 1193/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0200 - mae: 0.1027\n",
      "Epoch 1194/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0196 - mae: 0.1018\n",
      "Epoch 1195/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0199 - mae: 0.1034\n",
      "Epoch 1196/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0202 - mae: 0.1039\n",
      "Epoch 1197/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0236 - mae: 0.1114\n",
      "Epoch 1198/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0193 - mae: 0.0986\n",
      "Epoch 1199/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0200 - mae: 0.1021\n",
      "Epoch 1200/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0199 - mae: 0.1019\n",
      "Epoch 1201/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1013\n",
      "Epoch 1202/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0199 - mae: 0.1023\n",
      "Epoch 1203/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0191 - mae: 0.0988\n",
      "Epoch 1204/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0197 - mae: 0.1005\n",
      "Epoch 1205/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0199 - mae: 0.1023\n",
      "Epoch 1206/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0191 - mae: 0.0998\n",
      "Epoch 1207/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0194 - mae: 0.1003\n",
      "Epoch 1208/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0188 - mae: 0.0984\n",
      "Epoch 1209/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0212 - mae: 0.1025\n",
      "Epoch 1210/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0193 - mae: 0.1007\n",
      "Epoch 1211/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0190 - mae: 0.0997\n",
      "Epoch 1212/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0186 - mae: 0.0987\n",
      "Epoch 1213/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0190 - mae: 0.1001\n",
      "Epoch 1214/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0183 - mae: 0.0976\n",
      "Epoch 1215/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0179 - mae: 0.0969\n",
      "Epoch 1216/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0191 - mae: 0.1011\n",
      "Epoch 1217/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0194 - mae: 0.1024\n",
      "Epoch 1218/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0184 - mae: 0.0983\n",
      "Epoch 1219/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0197 - mae: 0.1033\n",
      "Epoch 1220/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0192 - mae: 0.1010\n",
      "Epoch 1221/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0191 - mae: 0.1003\n",
      "Epoch 1222/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0192 - mae: 0.1007\n",
      "Epoch 1223/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0186 - mae: 0.0985\n",
      "Epoch 1224/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0193 - mae: 0.1003\n",
      "Epoch 1225/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0209 - mae: 0.1052\n",
      "Epoch 1226/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0180 - mae: 0.0970\n",
      "Epoch 1227/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0180 - mae: 0.0965\n",
      "Epoch 1228/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0180 - mae: 0.0961\n",
      "Epoch 1229/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0179 - mae: 0.0971\n",
      "Epoch 1230/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0191 - mae: 0.1000\n",
      "Epoch 1231/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0183 - mae: 0.0975\n",
      "Epoch 1232/2000\n",
      "2019/2019 [==============================] - 0s 112us/sample - loss: 0.0179 - mae: 0.0964\n",
      "Epoch 1233/2000\n",
      "2019/2019 [==============================] - 0s 120us/sample - loss: 0.0186 - mae: 0.0978\n",
      "Epoch 1234/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0212 - mae: 0.1045\n",
      "Epoch 1235/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0190 - mae: 0.1001\n",
      "Epoch 1236/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0184 - mae: 0.0974\n",
      "Epoch 1237/2000\n",
      "2019/2019 [==============================] - 0s 123us/sample - loss: 0.0205 - mae: 0.1047\n",
      "Epoch 1238/2000\n",
      "2019/2019 [==============================] - 0s 108us/sample - loss: 0.0202 - mae: 0.1046\n",
      "Epoch 1239/2000\n",
      "2019/2019 [==============================] - 0s 103us/sample - loss: 0.0207 - mae: 0.1047\n",
      "Epoch 1240/2000\n",
      "2019/2019 [==============================] - 0s 97us/sample - loss: 0.0185 - mae: 0.0985\n",
      "Epoch 1241/2000\n",
      "2019/2019 [==============================] - 0s 115us/sample - loss: 0.0192 - mae: 0.1007\n",
      "Epoch 1242/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0187 - mae: 0.0992\n",
      "Epoch 1243/2000\n",
      "2019/2019 [==============================] - 0s 160us/sample - loss: 0.0188 - mae: 0.0991\n",
      "Epoch 1244/2000\n",
      "2019/2019 [==============================] - 0s 130us/sample - loss: 0.0185 - mae: 0.0978\n",
      "Epoch 1245/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0182 - mae: 0.0972\n",
      "Epoch 1246/2000\n",
      "2019/2019 [==============================] - 0s 103us/sample - loss: 0.0202 - mae: 0.1037\n",
      "Epoch 1247/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 109us/sample - loss: 0.0199 - mae: 0.1031\n",
      "Epoch 1248/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0189 - mae: 0.0991\n",
      "Epoch 1249/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0190 - mae: 0.1001\n",
      "Epoch 1250/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0182 - mae: 0.0979\n",
      "Epoch 1251/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0180 - mae: 0.0973\n",
      "Epoch 1252/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0185 - mae: 0.0988\n",
      "Epoch 1253/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0186 - mae: 0.0990\n",
      "Epoch 1254/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0195 - mae: 0.1016\n",
      "Epoch 1255/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0175 - mae: 0.0948\n",
      "Epoch 1256/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0183 - mae: 0.0981\n",
      "Epoch 1257/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0184 - mae: 0.0983\n",
      "Epoch 1258/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0180 - mae: 0.0973\n",
      "Epoch 1259/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0185 - mae: 0.0980\n",
      "Epoch 1260/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0198 - mae: 0.1040\n",
      "Epoch 1261/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0202 - mae: 0.1034\n",
      "Epoch 1262/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0188 - mae: 0.0999\n",
      "Epoch 1263/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0187 - mae: 0.0980\n",
      "Epoch 1264/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0193 - mae: 0.1012\n",
      "Epoch 1265/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0225 - mae: 0.1093\n",
      "Epoch 1266/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0189 - mae: 0.0996\n",
      "Epoch 1267/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0192 - mae: 0.1018\n",
      "Epoch 1268/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.0998\n",
      "Epoch 1269/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0188 - mae: 0.0993\n",
      "Epoch 1270/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0191 - mae: 0.1005\n",
      "Epoch 1271/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0185 - mae: 0.0979\n",
      "Epoch 1272/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0187 - mae: 0.0984\n",
      "Epoch 1273/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0199 - mae: 0.1026\n",
      "Epoch 1274/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0197 - mae: 0.1022\n",
      "Epoch 1275/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0984\n",
      "Epoch 1276/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0188 - mae: 0.0991\n",
      "Epoch 1277/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0185 - mae: 0.0983\n",
      "Epoch 1278/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0986\n",
      "Epoch 1279/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0188 - mae: 0.0994\n",
      "Epoch 1280/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0190 - mae: 0.1003\n",
      "Epoch 1281/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0198 - mae: 0.1030\n",
      "Epoch 1282/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0194 - mae: 0.1016\n",
      "Epoch 1283/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0971\n",
      "Epoch 1284/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0973\n",
      "Epoch 1285/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0179 - mae: 0.0964\n",
      "Epoch 1286/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0182 - mae: 0.0981\n",
      "Epoch 1287/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0179 - mae: 0.0974\n",
      "Epoch 1288/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0198 - mae: 0.1018\n",
      "Epoch 1289/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0195 - mae: 0.1016\n",
      "Epoch 1290/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0194 - mae: 0.1000\n",
      "Epoch 1291/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0182 - mae: 0.0980\n",
      "Epoch 1292/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0177 - mae: 0.0960\n",
      "Epoch 1293/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0182 - mae: 0.0983\n",
      "Epoch 1294/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0188 - mae: 0.0984\n",
      "Epoch 1295/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0188 - mae: 0.1006\n",
      "Epoch 1296/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0197 - mae: 0.1036\n",
      "Epoch 1297/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0974\n",
      "Epoch 1298/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0184 - mae: 0.0983\n",
      "Epoch 1299/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0206 - mae: 0.1052\n",
      "Epoch 1300/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0196 - mae: 0.1015\n",
      "Epoch 1301/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0181 - mae: 0.0972\n",
      "Epoch 1302/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0177 - mae: 0.0967\n",
      "Epoch 1303/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0192 - mae: 0.1005\n",
      "Epoch 1304/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0190 - mae: 0.1004\n",
      "Epoch 1305/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0965\n",
      "Epoch 1306/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0990\n",
      "Epoch 1307/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0179 - mae: 0.0968\n",
      "Epoch 1308/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0186 - mae: 0.0984\n",
      "Epoch 1309/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0181 - mae: 0.0978\n",
      "Epoch 1310/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0197 - mae: 0.1029\n",
      "Epoch 1311/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0194 - mae: 0.1020\n",
      "Epoch 1312/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0184 - mae: 0.0987\n",
      "Epoch 1313/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0191 - mae: 0.1001\n",
      "Epoch 1314/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0190 - mae: 0.1007\n",
      "Epoch 1315/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0182 - mae: 0.0983\n",
      "Epoch 1316/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0181 - mae: 0.0969\n",
      "Epoch 1317/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0182 - mae: 0.0988\n",
      "Epoch 1318/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0191 - mae: 0.1006\n",
      "Epoch 1319/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0183 - mae: 0.0970\n",
      "Epoch 1320/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0992\n",
      "Epoch 1321/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.1013\n",
      "Epoch 1322/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0188 - mae: 0.1001\n",
      "Epoch 1323/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0188 - mae: 0.1003\n",
      "Epoch 1324/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0180 - mae: 0.0966\n",
      "Epoch 1325/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0184 - mae: 0.0987\n",
      "Epoch 1326/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0183 - mae: 0.0982\n",
      "Epoch 1327/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0250 - mae: 0.1154\n",
      "Epoch 1328/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0197 - mae: 0.1030\n",
      "Epoch 1329/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0190 - mae: 0.1012\n",
      "Epoch 1330/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0187 - mae: 0.0993\n",
      "Epoch 1331/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0189 - mae: 0.1008\n",
      "Epoch 1332/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0190 - mae: 0.1016\n",
      "Epoch 1333/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0992\n",
      "Epoch 1334/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0186 - mae: 0.1002\n",
      "Epoch 1335/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0189 - mae: 0.1007\n",
      "Epoch 1336/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0181 - mae: 0.0981\n",
      "Epoch 1337/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0182 - mae: 0.0979\n",
      "Epoch 1338/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1044\n",
      "Epoch 1339/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0181 - mae: 0.0980\n",
      "Epoch 1340/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0186 - mae: 0.0979\n",
      "Epoch 1341/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0187 - mae: 0.0988\n",
      "Epoch 1342/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0181 - mae: 0.0973\n",
      "Epoch 1343/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0190 - mae: 0.0997\n",
      "Epoch 1344/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0988\n",
      "Epoch 1345/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0986\n",
      "Epoch 1346/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0178 - mae: 0.0974\n",
      "Epoch 1347/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0189 - mae: 0.0995\n",
      "Epoch 1348/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0981\n",
      "Epoch 1349/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0186 - mae: 0.0999\n",
      "Epoch 1350/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0187 - mae: 0.0987\n",
      "Epoch 1351/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0211 - mae: 0.1058\n",
      "Epoch 1352/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0192 - mae: 0.1007\n",
      "Epoch 1353/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.1005\n",
      "Epoch 1354/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0190 - mae: 0.0993\n",
      "Epoch 1355/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0183 - mae: 0.0977\n",
      "Epoch 1356/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0192 - mae: 0.1019\n",
      "Epoch 1357/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0994\n",
      "Epoch 1358/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0182 - mae: 0.0983\n",
      "Epoch 1359/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0182 - mae: 0.0992\n",
      "Epoch 1360/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0185 - mae: 0.0986\n",
      "Epoch 1361/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0186 - mae: 0.0999\n",
      "Epoch 1362/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0183 - mae: 0.0992\n",
      "Epoch 1363/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0177 - mae: 0.0969\n",
      "Epoch 1364/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0197 - mae: 0.1031\n",
      "Epoch 1365/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0200 - mae: 0.1045\n",
      "Epoch 1366/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0978\n",
      "Epoch 1367/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0182 - mae: 0.0981\n",
      "Epoch 1368/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0981\n",
      "Epoch 1369/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0190 - mae: 0.1011\n",
      "Epoch 1370/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0180 - mae: 0.0974\n",
      "Epoch 1371/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0230 - mae: 0.1116\n",
      "Epoch 1372/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0209 - mae: 0.1063\n",
      "Epoch 1373/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0198 - mae: 0.1027\n",
      "Epoch 1374/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0190 - mae: 0.1009\n",
      "Epoch 1375/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0194 - mae: 0.1029\n",
      "Epoch 1376/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0187 - mae: 0.0999\n",
      "Epoch 1377/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0197 - mae: 0.1042\n",
      "Epoch 1378/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0179 - mae: 0.0976\n",
      "Epoch 1379/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0954\n",
      "Epoch 1380/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0176 - mae: 0.0964\n",
      "Epoch 1381/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0186 - mae: 0.0997\n",
      "Epoch 1382/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0187 - mae: 0.1002\n",
      "Epoch 1383/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0195 - mae: 0.1021\n",
      "Epoch 1384/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0184 - mae: 0.0991\n",
      "Epoch 1385/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0178 - mae: 0.0973\n",
      "Epoch 1386/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0178 - mae: 0.0966\n",
      "Epoch 1387/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0977\n",
      "Epoch 1388/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0180 - mae: 0.0975\n",
      "Epoch 1389/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0177 - mae: 0.0967\n",
      "Epoch 1390/2000\n",
      "2019/2019 [==============================] - 0s 97us/sample - loss: 0.0182 - mae: 0.0982\n",
      "Epoch 1391/2000\n",
      "2019/2019 [==============================] - 0s 98us/sample - loss: 0.0178 - mae: 0.0976\n",
      "Epoch 1392/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0177 - mae: 0.0965\n",
      "Epoch 1393/2000\n",
      "2019/2019 [==============================] - 0s 136us/sample - loss: 0.0185 - mae: 0.0994\n",
      "Epoch 1394/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0182 - mae: 0.0984\n",
      "Epoch 1395/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0188 - mae: 0.0995\n",
      "Epoch 1396/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0189 - mae: 0.0997\n",
      "Epoch 1397/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0987\n",
      "Epoch 1398/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.0986\n",
      "Epoch 1399/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0190 - mae: 0.1009\n",
      "Epoch 1400/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0194 - mae: 0.1018\n",
      "Epoch 1401/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0183 - mae: 0.0979\n",
      "Epoch 1402/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0182 - mae: 0.0983\n",
      "Epoch 1403/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0192 - mae: 0.1011\n",
      "Epoch 1404/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0180 - mae: 0.0985\n",
      "Epoch 1405/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0190 - mae: 0.0991\n",
      "Epoch 1406/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0188 - mae: 0.0996\n",
      "Epoch 1407/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0188 - mae: 0.1004\n",
      "Epoch 1408/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0975\n",
      "Epoch 1409/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0231 - mae: 0.1118\n",
      "Epoch 1410/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.1002\n",
      "Epoch 1411/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0188 - mae: 0.1008\n",
      "Epoch 1412/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0171 - mae: 0.0949\n",
      "Epoch 1413/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.1026\n",
      "Epoch 1414/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0994\n",
      "Epoch 1415/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0988\n",
      "Epoch 1416/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0182 - mae: 0.0979\n",
      "Epoch 1417/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0179 - mae: 0.0974\n",
      "Epoch 1418/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0182 - mae: 0.0983\n",
      "Epoch 1419/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0175 - mae: 0.0956\n",
      "Epoch 1420/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0184 - mae: 0.0986\n",
      "Epoch 1421/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0177 - mae: 0.0963\n",
      "Epoch 1422/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0183 - mae: 0.0988\n",
      "Epoch 1423/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0983\n",
      "Epoch 1424/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0181 - mae: 0.0980\n",
      "Epoch 1425/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0187 - mae: 0.0999\n",
      "Epoch 1426/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0222 - mae: 0.1101\n",
      "Epoch 1427/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0207 - mae: 0.1049\n",
      "Epoch 1428/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0190 - mae: 0.1002\n",
      "Epoch 1429/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0182 - mae: 0.0987\n",
      "Epoch 1430/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0184 - mae: 0.0986\n",
      "Epoch 1431/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0189 - mae: 0.0999\n",
      "Epoch 1432/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0185 - mae: 0.0977\n",
      "Epoch 1433/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0183 - mae: 0.0991\n",
      "Epoch 1434/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0182 - mae: 0.0975\n",
      "Epoch 1435/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0179 - mae: 0.0975\n",
      "Epoch 1436/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0189 - mae: 0.1004\n",
      "Epoch 1437/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0204 - mae: 0.1041\n",
      "Epoch 1438/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0182 - mae: 0.0990\n",
      "Epoch 1439/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0181 - mae: 0.0986\n",
      "Epoch 1440/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0182 - mae: 0.0987\n",
      "Epoch 1441/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0177 - mae: 0.0962\n",
      "Epoch 1442/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0188 - mae: 0.1007\n",
      "Epoch 1443/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0174 - mae: 0.0966\n",
      "Epoch 1444/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0176 - mae: 0.0965\n",
      "Epoch 1445/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0184 - mae: 0.0994\n",
      "Epoch 1446/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0191 - mae: 0.1008\n",
      "Epoch 1447/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0185 - mae: 0.0992\n",
      "Epoch 1448/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0179 - mae: 0.0971\n",
      "Epoch 1449/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0175 - mae: 0.0961\n",
      "Epoch 1450/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0178 - mae: 0.0971\n",
      "Epoch 1451/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0189 - mae: 0.1011\n",
      "Epoch 1452/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0190 - mae: 0.1012\n",
      "Epoch 1453/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0186 - mae: 0.1002\n",
      "Epoch 1454/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0999\n",
      "Epoch 1455/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0177 - mae: 0.0968\n",
      "Epoch 1456/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0187 - mae: 0.1010\n",
      "Epoch 1457/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0176 - mae: 0.0960\n",
      "Epoch 1458/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.1002\n",
      "Epoch 1459/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0187 - mae: 0.1006\n",
      "Epoch 1460/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0189 - mae: 0.1000\n",
      "Epoch 1461/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0199 - mae: 0.1043\n",
      "Epoch 1462/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0191 - mae: 0.1010\n",
      "Epoch 1463/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0191 - mae: 0.1010\n",
      "Epoch 1464/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0177 - mae: 0.0969\n",
      "Epoch 1465/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0181 - mae: 0.0984\n",
      "Epoch 1466/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0200 - mae: 0.1039\n",
      "Epoch 1467/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0184 - mae: 0.0996\n",
      "Epoch 1468/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0980\n",
      "Epoch 1469/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0190 - mae: 0.1005\n",
      "Epoch 1470/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0189 - mae: 0.1007\n",
      "Epoch 1471/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0193 - mae: 0.1025\n",
      "Epoch 1472/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0181 - mae: 0.0968\n",
      "Epoch 1473/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0189 - mae: 0.0996\n",
      "Epoch 1474/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0182 - mae: 0.0985\n",
      "Epoch 1475/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0176 - mae: 0.0965\n",
      "Epoch 1476/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0182 - mae: 0.0982\n",
      "Epoch 1477/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0187 - mae: 0.1000\n",
      "Epoch 1478/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0182 - mae: 0.0980\n",
      "Epoch 1479/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0190 - mae: 0.1018\n",
      "Epoch 1480/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0177 - mae: 0.0978\n",
      "Epoch 1481/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0175 - mae: 0.0958\n",
      "Epoch 1482/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0179 - mae: 0.0983\n",
      "Epoch 1483/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0975\n",
      "Epoch 1484/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0183 - mae: 0.0985\n",
      "Epoch 1485/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0994\n",
      "Epoch 1486/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0186 - mae: 0.0993\n",
      "Epoch 1487/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0180 - mae: 0.0981\n",
      "Epoch 1488/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0180 - mae: 0.0982\n",
      "Epoch 1489/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0174 - mae: 0.0959\n",
      "Epoch 1490/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0181 - mae: 0.0985\n",
      "Epoch 1491/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.1002\n",
      "Epoch 1492/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0176 - mae: 0.0966\n",
      "Epoch 1493/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0182 - mae: 0.0987\n",
      "Epoch 1494/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0179 - mae: 0.0982\n",
      "Epoch 1495/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0175 - mae: 0.0962\n",
      "Epoch 1496/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0195 - mae: 0.1008\n",
      "Epoch 1497/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0179 - mae: 0.0976\n",
      "Epoch 1498/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0182 - mae: 0.0996\n",
      "Epoch 1499/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0192 - mae: 0.1009\n",
      "Epoch 1500/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0189 - mae: 0.1007\n",
      "Epoch 1501/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0176 - mae: 0.0963\n",
      "Epoch 1502/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0186 - mae: 0.1007\n",
      "Epoch 1503/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0178 - mae: 0.0976\n",
      "Epoch 1504/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0176 - mae: 0.0974\n",
      "Epoch 1505/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0176 - mae: 0.0964\n",
      "Epoch 1506/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0174 - mae: 0.0956\n",
      "Epoch 1507/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0189 - mae: 0.1013\n",
      "Epoch 1508/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0190 - mae: 0.1013\n",
      "Epoch 1509/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0177 - mae: 0.0977\n",
      "Epoch 1510/2000\n",
      "2019/2019 [==============================] - 0s 99us/sample - loss: 0.0192 - mae: 0.1012\n",
      "Epoch 1511/2000\n",
      "2019/2019 [==============================] - 0s 105us/sample - loss: 0.0181 - mae: 0.0985\n",
      "Epoch 1512/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0176 - mae: 0.0959\n",
      "Epoch 1513/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0178 - mae: 0.0969\n",
      "Epoch 1514/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0190 - mae: 0.1012\n",
      "Epoch 1515/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0190 - mae: 0.1011\n",
      "Epoch 1516/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0186 - mae: 0.1008\n",
      "Epoch 1517/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0177 - mae: 0.0971\n",
      "Epoch 1518/2000\n",
      "2019/2019 [==============================] - 0s 92us/sample - loss: 0.0186 - mae: 0.1000\n",
      "Epoch 1519/2000\n",
      "2019/2019 [==============================] - 0s 92us/sample - loss: 0.0178 - mae: 0.0982\n",
      "Epoch 1520/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0174 - mae: 0.0963\n",
      "Epoch 1521/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0190 - mae: 0.1009\n",
      "Epoch 1522/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0187 - mae: 0.0998\n",
      "Epoch 1523/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0183 - mae: 0.0987\n",
      "Epoch 1524/2000\n",
      "2019/2019 [==============================] - 0s 98us/sample - loss: 0.0184 - mae: 0.0992\n",
      "Epoch 1525/2000\n",
      "2019/2019 [==============================] - 0s 107us/sample - loss: 0.0173 - mae: 0.0958\n",
      "Epoch 1526/2000\n",
      "2019/2019 [==============================] - 0s 113us/sample - loss: 0.0179 - mae: 0.0975\n",
      "Epoch 1527/2000\n",
      "2019/2019 [==============================] - 0s 104us/sample - loss: 0.0179 - mae: 0.0974\n",
      "Epoch 1528/2000\n",
      "2019/2019 [==============================] - 0s 99us/sample - loss: 0.0171 - mae: 0.0952\n",
      "Epoch 1529/2000\n",
      "2019/2019 [==============================] - 0s 96us/sample - loss: 0.0176 - mae: 0.0965\n",
      "Epoch 1530/2000\n",
      "2019/2019 [==============================] - 0s 97us/sample - loss: 0.0175 - mae: 0.0970\n",
      "Epoch 1531/2000\n",
      "2019/2019 [==============================] - 0s 96us/sample - loss: 0.0201 - mae: 0.1048\n",
      "Epoch 1532/2000\n",
      "2019/2019 [==============================] - 0s 130us/sample - loss: 0.0179 - mae: 0.0979\n",
      "Epoch 1533/2000\n",
      "2019/2019 [==============================] - 0s 107us/sample - loss: 0.0180 - mae: 0.0986\n",
      "Epoch 1534/2000\n",
      "2019/2019 [==============================] - 0s 110us/sample - loss: 0.0194 - mae: 0.1027\n",
      "Epoch 1535/2000\n",
      "2019/2019 [==============================] - 0s 101us/sample - loss: 0.0171 - mae: 0.0953\n",
      "Epoch 1536/2000\n",
      "2019/2019 [==============================] - 0s 96us/sample - loss: 0.0176 - mae: 0.0967\n",
      "Epoch 1537/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0175 - mae: 0.0962\n",
      "Epoch 1538/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0182 - mae: 0.0985\n",
      "Epoch 1539/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0177 - mae: 0.0971\n",
      "Epoch 1540/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0187 - mae: 0.1003\n",
      "Epoch 1541/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0189 - mae: 0.1007\n",
      "Epoch 1542/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0172 - mae: 0.0949\n",
      "Epoch 1543/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0173 - mae: 0.0960\n",
      "Epoch 1544/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0185 - mae: 0.0999\n",
      "Epoch 1545/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0176 - mae: 0.0970\n",
      "Epoch 1546/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0179 - mae: 0.0977\n",
      "Epoch 1547/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0179 - mae: 0.0975\n",
      "Epoch 1548/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0197 - mae: 0.1028\n",
      "Epoch 1549/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0200 - mae: 0.1037\n",
      "Epoch 1550/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0177 - mae: 0.0966\n",
      "Epoch 1551/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0174 - mae: 0.0964\n",
      "Epoch 1552/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0189 - mae: 0.0999\n",
      "Epoch 1553/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0187 - mae: 0.0999\n",
      "Epoch 1554/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0187 - mae: 0.1001\n",
      "Epoch 1555/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0195 - mae: 0.1020\n",
      "Epoch 1556/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0181 - mae: 0.0977\n",
      "Epoch 1557/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0179 - mae: 0.0986\n",
      "Epoch 1558/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0209 - mae: 0.1070\n",
      "Epoch 1559/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0196 - mae: 0.1031\n",
      "Epoch 1560/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0182 - mae: 0.0988\n",
      "Epoch 1561/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0188 - mae: 0.1010\n",
      "Epoch 1562/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0186 - mae: 0.0995\n",
      "Epoch 1563/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0184 - mae: 0.0990\n",
      "Epoch 1564/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0176 - mae: 0.0963\n",
      "Epoch 1565/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0175 - mae: 0.0962\n",
      "Epoch 1566/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0173 - mae: 0.0957\n",
      "Epoch 1567/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0175 - mae: 0.0968\n",
      "Epoch 1568/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0180 - mae: 0.0984\n",
      "Epoch 1569/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0174 - mae: 0.0959\n",
      "Epoch 1570/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0172 - mae: 0.0960\n",
      "Epoch 1571/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0171 - mae: 0.0950\n",
      "Epoch 1572/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0461 - mae: 0.1625\n",
      "Epoch 1573/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0282 - mae: 0.1267\n",
      "Epoch 1574/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0235 - mae: 0.1124\n",
      "Epoch 1575/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0211 - mae: 0.1062\n",
      "Epoch 1576/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0205 - mae: 0.1038\n",
      "Epoch 1577/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0210 - mae: 0.1055\n",
      "Epoch 1578/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0196 - mae: 0.1024\n",
      "Epoch 1579/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.1012\n",
      "Epoch 1580/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0187 - mae: 0.0996\n",
      "Epoch 1581/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0194 - mae: 0.1010\n",
      "Epoch 1582/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0198 - mae: 0.1016\n",
      "Epoch 1583/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0195 - mae: 0.1015\n",
      "Epoch 1584/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0188 - mae: 0.1000\n",
      "Epoch 1585/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0192 - mae: 0.1018\n",
      "Epoch 1586/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0192 - mae: 0.1011\n",
      "Epoch 1587/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0194 - mae: 0.1019\n",
      "Epoch 1588/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0192 - mae: 0.1015\n",
      "Epoch 1589/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0189 - mae: 0.1009\n",
      "Epoch 1590/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0182 - mae: 0.0993\n",
      "Epoch 1591/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0201 - mae: 0.1044\n",
      "Epoch 1592/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0228 - mae: 0.1120\n",
      "Epoch 1593/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0188 - mae: 0.1005\n",
      "Epoch 1594/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0190 - mae: 0.1008\n",
      "Epoch 1595/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.1020\n",
      "Epoch 1596/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.1019\n",
      "Epoch 1597/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0189 - mae: 0.1001\n",
      "Epoch 1598/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0288 - mae: 0.1271\n",
      "Epoch 1599/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0190 - mae: 0.1004\n",
      "Epoch 1600/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0182 - mae: 0.0984\n",
      "Epoch 1601/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0184 - mae: 0.0985\n",
      "Epoch 1602/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0180 - mae: 0.0974\n",
      "Epoch 1603/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0176 - mae: 0.0967\n",
      "Epoch 1604/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0181 - mae: 0.0979\n",
      "Epoch 1605/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0178 - mae: 0.0960\n",
      "Epoch 1606/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0987\n",
      "Epoch 1607/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0175 - mae: 0.0959\n",
      "Epoch 1608/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0174 - mae: 0.0955\n",
      "Epoch 1609/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0192 - mae: 0.1015\n",
      "Epoch 1610/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0182 - mae: 0.0980\n",
      "Epoch 1611/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.0980\n",
      "Epoch 1612/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0184 - mae: 0.0987\n",
      "Epoch 1613/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0178 - mae: 0.0970\n",
      "Epoch 1614/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0176 - mae: 0.0965\n",
      "Epoch 1615/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0177 - mae: 0.0966\n",
      "Epoch 1616/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0182 - mae: 0.0985\n",
      "Epoch 1617/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0187 - mae: 0.0999\n",
      "Epoch 1618/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0181 - mae: 0.0980\n",
      "Epoch 1619/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0177 - mae: 0.0961\n",
      "Epoch 1620/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0198 - mae: 0.1029\n",
      "Epoch 1621/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0182 - mae: 0.0975\n",
      "Epoch 1622/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0190 - mae: 0.1015\n",
      "Epoch 1623/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0190 - mae: 0.1006\n",
      "Epoch 1624/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0180 - mae: 0.0978\n",
      "Epoch 1625/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0176 - mae: 0.0964\n",
      "Epoch 1626/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0182 - mae: 0.0991\n",
      "Epoch 1627/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0197 - mae: 0.1027\n",
      "Epoch 1628/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0181 - mae: 0.0983\n",
      "Epoch 1629/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0192 - mae: 0.1020\n",
      "Epoch 1630/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0191 - mae: 0.1017\n",
      "Epoch 1631/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0173 - mae: 0.0956\n",
      "Epoch 1632/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0983\n",
      "Epoch 1633/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0179 - mae: 0.0982\n",
      "Epoch 1634/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0173 - mae: 0.0958\n",
      "Epoch 1635/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0178 - mae: 0.0971\n",
      "Epoch 1636/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0173 - mae: 0.0957\n",
      "Epoch 1637/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0172 - mae: 0.0955\n",
      "Epoch 1638/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0178 - mae: 0.0970\n",
      "Epoch 1639/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0198 - mae: 0.1024\n",
      "Epoch 1640/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0208 - mae: 0.1049\n",
      "Epoch 1641/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0187 - mae: 0.1004\n",
      "Epoch 1642/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0986\n",
      "Epoch 1643/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0179 - mae: 0.0971\n",
      "Epoch 1644/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0171 - mae: 0.0948\n",
      "Epoch 1645/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0975\n",
      "Epoch 1646/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0176 - mae: 0.0963\n",
      "Epoch 1647/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0179 - mae: 0.0973\n",
      "Epoch 1648/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0187 - mae: 0.0998\n",
      "Epoch 1649/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0182 - mae: 0.0983\n",
      "Epoch 1650/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0183 - mae: 0.0992\n",
      "Epoch 1651/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0195 - mae: 0.1027\n",
      "Epoch 1652/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0182 - mae: 0.0994\n",
      "Epoch 1653/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0178 - mae: 0.0976\n",
      "Epoch 1654/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0299 - mae: 0.1290\n",
      "Epoch 1655/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0228 - mae: 0.1109\n",
      "Epoch 1656/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0178 - mae: 0.0983\n",
      "Epoch 1657/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0192 - mae: 0.1009\n",
      "Epoch 1658/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0185 - mae: 0.1008\n",
      "Epoch 1659/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0179 - mae: 0.0985\n",
      "Epoch 1660/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0172 - mae: 0.0959\n",
      "Epoch 1661/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0182 - mae: 0.0997\n",
      "Epoch 1662/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0177 - mae: 0.0973\n",
      "Epoch 1663/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0180 - mae: 0.0980\n",
      "Epoch 1664/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0183 - mae: 0.0986\n",
      "Epoch 1665/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0176 - mae: 0.0953\n",
      "Epoch 1666/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0176 - mae: 0.0969\n",
      "Epoch 1667/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0173 - mae: 0.0961\n",
      "Epoch 1668/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0188 - mae: 0.0996\n",
      "Epoch 1669/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0183 - mae: 0.0986\n",
      "Epoch 1670/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0183 - mae: 0.0984\n",
      "Epoch 1671/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0173 - mae: 0.0960\n",
      "Epoch 1672/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0174 - mae: 0.0963\n",
      "Epoch 1673/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0176 - mae: 0.0968\n",
      "Epoch 1674/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0184 - mae: 0.0995\n",
      "Epoch 1675/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0172 - mae: 0.0957\n",
      "Epoch 1676/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0176 - mae: 0.0970\n",
      "Epoch 1677/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0173 - mae: 0.0962\n",
      "Epoch 1678/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0181 - mae: 0.0981\n",
      "Epoch 1679/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0177 - mae: 0.0977\n",
      "Epoch 1680/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0186 - mae: 0.0993\n",
      "Epoch 1681/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0174 - mae: 0.0959\n",
      "Epoch 1682/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0204 - mae: 0.1045\n",
      "Epoch 1683/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0180 - mae: 0.0976\n",
      "Epoch 1684/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0177 - mae: 0.0970\n",
      "Epoch 1685/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0180 - mae: 0.0980\n",
      "Epoch 1686/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0179 - mae: 0.0975\n",
      "Epoch 1687/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0174 - mae: 0.0955\n",
      "Epoch 1688/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0176 - mae: 0.0970\n",
      "Epoch 1689/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0179 - mae: 0.0973\n",
      "Epoch 1690/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0179 - mae: 0.0975\n",
      "Epoch 1691/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0188 - mae: 0.1002\n",
      "Epoch 1692/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0180 - mae: 0.0980\n",
      "Epoch 1693/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0188 - mae: 0.1000\n",
      "Epoch 1694/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0182 - mae: 0.0993\n",
      "Epoch 1695/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0178 - mae: 0.0978\n",
      "Epoch 1696/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0180 - mae: 0.0983\n",
      "Epoch 1697/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0179 - mae: 0.0979\n",
      "Epoch 1698/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0174 - mae: 0.0962\n",
      "Epoch 1699/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0174 - mae: 0.0963\n",
      "Epoch 1700/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0183 - mae: 0.0978\n",
      "Epoch 1701/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0181 - mae: 0.0970\n",
      "Epoch 1702/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0982\n",
      "Epoch 1703/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0174 - mae: 0.0961\n",
      "Epoch 1704/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.0990\n",
      "Epoch 1705/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0180 - mae: 0.0979\n",
      "Epoch 1706/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0176 - mae: 0.0967\n",
      "Epoch 1707/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0986\n",
      "Epoch 1708/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0178 - mae: 0.0973\n",
      "Epoch 1709/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0185 - mae: 0.1008\n",
      "Epoch 1710/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0183 - mae: 0.0991\n",
      "Epoch 1711/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0180 - mae: 0.0979\n",
      "Epoch 1712/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.1009\n",
      "Epoch 1713/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0174 - mae: 0.0965\n",
      "Epoch 1714/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0188 - mae: 0.1004\n",
      "Epoch 1715/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0171 - mae: 0.0949\n",
      "Epoch 1716/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0172 - mae: 0.0957\n",
      "Epoch 1717/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0184 - mae: 0.1000\n",
      "Epoch 1718/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0178 - mae: 0.0977\n",
      "Epoch 1719/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0175 - mae: 0.0971\n",
      "Epoch 1720/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0170 - mae: 0.0950\n",
      "Epoch 1721/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0168 - mae: 0.0944\n",
      "Epoch 1722/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0168 - mae: 0.0945\n",
      "Epoch 1723/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0172 - mae: 0.0953\n",
      "Epoch 1724/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0178 - mae: 0.0979\n",
      "Epoch 1725/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0186 - mae: 0.0997\n",
      "Epoch 1726/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0182 - mae: 0.1001\n",
      "Epoch 1727/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0176 - mae: 0.0965\n",
      "Epoch 1728/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0187 - mae: 0.1011\n",
      "Epoch 1729/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0176 - mae: 0.0978\n",
      "Epoch 1730/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0177 - mae: 0.0973\n",
      "Epoch 1731/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0183 - mae: 0.1004\n",
      "Epoch 1732/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0178 - mae: 0.0964\n",
      "Epoch 1733/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0181 - mae: 0.0991\n",
      "Epoch 1734/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0223 - mae: 0.1105\n",
      "Epoch 1735/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0183 - mae: 0.1001\n",
      "Epoch 1736/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0173 - mae: 0.0962\n",
      "Epoch 1737/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0179 - mae: 0.0968\n",
      "Epoch 1738/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0175 - mae: 0.0964\n",
      "Epoch 1739/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0180 - mae: 0.0992\n",
      "Epoch 1740/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0185 - mae: 0.0995\n",
      "Epoch 1741/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0173 - mae: 0.0958\n",
      "Epoch 1742/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0174 - mae: 0.0968\n",
      "Epoch 1743/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0186 - mae: 0.0996\n",
      "Epoch 1744/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0172 - mae: 0.0962\n",
      "Epoch 1745/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0170 - mae: 0.0957\n",
      "Epoch 1746/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0193 - mae: 0.1031\n",
      "Epoch 1747/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0188 - mae: 0.1008\n",
      "Epoch 1748/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0199 - mae: 0.1037\n",
      "Epoch 1749/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0175 - mae: 0.0971\n",
      "Epoch 1750/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0194 - mae: 0.1028\n",
      "Epoch 1751/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0178 - mae: 0.0967\n",
      "Epoch 1752/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0178 - mae: 0.0979\n",
      "Epoch 1753/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0179 - mae: 0.0983\n",
      "Epoch 1754/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0189 - mae: 0.1011\n",
      "Epoch 1755/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0187 - mae: 0.1006\n",
      "Epoch 1756/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0182 - mae: 0.0988\n",
      "Epoch 1757/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0170 - mae: 0.0952\n",
      "Epoch 1758/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0203 - mae: 0.1046\n",
      "Epoch 1759/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0176 - mae: 0.0966\n",
      "Epoch 1760/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0175 - mae: 0.0963\n",
      "Epoch 1761/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0998\n",
      "Epoch 1762/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0170 - mae: 0.0946\n",
      "Epoch 1763/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0171 - mae: 0.0948\n",
      "Epoch 1764/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0992\n",
      "Epoch 1765/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0178 - mae: 0.0971\n",
      "Epoch 1766/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0169 - mae: 0.0941\n",
      "Epoch 1767/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0173 - mae: 0.0963\n",
      "Epoch 1768/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0191 - mae: 0.1018\n",
      "Epoch 1769/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0189 - mae: 0.1002\n",
      "Epoch 1770/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0202 - mae: 0.1033\n",
      "Epoch 1771/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0226 - mae: 0.1039\n",
      "Epoch 1772/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0191 - mae: 0.1019\n",
      "Epoch 1773/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0189 - mae: 0.1009\n",
      "Epoch 1774/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0196 - mae: 0.1033\n",
      "Epoch 1775/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0191 - mae: 0.1001\n",
      "Epoch 1776/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0181 - mae: 0.0989\n",
      "Epoch 1777/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0184 - mae: 0.0991\n",
      "Epoch 1778/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0185 - mae: 0.1003\n",
      "Epoch 1779/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0182 - mae: 0.0984\n",
      "Epoch 1780/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0183 - mae: 0.0995\n",
      "Epoch 1781/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0173 - mae: 0.0961\n",
      "Epoch 1782/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0182 - mae: 0.0996\n",
      "Epoch 1783/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0224 - mae: 0.1094\n",
      "Epoch 1784/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0196 - mae: 0.1020\n",
      "Epoch 1785/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0184 - mae: 0.0994\n",
      "Epoch 1786/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0191 - mae: 0.1010\n",
      "Epoch 1787/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.1033\n",
      "Epoch 1788/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0177 - mae: 0.0976\n",
      "Epoch 1789/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0175 - mae: 0.0968\n",
      "Epoch 1790/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0178 - mae: 0.0974\n",
      "Epoch 1791/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0193 - mae: 0.1019\n",
      "Epoch 1792/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0196 - mae: 0.1027\n",
      "Epoch 1793/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0178 - mae: 0.0972\n",
      "Epoch 1794/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0174 - mae: 0.0964\n",
      "Epoch 1795/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0179 - mae: 0.0976\n",
      "Epoch 1796/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0177 - mae: 0.0976\n",
      "Epoch 1797/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0198 - mae: 0.1038\n",
      "Epoch 1798/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0185 - mae: 0.0993\n",
      "Epoch 1799/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0177 - mae: 0.0971\n",
      "Epoch 1800/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0175 - mae: 0.0966\n",
      "Epoch 1801/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0177 - mae: 0.0971\n",
      "Epoch 1802/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0177 - mae: 0.0978\n",
      "Epoch 1803/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0171 - mae: 0.0953\n",
      "Epoch 1804/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0183 - mae: 0.0985\n",
      "Epoch 1805/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0215 - mae: 0.1073\n",
      "Epoch 1806/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0199 - mae: 0.1037\n",
      "Epoch 1807/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0182 - mae: 0.0992\n",
      "Epoch 1808/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0193 - mae: 0.1029\n",
      "Epoch 1809/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0207 - mae: 0.1056\n",
      "Epoch 1810/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0198 - mae: 0.1033\n",
      "Epoch 1811/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0178 - mae: 0.0971\n",
      "Epoch 1812/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0177 - mae: 0.0974\n",
      "Epoch 1813/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0184 - mae: 0.0999\n",
      "Epoch 1814/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0971\n",
      "Epoch 1815/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0172 - mae: 0.0959\n",
      "Epoch 1816/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0221 - mae: 0.1081\n",
      "Epoch 1817/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0179 - mae: 0.0976\n",
      "Epoch 1818/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0178 - mae: 0.0976\n",
      "Epoch 1819/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0169 - mae: 0.0951\n",
      "Epoch 1820/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0175 - mae: 0.0963\n",
      "Epoch 1821/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0176 - mae: 0.0967\n",
      "Epoch 1822/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0175 - mae: 0.0963\n",
      "Epoch 1823/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0184 - mae: 0.0998\n",
      "Epoch 1824/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0174 - mae: 0.0959\n",
      "Epoch 1825/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0184 - mae: 0.0987\n",
      "Epoch 1826/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0182 - mae: 0.0985\n",
      "Epoch 1827/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0172 - mae: 0.0953\n",
      "Epoch 1828/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0179 - mae: 0.0976\n",
      "Epoch 1829/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0184 - mae: 0.0997\n",
      "Epoch 1830/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0173 - mae: 0.0961\n",
      "Epoch 1831/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0176 - mae: 0.0966\n",
      "Epoch 1832/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0174 - mae: 0.0970\n",
      "Epoch 1833/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0175 - mae: 0.0961\n",
      "Epoch 1834/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0171 - mae: 0.0961\n",
      "Epoch 1835/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0170 - mae: 0.0953\n",
      "Epoch 1836/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0179 - mae: 0.0980\n",
      "Epoch 1837/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0179 - mae: 0.0971\n",
      "Epoch 1838/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0174 - mae: 0.0959\n",
      "Epoch 1839/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0183 - mae: 0.0988\n",
      "Epoch 1840/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0176 - mae: 0.0975\n",
      "Epoch 1841/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0177 - mae: 0.0981\n",
      "Epoch 1842/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0216 - mae: 0.1089\n",
      "Epoch 1843/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0205 - mae: 0.1040\n",
      "Epoch 1844/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0194 - mae: 0.1022\n",
      "Epoch 1845/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0178 - mae: 0.0977\n",
      "Epoch 1846/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0182 - mae: 0.0992\n",
      "Epoch 1847/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0176 - mae: 0.0967\n",
      "Epoch 1848/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0171 - mae: 0.0949\n",
      "Epoch 1849/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0169 - mae: 0.0945\n",
      "Epoch 1850/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0173 - mae: 0.0959\n",
      "Epoch 1851/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0180 - mae: 0.0977\n",
      "Epoch 1852/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0174 - mae: 0.0964\n",
      "Epoch 1853/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0178 - mae: 0.0981\n",
      "Epoch 1854/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0176 - mae: 0.0964\n",
      "Epoch 1855/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0172 - mae: 0.0959\n",
      "Epoch 1856/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0184 - mae: 0.0996\n",
      "Epoch 1857/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0173 - mae: 0.0973\n",
      "Epoch 1858/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0175 - mae: 0.0975\n",
      "Epoch 1859/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0181 - mae: 0.0990\n",
      "Epoch 1860/2000\n",
      "2019/2019 [==============================] - 0s 116us/sample - loss: 0.0167 - mae: 0.0947\n",
      "Epoch 1861/2000\n",
      "2019/2019 [==============================] - 0s 104us/sample - loss: 0.0174 - mae: 0.0962\n",
      "Epoch 1862/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0196 - mae: 0.1017\n",
      "Epoch 1863/2000\n",
      "2019/2019 [==============================] - 0s 148us/sample - loss: 0.0173 - mae: 0.0971\n",
      "Epoch 1864/2000\n",
      "2019/2019 [==============================] - 0s 97us/sample - loss: 0.0182 - mae: 0.0988\n",
      "Epoch 1865/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0176 - mae: 0.0966\n",
      "Epoch 1866/2000\n",
      "2019/2019 [==============================] - 0s 100us/sample - loss: 0.0183 - mae: 0.1007\n",
      "Epoch 1867/2000\n",
      "2019/2019 [==============================] - 0s 92us/sample - loss: 0.0189 - mae: 0.1006\n",
      "Epoch 1868/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0177 - mae: 0.0967\n",
      "Epoch 1869/2000\n",
      "2019/2019 [==============================] - 0s 97us/sample - loss: 0.0181 - mae: 0.0980\n",
      "Epoch 1870/2000\n",
      "2019/2019 [==============================] - 0s 94us/sample - loss: 0.0182 - mae: 0.0989\n",
      "Epoch 1871/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0168 - mae: 0.0950\n",
      "Epoch 1872/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0170 - mae: 0.0948\n",
      "Epoch 1873/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0172 - mae: 0.0949\n",
      "Epoch 1874/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0181 - mae: 0.0978\n",
      "Epoch 1875/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0183 - mae: 0.0983\n",
      "Epoch 1876/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0170 - mae: 0.0954\n",
      "Epoch 1877/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0182 - mae: 0.0984\n",
      "Epoch 1878/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0234 - mae: 0.1129\n",
      "Epoch 1879/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0196 - mae: 0.1028\n",
      "Epoch 1880/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0173 - mae: 0.0966\n",
      "Epoch 1881/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0181 - mae: 0.0992\n",
      "Epoch 1882/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0168 - mae: 0.0945\n",
      "Epoch 1883/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0174 - mae: 0.0964\n",
      "Epoch 1884/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0177 - mae: 0.0977\n",
      "Epoch 1885/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0172 - mae: 0.0951\n",
      "Epoch 1886/2000\n",
      "2019/2019 [==============================] - 0s 92us/sample - loss: 0.0171 - mae: 0.0948\n",
      "Epoch 1887/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0172 - mae: 0.0951\n",
      "Epoch 1888/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0174 - mae: 0.0966\n",
      "Epoch 1889/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0176 - mae: 0.0970\n",
      "Epoch 1890/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0182 - mae: 0.0990\n",
      "Epoch 1891/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0171 - mae: 0.0955\n",
      "Epoch 1892/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0175 - mae: 0.0965\n",
      "Epoch 1893/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0172 - mae: 0.0964\n",
      "Epoch 1894/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0175 - mae: 0.0965\n",
      "Epoch 1895/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0176 - mae: 0.0978\n",
      "Epoch 1896/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0168 - mae: 0.0940\n",
      "Epoch 1897/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0180 - mae: 0.0978\n",
      "Epoch 1898/2000\n",
      "2019/2019 [==============================] - 0s 95us/sample - loss: 0.0172 - mae: 0.0963\n",
      "Epoch 1899/2000\n",
      "2019/2019 [==============================] - 0s 140us/sample - loss: 0.0191 - mae: 0.1014\n",
      "Epoch 1900/2000\n",
      "2019/2019 [==============================] - 0s 98us/sample - loss: 0.0174 - mae: 0.0964\n",
      "Epoch 1901/2000\n",
      "2019/2019 [==============================] - 0s 119us/sample - loss: 0.0205 - mae: 0.1063\n",
      "Epoch 1902/2000\n",
      "2019/2019 [==============================] - 0s 139us/sample - loss: 0.0181 - mae: 0.0980\n",
      "Epoch 1903/2000\n",
      "2019/2019 [==============================] - 0s 102us/sample - loss: 0.0179 - mae: 0.0979\n",
      "Epoch 1904/2000\n",
      "2019/2019 [==============================] - 0s 94us/sample - loss: 0.0179 - mae: 0.0979\n",
      "Epoch 1905/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0200 - mae: 0.1031\n",
      "Epoch 1906/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0177 - mae: 0.0972\n",
      "Epoch 1907/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0177 - mae: 0.0968\n",
      "Epoch 1908/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0230 - mae: 0.1099\n",
      "Epoch 1909/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0185 - mae: 0.0997\n",
      "Epoch 1910/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0196 - mae: 0.1028\n",
      "Epoch 1911/2000\n",
      "2019/2019 [==============================] - 0s 103us/sample - loss: 0.0192 - mae: 0.1017\n",
      "Epoch 1912/2000\n",
      "2019/2019 [==============================] - 0s 151us/sample - loss: 0.0194 - mae: 0.1025\n",
      "Epoch 1913/2000\n",
      "2019/2019 [==============================] - 0s 124us/sample - loss: 0.0178 - mae: 0.0975\n",
      "Epoch 1914/2000\n",
      "2019/2019 [==============================] - 0s 116us/sample - loss: 0.0177 - mae: 0.0974\n",
      "Epoch 1915/2000\n",
      "2019/2019 [==============================] - 0s 92us/sample - loss: 0.0186 - mae: 0.1009\n",
      "Epoch 1916/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0181 - mae: 0.0986\n",
      "Epoch 1917/2000\n",
      "2019/2019 [==============================] - 0s 98us/sample - loss: 0.0172 - mae: 0.0960\n",
      "Epoch 1918/2000\n",
      "2019/2019 [==============================] - 0s 99us/sample - loss: 0.0190 - mae: 0.1011\n",
      "Epoch 1919/2000\n",
      "2019/2019 [==============================] - 0s 98us/sample - loss: 0.0180 - mae: 0.0978\n",
      "Epoch 1920/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0178 - mae: 0.0979\n",
      "Epoch 1921/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0170 - mae: 0.0950\n",
      "Epoch 1922/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0175 - mae: 0.0972\n",
      "Epoch 1923/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0171 - mae: 0.0957\n",
      "Epoch 1924/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0182 - mae: 0.0979\n",
      "Epoch 1925/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0172 - mae: 0.0956\n",
      "Epoch 1926/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0174 - mae: 0.0957\n",
      "Epoch 1927/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0175 - mae: 0.0965\n",
      "Epoch 1928/2000\n",
      "2019/2019 [==============================] - 0s 129us/sample - loss: 0.0171 - mae: 0.0956\n",
      "Epoch 1929/2000\n",
      "2019/2019 [==============================] - 0s 131us/sample - loss: 0.0171 - mae: 0.0955\n",
      "Epoch 1930/2000\n",
      "2019/2019 [==============================] - 0s 133us/sample - loss: 0.0176 - mae: 0.0964\n",
      "Epoch 1931/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0171 - mae: 0.0957\n",
      "Epoch 1932/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0177 - mae: 0.0980\n",
      "Epoch 1933/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0183 - mae: 0.0998\n",
      "Epoch 1934/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0182 - mae: 0.0990\n",
      "Epoch 1935/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0177 - mae: 0.0977\n",
      "Epoch 1936/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0218 - mae: 0.1078\n",
      "Epoch 1937/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0190 - mae: 0.1003\n",
      "Epoch 1938/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0227 - mae: 0.1115\n",
      "Epoch 1939/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0180 - mae: 0.0979\n",
      "Epoch 1940/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0174 - mae: 0.0953\n",
      "Epoch 1941/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0199 - mae: 0.1030\n",
      "Epoch 1942/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0177 - mae: 0.0969\n",
      "Epoch 1943/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0192 - mae: 0.1026\n",
      "Epoch 1944/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0185 - mae: 0.0996\n",
      "Epoch 1945/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0203 - mae: 0.1041\n",
      "Epoch 1946/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.1000\n",
      "Epoch 1947/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0182 - mae: 0.0994\n",
      "Epoch 1948/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0172 - mae: 0.0958\n",
      "Epoch 1949/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0174 - mae: 0.0958\n",
      "Epoch 1950/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0176 - mae: 0.0970\n",
      "Epoch 1951/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0166 - mae: 0.0937\n",
      "Epoch 1952/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0172 - mae: 0.0965\n",
      "Epoch 1953/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0168 - mae: 0.0942\n",
      "Epoch 1954/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0176 - mae: 0.0973\n",
      "Epoch 1955/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0206 - mae: 0.1056\n",
      "Epoch 1956/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0211 - mae: 0.1058\n",
      "Epoch 1957/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0186 - mae: 0.1004\n",
      "Epoch 1958/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0192 - mae: 0.1022\n",
      "Epoch 1959/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0177 - mae: 0.0970\n",
      "Epoch 1960/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0174 - mae: 0.0970\n",
      "Epoch 1961/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0180 - mae: 0.0985\n",
      "Epoch 1962/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0182 - mae: 0.0992\n",
      "Epoch 1963/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0168 - mae: 0.0946\n",
      "Epoch 1964/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0171 - mae: 0.0965\n",
      "Epoch 1965/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0171 - mae: 0.0961\n",
      "Epoch 1966/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0172 - mae: 0.0956\n",
      "Epoch 1967/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0170 - mae: 0.0950\n",
      "Epoch 1968/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0176 - mae: 0.0982\n",
      "Epoch 1969/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0176 - mae: 0.0976\n",
      "Epoch 1970/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0173 - mae: 0.0959\n",
      "Epoch 1971/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0180 - mae: 0.0993\n",
      "Epoch 1972/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0172 - mae: 0.0967\n",
      "Epoch 1973/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0181 - mae: 0.0979\n",
      "Epoch 1974/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0176 - mae: 0.0974\n",
      "Epoch 1975/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0172 - mae: 0.0959\n",
      "Epoch 1976/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0182 - mae: 0.0992\n",
      "Epoch 1977/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0175 - mae: 0.0969\n",
      "Epoch 1978/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0173 - mae: 0.0963\n",
      "Epoch 1979/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0178 - mae: 0.0981\n",
      "Epoch 1980/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0170 - mae: 0.0959\n",
      "Epoch 1981/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0179 - mae: 0.0982\n",
      "Epoch 1982/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0175 - mae: 0.0961\n",
      "Epoch 1983/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0171 - mae: 0.0955\n",
      "Epoch 1984/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0171 - mae: 0.0948\n",
      "Epoch 1985/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0181 - mae: 0.0986\n",
      "Epoch 1986/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0174 - mae: 0.0958\n",
      "Epoch 1987/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0174 - mae: 0.0965\n",
      "Epoch 1988/2000\n",
      "2019/2019 [==============================] - 0s 148us/sample - loss: 0.0174 - mae: 0.0965\n",
      "Epoch 1989/2000\n",
      "2019/2019 [==============================] - 0s 105us/sample - loss: 0.0169 - mae: 0.0950\n",
      "Epoch 1990/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0181 - mae: 0.0983\n",
      "Epoch 1991/2000\n",
      "2019/2019 [==============================] - 0s 98us/sample - loss: 0.0169 - mae: 0.0946\n",
      "Epoch 1992/2000\n",
      "2019/2019 [==============================] - 0s 95us/sample - loss: 0.0186 - mae: 0.1002\n",
      "Epoch 1993/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0192 - mae: 0.1022\n",
      "Epoch 1994/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0170 - mae: 0.0957\n",
      "Epoch 1995/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0176 - mae: 0.0970\n",
      "Epoch 1996/2000\n",
      "2019/2019 [==============================] - 0s 94us/sample - loss: 0.0174 - mae: 0.0959\n",
      "Epoch 1997/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0187 - mae: 0.1005\n",
      "Epoch 1998/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0170 - mae: 0.0951\n",
      "Epoch 1999/2000\n",
      "2019/2019 [==============================] - 0s 109us/sample - loss: 0.0171 - mae: 0.0955\n",
      "Epoch 2000/2000\n",
      "2019/2019 [==============================] - 0s 99us/sample - loss: 0.0189 - mae: 0.1013\n",
      "mae: 0.10873536020517349\n",
      "Overfit mae: 0.09712191671133041\n",
      "Train on 2019 samples\n",
      "Epoch 1/2000\n",
      "2019/2019 [==============================] - 1s 561us/sample - loss: 21875.5889 - mae: 36.1441\n",
      "Epoch 2/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 11782.1066 - mae: 23.1838\n",
      "Epoch 3/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 61638.6495 - mae: 31.0927\n",
      "Epoch 4/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 9221.4438 - mae: 22.9525\n",
      "Epoch 5/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 2024.3747 - mae: 11.4236\n",
      "Epoch 6/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 2669.0902 - mae: 12.3889\n",
      "Epoch 7/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 546.0254 - mae: 7.1904\n",
      "Epoch 8/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 1999.5741 - mae: 8.1519\n",
      "Epoch 9/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 1421.8093 - mae: 8.5658\n",
      "Epoch 10/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 12601.0904 - mae: 18.2932\n",
      "Epoch 11/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 6517.4944 - mae: 12.6939\n",
      "Epoch 12/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 4632.5648 - mae: 13.3822\n",
      "Epoch 13/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 312.8401 - mae: 6.0361\n",
      "Epoch 14/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 344.2239 - mae: 5.6337\n",
      "Epoch 15/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 312.9730 - mae: 5.4159\n",
      "Epoch 16/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 480.1575 - mae: 5.5756\n",
      "Epoch 17/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 658.4293 - mae: 6.0490\n",
      "Epoch 18/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 265.4883 - mae: 5.1570\n",
      "Epoch 19/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 154.5386 - mae: 4.5719\n",
      "Epoch 20/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 180.0807 - mae: 5.0119\n",
      "Epoch 21/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 2359.6210 - mae: 9.6613\n",
      "Epoch 22/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 322.1359 - mae: 4.8744\n",
      "Epoch 23/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 146.0677 - mae: 4.0012\n",
      "Epoch 24/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1506.2050 - mae: 8.4248\n",
      "Epoch 25/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 222.7778 - mae: 4.0006\n",
      "Epoch 26/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 2154.5881 - mae: 8.2048\n",
      "Epoch 27/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 3515.8284 - mae: 9.9052\n",
      "Epoch 28/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 657.7737 - mae: 6.3302\n",
      "Epoch 29/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 292.9019 - mae: 4.9567\n",
      "Epoch 30/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 214.6179 - mae: 4.1700\n",
      "Epoch 31/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 415.4350 - mae: 4.3949\n",
      "Epoch 32/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 72.0233 - mae: 3.3804\n",
      "Epoch 33/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 61.7910 - mae: 3.3178\n",
      "Epoch 34/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 269.0178 - mae: 4.1275\n",
      "Epoch 35/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 174.6980 - mae: 3.5545\n",
      "Epoch 36/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 380.2997 - mae: 4.6865\n",
      "Epoch 37/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 213.9123 - mae: 3.5786\n",
      "Epoch 38/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 781.5423 - mae: 5.5994\n",
      "Epoch 39/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 124.2572 - mae: 3.2666\n",
      "Epoch 40/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 94.5781 - mae: 3.0749\n",
      "Epoch 41/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 452.0187 - mae: 5.1548\n",
      "Epoch 42/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 135.6756 - mae: 3.3222\n",
      "Epoch 43/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 678.6955 - mae: 4.6206\n",
      "Epoch 44/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 10780.7365 - mae: 17.0982\n",
      "Epoch 45/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 10706.4437 - mae: 19.2637\n",
      "Epoch 46/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 5778.3424 - mae: 12.5486\n",
      "Epoch 47/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 3353.5573 - mae: 7.6272\n",
      "Epoch 48/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 118.3655 - mae: 3.5931\n",
      "Epoch 49/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1167.9984 - mae: 5.7774\n",
      "Epoch 50/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 205.4869 - mae: 3.8629\n",
      "Epoch 51/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 461.8515 - mae: 4.2839\n",
      "Epoch 52/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 267.0250 - mae: 3.5972\n",
      "Epoch 53/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 689.6212 - mae: 4.5960\n",
      "Epoch 54/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 2616.2501 - mae: 9.5561\n",
      "Epoch 55/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 213.5767 - mae: 3.5695\n",
      "Epoch 56/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 197.3281 - mae: 3.1105\n",
      "Epoch 57/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 200.2607 - mae: 2.9915\n",
      "Epoch 58/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 159.5218 - mae: 2.9882\n",
      "Epoch 59/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 82.3808 - mae: 2.6681\n",
      "Epoch 60/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 92.8074 - mae: 2.4610\n",
      "Epoch 61/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 40.5044 - mae: 2.0496\n",
      "Epoch 62/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 32.7456 - mae: 1.8968\n",
      "Epoch 63/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 95.5567 - mae: 2.6839\n",
      "Epoch 64/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 64.2856 - mae: 2.0408\n",
      "Epoch 65/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 27.6072 - mae: 1.7775\n",
      "Epoch 66/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 1870.9932 - mae: 7.0841\n",
      "Epoch 67/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 4163.1298 - mae: 9.2268\n",
      "Epoch 68/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 186.7898 - mae: 3.3098\n",
      "Epoch 69/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 703.6905 - mae: 3.6400\n",
      "Epoch 70/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 3812.5710 - mae: 7.3729\n",
      "Epoch 71/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 5848.8935 - mae: 8.2470\n",
      "Epoch 72/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 2512.9133 - mae: 9.3643\n",
      "Epoch 73/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 14525.5072 - mae: 16.5893\n",
      "Epoch 74/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 204.4240 - mae: 3.1066\n",
      "Epoch 75/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 39.2607 - mae: 1.9999\n",
      "Epoch 76/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 36.8814 - mae: 1.7320\n",
      "Epoch 77/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 64.3300 - mae: 1.9060\n",
      "Epoch 78/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 280.1706 - mae: 3.0829\n",
      "Epoch 79/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 47.5233 - mae: 1.7670\n",
      "Epoch 80/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 585.9961 - mae: 3.7258\n",
      "Epoch 81/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 818.5686 - mae: 3.2528\n",
      "Epoch 82/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 250.1393 - mae: 2.2391\n",
      "Epoch 83/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 131.6629 - mae: 1.8138\n",
      "Epoch 84/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 78.7836 - mae: 1.6165\n",
      "Epoch 85/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 51.3988 - mae: 1.4156\n",
      "Epoch 86/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 35.6924 - mae: 1.2895\n",
      "Epoch 87/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 25.4904 - mae: 1.2031\n",
      "Epoch 88/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 18.7603 - mae: 1.1118\n",
      "Epoch 89/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 13.7319 - mae: 1.0522\n",
      "Epoch 90/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 10.8484 - mae: 0.9974\n",
      "Epoch 91/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 8.1912 - mae: 0.9604\n",
      "Epoch 92/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 6.4812 - mae: 0.9058\n",
      "Epoch 93/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 5.2188 - mae: 0.8748\n",
      "Epoch 94/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 4.4412 - mae: 0.8481\n",
      "Epoch 95/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 3.7775 - mae: 0.8197\n",
      "Epoch 96/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 3.4800 - mae: 0.8112\n",
      "Epoch 97/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 3.0334 - mae: 0.7801\n",
      "Epoch 98/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 2.8591 - mae: 0.7636\n",
      "Epoch 99/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 2.7477 - mae: 0.7605\n",
      "Epoch 100/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 2.4643 - mae: 0.7339\n",
      "Epoch 101/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 2.4862 - mae: 0.7305\n",
      "Epoch 102/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 3.0141 - mae: 0.7520\n",
      "Epoch 103/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 2.5376 - mae: 0.7152\n",
      "Epoch 104/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 71us/sample - loss: 2.6243 - mae: 0.7132\n",
      "Epoch 105/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 5.0005 - mae: 0.7914\n",
      "Epoch 106/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 6.0137 - mae: 0.7420\n",
      "Epoch 107/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 6.3509 - mae: 0.7947\n",
      "Epoch 108/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 6.8625 - mae: 0.7762\n",
      "Epoch 109/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 4.9744 - mae: 0.7167\n",
      "Epoch 110/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 3.2667 - mae: 0.6921\n",
      "Epoch 111/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 4.4145 - mae: 0.7395\n",
      "Epoch 112/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 3.2194 - mae: 0.6859\n",
      "Epoch 113/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 3.0696 - mae: 0.6770\n",
      "Epoch 114/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.9799 - mae: 0.6517\n",
      "Epoch 115/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.8672 - mae: 0.6390\n",
      "Epoch 116/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.9237 - mae: 0.6401\n",
      "Epoch 117/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 2.0609 - mae: 0.6329\n",
      "Epoch 118/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 2.3704 - mae: 0.6387\n",
      "Epoch 119/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 3.0646 - mae: 0.6579\n",
      "Epoch 120/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 4.8327 - mae: 0.6847\n",
      "Epoch 121/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 7.4272 - mae: 0.7679\n",
      "Epoch 122/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 10.1535 - mae: 0.7744\n",
      "Epoch 123/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 19.0924 - mae: 0.9343\n",
      "Epoch 124/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 19.7550 - mae: 1.0091\n",
      "Epoch 125/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 41.6359 - mae: 0.9423\n",
      "Epoch 126/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 22.6914 - mae: 0.8331\n",
      "Epoch 127/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 1.7878 - mae: 0.5982\n",
      "Epoch 128/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 1.5424 - mae: 0.5631\n",
      "Epoch 129/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 1.3796 - mae: 0.5414\n",
      "Epoch 130/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.2792 - mae: 0.5170\n",
      "Epoch 131/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.1697 - mae: 0.4988\n",
      "Epoch 132/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 1.0866 - mae: 0.4808\n",
      "Epoch 133/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 1.2877 - mae: 0.5314\n",
      "Epoch 134/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 1.0565 - mae: 0.4860\n",
      "Epoch 135/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.9732 - mae: 0.4674\n",
      "Epoch 136/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.9176 - mae: 0.4532\n",
      "Epoch 137/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.8789 - mae: 0.4405\n",
      "Epoch 138/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.8417 - mae: 0.4243\n",
      "Epoch 139/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.8114 - mae: 0.4135\n",
      "Epoch 140/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.7877 - mae: 0.4017\n",
      "Epoch 141/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.7645 - mae: 0.3920\n",
      "Epoch 142/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.7464 - mae: 0.3821\n",
      "Epoch 143/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.7295 - mae: 0.3736\n",
      "Epoch 144/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.7139 - mae: 0.3660\n",
      "Epoch 145/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.7016 - mae: 0.3584\n",
      "Epoch 146/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.6846 - mae: 0.3509\n",
      "Epoch 147/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.6769 - mae: 0.3437\n",
      "Epoch 148/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.6950 - mae: 0.3504\n",
      "Epoch 149/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.6824 - mae: 0.3420\n",
      "Epoch 150/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.6694 - mae: 0.3326\n",
      "Epoch 151/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.6593 - mae: 0.3247\n",
      "Epoch 152/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.6502 - mae: 0.3174\n",
      "Epoch 153/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.6409 - mae: 0.3104\n",
      "Epoch 154/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.6348 - mae: 0.3055\n",
      "Epoch 155/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.6250 - mae: 0.2982\n",
      "Epoch 156/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.6182 - mae: 0.2936\n",
      "Epoch 157/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.6118 - mae: 0.2893\n",
      "Epoch 158/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.6042 - mae: 0.2845\n",
      "Epoch 159/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5998 - mae: 0.2815\n",
      "Epoch 160/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5927 - mae: 0.2776\n",
      "Epoch 161/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.5875 - mae: 0.2746\n",
      "Epoch 162/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.5817 - mae: 0.2717\n",
      "Epoch 163/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.5775 - mae: 0.2695\n",
      "Epoch 164/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.5729 - mae: 0.2668\n",
      "Epoch 165/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.5673 - mae: 0.2639\n",
      "Epoch 166/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5627 - mae: 0.2615\n",
      "Epoch 167/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.5584 - mae: 0.2597\n",
      "Epoch 168/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5541 - mae: 0.2578\n",
      "Epoch 169/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.5507 - mae: 0.2560\n",
      "Epoch 170/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.5464 - mae: 0.2538\n",
      "Epoch 171/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5425 - mae: 0.2521\n",
      "Epoch 172/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5398 - mae: 0.2510\n",
      "Epoch 173/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.5365 - mae: 0.2503\n",
      "Epoch 174/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.5328 - mae: 0.2485\n",
      "Epoch 175/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5302 - mae: 0.2472\n",
      "Epoch 176/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5274 - mae: 0.2454\n",
      "Epoch 177/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5248 - mae: 0.2441\n",
      "Epoch 178/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.5227 - mae: 0.2430\n",
      "Epoch 179/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.5203 - mae: 0.2421\n",
      "Epoch 180/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5203 - mae: 0.2425\n",
      "Epoch 181/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.5175 - mae: 0.2406\n",
      "Epoch 182/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5162 - mae: 0.2400\n",
      "Epoch 183/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.5147 - mae: 0.2391\n",
      "Epoch 184/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5132 - mae: 0.2385\n",
      "Epoch 185/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5118 - mae: 0.2379\n",
      "Epoch 186/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.5110 - mae: 0.2375\n",
      "Epoch 187/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5109 - mae: 0.2380\n",
      "Epoch 188/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5087 - mae: 0.2364\n",
      "Epoch 189/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.5079 - mae: 0.2364\n",
      "Epoch 190/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.5063 - mae: 0.2357\n",
      "Epoch 191/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.5064 - mae: 0.2359\n",
      "Epoch 192/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.5043 - mae: 0.2344\n",
      "Epoch 193/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.5047 - mae: 0.2361\n",
      "Epoch 194/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.5024 - mae: 0.2341\n",
      "Epoch 195/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5015 - mae: 0.2335\n",
      "Epoch 196/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5009 - mae: 0.2337\n",
      "Epoch 197/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.4991 - mae: 0.2328\n",
      "Epoch 198/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.5009 - mae: 0.2347\n",
      "Epoch 199/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4990 - mae: 0.2338\n",
      "Epoch 200/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4967 - mae: 0.2324\n",
      "Epoch 201/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4955 - mae: 0.2320\n",
      "Epoch 202/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4951 - mae: 0.2321\n",
      "Epoch 203/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4946 - mae: 0.2324\n",
      "Epoch 204/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4932 - mae: 0.2314\n",
      "Epoch 205/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.4922 - mae: 0.2315\n",
      "Epoch 206/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.4917 - mae: 0.2313\n",
      "Epoch 207/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.5025 - mae: 0.2408\n",
      "Epoch 208/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4906 - mae: 0.2316\n",
      "Epoch 209/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4885 - mae: 0.2306\n",
      "Epoch 210/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4876 - mae: 0.2304\n",
      "Epoch 211/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4867 - mae: 0.2302\n",
      "Epoch 212/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4858 - mae: 0.2296\n",
      "Epoch 213/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4848 - mae: 0.2294\n",
      "Epoch 214/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.4848 - mae: 0.2309\n",
      "Epoch 215/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.4832 - mae: 0.2295\n",
      "Epoch 216/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.4823 - mae: 0.2296\n",
      "Epoch 217/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4811 - mae: 0.2292\n",
      "Epoch 218/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.4802 - mae: 0.2292\n",
      "Epoch 219/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.4794 - mae: 0.2287\n",
      "Epoch 220/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4792 - mae: 0.2296\n",
      "Epoch 221/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4779 - mae: 0.2289\n",
      "Epoch 222/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4779 - mae: 0.2296\n",
      "Epoch 223/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4760 - mae: 0.2289\n",
      "Epoch 224/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4747 - mae: 0.2275\n",
      "Epoch 225/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4737 - mae: 0.2282\n",
      "Epoch 226/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4739 - mae: 0.2294\n",
      "Epoch 227/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4726 - mae: 0.2287\n",
      "Epoch 228/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4733 - mae: 0.2301\n",
      "Epoch 229/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4708 - mae: 0.2277\n",
      "Epoch 230/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4817 - mae: 0.2310\n",
      "Epoch 231/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4694 - mae: 0.2281\n",
      "Epoch 232/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4676 - mae: 0.2272\n",
      "Epoch 233/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4669 - mae: 0.2275\n",
      "Epoch 234/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4655 - mae: 0.2265\n",
      "Epoch 235/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4650 - mae: 0.2272\n",
      "Epoch 236/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4700 - mae: 0.2322\n",
      "Epoch 237/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4649 - mae: 0.2306\n",
      "Epoch 238/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4627 - mae: 0.2268\n",
      "Epoch 239/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4612 - mae: 0.2265\n",
      "Epoch 240/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4607 - mae: 0.2277\n",
      "Epoch 241/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4614 - mae: 0.2291\n",
      "Epoch 242/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4587 - mae: 0.2268\n",
      "Epoch 243/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.4599 - mae: 0.2294\n",
      "Epoch 244/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4561 - mae: 0.2260\n",
      "Epoch 245/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4560 - mae: 0.2270\n",
      "Epoch 246/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4705 - mae: 0.2347\n",
      "Epoch 247/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.4555 - mae: 0.2279\n",
      "Epoch 248/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.4534 - mae: 0.2264\n",
      "Epoch 249/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.4534 - mae: 0.2276\n",
      "Epoch 250/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4526 - mae: 0.2285\n",
      "Epoch 251/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4506 - mae: 0.2272\n",
      "Epoch 252/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4516 - mae: 0.2284\n",
      "Epoch 253/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4480 - mae: 0.2260\n",
      "Epoch 254/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4472 - mae: 0.2264\n",
      "Epoch 255/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4459 - mae: 0.2259\n",
      "Epoch 256/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.4502 - mae: 0.2291\n",
      "Epoch 257/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.4603 - mae: 0.2357\n",
      "Epoch 258/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.4530 - mae: 0.2335\n",
      "Epoch 259/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4443 - mae: 0.2274\n",
      "Epoch 260/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4423 - mae: 0.2268\n",
      "Epoch 261/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.4408 - mae: 0.2261\n",
      "Epoch 262/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.4395 - mae: 0.2257\n",
      "Epoch 263/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.4373 - mae: 0.2238\n",
      "Epoch 264/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4372 - mae: 0.2253\n",
      "Epoch 265/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4364 - mae: 0.2254\n",
      "Epoch 266/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4335 - mae: 0.2234\n",
      "Epoch 267/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4330 - mae: 0.2247\n",
      "Epoch 268/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4335 - mae: 0.2262\n",
      "Epoch 269/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4316 - mae: 0.2258\n",
      "Epoch 270/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4518 - mae: 0.2358\n",
      "Epoch 271/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.4370 - mae: 0.2298\n",
      "Epoch 272/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4276 - mae: 0.2249\n",
      "Epoch 273/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.4269 - mae: 0.2252\n",
      "Epoch 274/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4299 - mae: 0.2293\n",
      "Epoch 275/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.4235 - mae: 0.2239\n",
      "Epoch 276/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4224 - mae: 0.2241\n",
      "Epoch 277/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.4209 - mae: 0.2230\n",
      "Epoch 278/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.4200 - mae: 0.2240\n",
      "Epoch 279/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4192 - mae: 0.2246\n",
      "Epoch 280/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4336 - mae: 0.2358\n",
      "Epoch 281/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.4459 - mae: 0.2393\n",
      "Epoch 282/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.4391 - mae: 0.2350\n",
      "Epoch 283/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.4542 - mae: 0.2406\n",
      "Epoch 284/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4207 - mae: 0.2286\n",
      "Epoch 285/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4127 - mae: 0.2238\n",
      "Epoch 286/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4102 - mae: 0.2235\n",
      "Epoch 287/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4088 - mae: 0.2232\n",
      "Epoch 288/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4076 - mae: 0.2225\n",
      "Epoch 289/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4057 - mae: 0.2226\n",
      "Epoch 290/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4047 - mae: 0.2228\n",
      "Epoch 291/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.4032 - mae: 0.2227\n",
      "Epoch 292/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.4017 - mae: 0.2228\n",
      "Epoch 293/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.4018 - mae: 0.2242\n",
      "Epoch 294/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4077 - mae: 0.2248\n",
      "Epoch 295/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4090 - mae: 0.2278\n",
      "Epoch 296/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4017 - mae: 0.2284\n",
      "Epoch 297/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3972 - mae: 0.2245\n",
      "Epoch 298/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3956 - mae: 0.2245\n",
      "Epoch 299/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3946 - mae: 0.2247\n",
      "Epoch 300/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3929 - mae: 0.2236\n",
      "Epoch 301/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3916 - mae: 0.2238\n",
      "Epoch 302/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.3901 - mae: 0.2231\n",
      "Epoch 303/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3888 - mae: 0.2233\n",
      "Epoch 304/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3875 - mae: 0.2235\n",
      "Epoch 305/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3859 - mae: 0.2230\n",
      "Epoch 306/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3845 - mae: 0.2227\n",
      "Epoch 307/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3832 - mae: 0.2227\n",
      "Epoch 308/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3817 - mae: 0.2231\n",
      "Epoch 309/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3805 - mae: 0.2237\n",
      "Epoch 310/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3790 - mae: 0.2228\n",
      "Epoch 311/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3776 - mae: 0.2223\n",
      "Epoch 312/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.3763 - mae: 0.2227\n",
      "Epoch 313/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3747 - mae: 0.2218\n",
      "Epoch 314/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3733 - mae: 0.2226\n",
      "Epoch 315/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3718 - mae: 0.2222\n",
      "Epoch 316/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3702 - mae: 0.2217\n",
      "Epoch 317/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3688 - mae: 0.2222\n",
      "Epoch 318/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3674 - mae: 0.2218\n",
      "Epoch 319/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3660 - mae: 0.2225\n",
      "Epoch 320/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3645 - mae: 0.2224\n",
      "Epoch 321/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3630 - mae: 0.2219\n",
      "Epoch 322/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3617 - mae: 0.2221\n",
      "Epoch 323/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3600 - mae: 0.2225\n",
      "Epoch 324/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.3592 - mae: 0.2223\n",
      "Epoch 325/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3569 - mae: 0.2223\n",
      "Epoch 326/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3553 - mae: 0.2220\n",
      "Epoch 327/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3539 - mae: 0.2222\n",
      "Epoch 328/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.3528 - mae: 0.2221\n",
      "Epoch 329/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.3505 - mae: 0.2213\n",
      "Epoch 330/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3486 - mae: 0.2210\n",
      "Epoch 331/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3475 - mae: 0.2208\n",
      "Epoch 332/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3449 - mae: 0.2194\n",
      "Epoch 333/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3432 - mae: 0.2190\n",
      "Epoch 334/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3414 - mae: 0.2189\n",
      "Epoch 335/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3398 - mae: 0.2193\n",
      "Epoch 336/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3402 - mae: 0.2189\n",
      "Epoch 337/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3375 - mae: 0.2186\n",
      "Epoch 338/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3351 - mae: 0.2171\n",
      "Epoch 339/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3332 - mae: 0.2168\n",
      "Epoch 340/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3316 - mae: 0.2171\n",
      "Epoch 341/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3294 - mae: 0.2149\n",
      "Epoch 342/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3273 - mae: 0.2151\n",
      "Epoch 343/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.3309 - mae: 0.2163\n",
      "Epoch 344/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.3306 - mae: 0.2220\n",
      "Epoch 345/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.3257 - mae: 0.2195\n",
      "Epoch 346/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3236 - mae: 0.2187\n",
      "Epoch 347/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3217 - mae: 0.2184\n",
      "Epoch 348/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3197 - mae: 0.2182\n",
      "Epoch 349/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.3181 - mae: 0.2183\n",
      "Epoch 350/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3158 - mae: 0.2174\n",
      "Epoch 351/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3143 - mae: 0.2172\n",
      "Epoch 352/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3124 - mae: 0.2171\n",
      "Epoch 353/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3103 - mae: 0.2167\n",
      "Epoch 354/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3083 - mae: 0.2168\n",
      "Epoch 355/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.3064 - mae: 0.2159\n",
      "Epoch 356/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3048 - mae: 0.2157\n",
      "Epoch 357/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3025 - mae: 0.2157\n",
      "Epoch 358/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3004 - mae: 0.2149\n",
      "Epoch 359/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2984 - mae: 0.2145\n",
      "Epoch 360/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2961 - mae: 0.2136\n",
      "Epoch 361/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2982 - mae: 0.2147\n",
      "Epoch 362/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2924 - mae: 0.2117\n",
      "Epoch 363/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2900 - mae: 0.2120\n",
      "Epoch 364/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2873 - mae: 0.2102\n",
      "Epoch 365/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2848 - mae: 0.2092\n",
      "Epoch 366/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2820 - mae: 0.2080\n",
      "Epoch 367/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2788 - mae: 0.2047\n",
      "Epoch 368/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.2761 - mae: 0.2037\n",
      "Epoch 369/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.2734 - mae: 0.2021\n",
      "Epoch 370/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.2714 - mae: 0.2017\n",
      "Epoch 371/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.2695 - mae: 0.2015\n",
      "Epoch 372/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.2664 - mae: 0.1981\n",
      "Epoch 373/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2639 - mae: 0.1957\n",
      "Epoch 374/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.2618 - mae: 0.1969\n",
      "Epoch 375/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2598 - mae: 0.1933\n",
      "Epoch 376/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2986 - mae: 0.1998\n",
      "Epoch 377/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2599 - mae: 0.1942\n",
      "Epoch 378/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.2597 - mae: 0.1981\n",
      "Epoch 379/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.2547 - mae: 0.1907\n",
      "Epoch 380/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.2516 - mae: 0.1878\n",
      "Epoch 381/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.2512 - mae: 0.1878\n",
      "Epoch 382/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.2552 - mae: 0.1979\n",
      "Epoch 383/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2476 - mae: 0.1873\n",
      "Epoch 384/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.2439 - mae: 0.1834\n",
      "Epoch 385/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2412 - mae: 0.1811\n",
      "Epoch 386/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.2390 - mae: 0.1800\n",
      "Epoch 387/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2369 - mae: 0.1789\n",
      "Epoch 388/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2352 - mae: 0.1783\n",
      "Epoch 389/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2329 - mae: 0.1772\n",
      "Epoch 390/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2312 - mae: 0.1785\n",
      "Epoch 391/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2288 - mae: 0.1762\n",
      "Epoch 392/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2273 - mae: 0.1762\n",
      "Epoch 393/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2246 - mae: 0.1752\n",
      "Epoch 394/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2226 - mae: 0.1746\n",
      "Epoch 395/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2209 - mae: 0.1743\n",
      "Epoch 396/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.2190 - mae: 0.1736\n",
      "Epoch 397/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2166 - mae: 0.1726\n",
      "Epoch 398/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2153 - mae: 0.1728\n",
      "Epoch 399/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2132 - mae: 0.1729\n",
      "Epoch 400/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2116 - mae: 0.1734\n",
      "Epoch 401/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2107 - mae: 0.1722\n",
      "Epoch 402/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2096 - mae: 0.1737\n",
      "Epoch 403/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2072 - mae: 0.1724\n",
      "Epoch 404/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2044 - mae: 0.1704\n",
      "Epoch 405/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.2026 - mae: 0.1699\n",
      "Epoch 406/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2017 - mae: 0.1717\n",
      "Epoch 407/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1995 - mae: 0.1707\n",
      "Epoch 408/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1973 - mae: 0.1696\n",
      "Epoch 409/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1971 - mae: 0.1734\n",
      "Epoch 410/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1943 - mae: 0.1711\n",
      "Epoch 411/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1931 - mae: 0.1707\n",
      "Epoch 412/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1905 - mae: 0.1701\n",
      "Epoch 413/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1890 - mae: 0.1709\n",
      "Epoch 414/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1872 - mae: 0.1690\n",
      "Epoch 415/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1847 - mae: 0.1690\n",
      "Epoch 416/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1856 - mae: 0.1723\n",
      "Epoch 417/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1838 - mae: 0.1736\n",
      "Epoch 418/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1799 - mae: 0.1685\n",
      "Epoch 419/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1782 - mae: 0.1687\n",
      "Epoch 420/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1761 - mae: 0.1685\n",
      "Epoch 421/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1742 - mae: 0.1678\n",
      "Epoch 422/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1732 - mae: 0.1693\n",
      "Epoch 423/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1704 - mae: 0.1668\n",
      "Epoch 424/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1689 - mae: 0.1658\n",
      "Epoch 425/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1686 - mae: 0.1706\n",
      "Epoch 426/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1656 - mae: 0.1662\n",
      "Epoch 427/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1651 - mae: 0.1687\n",
      "Epoch 428/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1617 - mae: 0.1654\n",
      "Epoch 429/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1601 - mae: 0.1645\n",
      "Epoch 430/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1591 - mae: 0.1670\n",
      "Epoch 431/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1580 - mae: 0.1683\n",
      "Epoch 432/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1566 - mae: 0.1659\n",
      "Epoch 433/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1580 - mae: 0.1731\n",
      "Epoch 434/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1542 - mae: 0.1665\n",
      "Epoch 435/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1503 - mae: 0.1622\n",
      "Epoch 436/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1500 - mae: 0.1654\n",
      "Epoch 437/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1500 - mae: 0.1660\n",
      "Epoch 438/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1478 - mae: 0.1661\n",
      "Epoch 439/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1460 - mae: 0.1670\n",
      "Epoch 440/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1448 - mae: 0.1666\n",
      "Epoch 441/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1445 - mae: 0.1684\n",
      "Epoch 442/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1423 - mae: 0.1679\n",
      "Epoch 443/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1384 - mae: 0.1618\n",
      "Epoch 444/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1385 - mae: 0.1663\n",
      "Epoch 445/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1349 - mae: 0.1600\n",
      "Epoch 446/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1330 - mae: 0.1597\n",
      "Epoch 447/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1329 - mae: 0.1622\n",
      "Epoch 448/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1301 - mae: 0.1592\n",
      "Epoch 449/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1289 - mae: 0.1601\n",
      "Epoch 450/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1315 - mae: 0.1692\n",
      "Epoch 451/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1279 - mae: 0.1636\n",
      "Epoch 452/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1252 - mae: 0.1610\n",
      "Epoch 453/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1235 - mae: 0.1598\n",
      "Epoch 454/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1246 - mae: 0.1645\n",
      "Epoch 455/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1256 - mae: 0.1692\n",
      "Epoch 456/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1219 - mae: 0.1636\n",
      "Epoch 457/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1189 - mae: 0.1606\n",
      "Epoch 458/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1177 - mae: 0.1603\n",
      "Epoch 459/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1156 - mae: 0.1593\n",
      "Epoch 460/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1254 - mae: 0.1853\n",
      "Epoch 461/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2320 - mae: 0.2217\n",
      "Epoch 462/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1407 - mae: 0.2109\n",
      "Epoch 463/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1350 - mae: 0.2014\n",
      "Epoch 464/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1328 - mae: 0.2006\n",
      "Epoch 465/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1309 - mae: 0.1992\n",
      "Epoch 466/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1281 - mae: 0.1965\n",
      "Epoch 467/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1282 - mae: 0.2000\n",
      "Epoch 468/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1233 - mae: 0.1904\n",
      "Epoch 469/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1244 - mae: 0.1973\n",
      "Epoch 470/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1243 - mae: 0.1973\n",
      "Epoch 471/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1211 - mae: 0.1926\n",
      "Epoch 472/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1182 - mae: 0.1899\n",
      "Epoch 473/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1165 - mae: 0.1884\n",
      "Epoch 474/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1143 - mae: 0.1862\n",
      "Epoch 475/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1131 - mae: 0.1862\n",
      "Epoch 476/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1124 - mae: 0.1867\n",
      "Epoch 477/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1104 - mae: 0.1850\n",
      "Epoch 478/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1083 - mae: 0.1821\n",
      "Epoch 479/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.1149 - mae: 0.1857\n",
      "Epoch 480/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1092 - mae: 0.1854\n",
      "Epoch 481/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1067 - mae: 0.1831\n",
      "Epoch 482/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1179 - mae: 0.2068\n",
      "Epoch 483/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1126 - mae: 0.1971\n",
      "Epoch 484/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1100 - mae: 0.1937\n",
      "Epoch 485/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1058 - mae: 0.1876\n",
      "Epoch 486/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1037 - mae: 0.1858\n",
      "Epoch 487/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1022 - mae: 0.1842\n",
      "Epoch 488/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1002 - mae: 0.1812\n",
      "Epoch 489/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0993 - mae: 0.1820\n",
      "Epoch 490/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0986 - mae: 0.1815\n",
      "Epoch 491/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0995 - mae: 0.1864\n",
      "Epoch 492/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0965 - mae: 0.1805\n",
      "Epoch 493/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1150 - mae: 0.2154\n",
      "Epoch 494/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1161 - mae: 0.2250\n",
      "Epoch 495/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1073 - mae: 0.2047\n",
      "Epoch 496/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1054 - mae: 0.2012\n",
      "Epoch 497/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1022 - mae: 0.1970\n",
      "Epoch 498/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1006 - mae: 0.1972\n",
      "Epoch 499/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0988 - mae: 0.1949\n",
      "Epoch 500/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0971 - mae: 0.1939\n",
      "Epoch 501/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0950 - mae: 0.1916\n",
      "Epoch 502/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0920 - mae: 0.1871\n",
      "Epoch 503/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0905 - mae: 0.1858\n",
      "Epoch 504/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0886 - mae: 0.1829\n",
      "Epoch 505/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0876 - mae: 0.1830\n",
      "Epoch 506/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0861 - mae: 0.1815\n",
      "Epoch 507/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0848 - mae: 0.1799\n",
      "Epoch 508/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0835 - mae: 0.1795\n",
      "Epoch 509/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0828 - mae: 0.1785\n",
      "Epoch 510/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0803 - mae: 0.1753\n",
      "Epoch 511/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0838 - mae: 0.1834\n",
      "Epoch 512/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0840 - mae: 0.1851\n",
      "Epoch 513/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0798 - mae: 0.1778\n",
      "Epoch 514/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0796 - mae: 0.1804\n",
      "Epoch 515/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0767 - mae: 0.1743\n",
      "Epoch 516/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0764 - mae: 0.1741\n",
      "Epoch 517/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0756 - mae: 0.1748\n",
      "Epoch 518/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0755 - mae: 0.1757\n",
      "Epoch 519/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1621 - mae: 0.2275\n",
      "Epoch 520/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1106 - mae: 0.2432\n",
      "Epoch 521/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.2106 - mae: 0.2364\n",
      "Epoch 522/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1014 - mae: 0.2253\n",
      "Epoch 523/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1009 - mae: 0.2250\n",
      "Epoch 524/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1005 - mae: 0.2247\n",
      "Epoch 525/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1000 - mae: 0.2247\n",
      "Epoch 526/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1157 - mae: 0.2284\n",
      "Epoch 527/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0994 - mae: 0.2248\n",
      "Epoch 528/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0990 - mae: 0.2252\n",
      "Epoch 529/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0986 - mae: 0.2247\n",
      "Epoch 530/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0982 - mae: 0.2248\n",
      "Epoch 531/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0977 - mae: 0.2244\n",
      "Epoch 532/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0973 - mae: 0.2243\n",
      "Epoch 533/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0970 - mae: 0.2241\n",
      "Epoch 534/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0965 - mae: 0.2238\n",
      "Epoch 535/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0960 - mae: 0.2237\n",
      "Epoch 536/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0956 - mae: 0.2244\n",
      "Epoch 537/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0951 - mae: 0.2236\n",
      "Epoch 538/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0946 - mae: 0.2232\n",
      "Epoch 539/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0941 - mae: 0.2227\n",
      "Epoch 540/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0917 - mae: 0.2172\n",
      "Epoch 541/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0851 - mae: 0.1990\n",
      "Epoch 542/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0814 - mae: 0.1933\n",
      "Epoch 543/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0789 - mae: 0.1892\n",
      "Epoch 544/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0777 - mae: 0.1874\n",
      "Epoch 545/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0751 - mae: 0.1833\n",
      "Epoch 546/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0742 - mae: 0.1821\n",
      "Epoch 547/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0816 - mae: 0.1934\n",
      "Epoch 548/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0721 - mae: 0.1771\n",
      "Epoch 549/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0712 - mae: 0.1760\n",
      "Epoch 550/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0883 - mae: 0.2039\n",
      "Epoch 551/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0867 - mae: 0.2053\n",
      "Epoch 552/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0823 - mae: 0.1965\n",
      "Epoch 553/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0802 - mae: 0.1924\n",
      "Epoch 554/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0795 - mae: 0.1910\n",
      "Epoch 555/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0782 - mae: 0.1892\n",
      "Epoch 556/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0772 - mae: 0.1876\n",
      "Epoch 557/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0769 - mae: 0.1889\n",
      "Epoch 558/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0760 - mae: 0.1870\n",
      "Epoch 559/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0753 - mae: 0.1870\n",
      "Epoch 560/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0745 - mae: 0.1850\n",
      "Epoch 561/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0739 - mae: 0.1851\n",
      "Epoch 562/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0737 - mae: 0.1852\n",
      "Epoch 563/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0729 - mae: 0.1834\n",
      "Epoch 564/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0721 - mae: 0.1835\n",
      "Epoch 565/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0718 - mae: 0.1827\n",
      "Epoch 566/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0708 - mae: 0.1813\n",
      "Epoch 567/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0698 - mae: 0.1797\n",
      "Epoch 568/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0665 - mae: 0.1716\n",
      "Epoch 569/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0636 - mae: 0.1670\n",
      "Epoch 570/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0631 - mae: 0.1674\n",
      "Epoch 571/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0612 - mae: 0.1632\n",
      "Epoch 572/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0607 - mae: 0.1632\n",
      "Epoch 573/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0598 - mae: 0.1617\n",
      "Epoch 574/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0591 - mae: 0.1601\n",
      "Epoch 575/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0586 - mae: 0.1601\n",
      "Epoch 576/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0580 - mae: 0.1591\n",
      "Epoch 577/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0578 - mae: 0.1592\n",
      "Epoch 578/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0571 - mae: 0.1586\n",
      "Epoch 579/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0563 - mae: 0.1571\n",
      "Epoch 580/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0558 - mae: 0.1560\n",
      "Epoch 581/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0552 - mae: 0.1555\n",
      "Epoch 582/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0564 - mae: 0.1574\n",
      "Epoch 583/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0590 - mae: 0.1648\n",
      "Epoch 584/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0564 - mae: 0.1598\n",
      "Epoch 585/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0552 - mae: 0.1578\n",
      "Epoch 586/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0544 - mae: 0.1572\n",
      "Epoch 587/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0537 - mae: 0.1550\n",
      "Epoch 588/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0534 - mae: 0.1546\n",
      "Epoch 589/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0529 - mae: 0.1538\n",
      "Epoch 590/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0524 - mae: 0.1526\n",
      "Epoch 591/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0517 - mae: 0.1522\n",
      "Epoch 592/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0514 - mae: 0.1516\n",
      "Epoch 593/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0509 - mae: 0.1507\n",
      "Epoch 594/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0506 - mae: 0.1512\n",
      "Epoch 595/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0501 - mae: 0.1500\n",
      "Epoch 596/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0497 - mae: 0.1494\n",
      "Epoch 597/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0488 - mae: 0.1473\n",
      "Epoch 598/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0486 - mae: 0.1469\n",
      "Epoch 599/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0483 - mae: 0.1476\n",
      "Epoch 600/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0485 - mae: 0.1486\n",
      "Epoch 601/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0477 - mae: 0.1469\n",
      "Epoch 602/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0468 - mae: 0.1459\n",
      "Epoch 603/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0462 - mae: 0.1446\n",
      "Epoch 604/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0465 - mae: 0.1464\n",
      "Epoch 605/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0459 - mae: 0.1450\n",
      "Epoch 606/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0456 - mae: 0.1441\n",
      "Epoch 607/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0457 - mae: 0.1461\n",
      "Epoch 608/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0455 - mae: 0.1451\n",
      "Epoch 609/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0451 - mae: 0.1455\n",
      "Epoch 610/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0445 - mae: 0.1442\n",
      "Epoch 611/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0436 - mae: 0.1428\n",
      "Epoch 612/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0430 - mae: 0.1419\n",
      "Epoch 613/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0440 - mae: 0.1442\n",
      "Epoch 614/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0433 - mae: 0.1427\n",
      "Epoch 615/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0445 - mae: 0.1466\n",
      "Epoch 616/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0425 - mae: 0.1406\n",
      "Epoch 617/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0416 - mae: 0.1394\n",
      "Epoch 618/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0413 - mae: 0.1390\n",
      "Epoch 619/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0410 - mae: 0.1383\n",
      "Epoch 620/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0458 - mae: 0.1464\n",
      "Epoch 621/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0425 - mae: 0.1429\n",
      "Epoch 622/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0407 - mae: 0.1376\n",
      "Epoch 623/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0409 - mae: 0.1399\n",
      "Epoch 624/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0405 - mae: 0.1398\n",
      "Epoch 625/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0395 - mae: 0.1366\n",
      "Epoch 626/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0405 - mae: 0.1392\n",
      "Epoch 627/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0397 - mae: 0.1396\n",
      "Epoch 628/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0390 - mae: 0.1369\n",
      "Epoch 629/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0382 - mae: 0.1351\n",
      "Epoch 630/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0390 - mae: 0.1367\n",
      "Epoch 631/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0400 - mae: 0.1384\n",
      "Epoch 632/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0386 - mae: 0.1373\n",
      "Epoch 633/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0377 - mae: 0.1351\n",
      "Epoch 634/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0367 - mae: 0.1330\n",
      "Epoch 635/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0368 - mae: 0.1342\n",
      "Epoch 636/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0358 - mae: 0.1307\n",
      "Epoch 637/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0359 - mae: 0.1322\n",
      "Epoch 638/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0355 - mae: 0.1317\n",
      "Epoch 639/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0343 - mae: 0.1284\n",
      "Epoch 640/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0346 - mae: 0.1305\n",
      "Epoch 641/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0342 - mae: 0.1285\n",
      "Epoch 642/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0338 - mae: 0.1293\n",
      "Epoch 643/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0348 - mae: 0.1319\n",
      "Epoch 644/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0355 - mae: 0.1327\n",
      "Epoch 645/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0335 - mae: 0.1278\n",
      "Epoch 646/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0330 - mae: 0.1270\n",
      "Epoch 647/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0333 - mae: 0.1279\n",
      "Epoch 648/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0332 - mae: 0.1296\n",
      "Epoch 649/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0328 - mae: 0.1273\n",
      "Epoch 650/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0334 - mae: 0.1298\n",
      "Epoch 651/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0329 - mae: 0.1293\n",
      "Epoch 652/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0329 - mae: 0.1294\n",
      "Epoch 653/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0319 - mae: 0.1263\n",
      "Epoch 654/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0334 - mae: 0.1307\n",
      "Epoch 655/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0321 - mae: 0.1280\n",
      "Epoch 656/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0330 - mae: 0.1283\n",
      "Epoch 657/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0323 - mae: 0.1270\n",
      "Epoch 658/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0318 - mae: 0.1258\n",
      "Epoch 659/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0320 - mae: 0.1276\n",
      "Epoch 660/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0320 - mae: 0.1261\n",
      "Epoch 661/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0316 - mae: 0.1262\n",
      "Epoch 662/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0327 - mae: 0.1302\n",
      "Epoch 663/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0317 - mae: 0.1256\n",
      "Epoch 664/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0303 - mae: 0.1233\n",
      "Epoch 665/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0313 - mae: 0.1281\n",
      "Epoch 666/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0311 - mae: 0.1267\n",
      "Epoch 667/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0304 - mae: 0.1250\n",
      "Epoch 668/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0340 - mae: 0.1305\n",
      "Epoch 669/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0343 - mae: 0.1342\n",
      "Epoch 670/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0332 - mae: 0.1325\n",
      "Epoch 671/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0308 - mae: 0.1272\n",
      "Epoch 672/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0302 - mae: 0.1257\n",
      "Epoch 673/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0292 - mae: 0.1228\n",
      "Epoch 674/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0290 - mae: 0.1228\n",
      "Epoch 675/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0288 - mae: 0.1219\n",
      "Epoch 676/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0284 - mae: 0.1210\n",
      "Epoch 677/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0281 - mae: 0.1210\n",
      "Epoch 678/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0287 - mae: 0.1214\n",
      "Epoch 679/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0276 - mae: 0.1202\n",
      "Epoch 680/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0278 - mae: 0.1210\n",
      "Epoch 681/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0286 - mae: 0.1229\n",
      "Epoch 682/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0280 - mae: 0.1203\n",
      "Epoch 683/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0285 - mae: 0.1228\n",
      "Epoch 684/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0305 - mae: 0.1243\n",
      "Epoch 685/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0285 - mae: 0.1228\n",
      "Epoch 686/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0275 - mae: 0.1199\n",
      "Epoch 687/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0272 - mae: 0.1200\n",
      "Epoch 688/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0279 - mae: 0.1216\n",
      "Epoch 689/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0272 - mae: 0.1188\n",
      "Epoch 690/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0265 - mae: 0.1170\n",
      "Epoch 691/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0262 - mae: 0.1167\n",
      "Epoch 692/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0260 - mae: 0.1166\n",
      "Epoch 693/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0262 - mae: 0.1175\n",
      "Epoch 694/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0261 - mae: 0.1167\n",
      "Epoch 695/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0257 - mae: 0.1155\n",
      "Epoch 696/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0260 - mae: 0.1172\n",
      "Epoch 697/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0259 - mae: 0.1160\n",
      "Epoch 698/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0255 - mae: 0.1152\n",
      "Epoch 699/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0254 - mae: 0.1157\n",
      "Epoch 700/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0253 - mae: 0.1150\n",
      "Epoch 701/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0251 - mae: 0.1148\n",
      "Epoch 702/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0255 - mae: 0.1161\n",
      "Epoch 703/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0253 - mae: 0.1159\n",
      "Epoch 704/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0249 - mae: 0.1143\n",
      "Epoch 705/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0249 - mae: 0.1136\n",
      "Epoch 706/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0250 - mae: 0.1133\n",
      "Epoch 707/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0278 - mae: 0.1209\n",
      "Epoch 708/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0255 - mae: 0.1158\n",
      "Epoch 709/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0251 - mae: 0.1144\n",
      "Epoch 710/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0247 - mae: 0.1136\n",
      "Epoch 711/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0249 - mae: 0.1145\n",
      "Epoch 712/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0250 - mae: 0.1150\n",
      "Epoch 713/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0418 - mae: 0.1488\n",
      "Epoch 714/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0306 - mae: 0.1283\n",
      "Epoch 715/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0285 - mae: 0.1236\n",
      "Epoch 716/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0274 - mae: 0.1199\n",
      "Epoch 717/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0261 - mae: 0.1177\n",
      "Epoch 718/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0271 - mae: 0.1193\n",
      "Epoch 719/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0253 - mae: 0.1144\n",
      "Epoch 720/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0258 - mae: 0.1159\n",
      "Epoch 721/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0256 - mae: 0.1161\n",
      "Epoch 722/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0243 - mae: 0.1122\n",
      "Epoch 723/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0248 - mae: 0.1138\n",
      "Epoch 724/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0238 - mae: 0.1112\n",
      "Epoch 725/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0242 - mae: 0.1119\n",
      "Epoch 726/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0247 - mae: 0.1144\n",
      "Epoch 727/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0245 - mae: 0.1133\n",
      "Epoch 728/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0237 - mae: 0.1107\n",
      "Epoch 729/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0244 - mae: 0.1121\n",
      "Epoch 730/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0237 - mae: 0.1114\n",
      "Epoch 731/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0237 - mae: 0.1110\n",
      "Epoch 732/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0244 - mae: 0.1132\n",
      "Epoch 733/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0232 - mae: 0.1091\n",
      "Epoch 734/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0237 - mae: 0.1118\n",
      "Epoch 735/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0232 - mae: 0.1098\n",
      "Epoch 736/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0234 - mae: 0.1105\n",
      "Epoch 737/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0230 - mae: 0.1097\n",
      "Epoch 738/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0241 - mae: 0.1125\n",
      "Epoch 739/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0232 - mae: 0.1098\n",
      "Epoch 740/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0232 - mae: 0.1090\n",
      "Epoch 741/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0231 - mae: 0.1101\n",
      "Epoch 742/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0229 - mae: 0.1087\n",
      "Epoch 743/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0228 - mae: 0.1094\n",
      "Epoch 744/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0231 - mae: 0.1100\n",
      "Epoch 745/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0226 - mae: 0.1085\n",
      "Epoch 746/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0222 - mae: 0.1075\n",
      "Epoch 747/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1060\n",
      "Epoch 748/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0231 - mae: 0.1097\n",
      "Epoch 749/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0225 - mae: 0.1077\n",
      "Epoch 750/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0221 - mae: 0.1072\n",
      "Epoch 751/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0221 - mae: 0.1079\n",
      "Epoch 752/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0224 - mae: 0.1072\n",
      "Epoch 753/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0224 - mae: 0.1082\n",
      "Epoch 754/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0227 - mae: 0.1082\n",
      "Epoch 755/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0218 - mae: 0.1063\n",
      "Epoch 756/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0224 - mae: 0.1078\n",
      "Epoch 757/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0237 - mae: 0.1119\n",
      "Epoch 758/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0234 - mae: 0.1109\n",
      "Epoch 759/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0220 - mae: 0.1070\n",
      "Epoch 760/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0220 - mae: 0.1068\n",
      "Epoch 761/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0270 - mae: 0.1205\n",
      "Epoch 762/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0247 - mae: 0.1134\n",
      "Epoch 763/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0239 - mae: 0.1105\n",
      "Epoch 764/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0236 - mae: 0.1100\n",
      "Epoch 765/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0223 - mae: 0.1069\n",
      "Epoch 766/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0221 - mae: 0.1066\n",
      "Epoch 767/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0224 - mae: 0.1076\n",
      "Epoch 768/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0220 - mae: 0.1074\n",
      "Epoch 769/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0223 - mae: 0.1071\n",
      "Epoch 770/2000\n",
      "2019/2019 [==============================] - 0s 105us/sample - loss: 0.0217 - mae: 0.1064\n",
      "Epoch 771/2000\n",
      "2019/2019 [==============================] - 0s 152us/sample - loss: 0.0257 - mae: 0.1078\n",
      "Epoch 772/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0269 - mae: 0.1172\n",
      "Epoch 773/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0238 - mae: 0.1099\n",
      "Epoch 774/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0232 - mae: 0.1080\n",
      "Epoch 775/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0230 - mae: 0.1083\n",
      "Epoch 776/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0232 - mae: 0.1082\n",
      "Epoch 777/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0239 - mae: 0.1115\n",
      "Epoch 778/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0229 - mae: 0.1083\n",
      "Epoch 779/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0224 - mae: 0.1064\n",
      "Epoch 780/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0236 - mae: 0.1111\n",
      "Epoch 781/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0222 - mae: 0.1062\n",
      "Epoch 782/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0217 - mae: 0.1047\n",
      "Epoch 783/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0222 - mae: 0.1068\n",
      "Epoch 784/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0221 - mae: 0.1057\n",
      "Epoch 785/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0216 - mae: 0.1043\n",
      "Epoch 786/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0217 - mae: 0.1045\n",
      "Epoch 787/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0219 - mae: 0.1060\n",
      "Epoch 788/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0218 - mae: 0.1063\n",
      "Epoch 789/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0218 - mae: 0.1055\n",
      "Epoch 790/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0237 - mae: 0.1094\n",
      "Epoch 791/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0229 - mae: 0.1081\n",
      "Epoch 792/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0220 - mae: 0.1055\n",
      "Epoch 793/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0219 - mae: 0.1062\n",
      "Epoch 794/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0218 - mae: 0.1058\n",
      "Epoch 795/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0225 - mae: 0.1076\n",
      "Epoch 796/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0218 - mae: 0.1061\n",
      "Epoch 797/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0221 - mae: 0.1062\n",
      "Epoch 798/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0217 - mae: 0.1064\n",
      "Epoch 799/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0210 - mae: 0.1035\n",
      "Epoch 800/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0210 - mae: 0.1036\n",
      "Epoch 801/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0218 - mae: 0.1062\n",
      "Epoch 802/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0216 - mae: 0.1050\n",
      "Epoch 803/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0216 - mae: 0.1041\n",
      "Epoch 804/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0211 - mae: 0.1042\n",
      "Epoch 805/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0214 - mae: 0.1055\n",
      "Epoch 806/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0214 - mae: 0.1047\n",
      "Epoch 807/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0228 - mae: 0.1098\n",
      "Epoch 808/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0241 - mae: 0.1121\n",
      "Epoch 809/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0217 - mae: 0.1059\n",
      "Epoch 810/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0211 - mae: 0.1030\n",
      "Epoch 811/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0208 - mae: 0.1020\n",
      "Epoch 812/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0219 - mae: 0.1062\n",
      "Epoch 813/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0203 - mae: 0.1016\n",
      "Epoch 814/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0205 - mae: 0.1019\n",
      "Epoch 815/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0215 - mae: 0.1054\n",
      "Epoch 816/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0222 - mae: 0.1069\n",
      "Epoch 817/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0205 - mae: 0.1022\n",
      "Epoch 818/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0213 - mae: 0.1041\n",
      "Epoch 819/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0204 - mae: 0.1016\n",
      "Epoch 820/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0206 - mae: 0.1024\n",
      "Epoch 821/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0204 - mae: 0.1017\n",
      "Epoch 822/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0218 - mae: 0.1063\n",
      "Epoch 823/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0216 - mae: 0.1050\n",
      "Epoch 824/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0214 - mae: 0.1046\n",
      "Epoch 825/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0212 - mae: 0.1037\n",
      "Epoch 826/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0222 - mae: 0.1076\n",
      "Epoch 827/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0208 - mae: 0.1030\n",
      "Epoch 828/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0208 - mae: 0.1031\n",
      "Epoch 829/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0293 - mae: 0.1134\n",
      "Epoch 830/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0255 - mae: 0.1157\n",
      "Epoch 831/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0238 - mae: 0.1121\n",
      "Epoch 832/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0237 - mae: 0.1099\n",
      "Epoch 833/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0216 - mae: 0.1050\n",
      "Epoch 834/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0217 - mae: 0.1060\n",
      "Epoch 835/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0214 - mae: 0.1051\n",
      "Epoch 836/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0216 - mae: 0.1046\n",
      "Epoch 837/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0216 - mae: 0.1058\n",
      "Epoch 838/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0214 - mae: 0.1051\n",
      "Epoch 839/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0213 - mae: 0.1050\n",
      "Epoch 840/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0218 - mae: 0.1066\n",
      "Epoch 841/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0207 - mae: 0.1029\n",
      "Epoch 842/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0204 - mae: 0.1025\n",
      "Epoch 843/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0210 - mae: 0.1044\n",
      "Epoch 844/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0206 - mae: 0.1034\n",
      "Epoch 845/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0205 - mae: 0.1031\n",
      "Epoch 846/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0205 - mae: 0.1026\n",
      "Epoch 847/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0214 - mae: 0.1059\n",
      "Epoch 848/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0235 - mae: 0.1114\n",
      "Epoch 849/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0206 - mae: 0.1022\n",
      "Epoch 850/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0202 - mae: 0.1018\n",
      "Epoch 851/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0212 - mae: 0.1048\n",
      "Epoch 852/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0206 - mae: 0.1032\n",
      "Epoch 853/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0207 - mae: 0.1027\n",
      "Epoch 854/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0209 - mae: 0.1039\n",
      "Epoch 855/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0205 - mae: 0.1028\n",
      "Epoch 856/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0199 - mae: 0.1014\n",
      "Epoch 857/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0202 - mae: 0.1020\n",
      "Epoch 858/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0202 - mae: 0.1021\n",
      "Epoch 859/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0202 - mae: 0.1014\n",
      "Epoch 860/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0211 - mae: 0.1051\n",
      "Epoch 861/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0203 - mae: 0.1018\n",
      "Epoch 862/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0201 - mae: 0.1009\n",
      "Epoch 863/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0205 - mae: 0.1022\n",
      "Epoch 864/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0198 - mae: 0.1006\n",
      "Epoch 865/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0200 - mae: 0.1017\n",
      "Epoch 866/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0200 - mae: 0.1014\n",
      "Epoch 867/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0197 - mae: 0.1006\n",
      "Epoch 868/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0204 - mae: 0.1022\n",
      "Epoch 869/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0210 - mae: 0.1042\n",
      "Epoch 870/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0208 - mae: 0.1041\n",
      "Epoch 871/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0203 - mae: 0.1028\n",
      "Epoch 872/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0208 - mae: 0.1044\n",
      "Epoch 873/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0201 - mae: 0.1024\n",
      "Epoch 874/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0202 - mae: 0.1021\n",
      "Epoch 875/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0288 - mae: 0.1196\n",
      "Epoch 876/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0244 - mae: 0.1121\n",
      "Epoch 877/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0222 - mae: 0.1058\n",
      "Epoch 878/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0223 - mae: 0.1069\n",
      "Epoch 879/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0218 - mae: 0.1057\n",
      "Epoch 880/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0215 - mae: 0.1047\n",
      "Epoch 881/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0217 - mae: 0.1054\n",
      "Epoch 882/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0223 - mae: 0.1079\n",
      "Epoch 883/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0214 - mae: 0.1044\n",
      "Epoch 884/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0219 - mae: 0.1059\n",
      "Epoch 885/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0208 - mae: 0.1034\n",
      "Epoch 886/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0207 - mae: 0.1024\n",
      "Epoch 887/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0207 - mae: 0.1026\n",
      "Epoch 888/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0210 - mae: 0.1041\n",
      "Epoch 889/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0212 - mae: 0.1037\n",
      "Epoch 890/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0203 - mae: 0.1011\n",
      "Epoch 891/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0208 - mae: 0.1033\n",
      "Epoch 892/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0199 - mae: 0.0998\n",
      "Epoch 893/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0208 - mae: 0.1036\n",
      "Epoch 894/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0205 - mae: 0.1017\n",
      "Epoch 895/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0210 - mae: 0.1037\n",
      "Epoch 896/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0202 - mae: 0.1012\n",
      "Epoch 897/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0202 - mae: 0.1017\n",
      "Epoch 898/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0207 - mae: 0.1034\n",
      "Epoch 899/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0212 - mae: 0.1064\n",
      "Epoch 900/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0208 - mae: 0.1035\n",
      "Epoch 901/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0208 - mae: 0.1037\n",
      "Epoch 902/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0215 - mae: 0.1048\n",
      "Epoch 903/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0211 - mae: 0.1036\n",
      "Epoch 904/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0205 - mae: 0.1028\n",
      "Epoch 905/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0205 - mae: 0.1029\n",
      "Epoch 906/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0197 - mae: 0.1002\n",
      "Epoch 907/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0200 - mae: 0.1014\n",
      "Epoch 908/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0199 - mae: 0.1016\n",
      "Epoch 909/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0201 - mae: 0.1015\n",
      "Epoch 910/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0205 - mae: 0.1019\n",
      "Epoch 911/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0198 - mae: 0.1017\n",
      "Epoch 912/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0209 - mae: 0.1038\n",
      "Epoch 913/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0201 - mae: 0.1018\n",
      "Epoch 914/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0196 - mae: 0.1005\n",
      "Epoch 915/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0197 - mae: 0.1007\n",
      "Epoch 916/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0196 - mae: 0.0996\n",
      "Epoch 917/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0204 - mae: 0.1031\n",
      "Epoch 918/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0194 - mae: 0.0998\n",
      "Epoch 919/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0199 - mae: 0.1011\n",
      "Epoch 920/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0201 - mae: 0.1018\n",
      "Epoch 921/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0196 - mae: 0.1009\n",
      "Epoch 922/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0198 - mae: 0.1000\n",
      "Epoch 923/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0198 - mae: 0.1005\n",
      "Epoch 924/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0196 - mae: 0.1005\n",
      "Epoch 925/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0198 - mae: 0.1004\n",
      "Epoch 926/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0200 - mae: 0.1016\n",
      "Epoch 927/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0198 - mae: 0.1015\n",
      "Epoch 928/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0194 - mae: 0.0996\n",
      "Epoch 929/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0198 - mae: 0.1018\n",
      "Epoch 930/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0194 - mae: 0.1000\n",
      "Epoch 931/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0201 - mae: 0.1016\n",
      "Epoch 932/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0205 - mae: 0.1029\n",
      "Epoch 933/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0207 - mae: 0.1034\n",
      "Epoch 934/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0194 - mae: 0.0999\n",
      "Epoch 935/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0194 - mae: 0.1002\n",
      "Epoch 936/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1022\n",
      "Epoch 937/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0192 - mae: 0.0987\n",
      "Epoch 938/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0196 - mae: 0.1004\n",
      "Epoch 939/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0200 - mae: 0.1010\n",
      "Epoch 940/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0192 - mae: 0.0990\n",
      "Epoch 941/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0191 - mae: 0.0992\n",
      "Epoch 942/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0190 - mae: 0.0984\n",
      "Epoch 943/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0192 - mae: 0.0991\n",
      "Epoch 944/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0190 - mae: 0.0985\n",
      "Epoch 945/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0196 - mae: 0.1006\n",
      "Epoch 946/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0188 - mae: 0.0973\n",
      "Epoch 947/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0198 - mae: 0.1012\n",
      "Epoch 948/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0194 - mae: 0.0995\n",
      "Epoch 949/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.0990\n",
      "Epoch 950/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0193 - mae: 0.1007\n",
      "Epoch 951/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0191 - mae: 0.0985\n",
      "Epoch 952/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0194 - mae: 0.0998\n",
      "Epoch 953/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0189 - mae: 0.0983\n",
      "Epoch 954/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0218 - mae: 0.1061\n",
      "Epoch 955/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0207 - mae: 0.1040\n",
      "Epoch 956/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0200 - mae: 0.1025\n",
      "Epoch 957/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0193 - mae: 0.1008\n",
      "Epoch 958/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0191 - mae: 0.0990\n",
      "Epoch 959/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0233 - mae: 0.1112\n",
      "Epoch 960/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0206 - mae: 0.1035\n",
      "Epoch 961/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0198 - mae: 0.1006\n",
      "Epoch 962/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0203 - mae: 0.1023\n",
      "Epoch 963/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0193 - mae: 0.0994\n",
      "Epoch 964/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0188 - mae: 0.0983\n",
      "Epoch 965/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0196 - mae: 0.1011\n",
      "Epoch 966/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0195 - mae: 0.1002\n",
      "Epoch 967/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0191 - mae: 0.0992\n",
      "Epoch 968/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0195 - mae: 0.0999\n",
      "Epoch 969/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0186 - mae: 0.0975\n",
      "Epoch 970/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.0969\n",
      "Epoch 971/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.0983\n",
      "Epoch 972/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0195 - mae: 0.1007\n",
      "Epoch 973/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0193 - mae: 0.0994\n",
      "Epoch 974/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0184 - mae: 0.0964\n",
      "Epoch 975/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0190 - mae: 0.0987\n",
      "Epoch 976/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0208 - mae: 0.1054\n",
      "Epoch 977/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0192 - mae: 0.0995\n",
      "Epoch 978/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0202 - mae: 0.1021\n",
      "Epoch 979/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0189 - mae: 0.0987\n",
      "Epoch 980/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0188 - mae: 0.0975\n",
      "Epoch 981/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0190 - mae: 0.0975\n",
      "Epoch 982/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0201 - mae: 0.1019\n",
      "Epoch 983/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0191 - mae: 0.0990\n",
      "Epoch 984/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0188 - mae: 0.0982\n",
      "Epoch 985/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0186 - mae: 0.0966\n",
      "Epoch 986/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0968\n",
      "Epoch 987/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0184 - mae: 0.0968\n",
      "Epoch 988/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0190 - mae: 0.0987\n",
      "Epoch 989/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0188 - mae: 0.0972\n",
      "Epoch 990/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0191 - mae: 0.0988\n",
      "Epoch 991/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0189 - mae: 0.0985\n",
      "Epoch 992/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0186 - mae: 0.0960\n",
      "Epoch 993/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0190 - mae: 0.0993\n",
      "Epoch 994/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0197 - mae: 0.1005\n",
      "Epoch 995/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0187 - mae: 0.0977\n",
      "Epoch 996/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.0968\n",
      "Epoch 997/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0185 - mae: 0.0967\n",
      "Epoch 998/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0188 - mae: 0.0977\n",
      "Epoch 999/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0197 - mae: 0.1006\n",
      "Epoch 1000/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0198 - mae: 0.1003\n",
      "Epoch 1001/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0189 - mae: 0.0976\n",
      "Epoch 1002/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0189 - mae: 0.0972\n",
      "Epoch 1003/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0188 - mae: 0.0982\n",
      "Epoch 1004/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0185 - mae: 0.0961\n",
      "Epoch 1005/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.0968\n",
      "Epoch 1006/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0182 - mae: 0.0954\n",
      "Epoch 1007/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0190 - mae: 0.0984\n",
      "Epoch 1008/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0201 - mae: 0.1021\n",
      "Epoch 1009/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0203 - mae: 0.1037\n",
      "Epoch 1010/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0214 - mae: 0.1058\n",
      "Epoch 1011/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0979\n",
      "Epoch 1012/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0195 - mae: 0.1006\n",
      "Epoch 1013/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0184 - mae: 0.0967\n",
      "Epoch 1014/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0970\n",
      "Epoch 1015/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0188 - mae: 0.0981\n",
      "Epoch 1016/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0188 - mae: 0.0982\n",
      "Epoch 1017/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0182 - mae: 0.0953\n",
      "Epoch 1018/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0198 - mae: 0.1013\n",
      "Epoch 1019/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0962\n",
      "Epoch 1020/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0187 - mae: 0.0971\n",
      "Epoch 1021/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0977\n",
      "Epoch 1022/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0186 - mae: 0.0974\n",
      "Epoch 1023/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0190 - mae: 0.0983\n",
      "Epoch 1024/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0186 - mae: 0.0968\n",
      "Epoch 1025/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0186 - mae: 0.0973\n",
      "Epoch 1026/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0183 - mae: 0.0953\n",
      "Epoch 1027/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0201 - mae: 0.1029\n",
      "Epoch 1028/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0189 - mae: 0.0977\n",
      "Epoch 1029/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0193 - mae: 0.0974\n",
      "Epoch 1030/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0209 - mae: 0.1021\n",
      "Epoch 1031/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0190 - mae: 0.0992\n",
      "Epoch 1032/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0196 - mae: 0.1003\n",
      "Epoch 1033/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0190 - mae: 0.0987\n",
      "Epoch 1034/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0185 - mae: 0.0970\n",
      "Epoch 1035/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0194 - mae: 0.0997\n",
      "Epoch 1036/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0181 - mae: 0.0957\n",
      "Epoch 1037/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0964\n",
      "Epoch 1038/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0186 - mae: 0.0978\n",
      "Epoch 1039/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0181 - mae: 0.0955\n",
      "Epoch 1040/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0184 - mae: 0.0968\n",
      "Epoch 1041/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0193 - mae: 0.1003\n",
      "Epoch 1042/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0187 - mae: 0.0970\n",
      "Epoch 1043/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0178 - mae: 0.0947\n",
      "Epoch 1044/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0184 - mae: 0.0959\n",
      "Epoch 1045/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0190 - mae: 0.0986\n",
      "Epoch 1046/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.0973\n",
      "Epoch 1047/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0178 - mae: 0.0950\n",
      "Epoch 1048/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0185 - mae: 0.0979\n",
      "Epoch 1049/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0184 - mae: 0.0973\n",
      "Epoch 1050/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0971\n",
      "Epoch 1051/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0190 - mae: 0.0981\n",
      "Epoch 1052/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0222 - mae: 0.1076\n",
      "Epoch 1053/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0181 - mae: 0.0954\n",
      "Epoch 1054/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0180 - mae: 0.0953\n",
      "Epoch 1055/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0184 - mae: 0.0964\n",
      "Epoch 1056/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0180 - mae: 0.0961\n",
      "Epoch 1057/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0183 - mae: 0.0962\n",
      "Epoch 1058/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0180 - mae: 0.0960\n",
      "Epoch 1059/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0275 - mae: 0.1024\n",
      "Epoch 1060/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0205 - mae: 0.1040\n",
      "Epoch 1061/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0187 - mae: 0.0967\n",
      "Epoch 1062/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0184 - mae: 0.0966\n",
      "Epoch 1063/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0183 - mae: 0.0954\n",
      "Epoch 1064/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0187 - mae: 0.0978\n",
      "Epoch 1065/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0182 - mae: 0.0958\n",
      "Epoch 1066/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0188 - mae: 0.0980\n",
      "Epoch 1067/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.0974\n",
      "Epoch 1068/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0189 - mae: 0.0985\n",
      "Epoch 1069/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0186 - mae: 0.0972\n",
      "Epoch 1070/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0178 - mae: 0.0942\n",
      "Epoch 1071/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0225 - mae: 0.1091\n",
      "Epoch 1072/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0181 - mae: 0.0959\n",
      "Epoch 1073/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0181 - mae: 0.0954\n",
      "Epoch 1074/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0180 - mae: 0.0946\n",
      "Epoch 1075/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0178 - mae: 0.0948\n",
      "Epoch 1076/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0184 - mae: 0.0969\n",
      "Epoch 1077/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0190 - mae: 0.0980\n",
      "Epoch 1078/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0186 - mae: 0.0972\n",
      "Epoch 1079/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0178 - mae: 0.0952\n",
      "Epoch 1080/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.0975\n",
      "Epoch 1081/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0179 - mae: 0.0943\n",
      "Epoch 1082/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0182 - mae: 0.0960\n",
      "Epoch 1083/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0960\n",
      "Epoch 1084/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0212 - mae: 0.1046\n",
      "Epoch 1085/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0205 - mae: 0.1007\n",
      "Epoch 1086/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.0990\n",
      "Epoch 1087/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0192 - mae: 0.0991\n",
      "Epoch 1088/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0182 - mae: 0.0957\n",
      "Epoch 1089/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0186 - mae: 0.0967\n",
      "Epoch 1090/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0181 - mae: 0.0950\n",
      "Epoch 1091/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.0967\n",
      "Epoch 1092/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0182 - mae: 0.0954\n",
      "Epoch 1093/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0190 - mae: 0.0977\n",
      "Epoch 1094/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0182 - mae: 0.0948\n",
      "Epoch 1095/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0952\n",
      "Epoch 1096/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0179 - mae: 0.0949\n",
      "Epoch 1097/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0181 - mae: 0.0960\n",
      "Epoch 1098/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0183 - mae: 0.0964\n",
      "Epoch 1099/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0184 - mae: 0.0969\n",
      "Epoch 1100/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0182 - mae: 0.0961\n",
      "Epoch 1101/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0972\n",
      "Epoch 1102/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0977\n",
      "Epoch 1103/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0190 - mae: 0.1002\n",
      "Epoch 1104/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0180 - mae: 0.0954\n",
      "Epoch 1105/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0185 - mae: 0.0967\n",
      "Epoch 1106/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0179 - mae: 0.0949\n",
      "Epoch 1107/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0187 - mae: 0.0982\n",
      "Epoch 1108/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0177 - mae: 0.0942\n",
      "Epoch 1109/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0184 - mae: 0.0969\n",
      "Epoch 1110/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0189 - mae: 0.0977\n",
      "Epoch 1111/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0186 - mae: 0.0979\n",
      "Epoch 1112/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0193 - mae: 0.1000\n",
      "Epoch 1113/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0181 - mae: 0.0961\n",
      "Epoch 1114/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0176 - mae: 0.0944\n",
      "Epoch 1115/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0959\n",
      "Epoch 1116/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0179 - mae: 0.0952\n",
      "Epoch 1117/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0962\n",
      "Epoch 1118/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0179 - mae: 0.0951\n",
      "Epoch 1119/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0178 - mae: 0.0946\n",
      "Epoch 1120/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0187 - mae: 0.0980\n",
      "Epoch 1121/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0190 - mae: 0.0991\n",
      "Epoch 1122/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0181 - mae: 0.0961\n",
      "Epoch 1123/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0941\n",
      "Epoch 1124/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0193 - mae: 0.0994\n",
      "Epoch 1125/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0181 - mae: 0.0959\n",
      "Epoch 1126/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0196 - mae: 0.1017\n",
      "Epoch 1127/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0178 - mae: 0.0946\n",
      "Epoch 1128/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0177 - mae: 0.0945\n",
      "Epoch 1129/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0174 - mae: 0.0931\n",
      "Epoch 1130/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0184 - mae: 0.0975\n",
      "Epoch 1131/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0176 - mae: 0.0940\n",
      "Epoch 1132/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0975\n",
      "Epoch 1133/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0179 - mae: 0.0952\n",
      "Epoch 1134/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0970\n",
      "Epoch 1135/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0178 - mae: 0.0945\n",
      "Epoch 1136/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0177 - mae: 0.0948\n",
      "Epoch 1137/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0178 - mae: 0.0943\n",
      "Epoch 1138/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0182 - mae: 0.0962\n",
      "Epoch 1139/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0182 - mae: 0.0962\n",
      "Epoch 1140/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0179 - mae: 0.0950\n",
      "Epoch 1141/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0182 - mae: 0.0968\n",
      "Epoch 1142/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0174 - mae: 0.0945\n",
      "Epoch 1143/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0173 - mae: 0.0935\n",
      "Epoch 1144/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0184 - mae: 0.0974\n",
      "Epoch 1145/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0184 - mae: 0.0972\n",
      "Epoch 1146/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0177 - mae: 0.0946\n",
      "Epoch 1147/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0944\n",
      "Epoch 1148/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0177 - mae: 0.0955\n",
      "Epoch 1149/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0180 - mae: 0.0956\n",
      "Epoch 1150/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0174 - mae: 0.0933\n",
      "Epoch 1151/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0177 - mae: 0.0945\n",
      "Epoch 1152/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0940\n",
      "Epoch 1153/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0186 - mae: 0.0979\n",
      "Epoch 1154/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0977\n",
      "Epoch 1155/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0181 - mae: 0.0960\n",
      "Epoch 1156/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0176 - mae: 0.0946\n",
      "Epoch 1157/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0173 - mae: 0.0932\n",
      "Epoch 1158/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0180 - mae: 0.0957\n",
      "Epoch 1159/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0173 - mae: 0.0929\n",
      "Epoch 1160/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0175 - mae: 0.0942\n",
      "Epoch 1161/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0187 - mae: 0.0984\n",
      "Epoch 1162/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0182 - mae: 0.0963\n",
      "Epoch 1163/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0944\n",
      "Epoch 1164/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0182 - mae: 0.0977\n",
      "Epoch 1165/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0187 - mae: 0.0992\n",
      "Epoch 1166/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0177 - mae: 0.0948\n",
      "Epoch 1167/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0181 - mae: 0.0953\n",
      "Epoch 1168/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0187 - mae: 0.0980\n",
      "Epoch 1169/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0178 - mae: 0.0945\n",
      "Epoch 1170/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0192 - mae: 0.0989\n",
      "Epoch 1171/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0176 - mae: 0.0944\n",
      "Epoch 1172/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0179 - mae: 0.0959\n",
      "Epoch 1173/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0189 - mae: 0.0984\n",
      "Epoch 1174/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0201 - mae: 0.1022\n",
      "Epoch 1175/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0185 - mae: 0.0978\n",
      "Epoch 1176/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0186 - mae: 0.0978\n",
      "Epoch 1177/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.0964\n",
      "Epoch 1178/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0192 - mae: 0.0989\n",
      "Epoch 1179/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0178 - mae: 0.0950\n",
      "Epoch 1180/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0182 - mae: 0.0957\n",
      "Epoch 1181/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0180 - mae: 0.0959\n",
      "Epoch 1182/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0177 - mae: 0.0954\n",
      "Epoch 1183/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0179 - mae: 0.0956\n",
      "Epoch 1184/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0179 - mae: 0.0955\n",
      "Epoch 1185/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0178 - mae: 0.0956\n",
      "Epoch 1186/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0181 - mae: 0.0970\n",
      "Epoch 1187/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0946\n",
      "Epoch 1188/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0943\n",
      "Epoch 1189/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0174 - mae: 0.0936\n",
      "Epoch 1190/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0182 - mae: 0.0971\n",
      "Epoch 1191/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0175 - mae: 0.0940\n",
      "Epoch 1192/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0174 - mae: 0.0940\n",
      "Epoch 1193/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0170 - mae: 0.0930\n",
      "Epoch 1194/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0182 - mae: 0.0975\n",
      "Epoch 1195/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0177 - mae: 0.0946\n",
      "Epoch 1196/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0191 - mae: 0.0999\n",
      "Epoch 1197/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0204 - mae: 0.1052\n",
      "Epoch 1198/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0178 - mae: 0.0955\n",
      "Epoch 1199/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0176 - mae: 0.0946\n",
      "Epoch 1200/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0176 - mae: 0.0943\n",
      "Epoch 1201/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0177 - mae: 0.0951\n",
      "Epoch 1202/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0175 - mae: 0.0948\n",
      "Epoch 1203/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0187 - mae: 0.0983\n",
      "Epoch 1204/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0191 - mae: 0.0999\n",
      "Epoch 1205/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0182 - mae: 0.0965\n",
      "Epoch 1206/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0173 - mae: 0.0936\n",
      "Epoch 1207/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0172 - mae: 0.0931\n",
      "Epoch 1208/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0168 - mae: 0.0919\n",
      "Epoch 1209/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0174 - mae: 0.0943\n",
      "Epoch 1210/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0169 - mae: 0.0922\n",
      "Epoch 1211/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0173 - mae: 0.0935\n",
      "Epoch 1212/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0173 - mae: 0.0942\n",
      "Epoch 1213/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0174 - mae: 0.0941\n",
      "Epoch 1214/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0173 - mae: 0.0936\n",
      "Epoch 1215/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0174 - mae: 0.0942\n",
      "Epoch 1216/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0176 - mae: 0.0947\n",
      "Epoch 1217/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0175 - mae: 0.0948\n",
      "Epoch 1218/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0169 - mae: 0.0917\n",
      "Epoch 1219/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1018\n",
      "Epoch 1220/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0181 - mae: 0.0957\n",
      "Epoch 1221/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0173 - mae: 0.0935\n",
      "Epoch 1222/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0181 - mae: 0.0966\n",
      "Epoch 1223/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0167 - mae: 0.0915\n",
      "Epoch 1224/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0174 - mae: 0.0947\n",
      "Epoch 1225/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0173 - mae: 0.0944\n",
      "Epoch 1226/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0182 - mae: 0.0964\n",
      "Epoch 1227/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0169 - mae: 0.0922\n",
      "Epoch 1228/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0167 - mae: 0.0913\n",
      "Epoch 1229/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0170 - mae: 0.0921\n",
      "Epoch 1230/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0175 - mae: 0.0946\n",
      "Epoch 1231/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0167 - mae: 0.0921\n",
      "Epoch 1232/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0171 - mae: 0.0930\n",
      "Epoch 1233/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0186 - mae: 0.0970\n",
      "Epoch 1234/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0206 - mae: 0.1047\n",
      "Epoch 1235/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0193 - mae: 0.1001\n",
      "Epoch 1236/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0175 - mae: 0.0942\n",
      "Epoch 1237/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0173 - mae: 0.0945\n",
      "Epoch 1238/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0179 - mae: 0.0963\n",
      "Epoch 1239/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0176 - mae: 0.0954\n",
      "Epoch 1240/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0169 - mae: 0.0922\n",
      "Epoch 1241/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0172 - mae: 0.0932\n",
      "Epoch 1242/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0174 - mae: 0.0948\n",
      "Epoch 1243/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0165 - mae: 0.0914\n",
      "Epoch 1244/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0170 - mae: 0.0923\n",
      "Epoch 1245/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0173 - mae: 0.0941\n",
      "Epoch 1246/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0174 - mae: 0.0953\n",
      "Epoch 1247/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.1002\n",
      "Epoch 1248/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0179 - mae: 0.0961\n",
      "Epoch 1249/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0178 - mae: 0.0956\n",
      "Epoch 1250/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0176 - mae: 0.0954\n",
      "Epoch 1251/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0180 - mae: 0.0967\n",
      "Epoch 1252/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0177 - mae: 0.0953\n",
      "Epoch 1253/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0190 - mae: 0.0994\n",
      "Epoch 1254/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0179 - mae: 0.0953\n",
      "Epoch 1255/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0178 - mae: 0.0956\n",
      "Epoch 1256/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0178 - mae: 0.0961\n",
      "Epoch 1257/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0979\n",
      "Epoch 1258/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0172 - mae: 0.0932\n",
      "Epoch 1259/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0171 - mae: 0.0930\n",
      "Epoch 1260/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0994\n",
      "Epoch 1261/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0166 - mae: 0.0914\n",
      "Epoch 1262/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0178 - mae: 0.0960\n",
      "Epoch 1263/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0174 - mae: 0.0939\n",
      "Epoch 1264/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0171 - mae: 0.0938\n",
      "Epoch 1265/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0177 - mae: 0.0947\n",
      "Epoch 1266/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0173 - mae: 0.0940\n",
      "Epoch 1267/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0176 - mae: 0.0955\n",
      "Epoch 1268/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0177 - mae: 0.0954\n",
      "Epoch 1269/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0173 - mae: 0.0939\n",
      "Epoch 1270/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0175 - mae: 0.0946\n",
      "Epoch 1271/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0792 - mae: 0.1570\n",
      "Epoch 1272/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0378 - mae: 0.1286\n",
      "Epoch 1273/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0330 - mae: 0.1239\n",
      "Epoch 1274/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0292 - mae: 0.1224\n",
      "Epoch 1275/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0258 - mae: 0.1169\n",
      "Epoch 1276/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0252 - mae: 0.1146\n",
      "Epoch 1277/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0243 - mae: 0.1125\n",
      "Epoch 1278/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0235 - mae: 0.1111\n",
      "Epoch 1279/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0231 - mae: 0.1104\n",
      "Epoch 1280/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0225 - mae: 0.1087\n",
      "Epoch 1281/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0218 - mae: 0.1067\n",
      "Epoch 1282/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0216 - mae: 0.1058\n",
      "Epoch 1283/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0210 - mae: 0.1042\n",
      "Epoch 1284/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0215 - mae: 0.1060\n",
      "Epoch 1285/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0207 - mae: 0.1035\n",
      "Epoch 1286/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0210 - mae: 0.1046\n",
      "Epoch 1287/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0203 - mae: 0.1022\n",
      "Epoch 1288/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0212 - mae: 0.1050\n",
      "Epoch 1289/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0215 - mae: 0.1062\n",
      "Epoch 1290/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0205 - mae: 0.1027\n",
      "Epoch 1291/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0203 - mae: 0.1028\n",
      "Epoch 1292/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0206 - mae: 0.1031\n",
      "Epoch 1293/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0205 - mae: 0.1025\n",
      "Epoch 1294/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0202 - mae: 0.1023\n",
      "Epoch 1295/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0223 - mae: 0.1076\n",
      "Epoch 1296/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0215 - mae: 0.1053\n",
      "Epoch 1297/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0204 - mae: 0.1024\n",
      "Epoch 1298/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0205 - mae: 0.1034\n",
      "Epoch 1299/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0201 - mae: 0.1020\n",
      "Epoch 1300/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0201 - mae: 0.1019\n",
      "Epoch 1301/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0208 - mae: 0.1044\n",
      "Epoch 1302/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0196 - mae: 0.1002\n",
      "Epoch 1303/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0203 - mae: 0.1030\n",
      "Epoch 1304/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0199 - mae: 0.1010\n",
      "Epoch 1305/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0197 - mae: 0.1004\n",
      "Epoch 1306/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0198 - mae: 0.1005\n",
      "Epoch 1307/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0201 - mae: 0.1016\n",
      "Epoch 1308/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0201 - mae: 0.1013\n",
      "Epoch 1309/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0199 - mae: 0.1015\n",
      "Epoch 1310/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0195 - mae: 0.0998\n",
      "Epoch 1311/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0197 - mae: 0.0999\n",
      "Epoch 1312/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.1002\n",
      "Epoch 1313/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0204 - mae: 0.1024\n",
      "Epoch 1314/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0192 - mae: 0.0989\n",
      "Epoch 1315/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0196 - mae: 0.1010\n",
      "Epoch 1316/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0191 - mae: 0.0986\n",
      "Epoch 1317/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0190 - mae: 0.0989\n",
      "Epoch 1318/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0191 - mae: 0.0987\n",
      "Epoch 1319/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0193 - mae: 0.1000\n",
      "Epoch 1320/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0196 - mae: 0.1002\n",
      "Epoch 1321/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0196 - mae: 0.1001\n",
      "Epoch 1322/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0192 - mae: 0.0998\n",
      "Epoch 1323/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0194 - mae: 0.0995\n",
      "Epoch 1324/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0188 - mae: 0.0977\n",
      "Epoch 1325/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0190 - mae: 0.0989\n",
      "Epoch 1326/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0191 - mae: 0.0991\n",
      "Epoch 1327/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0186 - mae: 0.0976\n",
      "Epoch 1328/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0190 - mae: 0.0995\n",
      "Epoch 1329/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0195 - mae: 0.1009\n",
      "Epoch 1330/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0189 - mae: 0.0984\n",
      "Epoch 1331/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.0976\n",
      "Epoch 1332/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0188 - mae: 0.0992\n",
      "Epoch 1333/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0187 - mae: 0.0977\n",
      "Epoch 1334/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0192 - mae: 0.0996\n",
      "Epoch 1335/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0192 - mae: 0.1003\n",
      "Epoch 1336/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0187 - mae: 0.0978\n",
      "Epoch 1337/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.0984\n",
      "Epoch 1338/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0968\n",
      "Epoch 1339/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0194 - mae: 0.1005\n",
      "Epoch 1340/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.0979\n",
      "Epoch 1341/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0188 - mae: 0.0984\n",
      "Epoch 1342/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0183 - mae: 0.0971\n",
      "Epoch 1343/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0197 - mae: 0.1007\n",
      "Epoch 1344/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0190 - mae: 0.0988\n",
      "Epoch 1345/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.0985\n",
      "Epoch 1346/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0192 - mae: 0.0983\n",
      "Epoch 1347/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0195 - mae: 0.0995\n",
      "Epoch 1348/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0190 - mae: 0.0988\n",
      "Epoch 1349/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0248 - mae: 0.1116\n",
      "Epoch 1350/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0210 - mae: 0.1044\n",
      "Epoch 1351/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0201 - mae: 0.1018\n",
      "Epoch 1352/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0197 - mae: 0.1010\n",
      "Epoch 1353/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0194 - mae: 0.1011\n",
      "Epoch 1354/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0190 - mae: 0.0991\n",
      "Epoch 1355/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0190 - mae: 0.0996\n",
      "Epoch 1356/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0190 - mae: 0.0996\n",
      "Epoch 1357/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0981\n",
      "Epoch 1358/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0194 - mae: 0.1004\n",
      "Epoch 1359/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0972\n",
      "Epoch 1360/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0962\n",
      "Epoch 1361/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0956\n",
      "Epoch 1362/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0182 - mae: 0.0963\n",
      "Epoch 1363/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0980\n",
      "Epoch 1364/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0183 - mae: 0.0980\n",
      "Epoch 1365/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0185 - mae: 0.0978\n",
      "Epoch 1366/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0191 - mae: 0.1008\n",
      "Epoch 1367/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0977\n",
      "Epoch 1368/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.0976\n",
      "Epoch 1369/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0181 - mae: 0.0960\n",
      "Epoch 1370/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0185 - mae: 0.0978\n",
      "Epoch 1371/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0185 - mae: 0.0975\n",
      "Epoch 1372/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0182 - mae: 0.0969\n",
      "Epoch 1373/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0182 - mae: 0.0967\n",
      "Epoch 1374/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0181 - mae: 0.0971\n",
      "Epoch 1375/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0182 - mae: 0.0974\n",
      "Epoch 1376/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0179 - mae: 0.0957\n",
      "Epoch 1377/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0179 - mae: 0.0964\n",
      "Epoch 1378/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0179 - mae: 0.0959\n",
      "Epoch 1379/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0942\n",
      "Epoch 1380/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0177 - mae: 0.0955\n",
      "Epoch 1381/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.0987\n",
      "Epoch 1382/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0182 - mae: 0.0969\n",
      "Epoch 1383/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0184 - mae: 0.0978\n",
      "Epoch 1384/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0186 - mae: 0.0986\n",
      "Epoch 1385/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0182 - mae: 0.0966\n",
      "Epoch 1386/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0171 - mae: 0.0929\n",
      "Epoch 1387/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0946\n",
      "Epoch 1388/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0176 - mae: 0.0958\n",
      "Epoch 1389/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0170 - mae: 0.0932\n",
      "Epoch 1390/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0173 - mae: 0.0941\n",
      "Epoch 1391/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0170 - mae: 0.0931\n",
      "Epoch 1392/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0169 - mae: 0.0925\n",
      "Epoch 1393/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0173 - mae: 0.0941\n",
      "Epoch 1394/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0170 - mae: 0.0925\n",
      "Epoch 1395/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0172 - mae: 0.0943\n",
      "Epoch 1396/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0169 - mae: 0.0926\n",
      "Epoch 1397/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0173 - mae: 0.0930\n",
      "Epoch 1398/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0927\n",
      "Epoch 1399/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0172 - mae: 0.0935\n",
      "Epoch 1400/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0172 - mae: 0.0943\n",
      "Epoch 1401/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0169 - mae: 0.0926\n",
      "Epoch 1402/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0947\n",
      "Epoch 1403/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0174 - mae: 0.0946\n",
      "Epoch 1404/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0167 - mae: 0.0925\n",
      "Epoch 1405/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0179 - mae: 0.0965\n",
      "Epoch 1406/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0187 - mae: 0.0994\n",
      "Epoch 1407/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0172 - mae: 0.0948\n",
      "Epoch 1408/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0177 - mae: 0.0947\n",
      "Epoch 1409/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0174 - mae: 0.0942\n",
      "Epoch 1410/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0949\n",
      "Epoch 1411/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0174 - mae: 0.0944\n",
      "Epoch 1412/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0169 - mae: 0.0932\n",
      "Epoch 1413/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0194 - mae: 0.1005\n",
      "Epoch 1414/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0198 - mae: 0.1034\n",
      "Epoch 1415/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0175 - mae: 0.0950\n",
      "Epoch 1416/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0172 - mae: 0.0938\n",
      "Epoch 1417/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0174 - mae: 0.0953\n",
      "Epoch 1418/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0176 - mae: 0.0946\n",
      "Epoch 1419/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0176 - mae: 0.0943\n",
      "Epoch 1420/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0173 - mae: 0.0940\n",
      "Epoch 1421/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0173 - mae: 0.0931\n",
      "Epoch 1422/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0172 - mae: 0.0936\n",
      "Epoch 1423/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0173 - mae: 0.0946\n",
      "Epoch 1424/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0191 - mae: 0.0998\n",
      "Epoch 1425/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0175 - mae: 0.0951\n",
      "Epoch 1426/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0172 - mae: 0.0941\n",
      "Epoch 1427/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0171 - mae: 0.0932\n",
      "Epoch 1428/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0164 - mae: 0.0918\n",
      "Epoch 1429/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0171 - mae: 0.0942\n",
      "Epoch 1430/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0172 - mae: 0.0939\n",
      "Epoch 1431/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0168 - mae: 0.0923\n",
      "Epoch 1432/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0161 - mae: 0.0901\n",
      "Epoch 1433/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0162 - mae: 0.0905\n",
      "Epoch 1434/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0167 - mae: 0.0924\n",
      "Epoch 1435/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0165 - mae: 0.0923\n",
      "Epoch 1436/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0382 - mae: 0.1307\n",
      "Epoch 1437/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0233 - mae: 0.1124\n",
      "Epoch 1438/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0218 - mae: 0.1080\n",
      "Epoch 1439/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0207 - mae: 0.1033\n",
      "Epoch 1440/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0205 - mae: 0.1027\n",
      "Epoch 1441/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0195 - mae: 0.0997\n",
      "Epoch 1442/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0196 - mae: 0.1003\n",
      "Epoch 1443/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0195 - mae: 0.0996\n",
      "Epoch 1444/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0193 - mae: 0.0990\n",
      "Epoch 1445/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0199 - mae: 0.1008\n",
      "Epoch 1446/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0197 - mae: 0.0999\n",
      "Epoch 1447/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0186 - mae: 0.0976\n",
      "Epoch 1448/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0190 - mae: 0.0990\n",
      "Epoch 1449/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0186 - mae: 0.0971\n",
      "Epoch 1450/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0183 - mae: 0.0963\n",
      "Epoch 1451/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.0992\n",
      "Epoch 1452/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0192 - mae: 0.0995\n",
      "Epoch 1453/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0181 - mae: 0.0962\n",
      "Epoch 1454/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0187 - mae: 0.0970\n",
      "Epoch 1455/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0196 - mae: 0.1011\n",
      "Epoch 1456/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0181 - mae: 0.0962\n",
      "Epoch 1457/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0192 - mae: 0.1000\n",
      "Epoch 1458/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0189 - mae: 0.0987\n",
      "Epoch 1459/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0186 - mae: 0.0980\n",
      "Epoch 1460/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0184 - mae: 0.0977\n",
      "Epoch 1461/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0192 - mae: 0.1005\n",
      "Epoch 1462/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0193 - mae: 0.1011\n",
      "Epoch 1463/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0189 - mae: 0.0995\n",
      "Epoch 1464/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0200 - mae: 0.1031\n",
      "Epoch 1465/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0177 - mae: 0.0953\n",
      "Epoch 1466/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0189 - mae: 0.0998\n",
      "Epoch 1467/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0173 - mae: 0.0940\n",
      "Epoch 1468/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0178 - mae: 0.0963\n",
      "Epoch 1469/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0176 - mae: 0.0952\n",
      "Epoch 1470/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0171 - mae: 0.0943\n",
      "Epoch 1471/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0177 - mae: 0.0960\n",
      "Epoch 1472/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0183 - mae: 0.0980\n",
      "Epoch 1473/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0175 - mae: 0.0952\n",
      "Epoch 1474/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0177 - mae: 0.0954\n",
      "Epoch 1475/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0173 - mae: 0.0933\n",
      "Epoch 1476/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0179 - mae: 0.0968\n",
      "Epoch 1477/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0168 - mae: 0.0925\n",
      "Epoch 1478/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0269 - mae: 0.1213\n",
      "Epoch 1479/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0187 - mae: 0.0996\n",
      "Epoch 1480/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0173 - mae: 0.0946\n",
      "Epoch 1481/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0171 - mae: 0.0936\n",
      "Epoch 1482/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0174 - mae: 0.0946\n",
      "Epoch 1483/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0173 - mae: 0.0943\n",
      "Epoch 1484/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0932\n",
      "Epoch 1485/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0926\n",
      "Epoch 1486/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0930\n",
      "Epoch 1487/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0928\n",
      "Epoch 1488/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0165 - mae: 0.0917\n",
      "Epoch 1489/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0167 - mae: 0.0928\n",
      "Epoch 1490/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0169 - mae: 0.0933\n",
      "Epoch 1491/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0165 - mae: 0.0920\n",
      "Epoch 1492/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0173 - mae: 0.0945\n",
      "Epoch 1493/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0164 - mae: 0.0908\n",
      "Epoch 1494/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0165 - mae: 0.0914\n",
      "Epoch 1495/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0163 - mae: 0.0905\n",
      "Epoch 1496/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0163 - mae: 0.0917\n",
      "Epoch 1497/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0160 - mae: 0.0902\n",
      "Epoch 1498/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0163 - mae: 0.0911\n",
      "Epoch 1499/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0170 - mae: 0.0936\n",
      "Epoch 1500/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0170 - mae: 0.0944\n",
      "Epoch 1501/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0164 - mae: 0.0910\n",
      "Epoch 1502/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0164 - mae: 0.0913\n",
      "Epoch 1503/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0169 - mae: 0.0938\n",
      "Epoch 1504/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0162 - mae: 0.0905\n",
      "Epoch 1505/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0167 - mae: 0.0927\n",
      "Epoch 1506/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0164 - mae: 0.0914\n",
      "Epoch 1507/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0168 - mae: 0.0938\n",
      "Epoch 1508/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0183 - mae: 0.0974\n",
      "Epoch 1509/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0166 - mae: 0.0915\n",
      "Epoch 1510/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0192 - mae: 0.0998\n",
      "Epoch 1511/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0178 - mae: 0.0966\n",
      "Epoch 1512/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0171 - mae: 0.0933\n",
      "Epoch 1513/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0168 - mae: 0.0924\n",
      "Epoch 1514/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0175 - mae: 0.0949\n",
      "Epoch 1515/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0926\n",
      "Epoch 1516/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0173 - mae: 0.0947\n",
      "Epoch 1517/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0164 - mae: 0.0915\n",
      "Epoch 1518/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0162 - mae: 0.0909\n",
      "Epoch 1519/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0177 - mae: 0.0957\n",
      "Epoch 1520/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0166 - mae: 0.0923\n",
      "Epoch 1521/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0172 - mae: 0.0940\n",
      "Epoch 1522/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0165 - mae: 0.0916\n",
      "Epoch 1523/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0165 - mae: 0.0919\n",
      "Epoch 1524/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0164 - mae: 0.0916\n",
      "Epoch 1525/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0157 - mae: 0.0889\n",
      "Epoch 1526/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0164 - mae: 0.0915\n",
      "Epoch 1527/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0172 - mae: 0.0952\n",
      "Epoch 1528/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0155 - mae: 0.0888\n",
      "Epoch 1529/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0159 - mae: 0.0896\n",
      "Epoch 1530/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0157 - mae: 0.0894\n",
      "Epoch 1531/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0166 - mae: 0.0924\n",
      "Epoch 1532/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0156 - mae: 0.0894\n",
      "Epoch 1533/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0163 - mae: 0.0916\n",
      "Epoch 1534/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0162 - mae: 0.0911\n",
      "Epoch 1535/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0160 - mae: 0.0907\n",
      "Epoch 1536/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0181 - mae: 0.0973\n",
      "Epoch 1537/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0164 - mae: 0.0908\n",
      "Epoch 1538/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0159 - mae: 0.0898\n",
      "Epoch 1539/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0161 - mae: 0.0903\n",
      "Epoch 1540/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0168 - mae: 0.0936\n",
      "Epoch 1541/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0170 - mae: 0.0933\n",
      "Epoch 1542/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0172 - mae: 0.0935\n",
      "Epoch 1543/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0166 - mae: 0.0924\n",
      "Epoch 1544/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0169 - mae: 0.0935\n",
      "Epoch 1545/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0161 - mae: 0.0909\n",
      "Epoch 1546/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0173 - mae: 0.0959\n",
      "Epoch 1547/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0185 - mae: 0.0996\n",
      "Epoch 1548/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0169 - mae: 0.0945\n",
      "Epoch 1549/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0173 - mae: 0.0952\n",
      "Epoch 1550/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0177 - mae: 0.0966\n",
      "Epoch 1551/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0165 - mae: 0.0928\n",
      "Epoch 1552/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0162 - mae: 0.0913\n",
      "Epoch 1553/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0175 - mae: 0.0954\n",
      "Epoch 1554/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0168 - mae: 0.0923\n",
      "Epoch 1555/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0173 - mae: 0.0948\n",
      "Epoch 1556/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0170 - mae: 0.0937\n",
      "Epoch 1557/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0167 - mae: 0.0924\n",
      "Epoch 1558/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0209 - mae: 0.1041\n",
      "Epoch 1559/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0226 - mae: 0.1092\n",
      "Epoch 1560/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0206 - mae: 0.1038\n",
      "Epoch 1561/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0190 - mae: 0.0990\n",
      "Epoch 1562/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0189 - mae: 0.0991\n",
      "Epoch 1563/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0179 - mae: 0.0954\n",
      "Epoch 1564/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0182 - mae: 0.0972\n",
      "Epoch 1565/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0183 - mae: 0.0969\n",
      "Epoch 1566/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0169 - mae: 0.0928\n",
      "Epoch 1567/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0169 - mae: 0.0929\n",
      "Epoch 1568/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0170 - mae: 0.0934\n",
      "Epoch 1569/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0172 - mae: 0.0935\n",
      "Epoch 1570/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0185 - mae: 0.0973\n",
      "Epoch 1571/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0919\n",
      "Epoch 1572/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0169 - mae: 0.0921\n",
      "Epoch 1573/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0164 - mae: 0.0909\n",
      "Epoch 1574/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0168 - mae: 0.0917\n",
      "Epoch 1575/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0165 - mae: 0.0913\n",
      "Epoch 1576/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0174 - mae: 0.0943\n",
      "Epoch 1577/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0168 - mae: 0.0920\n",
      "Epoch 1578/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0162 - mae: 0.0902\n",
      "Epoch 1579/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0165 - mae: 0.0912\n",
      "Epoch 1580/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0908\n",
      "Epoch 1581/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0217 - mae: 0.1087\n",
      "Epoch 1582/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0195 - mae: 0.1011\n",
      "Epoch 1583/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0193 - mae: 0.1015\n",
      "Epoch 1584/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0178 - mae: 0.0965\n",
      "Epoch 1585/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0185 - mae: 0.0985\n",
      "Epoch 1586/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0182 - mae: 0.0976\n",
      "Epoch 1587/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0185 - mae: 0.0985\n",
      "Epoch 1588/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0172 - mae: 0.0946\n",
      "Epoch 1589/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0173 - mae: 0.0943\n",
      "Epoch 1590/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0170 - mae: 0.0941\n",
      "Epoch 1591/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0186 - mae: 0.0992\n",
      "Epoch 1592/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0192 - mae: 0.1008\n",
      "Epoch 1593/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0171 - mae: 0.0941\n",
      "Epoch 1594/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0189 - mae: 0.0999\n",
      "Epoch 1595/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0950\n",
      "Epoch 1596/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0173 - mae: 0.0940\n",
      "Epoch 1597/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0168 - mae: 0.0925\n",
      "Epoch 1598/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0169 - mae: 0.0934\n",
      "Epoch 1599/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0177 - mae: 0.0959\n",
      "Epoch 1600/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0954\n",
      "Epoch 1601/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0170 - mae: 0.0934\n",
      "Epoch 1602/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0173 - mae: 0.0941\n",
      "Epoch 1603/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0166 - mae: 0.0921\n",
      "Epoch 1604/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0170 - mae: 0.0939\n",
      "Epoch 1605/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0163 - mae: 0.0913\n",
      "Epoch 1606/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0169 - mae: 0.0920\n",
      "Epoch 1607/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0164 - mae: 0.0913\n",
      "Epoch 1608/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0163 - mae: 0.0910\n",
      "Epoch 1609/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0167 - mae: 0.0927\n",
      "Epoch 1610/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0162 - mae: 0.0909\n",
      "Epoch 1611/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0165 - mae: 0.0920\n",
      "Epoch 1612/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0168 - mae: 0.0932\n",
      "Epoch 1613/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0164 - mae: 0.0917\n",
      "Epoch 1614/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0168 - mae: 0.0927\n",
      "Epoch 1615/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0171 - mae: 0.0933\n",
      "Epoch 1616/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0165 - mae: 0.0923\n",
      "Epoch 1617/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0168 - mae: 0.0929\n",
      "Epoch 1618/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0172 - mae: 0.0933\n",
      "Epoch 1619/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0166 - mae: 0.0922\n",
      "Epoch 1620/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0175 - mae: 0.0953\n",
      "Epoch 1621/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0163 - mae: 0.0914\n",
      "Epoch 1622/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0178 - mae: 0.0961\n",
      "Epoch 1623/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0164 - mae: 0.0921\n",
      "Epoch 1624/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0170 - mae: 0.0940\n",
      "Epoch 1625/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0165 - mae: 0.0926\n",
      "Epoch 1626/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0956\n",
      "Epoch 1627/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0174 - mae: 0.0953\n",
      "Epoch 1628/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0179 - mae: 0.0966\n",
      "Epoch 1629/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0165 - mae: 0.0921\n",
      "Epoch 1630/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0210 - mae: 0.1066\n",
      "Epoch 1631/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0165 - mae: 0.0924\n",
      "Epoch 1632/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0165 - mae: 0.0921\n",
      "Epoch 1633/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0170 - mae: 0.0930\n",
      "Epoch 1634/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0162 - mae: 0.0909\n",
      "Epoch 1635/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0170 - mae: 0.0946\n",
      "Epoch 1636/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0171 - mae: 0.0934\n",
      "Epoch 1637/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0164 - mae: 0.0919\n",
      "Epoch 1638/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0163 - mae: 0.0920\n",
      "Epoch 1639/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0177 - mae: 0.0950\n",
      "Epoch 1640/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0173 - mae: 0.0943\n",
      "Epoch 1641/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0173 - mae: 0.0948\n",
      "Epoch 1642/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0183 - mae: 0.0969\n",
      "Epoch 1643/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0174 - mae: 0.0943\n",
      "Epoch 1644/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0163 - mae: 0.0916\n",
      "Epoch 1645/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0927\n",
      "Epoch 1646/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0173 - mae: 0.0957\n",
      "Epoch 1647/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0164 - mae: 0.0927\n",
      "Epoch 1648/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0927\n",
      "Epoch 1649/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0159 - mae: 0.0905\n",
      "Epoch 1650/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0162 - mae: 0.0923\n",
      "Epoch 1651/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0166 - mae: 0.0927\n",
      "Epoch 1652/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0161 - mae: 0.0908\n",
      "Epoch 1653/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0168 - mae: 0.0941\n",
      "Epoch 1654/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0172 - mae: 0.0945\n",
      "Epoch 1655/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0173 - mae: 0.0952\n",
      "Epoch 1656/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0159 - mae: 0.0904\n",
      "Epoch 1657/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0162 - mae: 0.0912\n",
      "Epoch 1658/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0171 - mae: 0.0948\n",
      "Epoch 1659/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0174 - mae: 0.0938\n",
      "Epoch 1660/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0165 - mae: 0.0921\n",
      "Epoch 1661/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0180 - mae: 0.0976\n",
      "Epoch 1662/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0166 - mae: 0.0920\n",
      "Epoch 1663/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0164 - mae: 0.0924\n",
      "Epoch 1664/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0168 - mae: 0.0939\n",
      "Epoch 1665/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0166 - mae: 0.0928\n",
      "Epoch 1666/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0161 - mae: 0.0910\n",
      "Epoch 1667/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0170 - mae: 0.0944\n",
      "Epoch 1668/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0167 - mae: 0.0933\n",
      "Epoch 1669/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0166 - mae: 0.0926\n",
      "Epoch 1670/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0161 - mae: 0.0910\n",
      "Epoch 1671/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0161 - mae: 0.0908\n",
      "Epoch 1672/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0165 - mae: 0.0926\n",
      "Epoch 1673/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0160 - mae: 0.0906\n",
      "Epoch 1674/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0166 - mae: 0.0920\n",
      "Epoch 1675/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0172 - mae: 0.0950\n",
      "Epoch 1676/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0161 - mae: 0.0919\n",
      "Epoch 1677/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0161 - mae: 0.0908\n",
      "Epoch 1678/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0166 - mae: 0.0925\n",
      "Epoch 1679/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0962\n",
      "Epoch 1680/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0165 - mae: 0.0929\n",
      "Epoch 1681/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0165 - mae: 0.0931\n",
      "Epoch 1682/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0179 - mae: 0.0975\n",
      "Epoch 1683/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0172 - mae: 0.0941\n",
      "Epoch 1684/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0167 - mae: 0.0937\n",
      "Epoch 1685/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0170 - mae: 0.0945\n",
      "Epoch 1686/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0163 - mae: 0.0917\n",
      "Epoch 1687/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0164 - mae: 0.0928\n",
      "Epoch 1688/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0174 - mae: 0.0952\n",
      "Epoch 1689/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0163 - mae: 0.0917\n",
      "Epoch 1690/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0165 - mae: 0.0922\n",
      "Epoch 1691/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0163 - mae: 0.0921\n",
      "Epoch 1692/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0163 - mae: 0.0921\n",
      "Epoch 1693/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0171 - mae: 0.0950\n",
      "Epoch 1694/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0203 - mae: 0.1005\n",
      "Epoch 1695/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0179 - mae: 0.0975\n",
      "Epoch 1696/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0182 - mae: 0.0980\n",
      "Epoch 1697/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0169 - mae: 0.0946\n",
      "Epoch 1698/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0167 - mae: 0.0943\n",
      "Epoch 1699/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0163 - mae: 0.0924\n",
      "Epoch 1700/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0166 - mae: 0.0935\n",
      "Epoch 1701/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0163 - mae: 0.0928\n",
      "Epoch 1702/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0161 - mae: 0.0913\n",
      "Epoch 1703/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0938\n",
      "Epoch 1704/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0170 - mae: 0.0947\n",
      "Epoch 1705/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0162 - mae: 0.0919\n",
      "Epoch 1706/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0159 - mae: 0.0904\n",
      "Epoch 1707/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0163 - mae: 0.0926\n",
      "Epoch 1708/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0166 - mae: 0.0934\n",
      "Epoch 1709/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0161 - mae: 0.0916\n",
      "Epoch 1710/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0162 - mae: 0.0917\n",
      "Epoch 1711/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0162 - mae: 0.0918\n",
      "Epoch 1712/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0166 - mae: 0.0926\n",
      "Epoch 1713/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0158 - mae: 0.0903\n",
      "Epoch 1714/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0161 - mae: 0.0911\n",
      "Epoch 1715/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0172 - mae: 0.0947\n",
      "Epoch 1716/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0164 - mae: 0.0918\n",
      "Epoch 1717/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0156 - mae: 0.0904\n",
      "Epoch 1718/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0170 - mae: 0.0951\n",
      "Epoch 1719/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0166 - mae: 0.0940\n",
      "Epoch 1720/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0165 - mae: 0.0930\n",
      "Epoch 1721/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0160 - mae: 0.0909\n",
      "Epoch 1722/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0157 - mae: 0.0901\n",
      "Epoch 1723/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0169 - mae: 0.0931\n",
      "Epoch 1724/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0164 - mae: 0.0923\n",
      "Epoch 1725/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0173 - mae: 0.0956\n",
      "Epoch 1726/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0163 - mae: 0.0927\n",
      "Epoch 1727/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0177 - mae: 0.0965\n",
      "Epoch 1728/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0167 - mae: 0.0938\n",
      "Epoch 1729/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0160 - mae: 0.0911\n",
      "Epoch 1730/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0164 - mae: 0.0921\n",
      "Epoch 1731/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0168 - mae: 0.0932\n",
      "Epoch 1732/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0160 - mae: 0.0903\n",
      "Epoch 1733/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0160 - mae: 0.0904\n",
      "Epoch 1734/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0161 - mae: 0.0917\n",
      "Epoch 1735/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0161 - mae: 0.0911\n",
      "Epoch 1736/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0164 - mae: 0.0927\n",
      "Epoch 1737/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0169 - mae: 0.0936\n",
      "Epoch 1738/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0169 - mae: 0.0943\n",
      "Epoch 1739/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0162 - mae: 0.0915\n",
      "Epoch 1740/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0166 - mae: 0.0931\n",
      "Epoch 1741/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0157 - mae: 0.0904\n",
      "Epoch 1742/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0174 - mae: 0.0954\n",
      "Epoch 1743/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0161 - mae: 0.0914\n",
      "Epoch 1744/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0161 - mae: 0.0915\n",
      "Epoch 1745/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0161 - mae: 0.0909\n",
      "Epoch 1746/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0162 - mae: 0.0923\n",
      "Epoch 1747/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0158 - mae: 0.0917\n",
      "Epoch 1748/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0161 - mae: 0.0913\n",
      "Epoch 1749/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0161 - mae: 0.0920\n",
      "Epoch 1750/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0170 - mae: 0.0950\n",
      "Epoch 1751/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0165 - mae: 0.0918\n",
      "Epoch 1752/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0165 - mae: 0.0929\n",
      "Epoch 1753/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0161 - mae: 0.0921\n",
      "Epoch 1754/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0161 - mae: 0.0912\n",
      "Epoch 1755/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0158 - mae: 0.0905\n",
      "Epoch 1756/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0162 - mae: 0.0928\n",
      "Epoch 1757/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0157 - mae: 0.0899\n",
      "Epoch 1758/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0159 - mae: 0.0906\n",
      "Epoch 1759/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0161 - mae: 0.0920\n",
      "Epoch 1760/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0957\n",
      "Epoch 1761/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0179 - mae: 0.0978\n",
      "Epoch 1762/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0157 - mae: 0.0908\n",
      "Epoch 1763/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0160 - mae: 0.0917\n",
      "Epoch 1764/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0160 - mae: 0.0910\n",
      "Epoch 1765/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0185 - mae: 0.0988\n",
      "Epoch 1766/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0158 - mae: 0.0910\n",
      "Epoch 1767/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0158 - mae: 0.0909\n",
      "Epoch 1768/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0169 - mae: 0.0939\n",
      "Epoch 1769/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0164 - mae: 0.0921\n",
      "Epoch 1770/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0163 - mae: 0.0925\n",
      "Epoch 1771/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0158 - mae: 0.0907\n",
      "Epoch 1772/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0155 - mae: 0.0896\n",
      "Epoch 1773/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0163 - mae: 0.0927\n",
      "Epoch 1774/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0169 - mae: 0.0944\n",
      "Epoch 1775/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0161 - mae: 0.0914\n",
      "Epoch 1776/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0157 - mae: 0.0905\n",
      "Epoch 1777/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0157 - mae: 0.0908\n",
      "Epoch 1778/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0162 - mae: 0.0930\n",
      "Epoch 1779/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0158 - mae: 0.0905\n",
      "Epoch 1780/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0172 - mae: 0.0961\n",
      "Epoch 1781/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0163 - mae: 0.0922\n",
      "Epoch 1782/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0157 - mae: 0.0898\n",
      "Epoch 1783/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0167 - mae: 0.0942\n",
      "Epoch 1784/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0169 - mae: 0.0930\n",
      "Epoch 1785/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0167 - mae: 0.0933\n",
      "Epoch 1786/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0158 - mae: 0.0904\n",
      "Epoch 1787/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0186 - mae: 0.1005\n",
      "Epoch 1788/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0159 - mae: 0.0908\n",
      "Epoch 1789/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0169 - mae: 0.0949\n",
      "Epoch 1790/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0168 - mae: 0.0946\n",
      "Epoch 1791/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0156 - mae: 0.0897\n",
      "Epoch 1792/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0158 - mae: 0.0899\n",
      "Epoch 1793/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0163 - mae: 0.0919\n",
      "Epoch 1794/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0162 - mae: 0.0926\n",
      "Epoch 1795/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0168 - mae: 0.0933\n",
      "Epoch 1796/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0160 - mae: 0.0906\n",
      "Epoch 1797/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0172 - mae: 0.0959\n",
      "Epoch 1798/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0166 - mae: 0.0932\n",
      "Epoch 1799/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0161 - mae: 0.0919\n",
      "Epoch 1800/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0159 - mae: 0.0907\n",
      "Epoch 1801/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0192 - mae: 0.0976\n",
      "Epoch 1802/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0179 - mae: 0.0982\n",
      "Epoch 1803/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0173 - mae: 0.0955\n",
      "Epoch 1804/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0965\n",
      "Epoch 1805/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0955\n",
      "Epoch 1806/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0165 - mae: 0.0920\n",
      "Epoch 1807/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0167 - mae: 0.0935\n",
      "Epoch 1808/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0169 - mae: 0.0936\n",
      "Epoch 1809/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0169 - mae: 0.0933\n",
      "Epoch 1810/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0169 - mae: 0.0938\n",
      "Epoch 1811/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0164 - mae: 0.0921\n",
      "Epoch 1812/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0164 - mae: 0.0923\n",
      "Epoch 1813/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0968\n",
      "Epoch 1814/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0159 - mae: 0.0893\n",
      "Epoch 1815/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0159 - mae: 0.0907\n",
      "Epoch 1816/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0164 - mae: 0.0921\n",
      "Epoch 1817/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0164 - mae: 0.0928\n",
      "Epoch 1818/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0164 - mae: 0.0925\n",
      "Epoch 1819/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0159 - mae: 0.0902\n",
      "Epoch 1820/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0163 - mae: 0.0917\n",
      "Epoch 1821/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0166 - mae: 0.0925\n",
      "Epoch 1822/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0163 - mae: 0.0917\n",
      "Epoch 1823/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0168 - mae: 0.0927\n",
      "Epoch 1824/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0165 - mae: 0.0929\n",
      "Epoch 1825/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0162 - mae: 0.0915\n",
      "Epoch 1826/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0161 - mae: 0.0913\n",
      "Epoch 1827/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0157 - mae: 0.0897\n",
      "Epoch 1828/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0169 - mae: 0.0938\n",
      "Epoch 1829/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0165 - mae: 0.0924\n",
      "Epoch 1830/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0168 - mae: 0.0926\n",
      "Epoch 1831/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0167 - mae: 0.0933\n",
      "Epoch 1832/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0163 - mae: 0.0919\n",
      "Epoch 1833/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0156 - mae: 0.0894\n",
      "Epoch 1834/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0158 - mae: 0.0908\n",
      "Epoch 1835/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0164 - mae: 0.0925\n",
      "Epoch 1836/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0176 - mae: 0.0967\n",
      "Epoch 1837/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0159 - mae: 0.0894\n",
      "Epoch 1838/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0169 - mae: 0.0942\n",
      "Epoch 1839/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0161 - mae: 0.0908\n",
      "Epoch 1840/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0162 - mae: 0.0914\n",
      "Epoch 1841/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0159 - mae: 0.0910\n",
      "Epoch 1842/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0160 - mae: 0.0915\n",
      "Epoch 1843/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0166 - mae: 0.0933\n",
      "Epoch 1844/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0164 - mae: 0.0924\n",
      "Epoch 1845/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0161 - mae: 0.0918\n",
      "Epoch 1846/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0177 - mae: 0.0959\n",
      "Epoch 1847/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0167 - mae: 0.0933\n",
      "Epoch 1848/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0166 - mae: 0.0928\n",
      "Epoch 1849/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0157 - mae: 0.0905\n",
      "Epoch 1850/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0161 - mae: 0.0913\n",
      "Epoch 1851/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0160 - mae: 0.0906\n",
      "Epoch 1852/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0162 - mae: 0.0923\n",
      "Epoch 1853/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0159 - mae: 0.0910\n",
      "Epoch 1854/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0162 - mae: 0.0918\n",
      "Epoch 1855/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0158 - mae: 0.0909\n",
      "Epoch 1856/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0162 - mae: 0.0917\n",
      "Epoch 1857/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0171 - mae: 0.0943\n",
      "Epoch 1858/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0166 - mae: 0.0935\n",
      "Epoch 1859/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0157 - mae: 0.0895\n",
      "Epoch 1860/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0159 - mae: 0.0910\n",
      "Epoch 1861/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0159 - mae: 0.0906\n",
      "Epoch 1862/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0165 - mae: 0.0937\n",
      "Epoch 1863/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0162 - mae: 0.0919\n",
      "Epoch 1864/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0162 - mae: 0.0916\n",
      "Epoch 1865/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0179 - mae: 0.0984\n",
      "Epoch 1866/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0157 - mae: 0.0906\n",
      "Epoch 1867/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0157 - mae: 0.0907\n",
      "Epoch 1868/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0161 - mae: 0.0918\n",
      "Epoch 1869/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0158 - mae: 0.0916\n",
      "Epoch 1870/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0175 - mae: 0.0956\n",
      "Epoch 1871/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0166 - mae: 0.0933\n",
      "Epoch 1872/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0166 - mae: 0.0924\n",
      "Epoch 1873/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0160 - mae: 0.0915\n",
      "Epoch 1874/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0159 - mae: 0.0905\n",
      "Epoch 1875/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0155 - mae: 0.0905\n",
      "Epoch 1876/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0157 - mae: 0.0905\n",
      "Epoch 1877/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0155 - mae: 0.0898\n",
      "Epoch 1878/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0161 - mae: 0.0914\n",
      "Epoch 1879/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0155 - mae: 0.0896\n",
      "Epoch 1880/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0150 - mae: 0.0887\n",
      "Epoch 1881/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0158 - mae: 0.0904\n",
      "Epoch 1882/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0155 - mae: 0.0900\n",
      "Epoch 1883/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0160 - mae: 0.0919\n",
      "Epoch 1884/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0168 - mae: 0.0939\n",
      "Epoch 1885/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0954\n",
      "Epoch 1886/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0159 - mae: 0.0907\n",
      "Epoch 1887/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0158 - mae: 0.0913\n",
      "Epoch 1888/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0156 - mae: 0.0904\n",
      "Epoch 1889/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0165 - mae: 0.0935\n",
      "Epoch 1890/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0163 - mae: 0.0932\n",
      "Epoch 1891/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0186 - mae: 0.1002\n",
      "Epoch 1892/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0161 - mae: 0.0913\n",
      "Epoch 1893/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0161 - mae: 0.0922\n",
      "Epoch 1894/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0159 - mae: 0.0914\n",
      "Epoch 1895/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0161 - mae: 0.0918\n",
      "Epoch 1896/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0152 - mae: 0.0892\n",
      "Epoch 1897/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0163 - mae: 0.0935\n",
      "Epoch 1898/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0153 - mae: 0.0899\n",
      "Epoch 1899/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0163 - mae: 0.0932\n",
      "Epoch 1900/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0159 - mae: 0.0911\n",
      "Epoch 1901/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0159 - mae: 0.0909\n",
      "Epoch 1902/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0159 - mae: 0.0922\n",
      "Epoch 1903/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0160 - mae: 0.0918\n",
      "Epoch 1904/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0154 - mae: 0.0898\n",
      "Epoch 1905/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0155 - mae: 0.0895\n",
      "Epoch 1906/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0157 - mae: 0.0902\n",
      "Epoch 1907/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0154 - mae: 0.0894\n",
      "Epoch 1908/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0156 - mae: 0.0902\n",
      "Epoch 1909/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0159 - mae: 0.0916\n",
      "Epoch 1910/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0159 - mae: 0.0917\n",
      "Epoch 1911/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0157 - mae: 0.0909\n",
      "Epoch 1912/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0162 - mae: 0.0919\n",
      "Epoch 1913/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0161 - mae: 0.0921\n",
      "Epoch 1914/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0172 - mae: 0.0955\n",
      "Epoch 1915/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0156 - mae: 0.0901\n",
      "Epoch 1916/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0165 - mae: 0.0938\n",
      "Epoch 1917/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0156 - mae: 0.0902\n",
      "Epoch 1918/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0162 - mae: 0.0927\n",
      "Epoch 1919/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0164 - mae: 0.0924\n",
      "Epoch 1920/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0154 - mae: 0.0896\n",
      "Epoch 1921/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0157 - mae: 0.0902\n",
      "Epoch 1922/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0165 - mae: 0.0935\n",
      "Epoch 1923/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0158 - mae: 0.0913\n",
      "Epoch 1924/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0162 - mae: 0.0915\n",
      "Epoch 1925/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0165 - mae: 0.0929\n",
      "Epoch 1926/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0161 - mae: 0.0929\n",
      "Epoch 1927/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0159 - mae: 0.0909\n",
      "Epoch 1928/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0154 - mae: 0.0889\n",
      "Epoch 1929/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0160 - mae: 0.0917\n",
      "Epoch 1930/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0161 - mae: 0.0922\n",
      "Epoch 1931/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0159 - mae: 0.0909\n",
      "Epoch 1932/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0157 - mae: 0.0914\n",
      "Epoch 1933/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0154 - mae: 0.0895\n",
      "Epoch 1934/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0161 - mae: 0.0920\n",
      "Epoch 1935/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0162 - mae: 0.0926\n",
      "Epoch 1936/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0162 - mae: 0.0922\n",
      "Epoch 1937/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0164 - mae: 0.0929\n",
      "Epoch 1938/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0169 - mae: 0.0942\n",
      "Epoch 1939/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0173 - mae: 0.0963\n",
      "Epoch 1940/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0163 - mae: 0.0923\n",
      "Epoch 1941/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0172 - mae: 0.0958\n",
      "Epoch 1942/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0158 - mae: 0.0908\n",
      "Epoch 1943/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0161 - mae: 0.0919\n",
      "Epoch 1944/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0158 - mae: 0.0916\n",
      "Epoch 1945/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0157 - mae: 0.0909\n",
      "Epoch 1946/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0156 - mae: 0.0896\n",
      "Epoch 1947/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0155 - mae: 0.0898\n",
      "Epoch 1948/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0161 - mae: 0.0923\n",
      "Epoch 1949/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0154 - mae: 0.0890\n",
      "Epoch 1950/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0160 - mae: 0.0911\n",
      "Epoch 1951/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0150 - mae: 0.0886\n",
      "Epoch 1952/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0167 - mae: 0.0941\n",
      "Epoch 1953/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0170 - mae: 0.0949\n",
      "Epoch 1954/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0156 - mae: 0.0902\n",
      "Epoch 1955/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0159 - mae: 0.0917\n",
      "Epoch 1956/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0167 - mae: 0.0943\n",
      "Epoch 1957/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0151 - mae: 0.0888\n",
      "Epoch 1958/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0158 - mae: 0.0909\n",
      "Epoch 1959/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0157 - mae: 0.0910\n",
      "Epoch 1960/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0161 - mae: 0.0927\n",
      "Epoch 1961/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0162 - mae: 0.0915\n",
      "Epoch 1962/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0156 - mae: 0.0904\n",
      "Epoch 1963/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0163 - mae: 0.0937\n",
      "Epoch 1964/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0160 - mae: 0.0916\n",
      "Epoch 1965/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0168 - mae: 0.0955\n",
      "Epoch 1966/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0164 - mae: 0.0931\n",
      "Epoch 1967/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0160 - mae: 0.0909\n",
      "Epoch 1968/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0164 - mae: 0.0928\n",
      "Epoch 1969/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0159 - mae: 0.0916\n",
      "Epoch 1970/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0160 - mae: 0.0916\n",
      "Epoch 1971/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0169 - mae: 0.0943\n",
      "Epoch 1972/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0157 - mae: 0.0906\n",
      "Epoch 1973/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0168 - mae: 0.0948\n",
      "Epoch 1974/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0159 - mae: 0.0917\n",
      "Epoch 1975/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0158 - mae: 0.0908\n",
      "Epoch 1976/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0160 - mae: 0.0918\n",
      "Epoch 1977/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0187 - mae: 0.1005\n",
      "Epoch 1978/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0190 - mae: 0.1022\n",
      "Epoch 1979/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0168 - mae: 0.0945\n",
      "Epoch 1980/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0160 - mae: 0.0916\n",
      "Epoch 1981/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0155 - mae: 0.0902\n",
      "Epoch 1982/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0167 - mae: 0.0944\n",
      "Epoch 1983/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0162 - mae: 0.0921\n",
      "Epoch 1984/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0160 - mae: 0.0920\n",
      "Epoch 1985/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0159 - mae: 0.0923\n",
      "Epoch 1986/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0158 - mae: 0.0914\n",
      "Epoch 1987/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0164 - mae: 0.0917\n",
      "Epoch 1988/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0163 - mae: 0.0926\n",
      "Epoch 1989/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0154 - mae: 0.0895\n",
      "Epoch 1990/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0158 - mae: 0.0908\n",
      "Epoch 1991/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0168 - mae: 0.0941\n",
      "Epoch 1992/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0167 - mae: 0.0950\n",
      "Epoch 1993/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0169 - mae: 0.0949\n",
      "Epoch 1994/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0158 - mae: 0.0911\n",
      "Epoch 1995/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0165 - mae: 0.0936\n",
      "Epoch 1996/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0158 - mae: 0.0906\n",
      "Epoch 1997/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0165 - mae: 0.0931\n",
      "Epoch 1998/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0154 - mae: 0.0896\n",
      "Epoch 1999/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0152 - mae: 0.0886\n",
      "Epoch 2000/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0158 - mae: 0.0908\n",
      "mae: 0.12848636507987976\n",
      "Overfit mae: 0.08845841884613037\n",
      "Train on 2019 samples\n",
      "Epoch 1/2000\n",
      "2019/2019 [==============================] - 1s 555us/sample - loss: 47473.0331 - mae: 39.2481\n",
      "Epoch 2/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 15881.8216 - mae: 28.3833\n",
      "Epoch 3/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 74646.0508 - mae: 48.8372\n",
      "Epoch 4/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 3363.1550 - mae: 14.7214\n",
      "Epoch 5/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 3938.1119 - mae: 14.9851\n",
      "Epoch 6/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2097.1888 - mae: 11.2190\n",
      "Epoch 7/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 2224.8965 - mae: 11.5303\n",
      "Epoch 8/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 1931.9857 - mae: 10.7260\n",
      "Epoch 9/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 1817.0105 - mae: 9.1911\n",
      "Epoch 10/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 5935.6916 - mae: 16.1959\n",
      "Epoch 11/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 6156.8063 - mae: 15.8717\n",
      "Epoch 12/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 8862.4061 - mae: 20.2239\n",
      "Epoch 13/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 2446.6678 - mae: 11.9439\n",
      "Epoch 14/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 2529.3921 - mae: 8.9978\n",
      "Epoch 15/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 1037.4366 - mae: 8.0177\n",
      "Epoch 16/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 2020.6125 - mae: 8.9855\n",
      "Epoch 17/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 1869.5122 - mae: 9.9738\n",
      "Epoch 18/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 655.0447 - mae: 5.4621\n",
      "Epoch 19/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 252.0460 - mae: 4.1431\n",
      "Epoch 20/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 385.5334 - mae: 5.8373\n",
      "Epoch 21/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 2639.0418 - mae: 11.0533\n",
      "Epoch 22/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 2397.0768 - mae: 9.9180\n",
      "Epoch 23/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 4425.7509 - mae: 9.1665\n",
      "Epoch 24/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 6362.3475 - mae: 17.3251\n",
      "Epoch 25/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1393.9175 - mae: 6.0472\n",
      "Epoch 26/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 17930.6161 - mae: 25.2307\n",
      "Epoch 27/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 11529.9865 - mae: 23.2853\n",
      "Epoch 28/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1040.7047 - mae: 10.7033\n",
      "Epoch 29/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 287.9887 - mae: 5.9173\n",
      "Epoch 30/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 178.0081 - mae: 4.7314\n",
      "Epoch 31/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 120.6061 - mae: 3.7927\n",
      "Epoch 32/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 533.6992 - mae: 6.4549\n",
      "Epoch 33/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 160.7149 - mae: 4.2641\n",
      "Epoch 34/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 2143.0685 - mae: 10.2854\n",
      "Epoch 35/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 3861.8251 - mae: 11.4480\n",
      "Epoch 36/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 466.0464 - mae: 6.3267\n",
      "Epoch 37/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 501.6151 - mae: 4.7595\n",
      "Epoch 38/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 892.5432 - mae: 6.0757\n",
      "Epoch 39/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 171.2358 - mae: 3.7616\n",
      "Epoch 40/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 407.8768 - mae: 4.3805\n",
      "Epoch 41/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 789.7463 - mae: 6.3169\n",
      "Epoch 42/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 250.0312 - mae: 4.1415\n",
      "Epoch 43/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 190.1055 - mae: 3.5210\n",
      "Epoch 44/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 3791.5876 - mae: 11.2427\n",
      "Epoch 45/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 3408.0591 - mae: 11.3839\n",
      "Epoch 46/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 7881.5361 - mae: 14.9001\n",
      "Epoch 47/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 6478.2291 - mae: 10.6955\n",
      "Epoch 48/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 5304.7892 - mae: 16.4002\n",
      "Epoch 49/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 2796.2098 - mae: 12.2002\n",
      "Epoch 50/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 548.1694 - mae: 8.3736\n",
      "Epoch 51/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 327.0858 - mae: 5.4630\n",
      "Epoch 52/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 76us/sample - loss: 126.5154 - mae: 5.2190\n",
      "Epoch 53/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 265.8907 - mae: 4.5535\n",
      "Epoch 54/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 363.3645 - mae: 4.5835\n",
      "Epoch 55/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 77.7903 - mae: 3.7178\n",
      "Epoch 56/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 64.6586 - mae: 3.4301\n",
      "Epoch 57/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 224.0245 - mae: 3.6847\n",
      "Epoch 58/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 103.1401 - mae: 3.3576\n",
      "Epoch 59/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 60.1013 - mae: 3.0875\n",
      "Epoch 60/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 102.2600 - mae: 3.2315\n",
      "Epoch 61/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 69.5695 - mae: 3.1381\n",
      "Epoch 62/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 75.7811 - mae: 3.0348\n",
      "Epoch 63/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 160.2041 - mae: 3.3461\n",
      "Epoch 64/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 37.7955 - mae: 2.5621\n",
      "Epoch 65/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 91.5559 - mae: 2.7172\n",
      "Epoch 66/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 42.3644 - mae: 2.4918\n",
      "Epoch 67/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 31.5816 - mae: 2.3588\n",
      "Epoch 68/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 34.3499 - mae: 2.2927\n",
      "Epoch 69/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 30.9609 - mae: 2.2453\n",
      "Epoch 70/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 26.8243 - mae: 2.1323\n",
      "Epoch 71/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 22.5043 - mae: 2.0187\n",
      "Epoch 72/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 27.0945 - mae: 2.0553\n",
      "Epoch 73/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 24.6311 - mae: 2.0273\n",
      "Epoch 74/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 20.9699 - mae: 1.8807\n",
      "Epoch 75/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 19.8190 - mae: 1.8045\n",
      "Epoch 76/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 22.5416 - mae: 1.8240\n",
      "Epoch 77/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 34.1299 - mae: 1.9541\n",
      "Epoch 78/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 47.1202 - mae: 2.1818\n",
      "Epoch 79/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 151.3598 - mae: 2.5717\n",
      "Epoch 80/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 2513.5595 - mae: 5.4301\n",
      "Epoch 81/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 2887.1144 - mae: 8.5462\n",
      "Epoch 82/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 2926.3639 - mae: 9.7738\n",
      "Epoch 83/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 2347.0875 - mae: 10.4619\n",
      "Epoch 84/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 147.7135 - mae: 2.9804\n",
      "Epoch 85/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 55.4864 - mae: 2.2519\n",
      "Epoch 86/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 28.6044 - mae: 1.7744\n",
      "Epoch 87/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 39.5953 - mae: 1.8671\n",
      "Epoch 88/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 20.9062 - mae: 1.6122\n",
      "Epoch 89/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 17.3902 - mae: 1.4333\n",
      "Epoch 90/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 15.8426 - mae: 1.4204\n",
      "Epoch 91/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 17.1543 - mae: 1.4054\n",
      "Epoch 92/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 18.2119 - mae: 1.4462\n",
      "Epoch 93/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 10.4529 - mae: 1.1521\n",
      "Epoch 94/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 13.0366 - mae: 1.1727\n",
      "Epoch 95/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 14.0706 - mae: 1.1798\n",
      "Epoch 96/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 10.7305 - mae: 1.0743\n",
      "Epoch 97/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 13.5681 - mae: 1.1396\n",
      "Epoch 98/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 9.4508 - mae: 1.0930\n",
      "Epoch 99/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 21.3371 - mae: 1.1799\n",
      "Epoch 100/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 18.6954 - mae: 1.1357\n",
      "Epoch 101/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 46.6887 - mae: 1.1396\n",
      "Epoch 102/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 24.6131 - mae: 1.0594\n",
      "Epoch 103/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 9.2812 - mae: 0.9811\n",
      "Epoch 104/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 4.9350 - mae: 0.8540\n",
      "Epoch 105/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 5.5802 - mae: 0.8834\n",
      "Epoch 106/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 5.7241 - mae: 0.8387\n",
      "Epoch 107/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 5.0224 - mae: 0.8415\n",
      "Epoch 108/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 12.1072 - mae: 1.1086\n",
      "Epoch 109/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 7.8933 - mae: 0.9395\n",
      "Epoch 110/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 5.9967 - mae: 0.9152\n",
      "Epoch 111/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 8.5476 - mae: 0.9664\n",
      "Epoch 112/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 7.3514 - mae: 0.9080\n",
      "Epoch 113/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 5.0774 - mae: 0.8528\n",
      "Epoch 114/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 4.5858 - mae: 0.8075\n",
      "Epoch 115/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 3.6848 - mae: 0.7549\n",
      "Epoch 116/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 7.3697 - mae: 0.8418\n",
      "Epoch 117/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 5.9663 - mae: 0.8295\n",
      "Epoch 118/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 3.3151 - mae: 0.7156\n",
      "Epoch 119/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 3.2499 - mae: 0.7059\n",
      "Epoch 120/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 8.0460 - mae: 0.9508\n",
      "Epoch 121/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 58.0057 - mae: 2.1484\n",
      "Epoch 122/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 88.9134 - mae: 3.0696\n",
      "Epoch 123/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 96.2080 - mae: 2.8168\n",
      "Epoch 124/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 12.9292 - mae: 1.2385\n",
      "Epoch 125/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 10.3892 - mae: 0.9486\n",
      "Epoch 126/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 8.9144 - mae: 0.9033\n",
      "Epoch 127/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 47.5742 - mae: 1.8491\n",
      "Epoch 128/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 28.0206 - mae: 1.5758\n",
      "Epoch 129/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 43.4134 - mae: 1.7414\n",
      "Epoch 130/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 94.8035 - mae: 1.7169\n",
      "Epoch 131/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 19.3681 - mae: 1.0473\n",
      "Epoch 132/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 15.4933 - mae: 1.0642\n",
      "Epoch 133/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 25.4543 - mae: 1.2178\n",
      "Epoch 134/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 5.2567 - mae: 0.7922\n",
      "Epoch 135/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 13.6524 - mae: 1.0845\n",
      "Epoch 136/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 25.2246 - mae: 1.3969\n",
      "Epoch 137/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 8.4848 - mae: 1.2201\n",
      "Epoch 138/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 15.6755 - mae: 1.1614\n",
      "Epoch 139/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 10.1976 - mae: 0.8316\n",
      "Epoch 140/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 4.2984 - mae: 0.8288\n",
      "Epoch 141/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 5.8447 - mae: 0.8183\n",
      "Epoch 142/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 3.6443 - mae: 0.6951\n",
      "Epoch 143/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 4.1011 - mae: 0.7352\n",
      "Epoch 144/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 2.5062 - mae: 0.6104\n",
      "Epoch 145/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 3.3884 - mae: 0.6258\n",
      "Epoch 146/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 7.4405 - mae: 0.9575\n",
      "Epoch 147/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 10.6874 - mae: 0.9794\n",
      "Epoch 148/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 8.6627 - mae: 1.0602\n",
      "Epoch 149/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 10.9111 - mae: 0.9430\n",
      "Epoch 150/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 18.0205 - mae: 1.2240\n",
      "Epoch 151/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 17.6313 - mae: 1.0503\n",
      "Epoch 152/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 24.3122 - mae: 1.2767\n",
      "Epoch 153/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 59.1008 - mae: 1.6743\n",
      "Epoch 154/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 84.7726 - mae: 1.8801\n",
      "Epoch 155/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 306.8598 - mae: 3.8853\n",
      "Epoch 156/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 110.7208 - mae: 2.9116\n",
      "Epoch 157/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 93.6973 - mae: 2.4350\n",
      "Epoch 158/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 51.5376 - mae: 1.7146\n",
      "Epoch 159/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 48.1498 - mae: 2.1790\n",
      "Epoch 160/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 13.2945 - mae: 1.0157\n",
      "Epoch 161/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 25.5956 - mae: 1.8008\n",
      "Epoch 162/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 9.7196 - mae: 0.8249\n",
      "Epoch 163/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 4.2991 - mae: 0.6918\n",
      "Epoch 164/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 8.0317 - mae: 0.7951\n",
      "Epoch 165/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 15.6728 - mae: 1.2149\n",
      "Epoch 166/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 8.3571 - mae: 0.9060\n",
      "Epoch 167/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 5.4068 - mae: 0.6949\n",
      "Epoch 168/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 4.8240 - mae: 0.6288\n",
      "Epoch 169/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 6.4191 - mae: 0.7688\n",
      "Epoch 170/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 11.1359 - mae: 0.8692\n",
      "Epoch 171/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 7.8950 - mae: 0.7993\n",
      "Epoch 172/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 159.8431 - mae: 1.8629\n",
      "Epoch 173/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 270.9909 - mae: 2.8150\n",
      "Epoch 174/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 42.9950 - mae: 1.4588\n",
      "Epoch 175/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 62.0542 - mae: 1.4945\n",
      "Epoch 176/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 43.9342 - mae: 1.4505\n",
      "Epoch 177/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 6.8888 - mae: 0.7069\n",
      "Epoch 178/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 3.1953 - mae: 0.5463\n",
      "Epoch 179/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 2.5810 - mae: 0.4781\n",
      "Epoch 180/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 5.8552 - mae: 0.6228\n",
      "Epoch 181/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 3.6279 - mae: 0.5173\n",
      "Epoch 182/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 2.8815 - mae: 0.5204\n",
      "Epoch 183/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 2.9371 - mae: 0.4420\n",
      "Epoch 184/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 2.0413 - mae: 0.4396\n",
      "Epoch 185/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 1.1924 - mae: 0.3776\n",
      "Epoch 186/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.9758 - mae: 0.3431\n",
      "Epoch 187/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.9670 - mae: 0.3292\n",
      "Epoch 188/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.9652 - mae: 0.3351\n",
      "Epoch 189/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 1.1901 - mae: 0.3626\n",
      "Epoch 190/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.8406 - mae: 0.3107\n",
      "Epoch 191/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 1.2333 - mae: 0.3257\n",
      "Epoch 192/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.8679 - mae: 0.2933\n",
      "Epoch 193/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.7309 - mae: 0.2948\n",
      "Epoch 194/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.7586 - mae: 0.2934\n",
      "Epoch 195/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.6943 - mae: 0.2747\n",
      "Epoch 196/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.6606 - mae: 0.2657\n",
      "Epoch 197/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.6864 - mae: 0.2685\n",
      "Epoch 198/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.7210 - mae: 0.2747\n",
      "Epoch 199/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.6797 - mae: 0.2664\n",
      "Epoch 200/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.6741 - mae: 0.2723\n",
      "Epoch 201/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.6793 - mae: 0.2738\n",
      "Epoch 202/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.6919 - mae: 0.2785\n",
      "Epoch 203/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.6535 - mae: 0.2601\n",
      "Epoch 204/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.6706 - mae: 0.2657\n",
      "Epoch 205/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.8464 - mae: 0.3169\n",
      "Epoch 206/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 1.0655 - mae: 0.3278\n",
      "Epoch 207/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.8720 - mae: 0.3399\n",
      "Epoch 208/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.8995 - mae: 0.2798\n",
      "Epoch 209/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.7033 - mae: 0.2732\n",
      "Epoch 210/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.6673 - mae: 0.2626\n",
      "Epoch 211/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.7558 - mae: 0.3039\n",
      "Epoch 212/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 3.2703 - mae: 0.5077\n",
      "Epoch 213/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 5.3944 - mae: 0.7685\n",
      "Epoch 214/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 3.0107 - mae: 0.4815\n",
      "Epoch 215/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 7.0284 - mae: 0.7874\n",
      "Epoch 216/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 5.6790 - mae: 0.7173\n",
      "Epoch 217/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 30.2738 - mae: 1.3366\n",
      "Epoch 218/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 13.0316 - mae: 0.7693\n",
      "Epoch 219/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 3.2485 - mae: 0.4854\n",
      "Epoch 220/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 3.9348 - mae: 0.6557\n",
      "Epoch 221/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1.4419 - mae: 0.3777\n",
      "Epoch 222/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1.0092 - mae: 0.3683\n",
      "Epoch 223/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1.0647 - mae: 0.3613\n",
      "Epoch 224/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 1.0335 - mae: 0.3320\n",
      "Epoch 225/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.7161 - mae: 0.3112\n",
      "Epoch 226/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.6343 - mae: 0.2888\n",
      "Epoch 227/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.9137 - mae: 0.3245\n",
      "Epoch 228/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.6555 - mae: 0.2837\n",
      "Epoch 229/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.5903 - mae: 0.2659\n",
      "Epoch 230/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.6088 - mae: 0.2609\n",
      "Epoch 231/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.6210 - mae: 0.2631\n",
      "Epoch 232/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.7476 - mae: 0.2886\n",
      "Epoch 233/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.7038 - mae: 0.2892\n",
      "Epoch 234/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 2.1214 - mae: 0.4317\n",
      "Epoch 235/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 2.6154 - mae: 0.5284\n",
      "Epoch 236/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 1.0704 - mae: 0.3675\n",
      "Epoch 237/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 1.0809 - mae: 0.3753\n",
      "Epoch 238/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.9405 - mae: 0.3133\n",
      "Epoch 239/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.8426 - mae: 0.2909\n",
      "Epoch 240/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1.2078 - mae: 0.3720\n",
      "Epoch 241/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.7014 - mae: 0.2844\n",
      "Epoch 242/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.6360 - mae: 0.2740\n",
      "Epoch 243/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.9797 - mae: 0.3384\n",
      "Epoch 244/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.9596 - mae: 0.3132\n",
      "Epoch 245/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.7889 - mae: 0.3036\n",
      "Epoch 246/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 3.1768 - mae: 0.4781\n",
      "Epoch 247/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 37.2284 - mae: 1.2048\n",
      "Epoch 248/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 25.6257 - mae: 1.0909\n",
      "Epoch 249/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 22.8860 - mae: 1.1811\n",
      "Epoch 250/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 15.6973 - mae: 0.9205\n",
      "Epoch 251/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 3.8094 - mae: 0.6924\n",
      "Epoch 252/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 2.3070 - mae: 0.5961\n",
      "Epoch 253/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 1.5069 - mae: 0.4946\n",
      "Epoch 254/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 2.3328 - mae: 0.5148\n",
      "Epoch 255/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 5.0847 - mae: 0.7065\n",
      "Epoch 256/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 2.7552 - mae: 0.4980\n",
      "Epoch 257/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.9508 - mae: 0.3830\n",
      "Epoch 258/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.9597 - mae: 0.3698\n",
      "Epoch 259/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.7443 - mae: 0.3273\n",
      "Epoch 260/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.6982 - mae: 0.3166\n",
      "Epoch 261/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.6452 - mae: 0.3013\n",
      "Epoch 262/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5900 - mae: 0.2905\n",
      "Epoch 263/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5932 - mae: 0.2949\n",
      "Epoch 264/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5837 - mae: 0.2866\n",
      "Epoch 265/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.5784 - mae: 0.2785\n",
      "Epoch 266/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5619 - mae: 0.2754\n",
      "Epoch 267/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.5599 - mae: 0.2751\n",
      "Epoch 268/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.5673 - mae: 0.2750\n",
      "Epoch 269/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.5933 - mae: 0.2791\n",
      "Epoch 270/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.5346 - mae: 0.2557\n",
      "Epoch 271/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5422 - mae: 0.2590\n",
      "Epoch 272/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.5340 - mae: 0.2568\n",
      "Epoch 273/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.5337 - mae: 0.2549\n",
      "Epoch 274/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5274 - mae: 0.2497\n",
      "Epoch 275/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5321 - mae: 0.2544\n",
      "Epoch 276/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5123 - mae: 0.2442\n",
      "Epoch 277/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5098 - mae: 0.2409\n",
      "Epoch 278/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.5126 - mae: 0.2437\n",
      "Epoch 279/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.5419 - mae: 0.2554\n",
      "Epoch 280/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 1.3610 - mae: 0.3840\n",
      "Epoch 281/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5472 - mae: 0.2579\n",
      "Epoch 282/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.6241 - mae: 0.2681\n",
      "Epoch 283/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5479 - mae: 0.2607\n",
      "Epoch 284/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5245 - mae: 0.2442\n",
      "Epoch 285/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1.2061 - mae: 0.3245\n",
      "Epoch 286/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 75us/sample - loss: 2.3966 - mae: 0.4773\n",
      "Epoch 287/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 2.1777 - mae: 0.3951\n",
      "Epoch 288/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 15.3696 - mae: 0.8446\n",
      "Epoch 289/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 6.1908 - mae: 0.6686\n",
      "Epoch 290/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.8187 - mae: 0.3284\n",
      "Epoch 291/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.7861 - mae: 0.3014\n",
      "Epoch 292/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.8361 - mae: 0.2938\n",
      "Epoch 293/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5372 - mae: 0.2500\n",
      "Epoch 294/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5229 - mae: 0.2457\n",
      "Epoch 295/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5264 - mae: 0.2468\n",
      "Epoch 296/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5299 - mae: 0.2501\n",
      "Epoch 297/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.5051 - mae: 0.2403\n",
      "Epoch 298/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5469 - mae: 0.2525\n",
      "Epoch 299/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.7154 - mae: 0.2667\n",
      "Epoch 300/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.8130 - mae: 0.2933\n",
      "Epoch 301/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.5421 - mae: 0.2591\n",
      "Epoch 302/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.4850 - mae: 0.2352\n",
      "Epoch 303/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4793 - mae: 0.2317\n",
      "Epoch 304/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4825 - mae: 0.2316\n",
      "Epoch 305/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5481 - mae: 0.2536\n",
      "Epoch 306/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5580 - mae: 0.2518\n",
      "Epoch 307/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4991 - mae: 0.2423\n",
      "Epoch 308/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.6051 - mae: 0.2585\n",
      "Epoch 309/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5150 - mae: 0.2482\n",
      "Epoch 310/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5189 - mae: 0.2391\n",
      "Epoch 311/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.5147 - mae: 0.2418\n",
      "Epoch 312/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4794 - mae: 0.2291\n",
      "Epoch 313/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4529 - mae: 0.2200\n",
      "Epoch 314/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4465 - mae: 0.2169\n",
      "Epoch 315/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4576 - mae: 0.2210\n",
      "Epoch 316/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4775 - mae: 0.2264\n",
      "Epoch 317/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4497 - mae: 0.2203\n",
      "Epoch 318/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4367 - mae: 0.2160\n",
      "Epoch 319/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4338 - mae: 0.2130\n",
      "Epoch 320/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4355 - mae: 0.2130\n",
      "Epoch 321/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4370 - mae: 0.2127\n",
      "Epoch 322/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4327 - mae: 0.2155\n",
      "Epoch 323/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4269 - mae: 0.2092\n",
      "Epoch 324/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4228 - mae: 0.2086\n",
      "Epoch 325/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4204 - mae: 0.2060\n",
      "Epoch 326/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4194 - mae: 0.2070\n",
      "Epoch 327/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1.0217 - mae: 0.2818\n",
      "Epoch 328/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 3.4167 - mae: 0.4531\n",
      "Epoch 329/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 16.6704 - mae: 0.7669\n",
      "Epoch 330/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1.7212 - mae: 0.4154\n",
      "Epoch 331/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 6.5104 - mae: 0.4754\n",
      "Epoch 332/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 15.0061 - mae: 0.9741\n",
      "Epoch 333/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 27.2707 - mae: 0.6816\n",
      "Epoch 334/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 1.3617 - mae: 0.3370\n",
      "Epoch 335/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.5520 - mae: 0.2521\n",
      "Epoch 336/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4663 - mae: 0.2310\n",
      "Epoch 337/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4479 - mae: 0.2226\n",
      "Epoch 338/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4331 - mae: 0.2178\n",
      "Epoch 339/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4247 - mae: 0.2137\n",
      "Epoch 340/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4179 - mae: 0.2109\n",
      "Epoch 341/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4122 - mae: 0.2072\n",
      "Epoch 342/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4079 - mae: 0.2045\n",
      "Epoch 343/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4045 - mae: 0.2024\n",
      "Epoch 344/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4012 - mae: 0.2005\n",
      "Epoch 345/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.3983 - mae: 0.1990\n",
      "Epoch 346/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3959 - mae: 0.1979\n",
      "Epoch 347/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3936 - mae: 0.1968\n",
      "Epoch 348/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3911 - mae: 0.1952\n",
      "Epoch 349/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3889 - mae: 0.1935\n",
      "Epoch 350/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3865 - mae: 0.1920\n",
      "Epoch 351/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3846 - mae: 0.1913\n",
      "Epoch 352/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3832 - mae: 0.1907\n",
      "Epoch 353/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3812 - mae: 0.1899\n",
      "Epoch 354/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3797 - mae: 0.1900\n",
      "Epoch 355/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.3776 - mae: 0.1887\n",
      "Epoch 356/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3758 - mae: 0.1883\n",
      "Epoch 357/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.3742 - mae: 0.1882\n",
      "Epoch 358/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3724 - mae: 0.1875\n",
      "Epoch 359/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3711 - mae: 0.1873\n",
      "Epoch 360/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3691 - mae: 0.1869\n",
      "Epoch 361/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3674 - mae: 0.1872\n",
      "Epoch 362/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3655 - mae: 0.1863\n",
      "Epoch 363/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3637 - mae: 0.1861\n",
      "Epoch 364/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3620 - mae: 0.1857\n",
      "Epoch 365/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3602 - mae: 0.1850\n",
      "Epoch 366/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.3583 - mae: 0.1843\n",
      "Epoch 367/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3566 - mae: 0.1845\n",
      "Epoch 368/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.3547 - mae: 0.1842\n",
      "Epoch 369/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3533 - mae: 0.1839\n",
      "Epoch 370/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3517 - mae: 0.1839\n",
      "Epoch 371/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3497 - mae: 0.1838\n",
      "Epoch 372/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3476 - mae: 0.1832\n",
      "Epoch 373/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3458 - mae: 0.1831\n",
      "Epoch 374/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3442 - mae: 0.1829\n",
      "Epoch 375/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3421 - mae: 0.1829\n",
      "Epoch 376/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3400 - mae: 0.1820\n",
      "Epoch 377/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.3383 - mae: 0.1820\n",
      "Epoch 378/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3364 - mae: 0.1819\n",
      "Epoch 379/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.3348 - mae: 0.1822\n",
      "Epoch 380/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3329 - mae: 0.1815\n",
      "Epoch 381/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3308 - mae: 0.1809\n",
      "Epoch 382/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3290 - mae: 0.1817\n",
      "Epoch 383/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3268 - mae: 0.1809\n",
      "Epoch 384/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3246 - mae: 0.1803\n",
      "Epoch 385/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3229 - mae: 0.1797\n",
      "Epoch 386/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3211 - mae: 0.1801\n",
      "Epoch 387/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3190 - mae: 0.1794\n",
      "Epoch 388/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3172 - mae: 0.1793\n",
      "Epoch 389/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3160 - mae: 0.1798\n",
      "Epoch 390/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3149 - mae: 0.1787\n",
      "Epoch 391/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3118 - mae: 0.1778\n",
      "Epoch 392/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3097 - mae: 0.1780\n",
      "Epoch 393/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3071 - mae: 0.1769\n",
      "Epoch 394/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3053 - mae: 0.1775\n",
      "Epoch 395/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.3032 - mae: 0.1770\n",
      "Epoch 396/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.3011 - mae: 0.1767\n",
      "Epoch 397/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2988 - mae: 0.1766\n",
      "Epoch 398/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2966 - mae: 0.1761\n",
      "Epoch 399/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.5261 - mae: 0.2072\n",
      "Epoch 400/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.5956 - mae: 0.2082\n",
      "Epoch 401/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2963 - mae: 0.1841\n",
      "Epoch 402/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2918 - mae: 0.1811\n",
      "Epoch 403/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2897 - mae: 0.1800\n",
      "Epoch 404/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2868 - mae: 0.1792\n",
      "Epoch 405/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2835 - mae: 0.1763\n",
      "Epoch 406/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2820 - mae: 0.1766\n",
      "Epoch 407/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2793 - mae: 0.1757\n",
      "Epoch 408/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2770 - mae: 0.1749\n",
      "Epoch 409/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.2749 - mae: 0.1749\n",
      "Epoch 410/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.2729 - mae: 0.1750\n",
      "Epoch 411/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2702 - mae: 0.1738\n",
      "Epoch 412/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2680 - mae: 0.1739\n",
      "Epoch 413/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2665 - mae: 0.1740\n",
      "Epoch 414/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2642 - mae: 0.1748\n",
      "Epoch 415/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2613 - mae: 0.1730\n",
      "Epoch 416/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2589 - mae: 0.1713\n",
      "Epoch 417/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2568 - mae: 0.1715\n",
      "Epoch 418/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2544 - mae: 0.1716\n",
      "Epoch 419/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2522 - mae: 0.1712\n",
      "Epoch 420/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.2502 - mae: 0.1709\n",
      "Epoch 421/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.2475 - mae: 0.1704\n",
      "Epoch 422/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.2454 - mae: 0.1696\n",
      "Epoch 423/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.2426 - mae: 0.1689\n",
      "Epoch 424/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2411 - mae: 0.1690\n",
      "Epoch 425/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2386 - mae: 0.1691\n",
      "Epoch 426/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2361 - mae: 0.1686\n",
      "Epoch 427/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2336 - mae: 0.1686\n",
      "Epoch 428/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2315 - mae: 0.1675\n",
      "Epoch 429/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2301 - mae: 0.1695\n",
      "Epoch 430/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.2272 - mae: 0.1680\n",
      "Epoch 431/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.2253 - mae: 0.1680\n",
      "Epoch 432/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.2229 - mae: 0.1682\n",
      "Epoch 433/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.2195 - mae: 0.1660\n",
      "Epoch 434/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2177 - mae: 0.1668\n",
      "Epoch 435/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.2160 - mae: 0.1662\n",
      "Epoch 436/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2166 - mae: 0.1681\n",
      "Epoch 437/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2111 - mae: 0.1652\n",
      "Epoch 438/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2117 - mae: 0.1672\n",
      "Epoch 439/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2064 - mae: 0.1641\n",
      "Epoch 440/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2040 - mae: 0.1633\n",
      "Epoch 441/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.2038 - mae: 0.1658\n",
      "Epoch 442/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.1998 - mae: 0.1633\n",
      "Epoch 443/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.1974 - mae: 0.1622\n",
      "Epoch 444/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1946 - mae: 0.1610\n",
      "Epoch 445/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1927 - mae: 0.1622\n",
      "Epoch 446/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1908 - mae: 0.1624\n",
      "Epoch 447/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1885 - mae: 0.1617\n",
      "Epoch 448/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1866 - mae: 0.1619\n",
      "Epoch 449/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1844 - mae: 0.1609\n",
      "Epoch 450/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1865 - mae: 0.1637\n",
      "Epoch 451/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1797 - mae: 0.1605\n",
      "Epoch 452/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.1793 - mae: 0.1617\n",
      "Epoch 453/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.1748 - mae: 0.1587\n",
      "Epoch 454/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.1744 - mae: 0.1610\n",
      "Epoch 455/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1742 - mae: 0.1625\n",
      "Epoch 456/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1692 - mae: 0.1591\n",
      "Epoch 457/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1667 - mae: 0.1586\n",
      "Epoch 458/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.2800 - mae: 0.1849\n",
      "Epoch 459/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 9.3899 - mae: 0.7161\n",
      "Epoch 460/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 2.0612 - mae: 0.3801\n",
      "Epoch 461/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 5.9010 - mae: 0.3037\n",
      "Epoch 462/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.2035 - mae: 0.2192\n",
      "Epoch 463/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.1932 - mae: 0.2116\n",
      "Epoch 464/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1816 - mae: 0.1972\n",
      "Epoch 465/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.1761 - mae: 0.1903\n",
      "Epoch 466/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1713 - mae: 0.1838\n",
      "Epoch 467/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1690 - mae: 0.1833\n",
      "Epoch 468/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1657 - mae: 0.1790\n",
      "Epoch 469/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1640 - mae: 0.1786\n",
      "Epoch 470/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1613 - mae: 0.1753\n",
      "Epoch 471/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1591 - mae: 0.1737\n",
      "Epoch 472/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1574 - mae: 0.1726\n",
      "Epoch 473/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.1555 - mae: 0.1713\n",
      "Epoch 474/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.1543 - mae: 0.1717\n",
      "Epoch 475/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.1550 - mae: 0.1711\n",
      "Epoch 476/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.1511 - mae: 0.1690\n",
      "Epoch 477/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1497 - mae: 0.1692\n",
      "Epoch 478/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1482 - mae: 0.1686\n",
      "Epoch 479/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1466 - mae: 0.1684\n",
      "Epoch 480/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1467 - mae: 0.1712\n",
      "Epoch 481/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.1439 - mae: 0.1677\n",
      "Epoch 482/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1427 - mae: 0.1682\n",
      "Epoch 483/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1410 - mae: 0.1664\n",
      "Epoch 484/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.1399 - mae: 0.1671\n",
      "Epoch 485/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1383 - mae: 0.1654\n",
      "Epoch 486/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.1370 - mae: 0.1651\n",
      "Epoch 487/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1357 - mae: 0.1654\n",
      "Epoch 488/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1347 - mae: 0.1644\n",
      "Epoch 489/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1331 - mae: 0.1637\n",
      "Epoch 490/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1320 - mae: 0.1633\n",
      "Epoch 491/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1309 - mae: 0.1631\n",
      "Epoch 492/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1302 - mae: 0.1638\n",
      "Epoch 493/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1297 - mae: 0.1660\n",
      "Epoch 494/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1279 - mae: 0.1627\n",
      "Epoch 495/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.1265 - mae: 0.1620\n",
      "Epoch 496/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1256 - mae: 0.1619\n",
      "Epoch 497/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1247 - mae: 0.1606\n",
      "Epoch 498/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.1234 - mae: 0.1611\n",
      "Epoch 499/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.1223 - mae: 0.1604\n",
      "Epoch 500/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1216 - mae: 0.1605\n",
      "Epoch 501/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1203 - mae: 0.1601\n",
      "Epoch 502/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1193 - mae: 0.1591\n",
      "Epoch 503/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1183 - mae: 0.1588\n",
      "Epoch 504/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1175 - mae: 0.1587\n",
      "Epoch 505/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.1168 - mae: 0.1589\n",
      "Epoch 506/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.1167 - mae: 0.1595\n",
      "Epoch 507/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.1165 - mae: 0.1593\n",
      "Epoch 508/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.1150 - mae: 0.1587\n",
      "Epoch 509/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1134 - mae: 0.1582\n",
      "Epoch 510/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1127 - mae: 0.1585\n",
      "Epoch 511/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1119 - mae: 0.1587\n",
      "Epoch 512/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1108 - mae: 0.1574\n",
      "Epoch 513/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1101 - mae: 0.1573\n",
      "Epoch 514/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.1095 - mae: 0.1584\n",
      "Epoch 515/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.1086 - mae: 0.1572\n",
      "Epoch 516/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.1079 - mae: 0.1570\n",
      "Epoch 517/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.1085 - mae: 0.1581\n",
      "Epoch 518/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.1135 - mae: 0.1600\n",
      "Epoch 519/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1059 - mae: 0.1564\n",
      "Epoch 520/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1055 - mae: 0.1581\n",
      "Epoch 521/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1046 - mae: 0.1566\n",
      "Epoch 522/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1039 - mae: 0.1570\n",
      "Epoch 523/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1031 - mae: 0.1563\n",
      "Epoch 524/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1027 - mae: 0.1556\n",
      "Epoch 525/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1023 - mae: 0.1569\n",
      "Epoch 526/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.1014 - mae: 0.1570\n",
      "Epoch 527/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.1011 - mae: 0.1568\n",
      "Epoch 528/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.1014 - mae: 0.1567\n",
      "Epoch 529/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1038 - mae: 0.1598\n",
      "Epoch 530/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1024 - mae: 0.1590\n",
      "Epoch 531/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0989 - mae: 0.1549\n",
      "Epoch 532/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0981 - mae: 0.1557\n",
      "Epoch 533/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0973 - mae: 0.1560\n",
      "Epoch 534/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0966 - mae: 0.1557\n",
      "Epoch 535/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0960 - mae: 0.1554\n",
      "Epoch 536/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0954 - mae: 0.1551\n",
      "Epoch 537/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0948 - mae: 0.1553\n",
      "Epoch 538/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0991 - mae: 0.1576\n",
      "Epoch 539/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0939 - mae: 0.1550\n",
      "Epoch 540/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0932 - mae: 0.1546\n",
      "Epoch 541/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0930 - mae: 0.1556\n",
      "Epoch 542/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0937 - mae: 0.1562\n",
      "Epoch 543/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0915 - mae: 0.1545\n",
      "Epoch 544/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0905 - mae: 0.1531\n",
      "Epoch 545/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0899 - mae: 0.1525\n",
      "Epoch 546/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0893 - mae: 0.1529\n",
      "Epoch 547/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0886 - mae: 0.1532\n",
      "Epoch 548/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0886 - mae: 0.1536\n",
      "Epoch 549/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0876 - mae: 0.1525\n",
      "Epoch 550/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0868 - mae: 0.1523\n",
      "Epoch 551/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0864 - mae: 0.1515\n",
      "Epoch 552/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0857 - mae: 0.1521\n",
      "Epoch 553/2000\n",
      "2019/2019 [==============================] - 0s 92us/sample - loss: 0.0859 - mae: 0.1536\n",
      "Epoch 554/2000\n",
      "2019/2019 [==============================] - 0s 95us/sample - loss: 0.0856 - mae: 0.1538\n",
      "Epoch 555/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0840 - mae: 0.1522\n",
      "Epoch 556/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0839 - mae: 0.1543\n",
      "Epoch 557/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0834 - mae: 0.1521\n",
      "Epoch 558/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0824 - mae: 0.1518\n",
      "Epoch 559/2000\n",
      "2019/2019 [==============================] - 0s 97us/sample - loss: 0.0827 - mae: 0.1544\n",
      "Epoch 560/2000\n",
      "2019/2019 [==============================] - 0s 97us/sample - loss: 0.0806 - mae: 0.1502\n",
      "Epoch 561/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0806 - mae: 0.1525\n",
      "Epoch 562/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0798 - mae: 0.1512\n",
      "Epoch 563/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0788 - mae: 0.1495\n",
      "Epoch 564/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0782 - mae: 0.1496\n",
      "Epoch 565/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0776 - mae: 0.1491\n",
      "Epoch 566/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0769 - mae: 0.1495\n",
      "Epoch 567/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0764 - mae: 0.1489\n",
      "Epoch 568/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0758 - mae: 0.1486\n",
      "Epoch 569/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0755 - mae: 0.1490\n",
      "Epoch 570/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0755 - mae: 0.1504\n",
      "Epoch 571/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0741 - mae: 0.1476\n",
      "Epoch 572/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0737 - mae: 0.1487\n",
      "Epoch 573/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0729 - mae: 0.1476\n",
      "Epoch 574/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0726 - mae: 0.1486\n",
      "Epoch 575/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0717 - mae: 0.1476\n",
      "Epoch 576/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0710 - mae: 0.1470\n",
      "Epoch 577/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0706 - mae: 0.1474\n",
      "Epoch 578/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0705 - mae: 0.1476\n",
      "Epoch 579/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0696 - mae: 0.1469\n",
      "Epoch 580/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0689 - mae: 0.1465\n",
      "Epoch 581/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0689 - mae: 0.1478\n",
      "Epoch 582/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0679 - mae: 0.1450\n",
      "Epoch 583/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0673 - mae: 0.1463\n",
      "Epoch 584/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0669 - mae: 0.1457\n",
      "Epoch 585/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0664 - mae: 0.1463\n",
      "Epoch 586/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0657 - mae: 0.1460\n",
      "Epoch 587/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0650 - mae: 0.1433\n",
      "Epoch 588/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0648 - mae: 0.1449\n",
      "Epoch 589/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0645 - mae: 0.1461\n",
      "Epoch 590/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0640 - mae: 0.1445\n",
      "Epoch 591/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0628 - mae: 0.1420\n",
      "Epoch 592/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0627 - mae: 0.1439\n",
      "Epoch 593/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0632 - mae: 0.1460\n",
      "Epoch 594/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0616 - mae: 0.1438\n",
      "Epoch 595/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0615 - mae: 0.1441\n",
      "Epoch 596/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0606 - mae: 0.1429\n",
      "Epoch 597/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0600 - mae: 0.1437\n",
      "Epoch 598/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0590 - mae: 0.1411\n",
      "Epoch 599/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0589 - mae: 0.1425\n",
      "Epoch 600/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0572 - mae: 0.1385\n",
      "Epoch 601/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0572 - mae: 0.1403\n",
      "Epoch 602/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0571 - mae: 0.1401\n",
      "Epoch 603/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0559 - mae: 0.1385\n",
      "Epoch 604/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0558 - mae: 0.1395\n",
      "Epoch 605/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0563 - mae: 0.1412\n",
      "Epoch 606/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0541 - mae: 0.1380\n",
      "Epoch 607/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0526 - mae: 0.1351\n",
      "Epoch 608/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0530 - mae: 0.1372\n",
      "Epoch 609/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0527 - mae: 0.1377\n",
      "Epoch 610/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0516 - mae: 0.1345\n",
      "Epoch 611/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0503 - mae: 0.1322\n",
      "Epoch 612/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0498 - mae: 0.1336\n",
      "Epoch 613/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0488 - mae: 0.1314\n",
      "Epoch 614/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0490 - mae: 0.1310\n",
      "Epoch 615/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0488 - mae: 0.1318\n",
      "Epoch 616/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0478 - mae: 0.1298\n",
      "Epoch 617/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0475 - mae: 0.1310\n",
      "Epoch 618/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0484 - mae: 0.1334\n",
      "Epoch 619/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0494 - mae: 0.1363\n",
      "Epoch 620/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0480 - mae: 0.1361\n",
      "Epoch 621/2000\n",
      "2019/2019 [==============================] - 0s 116us/sample - loss: 0.0461 - mae: 0.1312\n",
      "Epoch 622/2000\n",
      "2019/2019 [==============================] - 0s 157us/sample - loss: 0.0456 - mae: 0.1299\n",
      "Epoch 623/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0455 - mae: 0.1320\n",
      "Epoch 624/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0456 - mae: 0.1322\n",
      "Epoch 625/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0456 - mae: 0.1325\n",
      "Epoch 626/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0456 - mae: 0.1343\n",
      "Epoch 627/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0438 - mae: 0.1288\n",
      "Epoch 628/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0444 - mae: 0.1315\n",
      "Epoch 629/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0446 - mae: 0.1335\n",
      "Epoch 630/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0446 - mae: 0.1355\n",
      "Epoch 631/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0422 - mae: 0.1281\n",
      "Epoch 632/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0437 - mae: 0.1333\n",
      "Epoch 633/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0434 - mae: 0.1329\n",
      "Epoch 634/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0411 - mae: 0.1278\n",
      "Epoch 635/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0412 - mae: 0.1290\n",
      "Epoch 636/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0404 - mae: 0.1272\n",
      "Epoch 637/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0400 - mae: 0.1261\n",
      "Epoch 638/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0423 - mae: 0.1340\n",
      "Epoch 639/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0395 - mae: 0.1262\n",
      "Epoch 640/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0413 - mae: 0.1318\n",
      "Epoch 641/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0405 - mae: 0.1314\n",
      "Epoch 642/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0409 - mae: 0.1308\n",
      "Epoch 643/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0400 - mae: 0.1295\n",
      "Epoch 644/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0378 - mae: 0.1251\n",
      "Epoch 645/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0374 - mae: 0.1236\n",
      "Epoch 646/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0383 - mae: 0.1295\n",
      "Epoch 647/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0376 - mae: 0.1264\n",
      "Epoch 648/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0366 - mae: 0.1242\n",
      "Epoch 649/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0365 - mae: 0.1242\n",
      "Epoch 650/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0441 - mae: 0.1262\n",
      "Epoch 651/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0376 - mae: 0.1299\n",
      "Epoch 652/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0367 - mae: 0.1275\n",
      "Epoch 653/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0368 - mae: 0.1274\n",
      "Epoch 654/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0366 - mae: 0.1270\n",
      "Epoch 655/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0369 - mae: 0.1280\n",
      "Epoch 656/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0371 - mae: 0.1282\n",
      "Epoch 657/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0372 - mae: 0.1296\n",
      "Epoch 658/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0383 - mae: 0.1320\n",
      "Epoch 659/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0363 - mae: 0.1285\n",
      "Epoch 660/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0356 - mae: 0.1260\n",
      "Epoch 661/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0347 - mae: 0.1252\n",
      "Epoch 662/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0352 - mae: 0.1267\n",
      "Epoch 663/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0339 - mae: 0.1229\n",
      "Epoch 664/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0336 - mae: 0.1226\n",
      "Epoch 665/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0338 - mae: 0.1244\n",
      "Epoch 666/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0352 - mae: 0.1282\n",
      "Epoch 667/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0333 - mae: 0.1232\n",
      "Epoch 668/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0328 - mae: 0.1235\n",
      "Epoch 669/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0336 - mae: 0.1251\n",
      "Epoch 670/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0336 - mae: 0.1259\n",
      "Epoch 671/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0327 - mae: 0.1217\n",
      "Epoch 672/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0327 - mae: 0.1243\n",
      "Epoch 673/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0324 - mae: 0.1243\n",
      "Epoch 674/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0322 - mae: 0.1230\n",
      "Epoch 675/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0333 - mae: 0.1263\n",
      "Epoch 676/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0321 - mae: 0.1243\n",
      "Epoch 677/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0313 - mae: 0.1211\n",
      "Epoch 678/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0328 - mae: 0.1268\n",
      "Epoch 679/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0329 - mae: 0.1270\n",
      "Epoch 680/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0312 - mae: 0.1235\n",
      "Epoch 681/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0309 - mae: 0.1208\n",
      "Epoch 682/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0308 - mae: 0.1217\n",
      "Epoch 683/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0307 - mae: 0.1224\n",
      "Epoch 684/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0332 - mae: 0.1290\n",
      "Epoch 685/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0327 - mae: 0.1270\n",
      "Epoch 686/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0323 - mae: 0.1258\n",
      "Epoch 687/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0306 - mae: 0.1231\n",
      "Epoch 688/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0306 - mae: 0.1222\n",
      "Epoch 689/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0303 - mae: 0.1223\n",
      "Epoch 690/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0320 - mae: 0.1270\n",
      "Epoch 691/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0295 - mae: 0.1201\n",
      "Epoch 692/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0303 - mae: 0.1233\n",
      "Epoch 693/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0302 - mae: 0.1229\n",
      "Epoch 694/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0296 - mae: 0.1208\n",
      "Epoch 695/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0289 - mae: 0.1186\n",
      "Epoch 696/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0296 - mae: 0.1221\n",
      "Epoch 697/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0311 - mae: 0.1264\n",
      "Epoch 698/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0311 - mae: 0.1253\n",
      "Epoch 699/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0295 - mae: 0.1221\n",
      "Epoch 700/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0304 - mae: 0.1232\n",
      "Epoch 701/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0283 - mae: 0.1180\n",
      "Epoch 702/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0280 - mae: 0.1162\n",
      "Epoch 703/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0279 - mae: 0.1171\n",
      "Epoch 704/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0282 - mae: 0.1188\n",
      "Epoch 705/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0283 - mae: 0.1185\n",
      "Epoch 706/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0293 - mae: 0.1219\n",
      "Epoch 707/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0292 - mae: 0.1217\n",
      "Epoch 708/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0282 - mae: 0.1185\n",
      "Epoch 709/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0279 - mae: 0.1175\n",
      "Epoch 710/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0282 - mae: 0.1182\n",
      "Epoch 711/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0286 - mae: 0.1197\n",
      "Epoch 712/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0292 - mae: 0.1219\n",
      "Epoch 713/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0305 - mae: 0.1230\n",
      "Epoch 714/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0339 - mae: 0.1333\n",
      "Epoch 715/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0281 - mae: 0.1181\n",
      "Epoch 716/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0289 - mae: 0.1210\n",
      "Epoch 717/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0283 - mae: 0.1205\n",
      "Epoch 718/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0277 - mae: 0.1186\n",
      "Epoch 719/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0282 - mae: 0.1200\n",
      "Epoch 720/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0288 - mae: 0.1215\n",
      "Epoch 721/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0282 - mae: 0.1211\n",
      "Epoch 722/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0264 - mae: 0.1140\n",
      "Epoch 723/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0291 - mae: 0.1230\n",
      "Epoch 724/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0275 - mae: 0.1184\n",
      "Epoch 725/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0278 - mae: 0.1188\n",
      "Epoch 726/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0381 - mae: 0.1436\n",
      "Epoch 727/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0364 - mae: 0.1386\n",
      "Epoch 728/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0335 - mae: 0.1308\n",
      "Epoch 729/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0313 - mae: 0.1270\n",
      "Epoch 730/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0306 - mae: 0.1233\n",
      "Epoch 731/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0295 - mae: 0.1217\n",
      "Epoch 732/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0326 - mae: 0.1313\n",
      "Epoch 733/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0309 - mae: 0.1270\n",
      "Epoch 734/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0297 - mae: 0.1232\n",
      "Epoch 735/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0279 - mae: 0.1188\n",
      "Epoch 736/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0283 - mae: 0.1217\n",
      "Epoch 737/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0274 - mae: 0.1182\n",
      "Epoch 738/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0276 - mae: 0.1212\n",
      "Epoch 739/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0270 - mae: 0.1180\n",
      "Epoch 740/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0288 - mae: 0.1218\n",
      "Epoch 741/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0284 - mae: 0.1225\n",
      "Epoch 742/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0272 - mae: 0.1188\n",
      "Epoch 743/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0282 - mae: 0.1227\n",
      "Epoch 744/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0267 - mae: 0.1178\n",
      "Epoch 745/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0268 - mae: 0.1177\n",
      "Epoch 746/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0275 - mae: 0.1195\n",
      "Epoch 747/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0263 - mae: 0.1165\n",
      "Epoch 748/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0281 - mae: 0.1221\n",
      "Epoch 749/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0271 - mae: 0.1187\n",
      "Epoch 750/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0262 - mae: 0.1166\n",
      "Epoch 751/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0271 - mae: 0.1191\n",
      "Epoch 752/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0280 - mae: 0.1218\n",
      "Epoch 753/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0276 - mae: 0.1214\n",
      "Epoch 754/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0266 - mae: 0.1172\n",
      "Epoch 755/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0255 - mae: 0.1136\n",
      "Epoch 756/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0263 - mae: 0.1165\n",
      "Epoch 757/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0261 - mae: 0.1162\n",
      "Epoch 758/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0266 - mae: 0.1173\n",
      "Epoch 759/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0256 - mae: 0.1146\n",
      "Epoch 760/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0260 - mae: 0.1164\n",
      "Epoch 761/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0304 - mae: 0.1265\n",
      "Epoch 762/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0283 - mae: 0.1218\n",
      "Epoch 763/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0272 - mae: 0.1192\n",
      "Epoch 764/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0295 - mae: 0.1263\n",
      "Epoch 765/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0262 - mae: 0.1170\n",
      "Epoch 766/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0258 - mae: 0.1155\n",
      "Epoch 767/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0281 - mae: 0.1228\n",
      "Epoch 768/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0263 - mae: 0.1173\n",
      "Epoch 769/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0260 - mae: 0.1156\n",
      "Epoch 770/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0259 - mae: 0.1156\n",
      "Epoch 771/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0260 - mae: 0.1160\n",
      "Epoch 772/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0259 - mae: 0.1153\n",
      "Epoch 773/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0259 - mae: 0.1154\n",
      "Epoch 774/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0263 - mae: 0.1176\n",
      "Epoch 775/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0258 - mae: 0.1161\n",
      "Epoch 776/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0258 - mae: 0.1161\n",
      "Epoch 777/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0254 - mae: 0.1149\n",
      "Epoch 778/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0266 - mae: 0.1187\n",
      "Epoch 779/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0249 - mae: 0.1126\n",
      "Epoch 780/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0261 - mae: 0.1172\n",
      "Epoch 781/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0274 - mae: 0.1215\n",
      "Epoch 782/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0270 - mae: 0.1197\n",
      "Epoch 783/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0258 - mae: 0.1165\n",
      "Epoch 784/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0248 - mae: 0.1132\n",
      "Epoch 785/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0242 - mae: 0.1121\n",
      "Epoch 786/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0251 - mae: 0.1134\n",
      "Epoch 787/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0244 - mae: 0.1118\n",
      "Epoch 788/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0247 - mae: 0.1138\n",
      "Epoch 789/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0247 - mae: 0.1125\n",
      "Epoch 790/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0297 - mae: 0.1258\n",
      "Epoch 791/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0288 - mae: 0.1247\n",
      "Epoch 792/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0259 - mae: 0.1167\n",
      "Epoch 793/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0258 - mae: 0.1159\n",
      "Epoch 794/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0264 - mae: 0.1172\n",
      "Epoch 795/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0246 - mae: 0.1126\n",
      "Epoch 796/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0248 - mae: 0.1128\n",
      "Epoch 797/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0256 - mae: 0.1156\n",
      "Epoch 798/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0250 - mae: 0.1135\n",
      "Epoch 799/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0241 - mae: 0.1111\n",
      "Epoch 800/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0245 - mae: 0.1128\n",
      "Epoch 801/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0254 - mae: 0.1152\n",
      "Epoch 802/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0254 - mae: 0.1147\n",
      "Epoch 803/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0242 - mae: 0.1106\n",
      "Epoch 804/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0245 - mae: 0.1118\n",
      "Epoch 805/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0243 - mae: 0.1129\n",
      "Epoch 806/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0245 - mae: 0.1120\n",
      "Epoch 807/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0257 - mae: 0.1176\n",
      "Epoch 808/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0286 - mae: 0.1235\n",
      "Epoch 809/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0250 - mae: 0.1138\n",
      "Epoch 810/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0247 - mae: 0.1135\n",
      "Epoch 811/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0248 - mae: 0.1138\n",
      "Epoch 812/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0254 - mae: 0.1157\n",
      "Epoch 813/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0248 - mae: 0.1146\n",
      "Epoch 814/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0235 - mae: 0.1092\n",
      "Epoch 815/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0280 - mae: 0.1228\n",
      "Epoch 816/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0250 - mae: 0.1146\n",
      "Epoch 817/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0242 - mae: 0.1115\n",
      "Epoch 818/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0245 - mae: 0.1117\n",
      "Epoch 819/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0235 - mae: 0.1100\n",
      "Epoch 820/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0241 - mae: 0.1122\n",
      "Epoch 821/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0245 - mae: 0.1126\n",
      "Epoch 822/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0237 - mae: 0.1102\n",
      "Epoch 823/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0239 - mae: 0.1123\n",
      "Epoch 824/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0233 - mae: 0.1090\n",
      "Epoch 825/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0245 - mae: 0.1132\n",
      "Epoch 826/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0263 - mae: 0.1177\n",
      "Epoch 827/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0241 - mae: 0.1120\n",
      "Epoch 828/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0242 - mae: 0.1109\n",
      "Epoch 829/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0242 - mae: 0.1128\n",
      "Epoch 830/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0239 - mae: 0.1118\n",
      "Epoch 831/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0239 - mae: 0.1106\n",
      "Epoch 832/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0239 - mae: 0.1117\n",
      "Epoch 833/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0236 - mae: 0.1103\n",
      "Epoch 834/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0235 - mae: 0.1111\n",
      "Epoch 835/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0298 - mae: 0.1272\n",
      "Epoch 836/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0242 - mae: 0.1115\n",
      "Epoch 837/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0233 - mae: 0.1095\n",
      "Epoch 838/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0241 - mae: 0.1122\n",
      "Epoch 839/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0233 - mae: 0.1094\n",
      "Epoch 840/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0233 - mae: 0.1105\n",
      "Epoch 841/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0256 - mae: 0.1165\n",
      "Epoch 842/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0232 - mae: 0.1094\n",
      "Epoch 843/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0252 - mae: 0.1151\n",
      "Epoch 844/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0234 - mae: 0.1099\n",
      "Epoch 845/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0231 - mae: 0.1095\n",
      "Epoch 846/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0223 - mae: 0.1065\n",
      "Epoch 847/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0237 - mae: 0.1097\n",
      "Epoch 848/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0236 - mae: 0.1104\n",
      "Epoch 849/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0247 - mae: 0.1134\n",
      "Epoch 850/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0233 - mae: 0.1097\n",
      "Epoch 851/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0349 - mae: 0.1398\n",
      "Epoch 852/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0306 - mae: 0.1293\n",
      "Epoch 853/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0261 - mae: 0.1179\n",
      "Epoch 854/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0258 - mae: 0.1172\n",
      "Epoch 855/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0250 - mae: 0.1135\n",
      "Epoch 856/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0251 - mae: 0.1148\n",
      "Epoch 857/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0256 - mae: 0.1165\n",
      "Epoch 858/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0240 - mae: 0.1105\n",
      "Epoch 859/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0238 - mae: 0.1104\n",
      "Epoch 860/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0233 - mae: 0.1102\n",
      "Epoch 861/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0242 - mae: 0.1124\n",
      "Epoch 862/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0230 - mae: 0.1089\n",
      "Epoch 863/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0230 - mae: 0.1076\n",
      "Epoch 864/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0243 - mae: 0.1121\n",
      "Epoch 865/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0251 - mae: 0.1148\n",
      "Epoch 866/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0244 - mae: 0.1136\n",
      "Epoch 867/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0248 - mae: 0.1134\n",
      "Epoch 868/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0264 - mae: 0.1185\n",
      "Epoch 869/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0235 - mae: 0.1102\n",
      "Epoch 870/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0233 - mae: 0.1093\n",
      "Epoch 871/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0240 - mae: 0.1125\n",
      "Epoch 872/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0268 - mae: 0.1195\n",
      "Epoch 873/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0235 - mae: 0.1103\n",
      "Epoch 874/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0278 - mae: 0.1216\n",
      "Epoch 875/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0252 - mae: 0.1149\n",
      "Epoch 876/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0232 - mae: 0.1095\n",
      "Epoch 877/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0236 - mae: 0.1104\n",
      "Epoch 878/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0241 - mae: 0.1137\n",
      "Epoch 879/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0230 - mae: 0.1089\n",
      "Epoch 880/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0239 - mae: 0.1107\n",
      "Epoch 881/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0235 - mae: 0.1105\n",
      "Epoch 882/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0238 - mae: 0.1112\n",
      "Epoch 883/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0232 - mae: 0.1089\n",
      "Epoch 884/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0225 - mae: 0.1074\n",
      "Epoch 885/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0225 - mae: 0.1083\n",
      "Epoch 886/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0229 - mae: 0.1087\n",
      "Epoch 887/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0241 - mae: 0.1124\n",
      "Epoch 888/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0239 - mae: 0.1115\n",
      "Epoch 889/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0228 - mae: 0.1085\n",
      "Epoch 890/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0230 - mae: 0.1088\n",
      "Epoch 891/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0235 - mae: 0.1100\n",
      "Epoch 892/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0236 - mae: 0.1107\n",
      "Epoch 893/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0230 - mae: 0.1093\n",
      "Epoch 894/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0230 - mae: 0.1085\n",
      "Epoch 895/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0234 - mae: 0.1095\n",
      "Epoch 896/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0229 - mae: 0.1073\n",
      "Epoch 897/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0231 - mae: 0.1089\n",
      "Epoch 898/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0227 - mae: 0.1086\n",
      "Epoch 899/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0228 - mae: 0.1092\n",
      "Epoch 900/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0239 - mae: 0.1126\n",
      "Epoch 901/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0221 - mae: 0.1065\n",
      "Epoch 902/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0259 - mae: 0.1170\n",
      "Epoch 903/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0237 - mae: 0.1111\n",
      "Epoch 904/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0225 - mae: 0.1075\n",
      "Epoch 905/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0223 - mae: 0.1070\n",
      "Epoch 906/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0223 - mae: 0.1070\n",
      "Epoch 907/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0235 - mae: 0.1104\n",
      "Epoch 908/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0247 - mae: 0.1144\n",
      "Epoch 909/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0246 - mae: 0.1147\n",
      "Epoch 910/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0240 - mae: 0.1134\n",
      "Epoch 911/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0226 - mae: 0.1080\n",
      "Epoch 912/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0234 - mae: 0.1105\n",
      "Epoch 913/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0217 - mae: 0.1052\n",
      "Epoch 914/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0217 - mae: 0.1045\n",
      "Epoch 915/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0229 - mae: 0.1085\n",
      "Epoch 916/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0239 - mae: 0.1124\n",
      "Epoch 917/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0236 - mae: 0.1102\n",
      "Epoch 918/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0248 - mae: 0.1153\n",
      "Epoch 919/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0239 - mae: 0.1128\n",
      "Epoch 920/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0247 - mae: 0.1145\n",
      "Epoch 921/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0239 - mae: 0.1126\n",
      "Epoch 922/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0279 - mae: 0.1242\n",
      "Epoch 923/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0241 - mae: 0.1122\n",
      "Epoch 924/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0241 - mae: 0.1122\n",
      "Epoch 925/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0227 - mae: 0.1087\n",
      "Epoch 926/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0228 - mae: 0.1094\n",
      "Epoch 927/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0228 - mae: 0.1097\n",
      "Epoch 928/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0221 - mae: 0.1064\n",
      "Epoch 929/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0261 - mae: 0.1197\n",
      "Epoch 930/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0228 - mae: 0.1095\n",
      "Epoch 931/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0225 - mae: 0.1075\n",
      "Epoch 932/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0222 - mae: 0.1080\n",
      "Epoch 933/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0222 - mae: 0.1063\n",
      "Epoch 934/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0219 - mae: 0.1065\n",
      "Epoch 935/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0220 - mae: 0.1062\n",
      "Epoch 936/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0248 - mae: 0.1150\n",
      "Epoch 937/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0255 - mae: 0.1173\n",
      "Epoch 938/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0216 - mae: 0.1046\n",
      "Epoch 939/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0221 - mae: 0.1057\n",
      "Epoch 940/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0228 - mae: 0.1088\n",
      "Epoch 941/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0223 - mae: 0.1079\n",
      "Epoch 942/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0254 - mae: 0.1151\n",
      "Epoch 943/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0240 - mae: 0.1120\n",
      "Epoch 944/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0246 - mae: 0.1112\n",
      "Epoch 945/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0264 - mae: 0.1183\n",
      "Epoch 946/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0244 - mae: 0.1137\n",
      "Epoch 947/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0221 - mae: 0.1066\n",
      "Epoch 948/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0278 - mae: 0.1227\n",
      "Epoch 949/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0256 - mae: 0.1152\n",
      "Epoch 950/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0252 - mae: 0.1150\n",
      "Epoch 951/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0240 - mae: 0.1116\n",
      "Epoch 952/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0232 - mae: 0.1091\n",
      "Epoch 953/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0239 - mae: 0.1123\n",
      "Epoch 954/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0227 - mae: 0.1070\n",
      "Epoch 955/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0236 - mae: 0.1116\n",
      "Epoch 956/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0231 - mae: 0.1109\n",
      "Epoch 957/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0221 - mae: 0.1057\n",
      "Epoch 958/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0220 - mae: 0.1062\n",
      "Epoch 959/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0239 - mae: 0.1126\n",
      "Epoch 960/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1058\n",
      "Epoch 961/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0228 - mae: 0.1089\n",
      "Epoch 962/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0222 - mae: 0.1070\n",
      "Epoch 963/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0226 - mae: 0.1084\n",
      "Epoch 964/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0215 - mae: 0.1050\n",
      "Epoch 965/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0215 - mae: 0.1057\n",
      "Epoch 966/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0225 - mae: 0.1083\n",
      "Epoch 967/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0226 - mae: 0.1086\n",
      "Epoch 968/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0243 - mae: 0.1136\n",
      "Epoch 969/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0221 - mae: 0.1076\n",
      "Epoch 970/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0253 - mae: 0.1152\n",
      "Epoch 971/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0226 - mae: 0.1080\n",
      "Epoch 972/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0241 - mae: 0.1129\n",
      "Epoch 973/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0227 - mae: 0.1092\n",
      "Epoch 974/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0225 - mae: 0.1086\n",
      "Epoch 975/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0237 - mae: 0.1118\n",
      "Epoch 976/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0233 - mae: 0.1115\n",
      "Epoch 977/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0229 - mae: 0.1088\n",
      "Epoch 978/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0222 - mae: 0.1065\n",
      "Epoch 979/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0217 - mae: 0.1050\n",
      "Epoch 980/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0238 - mae: 0.1115\n",
      "Epoch 981/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0232 - mae: 0.1111\n",
      "Epoch 982/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0219 - mae: 0.1047\n",
      "Epoch 983/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0219 - mae: 0.1066\n",
      "Epoch 984/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0253 - mae: 0.1168\n",
      "Epoch 985/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0231 - mae: 0.1096\n",
      "Epoch 986/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0216 - mae: 0.1052\n",
      "Epoch 987/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0220 - mae: 0.1070\n",
      "Epoch 988/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0225 - mae: 0.1084\n",
      "Epoch 989/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0241 - mae: 0.1123\n",
      "Epoch 990/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0263 - mae: 0.1189\n",
      "Epoch 991/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0225 - mae: 0.1085\n",
      "Epoch 992/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0223 - mae: 0.1068\n",
      "Epoch 993/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0222 - mae: 0.1071\n",
      "Epoch 994/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0216 - mae: 0.1046\n",
      "Epoch 995/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0494 - mae: 0.1390\n",
      "Epoch 996/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0283 - mae: 0.1258\n",
      "Epoch 997/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0251 - mae: 0.1152\n",
      "Epoch 998/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0238 - mae: 0.1102\n",
      "Epoch 999/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0233 - mae: 0.1088\n",
      "Epoch 1000/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0230 - mae: 0.1083\n",
      "Epoch 1001/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0226 - mae: 0.1069\n",
      "Epoch 1002/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0229 - mae: 0.1087\n",
      "Epoch 1003/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0225 - mae: 0.1070\n",
      "Epoch 1004/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0227 - mae: 0.1068\n",
      "Epoch 1005/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0225 - mae: 0.1075\n",
      "Epoch 1006/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0233 - mae: 0.1090\n",
      "Epoch 1007/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0224 - mae: 0.1071\n",
      "Epoch 1008/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0222 - mae: 0.1074\n",
      "Epoch 1009/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0232 - mae: 0.1102\n",
      "Epoch 1010/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0237 - mae: 0.1120\n",
      "Epoch 1011/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0225 - mae: 0.1071\n",
      "Epoch 1012/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0244 - mae: 0.1124\n",
      "Epoch 1013/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0217 - mae: 0.1046\n",
      "Epoch 1014/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0218 - mae: 0.1058\n",
      "Epoch 1015/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0240 - mae: 0.1110\n",
      "Epoch 1016/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0222 - mae: 0.1075\n",
      "Epoch 1017/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0216 - mae: 0.1049\n",
      "Epoch 1018/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0221 - mae: 0.1076\n",
      "Epoch 1019/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0228 - mae: 0.1098\n",
      "Epoch 1020/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0221 - mae: 0.1069\n",
      "Epoch 1021/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0230 - mae: 0.1097\n",
      "Epoch 1022/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0239 - mae: 0.1130\n",
      "Epoch 1023/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0220 - mae: 0.1072\n",
      "Epoch 1024/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1062\n",
      "Epoch 1025/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0229 - mae: 0.1104\n",
      "Epoch 1026/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0239 - mae: 0.1134\n",
      "Epoch 1027/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0228 - mae: 0.1104\n",
      "Epoch 1028/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0223 - mae: 0.1086\n",
      "Epoch 1029/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0222 - mae: 0.1081\n",
      "Epoch 1030/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0218 - mae: 0.1067\n",
      "Epoch 1031/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0222 - mae: 0.1068\n",
      "Epoch 1032/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0229 - mae: 0.1091\n",
      "Epoch 1033/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0232 - mae: 0.1107\n",
      "Epoch 1034/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0221 - mae: 0.1072\n",
      "Epoch 1035/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0215 - mae: 0.1053\n",
      "Epoch 1036/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0220 - mae: 0.1068\n",
      "Epoch 1037/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0213 - mae: 0.1052\n",
      "Epoch 1038/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0221 - mae: 0.1062\n",
      "Epoch 1039/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0220 - mae: 0.1067\n",
      "Epoch 1040/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0228 - mae: 0.1089\n",
      "Epoch 1041/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0221 - mae: 0.1078\n",
      "Epoch 1042/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0215 - mae: 0.1057\n",
      "Epoch 1043/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0216 - mae: 0.1054\n",
      "Epoch 1044/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0222 - mae: 0.1076\n",
      "Epoch 1045/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0215 - mae: 0.1048\n",
      "Epoch 1046/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0212 - mae: 0.1052\n",
      "Epoch 1047/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0225 - mae: 0.1097\n",
      "Epoch 1048/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0218 - mae: 0.1082\n",
      "Epoch 1049/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0222 - mae: 0.1084\n",
      "Epoch 1050/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0216 - mae: 0.1051\n",
      "Epoch 1051/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0221 - mae: 0.1072\n",
      "Epoch 1052/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0217 - mae: 0.1057\n",
      "Epoch 1053/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0206 - mae: 0.1029\n",
      "Epoch 1054/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0237 - mae: 0.1120\n",
      "Epoch 1055/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0215 - mae: 0.1060\n",
      "Epoch 1056/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0220 - mae: 0.1070\n",
      "Epoch 1057/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0217 - mae: 0.1062\n",
      "Epoch 1058/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0215 - mae: 0.1059\n",
      "Epoch 1059/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0214 - mae: 0.1044\n",
      "Epoch 1060/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0238 - mae: 0.1114\n",
      "Epoch 1061/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0211 - mae: 0.1055\n",
      "Epoch 1062/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0215 - mae: 0.1057\n",
      "Epoch 1063/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0212 - mae: 0.1036\n",
      "Epoch 1064/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0214 - mae: 0.1056\n",
      "Epoch 1065/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0219 - mae: 0.1063\n",
      "Epoch 1066/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0212 - mae: 0.1050\n",
      "Epoch 1067/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0204 - mae: 0.1023\n",
      "Epoch 1068/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0208 - mae: 0.1039\n",
      "Epoch 1069/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0231 - mae: 0.1111\n",
      "Epoch 1070/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0219 - mae: 0.1070\n",
      "Epoch 1071/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0220 - mae: 0.1067\n",
      "Epoch 1072/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0203 - mae: 0.1013\n",
      "Epoch 1073/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0216 - mae: 0.1058\n",
      "Epoch 1074/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0223 - mae: 0.1086\n",
      "Epoch 1075/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0206 - mae: 0.1033\n",
      "Epoch 1076/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0213 - mae: 0.1053\n",
      "Epoch 1077/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0230 - mae: 0.1098\n",
      "Epoch 1078/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0212 - mae: 0.1050\n",
      "Epoch 1079/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0200 - mae: 0.1009\n",
      "Epoch 1080/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0200 - mae: 0.1006\n",
      "Epoch 1081/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0206 - mae: 0.1027\n",
      "Epoch 1082/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0215 - mae: 0.1052\n",
      "Epoch 1083/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0208 - mae: 0.1052\n",
      "Epoch 1084/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0286 - mae: 0.1265\n",
      "Epoch 1085/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0219 - mae: 0.1079\n",
      "Epoch 1086/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0237 - mae: 0.1111\n",
      "Epoch 1087/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0215 - mae: 0.1058\n",
      "Epoch 1088/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0209 - mae: 0.1037\n",
      "Epoch 1089/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0208 - mae: 0.1030\n",
      "Epoch 1090/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0235 - mae: 0.1114\n",
      "Epoch 1091/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0230 - mae: 0.1106\n",
      "Epoch 1092/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0211 - mae: 0.1050\n",
      "Epoch 1093/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0210 - mae: 0.1046\n",
      "Epoch 1094/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0203 - mae: 0.1024\n",
      "Epoch 1095/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0202 - mae: 0.1014\n",
      "Epoch 1096/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0211 - mae: 0.1045\n",
      "Epoch 1097/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0207 - mae: 0.1033\n",
      "Epoch 1098/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0198 - mae: 0.1006\n",
      "Epoch 1099/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0216 - mae: 0.1059\n",
      "Epoch 1100/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0209 - mae: 0.1032\n",
      "Epoch 1101/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0230 - mae: 0.1093\n",
      "Epoch 1102/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0222 - mae: 0.1087\n",
      "Epoch 1103/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0217 - mae: 0.1067\n",
      "Epoch 1104/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0229 - mae: 0.1109\n",
      "Epoch 1105/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0203 - mae: 0.1028\n",
      "Epoch 1106/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0214 - mae: 0.1058\n",
      "Epoch 1107/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0225 - mae: 0.1089\n",
      "Epoch 1108/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0207 - mae: 0.1028\n",
      "Epoch 1109/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0208 - mae: 0.1036\n",
      "Epoch 1110/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0205 - mae: 0.1035\n",
      "Epoch 1111/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0213 - mae: 0.1062\n",
      "Epoch 1112/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0238 - mae: 0.1124\n",
      "Epoch 1113/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0217 - mae: 0.1072\n",
      "Epoch 1114/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0223 - mae: 0.1085\n",
      "Epoch 1115/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0223 - mae: 0.1085\n",
      "Epoch 1116/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0274 - mae: 0.1213\n",
      "Epoch 1117/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0205 - mae: 0.1025\n",
      "Epoch 1118/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0212 - mae: 0.1047\n",
      "Epoch 1119/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0217 - mae: 0.1078\n",
      "Epoch 1120/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1055\n",
      "Epoch 1121/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0218 - mae: 0.1073\n",
      "Epoch 1122/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0241 - mae: 0.1147\n",
      "Epoch 1123/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0221 - mae: 0.1079\n",
      "Epoch 1124/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0222 - mae: 0.1077\n",
      "Epoch 1125/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0207 - mae: 0.1034\n",
      "Epoch 1126/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0221 - mae: 0.1083\n",
      "Epoch 1127/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0209 - mae: 0.1049\n",
      "Epoch 1128/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0210 - mae: 0.1053\n",
      "Epoch 1129/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0212 - mae: 0.1045\n",
      "Epoch 1130/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0202 - mae: 0.1027\n",
      "Epoch 1131/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1013\n",
      "Epoch 1132/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0205 - mae: 0.1037\n",
      "Epoch 1133/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0205 - mae: 0.1044\n",
      "Epoch 1134/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0216 - mae: 0.1065\n",
      "Epoch 1135/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0207 - mae: 0.1042\n",
      "Epoch 1136/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0211 - mae: 0.1054\n",
      "Epoch 1137/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1014\n",
      "Epoch 1138/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0216 - mae: 0.1074\n",
      "Epoch 1139/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0213 - mae: 0.1056\n",
      "Epoch 1140/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0205 - mae: 0.1036\n",
      "Epoch 1141/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0199 - mae: 0.1021\n",
      "Epoch 1142/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0203 - mae: 0.1027\n",
      "Epoch 1143/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0202 - mae: 0.1030\n",
      "Epoch 1144/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0202 - mae: 0.1024\n",
      "Epoch 1145/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0208 - mae: 0.1038\n",
      "Epoch 1146/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0209 - mae: 0.1044\n",
      "Epoch 1147/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0197 - mae: 0.1007\n",
      "Epoch 1148/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0203 - mae: 0.1034\n",
      "Epoch 1149/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0213 - mae: 0.1063\n",
      "Epoch 1150/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0223 - mae: 0.1086\n",
      "Epoch 1151/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0212 - mae: 0.1044\n",
      "Epoch 1152/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0220 - mae: 0.1073\n",
      "Epoch 1153/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0211 - mae: 0.1058\n",
      "Epoch 1154/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0215 - mae: 0.1066\n",
      "Epoch 1155/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0216 - mae: 0.1069\n",
      "Epoch 1156/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0207 - mae: 0.1033\n",
      "Epoch 1157/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0213 - mae: 0.1061\n",
      "Epoch 1158/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0214 - mae: 0.1055\n",
      "Epoch 1159/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0203 - mae: 0.1022\n",
      "Epoch 1160/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0205 - mae: 0.1038\n",
      "Epoch 1161/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0237 - mae: 0.1123\n",
      "Epoch 1162/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0203 - mae: 0.1023\n",
      "Epoch 1163/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0205 - mae: 0.1041\n",
      "Epoch 1164/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0203 - mae: 0.1025\n",
      "Epoch 1165/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0211 - mae: 0.1058\n",
      "Epoch 1166/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0214 - mae: 0.1063\n",
      "Epoch 1167/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0203 - mae: 0.1038\n",
      "Epoch 1168/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0212 - mae: 0.1052\n",
      "Epoch 1169/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0204 - mae: 0.1035\n",
      "Epoch 1170/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0204 - mae: 0.1027\n",
      "Epoch 1171/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0199 - mae: 0.1019\n",
      "Epoch 1172/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0227 - mae: 0.1107\n",
      "Epoch 1173/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0199 - mae: 0.1017\n",
      "Epoch 1174/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0199 - mae: 0.1014\n",
      "Epoch 1175/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0210 - mae: 0.1042\n",
      "Epoch 1176/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0202 - mae: 0.1028\n",
      "Epoch 1177/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0203 - mae: 0.1025\n",
      "Epoch 1178/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0219 - mae: 0.1076\n",
      "Epoch 1179/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0209 - mae: 0.1051\n",
      "Epoch 1180/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0214 - mae: 0.1055\n",
      "Epoch 1181/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0223 - mae: 0.1092\n",
      "Epoch 1182/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0211 - mae: 0.1055\n",
      "Epoch 1183/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0207 - mae: 0.1041\n",
      "Epoch 1184/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0201 - mae: 0.1027\n",
      "Epoch 1185/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0210 - mae: 0.1049\n",
      "Epoch 1186/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0216 - mae: 0.1066\n",
      "Epoch 1187/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0206 - mae: 0.1038\n",
      "Epoch 1188/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0209 - mae: 0.1046\n",
      "Epoch 1189/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0216 - mae: 0.1059\n",
      "Epoch 1190/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0217 - mae: 0.1076\n",
      "Epoch 1191/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0225 - mae: 0.1094\n",
      "Epoch 1192/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0209 - mae: 0.1059\n",
      "Epoch 1193/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0203 - mae: 0.1028\n",
      "Epoch 1194/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0209 - mae: 0.1054\n",
      "Epoch 1195/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0207 - mae: 0.1041\n",
      "Epoch 1196/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0205 - mae: 0.1034\n",
      "Epoch 1197/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0228 - mae: 0.1090\n",
      "Epoch 1198/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0210 - mae: 0.1040\n",
      "Epoch 1199/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0215 - mae: 0.1068\n",
      "Epoch 1200/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0208 - mae: 0.1033\n",
      "Epoch 1201/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0227 - mae: 0.1099\n",
      "Epoch 1202/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0198 - mae: 0.1015\n",
      "Epoch 1203/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0202 - mae: 0.1030\n",
      "Epoch 1204/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0198 - mae: 0.1012\n",
      "Epoch 1205/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0206 - mae: 0.1032\n",
      "Epoch 1206/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0202 - mae: 0.1017\n",
      "Epoch 1207/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1079\n",
      "Epoch 1208/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0199 - mae: 0.1024\n",
      "Epoch 1209/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0208 - mae: 0.1049\n",
      "Epoch 1210/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0196 - mae: 0.1003\n",
      "Epoch 1211/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1021\n",
      "Epoch 1212/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0211 - mae: 0.1051\n",
      "Epoch 1213/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0198 - mae: 0.1004\n",
      "Epoch 1214/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0199 - mae: 0.1017\n",
      "Epoch 1215/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0207 - mae: 0.1046\n",
      "Epoch 1216/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0204 - mae: 0.1025\n",
      "Epoch 1217/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0205 - mae: 0.1040\n",
      "Epoch 1218/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0199 - mae: 0.1010\n",
      "Epoch 1219/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0204 - mae: 0.1031\n",
      "Epoch 1220/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0215 - mae: 0.1049\n",
      "Epoch 1221/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0206 - mae: 0.1037\n",
      "Epoch 1222/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0200 - mae: 0.1025\n",
      "Epoch 1223/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0210 - mae: 0.1055\n",
      "Epoch 1224/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0213 - mae: 0.1075\n",
      "Epoch 1225/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0217 - mae: 0.1074\n",
      "Epoch 1226/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0204 - mae: 0.1039\n",
      "Epoch 1227/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0213 - mae: 0.1060\n",
      "Epoch 1228/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0203 - mae: 0.1031\n",
      "Epoch 1229/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0207 - mae: 0.1039\n",
      "Epoch 1230/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0218 - mae: 0.1087\n",
      "Epoch 1231/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0210 - mae: 0.1052\n",
      "Epoch 1232/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0215 - mae: 0.1061\n",
      "Epoch 1233/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0208 - mae: 0.1033\n",
      "Epoch 1234/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0220 - mae: 0.1075\n",
      "Epoch 1235/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0207 - mae: 0.1040\n",
      "Epoch 1236/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0214 - mae: 0.1049\n",
      "Epoch 1237/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0214 - mae: 0.1070\n",
      "Epoch 1238/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0205 - mae: 0.1038\n",
      "Epoch 1239/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0206 - mae: 0.1030\n",
      "Epoch 1240/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0221 - mae: 0.1081\n",
      "Epoch 1241/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0218 - mae: 0.1067\n",
      "Epoch 1242/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0207 - mae: 0.1033\n",
      "Epoch 1243/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0211 - mae: 0.1053\n",
      "Epoch 1244/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0203 - mae: 0.1025\n",
      "Epoch 1245/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.0999\n",
      "Epoch 1246/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0202 - mae: 0.1025\n",
      "Epoch 1247/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0207 - mae: 0.1037\n",
      "Epoch 1248/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0204 - mae: 0.1032\n",
      "Epoch 1249/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0207 - mae: 0.1040\n",
      "Epoch 1250/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0208 - mae: 0.1055\n",
      "Epoch 1251/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0208 - mae: 0.1052\n",
      "Epoch 1252/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0228 - mae: 0.1119\n",
      "Epoch 1253/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0217 - mae: 0.1071\n",
      "Epoch 1254/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0215 - mae: 0.1072\n",
      "Epoch 1255/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0196 - mae: 0.1007\n",
      "Epoch 1256/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0207 - mae: 0.1050\n",
      "Epoch 1257/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0211 - mae: 0.1058\n",
      "Epoch 1258/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0206 - mae: 0.1038\n",
      "Epoch 1259/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0211 - mae: 0.1051\n",
      "Epoch 1260/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0196 - mae: 0.1004\n",
      "Epoch 1261/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0224 - mae: 0.1089\n",
      "Epoch 1262/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0205 - mae: 0.1036\n",
      "Epoch 1263/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1016\n",
      "Epoch 1264/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0200 - mae: 0.1031\n",
      "Epoch 1265/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0197 - mae: 0.1005\n",
      "Epoch 1266/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0197 - mae: 0.1006\n",
      "Epoch 1267/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0214 - mae: 0.1067\n",
      "Epoch 1268/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0231 - mae: 0.1111\n",
      "Epoch 1269/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0231 - mae: 0.1116\n",
      "Epoch 1270/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0215 - mae: 0.1064\n",
      "Epoch 1271/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0214 - mae: 0.1053\n",
      "Epoch 1272/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0210 - mae: 0.1041\n",
      "Epoch 1273/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0214 - mae: 0.1071\n",
      "Epoch 1274/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0207 - mae: 0.1030\n",
      "Epoch 1275/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0199 - mae: 0.1013\n",
      "Epoch 1276/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0196 - mae: 0.1003\n",
      "Epoch 1277/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.1003\n",
      "Epoch 1278/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0209 - mae: 0.1054\n",
      "Epoch 1279/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0197 - mae: 0.1002\n",
      "Epoch 1280/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0201 - mae: 0.1027\n",
      "Epoch 1281/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0208 - mae: 0.1041\n",
      "Epoch 1282/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0204 - mae: 0.1032\n",
      "Epoch 1283/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0198 - mae: 0.1013\n",
      "Epoch 1284/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0197 - mae: 0.1005\n",
      "Epoch 1285/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0206 - mae: 0.1034\n",
      "Epoch 1286/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1020\n",
      "Epoch 1287/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0211 - mae: 0.1055\n",
      "Epoch 1288/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0210 - mae: 0.1044\n",
      "Epoch 1289/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0200 - mae: 0.1026\n",
      "Epoch 1290/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0198 - mae: 0.1016\n",
      "Epoch 1291/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0206 - mae: 0.1028\n",
      "Epoch 1292/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0224 - mae: 0.1099\n",
      "Epoch 1293/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0214 - mae: 0.1078\n",
      "Epoch 1294/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0207 - mae: 0.1044\n",
      "Epoch 1295/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0203 - mae: 0.1030\n",
      "Epoch 1296/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0202 - mae: 0.1031\n",
      "Epoch 1297/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0208 - mae: 0.1034\n",
      "Epoch 1298/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0220 - mae: 0.1082\n",
      "Epoch 1299/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0202 - mae: 0.1027\n",
      "Epoch 1300/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0204 - mae: 0.1036\n",
      "Epoch 1301/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0208 - mae: 0.1043\n",
      "Epoch 1302/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0196 - mae: 0.1002\n",
      "Epoch 1303/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0211 - mae: 0.1045\n",
      "Epoch 1304/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0191 - mae: 0.0986\n",
      "Epoch 1305/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0196 - mae: 0.1005\n",
      "Epoch 1306/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0202 - mae: 0.1030\n",
      "Epoch 1307/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0197 - mae: 0.1005\n",
      "Epoch 1308/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0203 - mae: 0.1034\n",
      "Epoch 1309/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1028\n",
      "Epoch 1310/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0234 - mae: 0.1110\n",
      "Epoch 1311/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0196 - mae: 0.1000\n",
      "Epoch 1312/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0226 - mae: 0.1097\n",
      "Epoch 1313/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0230 - mae: 0.1109\n",
      "Epoch 1314/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0205 - mae: 0.1025\n",
      "Epoch 1315/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0200 - mae: 0.1016\n",
      "Epoch 1316/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0206 - mae: 0.1027\n",
      "Epoch 1317/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0196 - mae: 0.1005\n",
      "Epoch 1318/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0197 - mae: 0.1002\n",
      "Epoch 1319/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0209 - mae: 0.1043\n",
      "Epoch 1320/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0209 - mae: 0.1053\n",
      "Epoch 1321/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0195 - mae: 0.1000\n",
      "Epoch 1322/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0198 - mae: 0.1018\n",
      "Epoch 1323/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0211 - mae: 0.1047\n",
      "Epoch 1324/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0200 - mae: 0.1015\n",
      "Epoch 1325/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0208 - mae: 0.1043\n",
      "Epoch 1326/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0213 - mae: 0.1062\n",
      "Epoch 1327/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0207 - mae: 0.1052\n",
      "Epoch 1328/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0205 - mae: 0.1047\n",
      "Epoch 1329/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0199 - mae: 0.1020\n",
      "Epoch 1330/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0190 - mae: 0.0989\n",
      "Epoch 1331/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0187 - mae: 0.0978\n",
      "Epoch 1332/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0194 - mae: 0.0996\n",
      "Epoch 1333/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0193 - mae: 0.0996\n",
      "Epoch 1334/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0197 - mae: 0.1022\n",
      "Epoch 1335/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0202 - mae: 0.1033\n",
      "Epoch 1336/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0215 - mae: 0.1071\n",
      "Epoch 1337/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.1018\n",
      "Epoch 1338/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0216 - mae: 0.1064\n",
      "Epoch 1339/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0192 - mae: 0.1002\n",
      "Epoch 1340/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.0998\n",
      "Epoch 1341/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.1007\n",
      "Epoch 1342/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0200 - mae: 0.1012\n",
      "Epoch 1343/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0210 - mae: 0.1060\n",
      "Epoch 1344/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0199 - mae: 0.1020\n",
      "Epoch 1345/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0203 - mae: 0.1038\n",
      "Epoch 1346/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0195 - mae: 0.1005\n",
      "Epoch 1347/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0197 - mae: 0.1005\n",
      "Epoch 1348/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1028\n",
      "Epoch 1349/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0197 - mae: 0.1007\n",
      "Epoch 1350/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0209 - mae: 0.1053\n",
      "Epoch 1351/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0210 - mae: 0.1069\n",
      "Epoch 1352/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0228 - mae: 0.1112\n",
      "Epoch 1353/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0238 - mae: 0.1136\n",
      "Epoch 1354/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0219 - mae: 0.1049\n",
      "Epoch 1355/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0196 - mae: 0.1009\n",
      "Epoch 1356/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0204 - mae: 0.1027\n",
      "Epoch 1357/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0213 - mae: 0.1055\n",
      "Epoch 1358/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0202 - mae: 0.1025\n",
      "Epoch 1359/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.1007\n",
      "Epoch 1360/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0216 - mae: 0.1066\n",
      "Epoch 1361/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0267 - mae: 0.1109\n",
      "Epoch 1362/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0267 - mae: 0.1204\n",
      "Epoch 1363/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0241 - mae: 0.1133\n",
      "Epoch 1364/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0236 - mae: 0.1108\n",
      "Epoch 1365/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0217 - mae: 0.1054\n",
      "Epoch 1366/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0214 - mae: 0.1046\n",
      "Epoch 1367/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0208 - mae: 0.1044\n",
      "Epoch 1368/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0215 - mae: 0.1055\n",
      "Epoch 1369/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0229 - mae: 0.1107\n",
      "Epoch 1370/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0206 - mae: 0.1032\n",
      "Epoch 1371/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0212 - mae: 0.1056\n",
      "Epoch 1372/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0203 - mae: 0.1026\n",
      "Epoch 1373/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0205 - mae: 0.1029\n",
      "Epoch 1374/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0203 - mae: 0.1029\n",
      "Epoch 1375/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0201 - mae: 0.1028\n",
      "Epoch 1376/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0200 - mae: 0.1017\n",
      "Epoch 1377/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0207 - mae: 0.1056\n",
      "Epoch 1378/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0201 - mae: 0.1033\n",
      "Epoch 1379/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0196 - mae: 0.1003\n",
      "Epoch 1380/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.1003\n",
      "Epoch 1381/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0203 - mae: 0.1022\n",
      "Epoch 1382/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0200 - mae: 0.1023\n",
      "Epoch 1383/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0207 - mae: 0.1036\n",
      "Epoch 1384/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0211 - mae: 0.1047\n",
      "Epoch 1385/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.0993\n",
      "Epoch 1386/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0190 - mae: 0.0995\n",
      "Epoch 1387/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0204 - mae: 0.1038\n",
      "Epoch 1388/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0193 - mae: 0.0996\n",
      "Epoch 1389/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0197 - mae: 0.1013\n",
      "Epoch 1390/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0196 - mae: 0.1008\n",
      "Epoch 1391/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0191 - mae: 0.0995\n",
      "Epoch 1392/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.1009\n",
      "Epoch 1393/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0196 - mae: 0.1012\n",
      "Epoch 1394/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0190 - mae: 0.0985\n",
      "Epoch 1395/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0193 - mae: 0.0995\n",
      "Epoch 1396/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0197 - mae: 0.1007\n",
      "Epoch 1397/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0193 - mae: 0.1004\n",
      "Epoch 1398/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0194 - mae: 0.1010\n",
      "Epoch 1399/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0209 - mae: 0.1041\n",
      "Epoch 1400/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0191 - mae: 0.0994\n",
      "Epoch 1401/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0194 - mae: 0.1004\n",
      "Epoch 1402/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1037\n",
      "Epoch 1403/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0206 - mae: 0.1043\n",
      "Epoch 1404/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0197 - mae: 0.1005\n",
      "Epoch 1405/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0198 - mae: 0.1025\n",
      "Epoch 1406/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.0997\n",
      "Epoch 1407/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0191 - mae: 0.0983\n",
      "Epoch 1408/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0216 - mae: 0.1070\n",
      "Epoch 1409/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0206 - mae: 0.1037\n",
      "Epoch 1410/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0194 - mae: 0.1002\n",
      "Epoch 1411/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0194 - mae: 0.1003\n",
      "Epoch 1412/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0189 - mae: 0.0986\n",
      "Epoch 1413/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0189 - mae: 0.0978\n",
      "Epoch 1414/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0196 - mae: 0.1007\n",
      "Epoch 1415/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.1008\n",
      "Epoch 1416/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0207 - mae: 0.1031\n",
      "Epoch 1417/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0194 - mae: 0.1003\n",
      "Epoch 1418/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0191 - mae: 0.0999\n",
      "Epoch 1419/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0192 - mae: 0.0988\n",
      "Epoch 1420/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0198 - mae: 0.1012\n",
      "Epoch 1421/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0209 - mae: 0.1038\n",
      "Epoch 1422/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0214 - mae: 0.1068\n",
      "Epoch 1423/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0190 - mae: 0.0989\n",
      "Epoch 1424/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0214 - mae: 0.1073\n",
      "Epoch 1425/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.1010\n",
      "Epoch 1426/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0205 - mae: 0.1042\n",
      "Epoch 1427/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0211 - mae: 0.1054\n",
      "Epoch 1428/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.0997\n",
      "Epoch 1429/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0189 - mae: 0.0996\n",
      "Epoch 1430/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0206 - mae: 0.1046\n",
      "Epoch 1431/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0191 - mae: 0.1000\n",
      "Epoch 1432/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0188 - mae: 0.0987\n",
      "Epoch 1433/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0194 - mae: 0.1001\n",
      "Epoch 1434/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0196 - mae: 0.1002\n",
      "Epoch 1435/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.0990\n",
      "Epoch 1436/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0209 - mae: 0.1049\n",
      "Epoch 1437/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0199 - mae: 0.1020\n",
      "Epoch 1438/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0239 - mae: 0.1132\n",
      "Epoch 1439/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0203 - mae: 0.1032\n",
      "Epoch 1440/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0203 - mae: 0.1035\n",
      "Epoch 1441/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0198 - mae: 0.1018\n",
      "Epoch 1442/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0188 - mae: 0.0983\n",
      "Epoch 1443/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0190 - mae: 0.0993\n",
      "Epoch 1444/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.1011\n",
      "Epoch 1445/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0203 - mae: 0.1031\n",
      "Epoch 1446/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0229 - mae: 0.1104\n",
      "Epoch 1447/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0189 - mae: 0.0994\n",
      "Epoch 1448/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0187 - mae: 0.0988\n",
      "Epoch 1449/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0195 - mae: 0.1011\n",
      "Epoch 1450/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.1001\n",
      "Epoch 1451/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0200 - mae: 0.1035\n",
      "Epoch 1452/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0206 - mae: 0.1041\n",
      "Epoch 1453/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0193 - mae: 0.1000\n",
      "Epoch 1454/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0195 - mae: 0.1008\n",
      "Epoch 1455/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0191 - mae: 0.0996\n",
      "Epoch 1456/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0191 - mae: 0.0992\n",
      "Epoch 1457/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.0985\n",
      "Epoch 1458/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0186 - mae: 0.0980\n",
      "Epoch 1459/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0192 - mae: 0.1011\n",
      "Epoch 1460/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0196 - mae: 0.1008\n",
      "Epoch 1461/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.1013\n",
      "Epoch 1462/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0193 - mae: 0.1006\n",
      "Epoch 1463/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0194 - mae: 0.1011\n",
      "Epoch 1464/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0220 - mae: 0.1085\n",
      "Epoch 1465/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0197 - mae: 0.1015\n",
      "Epoch 1466/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0198 - mae: 0.1018\n",
      "Epoch 1467/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0192 - mae: 0.1002\n",
      "Epoch 1468/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.1000\n",
      "Epoch 1469/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0199 - mae: 0.1017\n",
      "Epoch 1470/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0208 - mae: 0.1044\n",
      "Epoch 1471/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0211 - mae: 0.1057\n",
      "Epoch 1472/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0258 - mae: 0.1156\n",
      "Epoch 1473/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0281 - mae: 0.1207\n",
      "Epoch 1474/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0233 - mae: 0.1106\n",
      "Epoch 1475/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0225 - mae: 0.1086\n",
      "Epoch 1476/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0209 - mae: 0.1046\n",
      "Epoch 1477/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0207 - mae: 0.1044\n",
      "Epoch 1478/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0206 - mae: 0.1032\n",
      "Epoch 1479/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0199 - mae: 0.1017\n",
      "Epoch 1480/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0206 - mae: 0.1044\n",
      "Epoch 1481/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0198 - mae: 0.1012\n",
      "Epoch 1482/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0198 - mae: 0.1018\n",
      "Epoch 1483/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0202 - mae: 0.1032\n",
      "Epoch 1484/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0198 - mae: 0.1016\n",
      "Epoch 1485/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0198 - mae: 0.1020\n",
      "Epoch 1486/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0193 - mae: 0.1000\n",
      "Epoch 1487/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0202 - mae: 0.1028\n",
      "Epoch 1488/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0197 - mae: 0.1011\n",
      "Epoch 1489/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0195 - mae: 0.1006\n",
      "Epoch 1490/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0201 - mae: 0.1023\n",
      "Epoch 1491/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0190 - mae: 0.0995\n",
      "Epoch 1492/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0196 - mae: 0.1010\n",
      "Epoch 1493/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.1008\n",
      "Epoch 1494/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0208 - mae: 0.1048\n",
      "Epoch 1495/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0202 - mae: 0.1031\n",
      "Epoch 1496/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0193 - mae: 0.0997\n",
      "Epoch 1497/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0201 - mae: 0.1021\n",
      "Epoch 1498/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0194 - mae: 0.1002\n",
      "Epoch 1499/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0225 - mae: 0.1092\n",
      "Epoch 1500/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0197 - mae: 0.1017\n",
      "Epoch 1501/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0191 - mae: 0.0994\n",
      "Epoch 1502/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0194 - mae: 0.1007\n",
      "Epoch 1503/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0207 - mae: 0.1049\n",
      "Epoch 1504/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.1011\n",
      "Epoch 1505/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.0995\n",
      "Epoch 1506/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0197 - mae: 0.1010\n",
      "Epoch 1507/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0205 - mae: 0.1042\n",
      "Epoch 1508/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0198 - mae: 0.1017\n",
      "Epoch 1509/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0190 - mae: 0.0991\n",
      "Epoch 1510/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0192 - mae: 0.0998\n",
      "Epoch 1511/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1028\n",
      "Epoch 1512/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0204 - mae: 0.1024\n",
      "Epoch 1513/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0194 - mae: 0.0996\n",
      "Epoch 1514/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0205 - mae: 0.1049\n",
      "Epoch 1515/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1087\n",
      "Epoch 1516/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0201 - mae: 0.1020\n",
      "Epoch 1517/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0194 - mae: 0.1000\n",
      "Epoch 1518/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0199 - mae: 0.1025\n",
      "Epoch 1519/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0208 - mae: 0.1044\n",
      "Epoch 1520/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0189 - mae: 0.0979\n",
      "Epoch 1521/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0189 - mae: 0.0983\n",
      "Epoch 1522/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0209 - mae: 0.1050\n",
      "Epoch 1523/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0196 - mae: 0.1010\n",
      "Epoch 1524/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0209 - mae: 0.1054\n",
      "Epoch 1525/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0198 - mae: 0.1010\n",
      "Epoch 1526/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.0984\n",
      "Epoch 1527/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0190 - mae: 0.0991\n",
      "Epoch 1528/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0190 - mae: 0.0992\n",
      "Epoch 1529/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0189 - mae: 0.0991\n",
      "Epoch 1530/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0190 - mae: 0.0987\n",
      "Epoch 1531/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0190 - mae: 0.1002\n",
      "Epoch 1532/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0191 - mae: 0.0999\n",
      "Epoch 1533/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0192 - mae: 0.1008\n",
      "Epoch 1534/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0188 - mae: 0.0987\n",
      "Epoch 1535/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0189 - mae: 0.0995\n",
      "Epoch 1536/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0192 - mae: 0.0995\n",
      "Epoch 1537/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0194 - mae: 0.1009\n",
      "Epoch 1538/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0190 - mae: 0.0989\n",
      "Epoch 1539/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0196 - mae: 0.1002\n",
      "Epoch 1540/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0189 - mae: 0.0989\n",
      "Epoch 1541/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0186 - mae: 0.0977\n",
      "Epoch 1542/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0971\n",
      "Epoch 1543/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0977\n",
      "Epoch 1544/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0192 - mae: 0.1002\n",
      "Epoch 1545/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0208 - mae: 0.1045\n",
      "Epoch 1546/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0190 - mae: 0.1004\n",
      "Epoch 1547/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0985\n",
      "Epoch 1548/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0187 - mae: 0.0990\n",
      "Epoch 1549/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0196 - mae: 0.1010\n",
      "Epoch 1550/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0981\n",
      "Epoch 1551/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0187 - mae: 0.0986\n",
      "Epoch 1552/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0197 - mae: 0.1013\n",
      "Epoch 1553/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0193 - mae: 0.1008\n",
      "Epoch 1554/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0196 - mae: 0.1010\n",
      "Epoch 1555/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.1007\n",
      "Epoch 1556/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0984\n",
      "Epoch 1557/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0187 - mae: 0.0998\n",
      "Epoch 1558/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0211 - mae: 0.1046\n",
      "Epoch 1559/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0192 - mae: 0.1006\n",
      "Epoch 1560/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0190 - mae: 0.0988\n",
      "Epoch 1561/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0215 - mae: 0.1059\n",
      "Epoch 1562/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0189 - mae: 0.0992\n",
      "Epoch 1563/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0192 - mae: 0.1002\n",
      "Epoch 1564/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.1002\n",
      "Epoch 1565/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.1012\n",
      "Epoch 1566/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0184 - mae: 0.0974\n",
      "Epoch 1567/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0196 - mae: 0.1010\n",
      "Epoch 1568/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0193 - mae: 0.1008\n",
      "Epoch 1569/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.0988\n",
      "Epoch 1570/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0187 - mae: 0.0977\n",
      "Epoch 1571/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0183 - mae: 0.0968\n",
      "Epoch 1572/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0196 - mae: 0.1006\n",
      "Epoch 1573/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0187 - mae: 0.0985\n",
      "Epoch 1574/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0198 - mae: 0.1012\n",
      "Epoch 1575/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0189 - mae: 0.0989\n",
      "Epoch 1576/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0235 - mae: 0.1112\n",
      "Epoch 1577/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0210 - mae: 0.1054\n",
      "Epoch 1578/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.1004\n",
      "Epoch 1579/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0192 - mae: 0.0994\n",
      "Epoch 1580/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0192 - mae: 0.0996\n",
      "Epoch 1581/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0190 - mae: 0.0990\n",
      "Epoch 1582/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0188 - mae: 0.0973\n",
      "Epoch 1583/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0206 - mae: 0.1053\n",
      "Epoch 1584/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0187 - mae: 0.0986\n",
      "Epoch 1585/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0212 - mae: 0.1066\n",
      "Epoch 1586/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0197 - mae: 0.1011\n",
      "Epoch 1587/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0189 - mae: 0.0986\n",
      "Epoch 1588/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0198 - mae: 0.1022\n",
      "Epoch 1589/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0186 - mae: 0.0977\n",
      "Epoch 1590/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0951\n",
      "Epoch 1591/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0198 - mae: 0.1015\n",
      "Epoch 1592/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0197 - mae: 0.1001\n",
      "Epoch 1593/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0183 - mae: 0.0967\n",
      "Epoch 1594/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0184 - mae: 0.0971\n",
      "Epoch 1595/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0182 - mae: 0.0969\n",
      "Epoch 1596/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0179 - mae: 0.0950\n",
      "Epoch 1597/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0178 - mae: 0.0954\n",
      "Epoch 1598/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0200 - mae: 0.1020\n",
      "Epoch 1599/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0208 - mae: 0.1038\n",
      "Epoch 1600/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0190 - mae: 0.0995\n",
      "Epoch 1601/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.0990\n",
      "Epoch 1602/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0221 - mae: 0.1089\n",
      "Epoch 1603/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0227 - mae: 0.1105\n",
      "Epoch 1604/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0208 - mae: 0.1041\n",
      "Epoch 1605/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0197 - mae: 0.1007\n",
      "Epoch 1606/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0191 - mae: 0.0998\n",
      "Epoch 1607/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0196 - mae: 0.1009\n",
      "Epoch 1608/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0984\n",
      "Epoch 1609/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0189 - mae: 0.0998\n",
      "Epoch 1610/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0195 - mae: 0.1007\n",
      "Epoch 1611/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0181 - mae: 0.0967\n",
      "Epoch 1612/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0185 - mae: 0.0978\n",
      "Epoch 1613/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0213 - mae: 0.1056\n",
      "Epoch 1614/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0197 - mae: 0.1007\n",
      "Epoch 1615/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0190 - mae: 0.0992\n",
      "Epoch 1616/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0189 - mae: 0.0988\n",
      "Epoch 1617/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0219 - mae: 0.1078\n",
      "Epoch 1618/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0191 - mae: 0.0987\n",
      "Epoch 1619/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0187 - mae: 0.0977\n",
      "Epoch 1620/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0215 - mae: 0.1060\n",
      "Epoch 1621/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0187 - mae: 0.0987\n",
      "Epoch 1622/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0182 - mae: 0.0975\n",
      "Epoch 1623/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0179 - mae: 0.0960\n",
      "Epoch 1624/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0182 - mae: 0.0961\n",
      "Epoch 1625/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0983\n",
      "Epoch 1626/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0191 - mae: 0.0995\n",
      "Epoch 1627/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0194 - mae: 0.1006\n",
      "Epoch 1628/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0187 - mae: 0.0982\n",
      "Epoch 1629/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0190 - mae: 0.0996\n",
      "Epoch 1630/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0390 - mae: 0.1483\n",
      "Epoch 1631/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0238 - mae: 0.1142\n",
      "Epoch 1632/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0223 - mae: 0.1091\n",
      "Epoch 1633/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0206 - mae: 0.1048\n",
      "Epoch 1634/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0198 - mae: 0.1015\n",
      "Epoch 1635/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0206 - mae: 0.1040\n",
      "Epoch 1636/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0199 - mae: 0.1019\n",
      "Epoch 1637/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0201 - mae: 0.1026\n",
      "Epoch 1638/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0204 - mae: 0.1037\n",
      "Epoch 1639/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0201 - mae: 0.1014\n",
      "Epoch 1640/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0194 - mae: 0.0999\n",
      "Epoch 1641/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0194 - mae: 0.0996\n",
      "Epoch 1642/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0206 - mae: 0.1032\n",
      "Epoch 1643/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0183 - mae: 0.0965\n",
      "Epoch 1644/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0184 - mae: 0.0975\n",
      "Epoch 1645/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0193 - mae: 0.0994\n",
      "Epoch 1646/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0183 - mae: 0.0974\n",
      "Epoch 1647/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0188 - mae: 0.0984\n",
      "Epoch 1648/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0186 - mae: 0.0975\n",
      "Epoch 1649/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0182 - mae: 0.0964\n",
      "Epoch 1650/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0194 - mae: 0.0997\n",
      "Epoch 1651/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.1009\n",
      "Epoch 1652/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0182 - mae: 0.0961\n",
      "Epoch 1653/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0188 - mae: 0.0990\n",
      "Epoch 1654/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0185 - mae: 0.0980\n",
      "Epoch 1655/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0210 - mae: 0.1054\n",
      "Epoch 1656/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0197 - mae: 0.1019\n",
      "Epoch 1657/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0199 - mae: 0.1022\n",
      "Epoch 1658/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0190 - mae: 0.0996\n",
      "Epoch 1659/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0196 - mae: 0.1016\n",
      "Epoch 1660/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0190 - mae: 0.0993\n",
      "Epoch 1661/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0975\n",
      "Epoch 1662/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.0976\n",
      "Epoch 1663/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.0970\n",
      "Epoch 1664/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0178 - mae: 0.0948\n",
      "Epoch 1665/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0192 - mae: 0.0993\n",
      "Epoch 1666/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0966\n",
      "Epoch 1667/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0213 - mae: 0.1065\n",
      "Epoch 1668/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0980\n",
      "Epoch 1669/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0190 - mae: 0.0988\n",
      "Epoch 1670/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0195 - mae: 0.0998\n",
      "Epoch 1671/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0180 - mae: 0.0968\n",
      "Epoch 1672/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0187 - mae: 0.0984\n",
      "Epoch 1673/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0197 - mae: 0.1021\n",
      "Epoch 1674/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0199 - mae: 0.1018\n",
      "Epoch 1675/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0197 - mae: 0.1023\n",
      "Epoch 1676/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0196 - mae: 0.0996\n",
      "Epoch 1677/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0183 - mae: 0.0960\n",
      "Epoch 1678/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0977\n",
      "Epoch 1679/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0196 - mae: 0.1018\n",
      "Epoch 1680/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0198 - mae: 0.1022\n",
      "Epoch 1681/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0196 - mae: 0.1009\n",
      "Epoch 1682/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0194 - mae: 0.1003\n",
      "Epoch 1683/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0198 - mae: 0.1016\n",
      "Epoch 1684/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0194 - mae: 0.1004\n",
      "Epoch 1685/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0196 - mae: 0.1007\n",
      "Epoch 1686/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0183 - mae: 0.0964\n",
      "Epoch 1687/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.1000\n",
      "Epoch 1688/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0968\n",
      "Epoch 1689/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0186 - mae: 0.0974\n",
      "Epoch 1690/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0186 - mae: 0.0977\n",
      "Epoch 1691/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0179 - mae: 0.0968\n",
      "Epoch 1692/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.1004\n",
      "Epoch 1693/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0211 - mae: 0.1042\n",
      "Epoch 1694/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0196 - mae: 0.1019\n",
      "Epoch 1695/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0182 - mae: 0.0961\n",
      "Epoch 1696/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0990\n",
      "Epoch 1697/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0982\n",
      "Epoch 1698/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0191 - mae: 0.0994\n",
      "Epoch 1699/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0190 - mae: 0.0993\n",
      "Epoch 1700/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0192 - mae: 0.0994\n",
      "Epoch 1701/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0201 - mae: 0.1020\n",
      "Epoch 1702/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0196 - mae: 0.1000\n",
      "Epoch 1703/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0213 - mae: 0.1060\n",
      "Epoch 1704/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0210 - mae: 0.1050\n",
      "Epoch 1705/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0210 - mae: 0.1063\n",
      "Epoch 1706/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.1003\n",
      "Epoch 1707/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0191 - mae: 0.0990\n",
      "Epoch 1708/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0194 - mae: 0.1011\n",
      "Epoch 1709/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0186 - mae: 0.0981\n",
      "Epoch 1710/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0971\n",
      "Epoch 1711/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.0979\n",
      "Epoch 1712/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0183 - mae: 0.0969\n",
      "Epoch 1713/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0194 - mae: 0.1001\n",
      "Epoch 1714/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0193 - mae: 0.1004\n",
      "Epoch 1715/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.1014\n",
      "Epoch 1716/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0191 - mae: 0.1002\n",
      "Epoch 1717/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0183 - mae: 0.0982\n",
      "Epoch 1718/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0187 - mae: 0.0994\n",
      "Epoch 1719/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0981\n",
      "Epoch 1720/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.0996\n",
      "Epoch 1721/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0981\n",
      "Epoch 1722/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.0979\n",
      "Epoch 1723/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0186 - mae: 0.0984\n",
      "Epoch 1724/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0183 - mae: 0.0973\n",
      "Epoch 1725/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0186 - mae: 0.0978\n",
      "Epoch 1726/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0212 - mae: 0.1061\n",
      "Epoch 1727/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0180 - mae: 0.0961\n",
      "Epoch 1728/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0183 - mae: 0.0974\n",
      "Epoch 1729/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0191 - mae: 0.0997\n",
      "Epoch 1730/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0187 - mae: 0.0993\n",
      "Epoch 1731/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0179 - mae: 0.0957\n",
      "Epoch 1732/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0178 - mae: 0.0954\n",
      "Epoch 1733/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0183 - mae: 0.0976\n",
      "Epoch 1734/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0191 - mae: 0.1011\n",
      "Epoch 1735/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0181 - mae: 0.0965\n",
      "Epoch 1736/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0183 - mae: 0.0974\n",
      "Epoch 1737/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0194 - mae: 0.1002\n",
      "Epoch 1738/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0189 - mae: 0.0990\n",
      "Epoch 1739/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.0967\n",
      "Epoch 1740/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0191 - mae: 0.0999\n",
      "Epoch 1741/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1033\n",
      "Epoch 1742/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0176 - mae: 0.0947\n",
      "Epoch 1743/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0977\n",
      "Epoch 1744/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0193 - mae: 0.0999\n",
      "Epoch 1745/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0194 - mae: 0.1014\n",
      "Epoch 1746/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0182 - mae: 0.0977\n",
      "Epoch 1747/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0192 - mae: 0.1007\n",
      "Epoch 1748/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0187 - mae: 0.0975\n",
      "Epoch 1749/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0176 - mae: 0.0946\n",
      "Epoch 1750/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0199 - mae: 0.1023\n",
      "Epoch 1751/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0967\n",
      "Epoch 1752/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0183 - mae: 0.0971\n",
      "Epoch 1753/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0184 - mae: 0.0976\n",
      "Epoch 1754/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.1010\n",
      "Epoch 1755/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0183 - mae: 0.0968\n",
      "Epoch 1756/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0186 - mae: 0.0978\n",
      "Epoch 1757/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0229 - mae: 0.0974\n",
      "Epoch 1758/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0210 - mae: 0.1061\n",
      "Epoch 1759/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0198 - mae: 0.1014\n",
      "Epoch 1760/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0185 - mae: 0.0987\n",
      "Epoch 1761/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0198 - mae: 0.1025\n",
      "Epoch 1762/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0196 - mae: 0.1012\n",
      "Epoch 1763/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0195 - mae: 0.1014\n",
      "Epoch 1764/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0198 - mae: 0.1039\n",
      "Epoch 1765/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0201 - mae: 0.1025\n",
      "Epoch 1766/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0188 - mae: 0.0987\n",
      "Epoch 1767/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0187 - mae: 0.0983\n",
      "Epoch 1768/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0198 - mae: 0.1016\n",
      "Epoch 1769/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0187 - mae: 0.0983\n",
      "Epoch 1770/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0200 - mae: 0.1028\n",
      "Epoch 1771/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0187 - mae: 0.0976\n",
      "Epoch 1772/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0174 - mae: 0.0933\n",
      "Epoch 1773/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0206 - mae: 0.1034\n",
      "Epoch 1774/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0197 - mae: 0.1013\n",
      "Epoch 1775/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0966\n",
      "Epoch 1776/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0184 - mae: 0.0974\n",
      "Epoch 1777/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0181 - mae: 0.0957\n",
      "Epoch 1778/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0184 - mae: 0.0967\n",
      "Epoch 1779/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0182 - mae: 0.0964\n",
      "Epoch 1780/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0183 - mae: 0.0975\n",
      "Epoch 1781/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0179 - mae: 0.0954\n",
      "Epoch 1782/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0191 - mae: 0.1005\n",
      "Epoch 1783/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0179 - mae: 0.0967\n",
      "Epoch 1784/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0188 - mae: 0.0999\n",
      "Epoch 1785/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0191 - mae: 0.0999\n",
      "Epoch 1786/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0193 - mae: 0.0995\n",
      "Epoch 1787/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0220 - mae: 0.1055\n",
      "Epoch 1788/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0204 - mae: 0.1057\n",
      "Epoch 1789/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0205 - mae: 0.1049\n",
      "Epoch 1790/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0195 - mae: 0.1012\n",
      "Epoch 1791/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0189 - mae: 0.0995\n",
      "Epoch 1792/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0205 - mae: 0.1052\n",
      "Epoch 1793/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0198 - mae: 0.1034\n",
      "Epoch 1794/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.1021\n",
      "Epoch 1795/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0305 - mae: 0.1264\n",
      "Epoch 1796/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0264 - mae: 0.1180\n",
      "Epoch 1797/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0217 - mae: 0.1068\n",
      "Epoch 1798/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0208 - mae: 0.1038\n",
      "Epoch 1799/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0208 - mae: 0.1044\n",
      "Epoch 1800/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0198 - mae: 0.1007\n",
      "Epoch 1801/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0226 - mae: 0.1104\n",
      "Epoch 1802/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0197 - mae: 0.1003\n",
      "Epoch 1803/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0203 - mae: 0.1027\n",
      "Epoch 1804/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0201 - mae: 0.1025\n",
      "Epoch 1805/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0238 - mae: 0.1106\n",
      "Epoch 1806/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0243 - mae: 0.1131\n",
      "Epoch 1807/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0223 - mae: 0.1074\n",
      "Epoch 1808/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0214 - mae: 0.1042\n",
      "Epoch 1809/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0220 - mae: 0.1069\n",
      "Epoch 1810/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0211 - mae: 0.1046\n",
      "Epoch 1811/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0216 - mae: 0.1073\n",
      "Epoch 1812/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0203 - mae: 0.1022\n",
      "Epoch 1813/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0200 - mae: 0.1013\n",
      "Epoch 1814/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0206 - mae: 0.1036\n",
      "Epoch 1815/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0228 - mae: 0.1094\n",
      "Epoch 1816/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0209 - mae: 0.1039\n",
      "Epoch 1817/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0207 - mae: 0.1029\n",
      "Epoch 1818/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0202 - mae: 0.1014\n",
      "Epoch 1819/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0201 - mae: 0.1013\n",
      "Epoch 1820/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0196 - mae: 0.1000\n",
      "Epoch 1821/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0198 - mae: 0.1007\n",
      "Epoch 1822/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0196 - mae: 0.0996\n",
      "Epoch 1823/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0193 - mae: 0.0987\n",
      "Epoch 1824/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0218 - mae: 0.1073\n",
      "Epoch 1825/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0201 - mae: 0.1014\n",
      "Epoch 1826/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0190 - mae: 0.0987\n",
      "Epoch 1827/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0189 - mae: 0.0977\n",
      "Epoch 1828/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0191 - mae: 0.0997\n",
      "Epoch 1829/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0191 - mae: 0.0984\n",
      "Epoch 1830/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0202 - mae: 0.1021\n",
      "Epoch 1831/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0976\n",
      "Epoch 1832/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0188 - mae: 0.0976\n",
      "Epoch 1833/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0188 - mae: 0.0979\n",
      "Epoch 1834/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0183 - mae: 0.0967\n",
      "Epoch 1835/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0185 - mae: 0.0975\n",
      "Epoch 1836/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0209 - mae: 0.1043\n",
      "Epoch 1837/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0955\n",
      "Epoch 1838/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.1001\n",
      "Epoch 1839/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0180 - mae: 0.0954\n",
      "Epoch 1840/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.0980\n",
      "Epoch 1841/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0192 - mae: 0.1002\n",
      "Epoch 1842/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0214 - mae: 0.1072\n",
      "Epoch 1843/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0201 - mae: 0.1038\n",
      "Epoch 1844/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0184 - mae: 0.0977\n",
      "Epoch 1845/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0185 - mae: 0.0966\n",
      "Epoch 1846/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0189 - mae: 0.0985\n",
      "Epoch 1847/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0179 - mae: 0.0949\n",
      "Epoch 1848/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0179 - mae: 0.0954\n",
      "Epoch 1849/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0183 - mae: 0.0963\n",
      "Epoch 1850/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0187 - mae: 0.0984\n",
      "Epoch 1851/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0187 - mae: 0.0980\n",
      "Epoch 1852/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0190 - mae: 0.0988\n",
      "Epoch 1853/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0189 - mae: 0.0991\n",
      "Epoch 1854/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0184 - mae: 0.0964\n",
      "Epoch 1855/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0181 - mae: 0.0960\n",
      "Epoch 1856/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0182 - mae: 0.0967\n",
      "Epoch 1857/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0178 - mae: 0.0951\n",
      "Epoch 1858/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0183 - mae: 0.0966\n",
      "Epoch 1859/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0976\n",
      "Epoch 1860/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0186 - mae: 0.0983\n",
      "Epoch 1861/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.0971\n",
      "Epoch 1862/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0192 - mae: 0.0998\n",
      "Epoch 1863/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0192 - mae: 0.1005\n",
      "Epoch 1864/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0192 - mae: 0.0994\n",
      "Epoch 1865/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0288 - mae: 0.1249\n",
      "Epoch 1866/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0188 - mae: 0.0984\n",
      "Epoch 1867/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0180 - mae: 0.0951\n",
      "Epoch 1868/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0180 - mae: 0.0959\n",
      "Epoch 1869/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0177 - mae: 0.0937\n",
      "Epoch 1870/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0182 - mae: 0.0965\n",
      "Epoch 1871/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0174 - mae: 0.0934\n",
      "Epoch 1872/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0173 - mae: 0.0930\n",
      "Epoch 1873/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0187 - mae: 0.0981\n",
      "Epoch 1874/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0190 - mae: 0.0991\n",
      "Epoch 1875/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0191 - mae: 0.1009\n",
      "Epoch 1876/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0181 - mae: 0.0962\n",
      "Epoch 1877/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0175 - mae: 0.0944\n",
      "Epoch 1878/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0183 - mae: 0.0965\n",
      "Epoch 1879/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0183 - mae: 0.0984\n",
      "Epoch 1880/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0185 - mae: 0.0975\n",
      "Epoch 1881/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0191 - mae: 0.1000\n",
      "Epoch 1882/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0175 - mae: 0.0935\n",
      "Epoch 1883/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0179 - mae: 0.0953\n",
      "Epoch 1884/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0181 - mae: 0.0965\n",
      "Epoch 1885/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0175 - mae: 0.0944\n",
      "Epoch 1886/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0174 - mae: 0.0938\n",
      "Epoch 1887/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0178 - mae: 0.0958\n",
      "Epoch 1888/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0181 - mae: 0.0955\n",
      "Epoch 1889/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0193 - mae: 0.1003\n",
      "Epoch 1890/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0980\n",
      "Epoch 1891/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0184 - mae: 0.0966\n",
      "Epoch 1892/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0963\n",
      "Epoch 1893/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0181 - mae: 0.0967\n",
      "Epoch 1894/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0978\n",
      "Epoch 1895/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0189 - mae: 0.0984\n",
      "Epoch 1896/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0179 - mae: 0.0954\n",
      "Epoch 1897/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0171 - mae: 0.0923\n",
      "Epoch 1898/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0187 - mae: 0.0990\n",
      "Epoch 1899/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0179 - mae: 0.0958\n",
      "Epoch 1900/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0182 - mae: 0.0981\n",
      "Epoch 1901/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0176 - mae: 0.0943\n",
      "Epoch 1902/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0187 - mae: 0.0980\n",
      "Epoch 1903/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0178 - mae: 0.0959\n",
      "Epoch 1904/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0186 - mae: 0.0978\n",
      "Epoch 1905/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0177 - mae: 0.0950\n",
      "Epoch 1906/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0184 - mae: 0.0968\n",
      "Epoch 1907/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0182 - mae: 0.0962\n",
      "Epoch 1908/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0194 - mae: 0.0993\n",
      "Epoch 1909/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0190 - mae: 0.0990\n",
      "Epoch 1910/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0188 - mae: 0.1001\n",
      "Epoch 1911/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0185 - mae: 0.0987\n",
      "Epoch 1912/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0177 - mae: 0.0951\n",
      "Epoch 1913/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0184 - mae: 0.0965\n",
      "Epoch 1914/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0179 - mae: 0.0953\n",
      "Epoch 1915/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0179 - mae: 0.0956\n",
      "Epoch 1916/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0182 - mae: 0.0964\n",
      "Epoch 1917/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.1004\n",
      "Epoch 1918/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0190 - mae: 0.0984\n",
      "Epoch 1919/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0179 - mae: 0.0954\n",
      "Epoch 1920/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0179 - mae: 0.0955\n",
      "Epoch 1921/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0178 - mae: 0.0949\n",
      "Epoch 1922/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0182 - mae: 0.0975\n",
      "Epoch 1923/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0200 - mae: 0.1030\n",
      "Epoch 1924/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.1010\n",
      "Epoch 1925/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0186 - mae: 0.0982\n",
      "Epoch 1926/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0186 - mae: 0.0982\n",
      "Epoch 1927/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0183 - mae: 0.0976\n",
      "Epoch 1928/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0182 - mae: 0.0967\n",
      "Epoch 1929/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0176 - mae: 0.0950\n",
      "Epoch 1930/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0184 - mae: 0.0978\n",
      "Epoch 1931/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0181 - mae: 0.0970\n",
      "Epoch 1932/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0186 - mae: 0.0981\n",
      "Epoch 1933/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0184 - mae: 0.0973\n",
      "Epoch 1934/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0182 - mae: 0.0965\n",
      "Epoch 1935/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0185 - mae: 0.0978\n",
      "Epoch 1936/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0176 - mae: 0.0948\n",
      "Epoch 1937/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0194 - mae: 0.1006\n",
      "Epoch 1938/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0190 - mae: 0.0991\n",
      "Epoch 1939/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0196 - mae: 0.1015\n",
      "Epoch 1940/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0179 - mae: 0.0973\n",
      "Epoch 1941/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0175 - mae: 0.0951\n",
      "Epoch 1942/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0174 - mae: 0.0947\n",
      "Epoch 1943/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0174 - mae: 0.0947\n",
      "Epoch 1944/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0183 - mae: 0.0978\n",
      "Epoch 1945/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0191 - mae: 0.0994\n",
      "Epoch 1946/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0179 - mae: 0.0964\n",
      "Epoch 1947/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0179 - mae: 0.0959\n",
      "Epoch 1948/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0183 - mae: 0.0974\n",
      "Epoch 1949/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0177 - mae: 0.0964\n",
      "Epoch 1950/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0173 - mae: 0.0939\n",
      "Epoch 1951/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0178 - mae: 0.0960\n",
      "Epoch 1952/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0182 - mae: 0.0972\n",
      "Epoch 1953/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0177 - mae: 0.0951\n",
      "Epoch 1954/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0177 - mae: 0.0953\n",
      "Epoch 1955/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0179 - mae: 0.0959\n",
      "Epoch 1956/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0176 - mae: 0.0947\n",
      "Epoch 1957/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0179 - mae: 0.0969\n",
      "Epoch 1958/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0183 - mae: 0.0971\n",
      "Epoch 1959/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0175 - mae: 0.0945\n",
      "Epoch 1960/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0183 - mae: 0.0969\n",
      "Epoch 1961/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0177 - mae: 0.0941\n",
      "Epoch 1962/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0202 - mae: 0.1016\n",
      "Epoch 1963/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0188 - mae: 0.0999\n",
      "Epoch 1964/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0177 - mae: 0.0959\n",
      "Epoch 1965/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0187 - mae: 0.0986\n",
      "Epoch 1966/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0174 - mae: 0.0946\n",
      "Epoch 1967/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0179 - mae: 0.0959\n",
      "Epoch 1968/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0182 - mae: 0.0974\n",
      "Epoch 1969/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0187 - mae: 0.0987\n",
      "Epoch 1970/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0250 - mae: 0.1135\n",
      "Epoch 1971/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0198 - mae: 0.1016\n",
      "Epoch 1972/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0180 - mae: 0.0968\n",
      "Epoch 1973/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0186 - mae: 0.0983\n",
      "Epoch 1974/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0195 - mae: 0.1025\n",
      "Epoch 1975/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0186 - mae: 0.0991\n",
      "Epoch 1976/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0180 - mae: 0.0965\n",
      "Epoch 1977/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0183 - mae: 0.0981\n",
      "Epoch 1978/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0195 - mae: 0.1018\n",
      "Epoch 1979/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0186 - mae: 0.0993\n",
      "Epoch 1980/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0185 - mae: 0.0975\n",
      "Epoch 1981/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0179 - mae: 0.0954\n",
      "Epoch 1982/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0186 - mae: 0.0988\n",
      "Epoch 1983/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0186 - mae: 0.0988\n",
      "Epoch 1984/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0181 - mae: 0.0975\n",
      "Epoch 1985/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0182 - mae: 0.0976\n",
      "Epoch 1986/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0195 - mae: 0.1020\n",
      "Epoch 1987/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0191 - mae: 0.0996\n",
      "Epoch 1988/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0176 - mae: 0.0947\n",
      "Epoch 1989/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0170 - mae: 0.0940\n",
      "Epoch 1990/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0177 - mae: 0.0961\n",
      "Epoch 1991/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0174 - mae: 0.0947\n",
      "Epoch 1992/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0187 - mae: 0.0991\n",
      "Epoch 1993/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0185 - mae: 0.0982\n",
      "Epoch 1994/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0177 - mae: 0.0952\n",
      "Epoch 1995/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0178 - mae: 0.0952\n",
      "Epoch 1996/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0177 - mae: 0.0952\n",
      "Epoch 1997/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0182 - mae: 0.0972\n",
      "Epoch 1998/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0192 - mae: 0.0981\n",
      "Epoch 1999/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0201 - mae: 0.1037\n",
      "Epoch 2000/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0194 - mae: 0.0998\n",
      "mae: 0.09908346831798553\n",
      "Overfit mae: 0.09657461941242218\n",
      "Train on 2019 samples\n",
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 1s 593us/sample - loss: 84412.4516 - mae: 48.1796\n",
      "Epoch 2/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 10874.6984 - mae: 17.4852\n",
      "Epoch 3/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2692.3774 - mae: 12.9562\n",
      "Epoch 4/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 1846.2303 - mae: 9.5658\n",
      "Epoch 5/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 2774.1624 - mae: 10.9219\n",
      "Epoch 6/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 385.8686 - mae: 7.0532\n",
      "Epoch 7/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 354.7137 - mae: 6.3308\n",
      "Epoch 8/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 199.3852 - mae: 6.1450\n",
      "Epoch 9/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 159.6073 - mae: 4.9065\n",
      "Epoch 10/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 95.8480 - mae: 4.5207\n",
      "Epoch 11/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 355.6717 - mae: 5.3956\n",
      "Epoch 12/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 1356.3868 - mae: 6.8569\n",
      "Epoch 13/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 905.9509 - mae: 6.2521\n",
      "Epoch 14/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 3300.0653 - mae: 11.3961\n",
      "Epoch 15/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 2560.4815 - mae: 8.2717\n",
      "Epoch 16/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 21201.8688 - mae: 23.5034\n",
      "Epoch 17/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 10887.6248 - mae: 13.9448\n",
      "Epoch 18/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 9964.3436 - mae: 17.1835\n",
      "Epoch 19/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1393.0761 - mae: 8.2064\n",
      "Epoch 20/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 309.9797 - mae: 4.8604\n",
      "Epoch 21/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 2219.9243 - mae: 7.7399\n",
      "Epoch 22/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 439.0919 - mae: 5.7224\n",
      "Epoch 23/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 6190.9881 - mae: 12.0419\n",
      "Epoch 24/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 10730.9156 - mae: 15.2736\n",
      "Epoch 25/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 566.6008 - mae: 7.0240\n",
      "Epoch 26/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 2051.1370 - mae: 7.9975\n",
      "Epoch 27/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 753.1407 - mae: 6.1391\n",
      "Epoch 28/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 373.9168 - mae: 3.8016\n",
      "Epoch 29/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 9472.2521 - mae: 13.2251\n",
      "Epoch 30/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 12055.8921 - mae: 19.1297\n",
      "Epoch 31/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 1109.9318 - mae: 6.9423\n",
      "Epoch 32/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 3103.3746 - mae: 10.9985\n",
      "Epoch 33/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 3822.8501 - mae: 10.9219\n",
      "Epoch 34/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 1308.9593 - mae: 5.6719\n",
      "Epoch 35/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 8046.2759 - mae: 10.9843\n",
      "Epoch 36/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 6920.4207 - mae: 8.6348\n",
      "Epoch 37/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 5449.2015 - mae: 10.3831\n",
      "Epoch 38/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 2818.0427 - mae: 6.1195\n",
      "Epoch 39/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 316.5188 - mae: 4.0748\n",
      "Epoch 40/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 132.2242 - mae: 2.6917\n",
      "Epoch 41/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 63.2464 - mae: 2.7128\n",
      "Epoch 42/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 56.7920 - mae: 2.5290\n",
      "Epoch 43/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 48.8607 - mae: 2.4294\n",
      "Epoch 44/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 37.5935 - mae: 2.2404\n",
      "Epoch 45/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 35.6361 - mae: 2.0641\n",
      "Epoch 46/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 36.8743 - mae: 2.0693\n",
      "Epoch 47/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 35.3470 - mae: 1.9683\n",
      "Epoch 48/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 36.3970 - mae: 1.7435\n",
      "Epoch 49/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 32.3251 - mae: 1.7452\n",
      "Epoch 50/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 32.2445 - mae: 1.6239\n",
      "Epoch 51/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 21.7027 - mae: 1.5596\n",
      "Epoch 52/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 32.7169 - mae: 1.5521\n",
      "Epoch 53/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 28.0848 - mae: 1.6465\n",
      "Epoch 54/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 36.7985 - mae: 1.5213\n",
      "Epoch 55/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 28.5920 - mae: 1.3902\n",
      "Epoch 56/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 53.9754 - mae: 1.5313\n",
      "Epoch 57/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 279.5602 - mae: 2.3286\n",
      "Epoch 58/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 560.5929 - mae: 2.8482\n",
      "Epoch 59/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 952.8345 - mae: 3.8740\n",
      "Epoch 60/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 868.9664 - mae: 3.3065\n",
      "Epoch 61/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 395.1655 - mae: 2.9134\n",
      "Epoch 62/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 1219.0370 - mae: 3.8674\n",
      "Epoch 63/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 1258.2191 - mae: 4.8486\n",
      "Epoch 64/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 1681.8742 - mae: 4.7615\n",
      "Epoch 65/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 281.0420 - mae: 3.0079\n",
      "Epoch 66/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 256.9000 - mae: 2.6433\n",
      "Epoch 67/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 267.9538 - mae: 1.9754\n",
      "Epoch 68/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 301.1069 - mae: 1.9470\n",
      "Epoch 69/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 318.1823 - mae: 1.8591\n",
      "Epoch 70/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 623.9684 - mae: 2.9053\n",
      "Epoch 71/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 895.3430 - mae: 3.5435\n",
      "Epoch 72/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 1374.9153 - mae: 3.7553\n",
      "Epoch 73/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 901.2643 - mae: 2.5177\n",
      "Epoch 74/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 1166.7571 - mae: 2.7132\n",
      "Epoch 75/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 1017.2021 - mae: 2.6087\n",
      "Epoch 76/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 1407.2954 - mae: 2.4663\n",
      "Epoch 77/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 994.9984 - mae: 2.3277\n",
      "Epoch 78/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 548.9471 - mae: 2.1451\n",
      "Epoch 79/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 809.7751 - mae: 1.8618\n",
      "Epoch 80/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1330.3931 - mae: 2.7076\n",
      "Epoch 81/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1197.7716 - mae: 2.0541\n",
      "Epoch 82/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 637.3106 - mae: 2.2420\n",
      "Epoch 83/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 386.5517 - mae: 1.4633\n",
      "Epoch 84/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 9.5002 - mae: 0.9576\n",
      "Epoch 85/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 4.7077 - mae: 0.6827\n",
      "Epoch 86/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 3.7723 - mae: 0.5993\n",
      "Epoch 87/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 6.6524 - mae: 0.8392\n",
      "Epoch 88/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 4.3327 - mae: 0.7101\n",
      "Epoch 89/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 2.8528 - mae: 0.5940\n",
      "Epoch 90/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 2.9716 - mae: 0.6040\n",
      "Epoch 91/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 2.4381 - mae: 0.5328\n",
      "Epoch 92/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 3.8944 - mae: 0.7017\n",
      "Epoch 93/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 2.5571 - mae: 0.5730\n",
      "Epoch 94/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 2.5620 - mae: 0.5670\n",
      "Epoch 95/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 2.0026 - mae: 0.4998\n",
      "Epoch 96/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 1.8612 - mae: 0.4740\n",
      "Epoch 97/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 1.8455 - mae: 0.4688\n",
      "Epoch 98/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 1.7661 - mae: 0.4594\n",
      "Epoch 99/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.7541 - mae: 0.4567\n",
      "Epoch 100/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.8356 - mae: 0.4874\n",
      "Epoch 101/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.6379 - mae: 0.4601\n",
      "Epoch 102/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.5671 - mae: 0.4465\n",
      "Epoch 103/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 1.5504 - mae: 0.4350\n",
      "Epoch 104/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1.6207 - mae: 0.4560\n",
      "Epoch 105/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 1.5606 - mae: 0.4533\n",
      "Epoch 106/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 1.6701 - mae: 0.4426\n",
      "Epoch 107/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 2.6665 - mae: 0.6266\n",
      "Epoch 108/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 3.8484 - mae: 0.7384\n",
      "Epoch 109/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.5597 - mae: 0.4445\n",
      "Epoch 110/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.6283 - mae: 0.4696\n",
      "Epoch 111/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 2.0568 - mae: 0.5372\n",
      "Epoch 112/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.7625 - mae: 0.4733\n",
      "Epoch 113/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 2.2664 - mae: 0.5207\n",
      "Epoch 114/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 3.8561 - mae: 0.5029\n",
      "Epoch 115/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 11.3501 - mae: 0.6167\n",
      "Epoch 116/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 25.7954 - mae: 0.6936\n",
      "Epoch 117/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 77.4049 - mae: 0.7834\n",
      "Epoch 118/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 501.3988 - mae: 1.3569\n",
      "Epoch 119/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 1207.7452 - mae: 1.7054\n",
      "Epoch 120/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 16.4525 - mae: 1.3574\n",
      "Epoch 121/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 6.6610 - mae: 0.7595\n",
      "Epoch 122/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 5.6952 - mae: 0.6220\n",
      "Epoch 123/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 5.9937 - mae: 0.4839\n",
      "Epoch 124/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 6.9486 - mae: 0.4594\n",
      "Epoch 125/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 7.5778 - mae: 0.5158\n",
      "Epoch 126/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 6.6585 - mae: 0.4712\n",
      "Epoch 127/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 5.3704 - mae: 0.4585\n",
      "Epoch 128/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 4.0797 - mae: 0.4364\n",
      "Epoch 129/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 3.0983 - mae: 0.4135\n",
      "Epoch 130/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1.1773 - mae: 0.3617\n",
      "Epoch 131/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.9761 - mae: 0.3648\n",
      "Epoch 132/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.9228 - mae: 0.3514\n",
      "Epoch 133/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.9203 - mae: 0.3491\n",
      "Epoch 134/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.9849 - mae: 0.3627\n",
      "Epoch 135/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.8925 - mae: 0.3372\n",
      "Epoch 136/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.8406 - mae: 0.3261\n",
      "Epoch 137/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.9065 - mae: 0.3520\n",
      "Epoch 138/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.8650 - mae: 0.3330\n",
      "Epoch 139/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.8779 - mae: 0.3147\n",
      "Epoch 140/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.9927 - mae: 0.3227\n",
      "Epoch 141/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 2.8881 - mae: 0.5346\n",
      "Epoch 142/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 1.8868 - mae: 0.3569\n",
      "Epoch 143/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 4.0463 - mae: 0.4040\n",
      "Epoch 144/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 8.3595 - mae: 0.3878\n",
      "Epoch 145/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 12.8056 - mae: 0.4027\n",
      "Epoch 146/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 16.7362 - mae: 0.4491\n",
      "Epoch 147/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 14.4406 - mae: 0.4375\n",
      "Epoch 148/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 7.0491 - mae: 0.3694\n",
      "Epoch 149/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 3.2710 - mae: 0.4544\n",
      "Epoch 150/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 1.8937 - mae: 0.3718\n",
      "Epoch 151/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 1.4126 - mae: 0.3956\n",
      "Epoch 152/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.8963 - mae: 0.3003\n",
      "Epoch 153/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.7388 - mae: 0.2821\n",
      "Epoch 154/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.7278 - mae: 0.2789\n",
      "Epoch 155/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.7221 - mae: 0.2862\n",
      "Epoch 156/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.7077 - mae: 0.2751\n",
      "Epoch 157/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1.0310 - mae: 0.3465\n",
      "Epoch 158/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.7210 - mae: 0.2916\n",
      "Epoch 159/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.7963 - mae: 0.3245\n",
      "Epoch 160/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.7086 - mae: 0.2775\n",
      "Epoch 161/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.8081 - mae: 0.3144\n",
      "Epoch 162/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 1.1135 - mae: 0.3618\n",
      "Epoch 163/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.7611 - mae: 0.4767\n",
      "Epoch 164/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.9360 - mae: 0.2935\n",
      "Epoch 165/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.6391 - mae: 0.4440\n",
      "Epoch 166/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.4159 - mae: 0.3135\n",
      "Epoch 167/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 2.3950 - mae: 0.2889\n",
      "Epoch 168/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 4.1490 - mae: 0.3008\n",
      "Epoch 169/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 5.8758 - mae: 0.3206\n",
      "Epoch 170/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 8.0146 - mae: 0.3277\n",
      "Epoch 171/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 8.6692 - mae: 0.4422\n",
      "Epoch 172/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 7.1569 - mae: 0.3644\n",
      "Epoch 173/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 5.8232 - mae: 0.3129\n",
      "Epoch 174/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 3.9059 - mae: 0.3026\n",
      "Epoch 175/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 3.5268 - mae: 0.7367\n",
      "Epoch 176/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 1.3564 - mae: 0.4272\n",
      "Epoch 177/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.6883 - mae: 0.2703\n",
      "Epoch 178/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.7392 - mae: 0.3014\n",
      "Epoch 179/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.6993 - mae: 0.2719\n",
      "Epoch 180/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1.5882 - mae: 0.4669\n",
      "Epoch 181/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.8328 - mae: 0.3237\n",
      "Epoch 182/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.6750 - mae: 0.2668\n",
      "Epoch 183/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.9069 - mae: 0.3537\n",
      "Epoch 184/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.7889 - mae: 0.2929\n",
      "Epoch 185/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 1.0190 - mae: 0.3032\n",
      "Epoch 186/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.8512 - mae: 0.3133\n",
      "Epoch 187/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1.3390 - mae: 0.4335\n",
      "Epoch 188/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.8029 - mae: 0.3064\n",
      "Epoch 189/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.7226 - mae: 0.2672\n",
      "Epoch 190/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.7655 - mae: 0.2564\n",
      "Epoch 191/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.9194 - mae: 0.5316\n",
      "Epoch 192/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 1.8141 - mae: 0.3400\n",
      "Epoch 193/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 4.4802 - mae: 0.3432\n",
      "Epoch 194/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 9.8290 - mae: 0.3810\n",
      "Epoch 195/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 5.0808 - mae: 0.3181\n",
      "Epoch 196/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 17.7208 - mae: 0.4013\n",
      "Epoch 197/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 8.8926 - mae: 0.3732\n",
      "Epoch 198/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.7668 - mae: 0.5109\n",
      "Epoch 199/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 1.7846 - mae: 0.4955\n",
      "Epoch 200/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.4366 - mae: 0.4405\n",
      "Epoch 201/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.1959 - mae: 0.3800\n",
      "Epoch 202/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.7130 - mae: 0.2503\n",
      "Epoch 203/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.8572 - mae: 0.3261\n",
      "Epoch 204/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.6408 - mae: 0.2314\n",
      "Epoch 205/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.6323 - mae: 0.2265\n",
      "Epoch 206/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.6190 - mae: 0.2219\n",
      "Epoch 207/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.6992 - mae: 0.2640\n",
      "Epoch 208/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.6062 - mae: 0.2346\n",
      "Epoch 209/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5771 - mae: 0.2131\n",
      "Epoch 210/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5774 - mae: 0.2184\n",
      "Epoch 211/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5950 - mae: 0.2308\n",
      "Epoch 212/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.6257 - mae: 0.2404\n",
      "Epoch 213/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.7671 - mae: 0.2609\n",
      "Epoch 214/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.6660 - mae: 0.2702\n",
      "Epoch 215/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.6111 - mae: 0.2456\n",
      "Epoch 216/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.5585 - mae: 0.2097\n",
      "Epoch 217/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.5501 - mae: 0.2038\n",
      "Epoch 218/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5499 - mae: 0.2043\n",
      "Epoch 219/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5446 - mae: 0.1977\n",
      "Epoch 220/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5470 - mae: 0.2001\n",
      "Epoch 221/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5431 - mae: 0.1982\n",
      "Epoch 222/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5449 - mae: 0.1997\n",
      "Epoch 223/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5446 - mae: 0.1991\n",
      "Epoch 224/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.5414 - mae: 0.1985\n",
      "Epoch 225/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.5384 - mae: 0.1951\n",
      "Epoch 226/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.5368 - mae: 0.1935\n",
      "Epoch 227/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.5511 - mae: 0.2113\n",
      "Epoch 228/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.5486 - mae: 0.2046\n",
      "Epoch 229/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5369 - mae: 0.1978\n",
      "Epoch 230/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5487 - mae: 0.2093\n",
      "Epoch 231/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5443 - mae: 0.2063\n",
      "Epoch 232/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5439 - mae: 0.2052\n",
      "Epoch 233/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5939 - mae: 0.2363\n",
      "Epoch 234/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5665 - mae: 0.2250\n",
      "Epoch 235/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5332 - mae: 0.1979\n",
      "Epoch 236/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.5326 - mae: 0.1973\n",
      "Epoch 237/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.5337 - mae: 0.2007\n",
      "Epoch 238/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.5292 - mae: 0.1956\n",
      "Epoch 239/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5346 - mae: 0.2030\n",
      "Epoch 240/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.5246 - mae: 0.1923\n",
      "Epoch 241/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.5239 - mae: 0.1925\n",
      "Epoch 242/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.5628 - mae: 0.2273\n",
      "Epoch 243/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.8665 - mae: 0.3119\n",
      "Epoch 244/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.6734 - mae: 0.2909\n",
      "Epoch 245/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.8715 - mae: 0.3558\n",
      "Epoch 246/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.8475 - mae: 0.3311\n",
      "Epoch 247/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5579 - mae: 0.2314\n",
      "Epoch 248/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.5204 - mae: 0.2047\n",
      "Epoch 249/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5185 - mae: 0.2017\n",
      "Epoch 250/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5170 - mae: 0.1995\n",
      "Epoch 251/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.5164 - mae: 0.1997\n",
      "Epoch 252/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5150 - mae: 0.1983\n",
      "Epoch 253/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5136 - mae: 0.1975\n",
      "Epoch 254/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5123 - mae: 0.1959\n",
      "Epoch 255/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5111 - mae: 0.1952\n",
      "Epoch 256/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5101 - mae: 0.1943\n",
      "Epoch 257/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.5094 - mae: 0.1951\n",
      "Epoch 258/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5106 - mae: 0.1969\n",
      "Epoch 259/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.5080 - mae: 0.1946\n",
      "Epoch 260/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5071 - mae: 0.1943\n",
      "Epoch 261/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5054 - mae: 0.1936\n",
      "Epoch 262/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.5044 - mae: 0.1929\n",
      "Epoch 263/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5039 - mae: 0.1938\n",
      "Epoch 264/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5029 - mae: 0.1933\n",
      "Epoch 265/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5048 - mae: 0.1970\n",
      "Epoch 266/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5046 - mae: 0.1972\n",
      "Epoch 267/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5047 - mae: 0.1982\n",
      "Epoch 268/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4993 - mae: 0.1931\n",
      "Epoch 269/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4972 - mae: 0.1913\n",
      "Epoch 270/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.4984 - mae: 0.1942\n",
      "Epoch 271/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5048 - mae: 0.1984\n",
      "Epoch 272/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4960 - mae: 0.1930\n",
      "Epoch 273/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4942 - mae: 0.1922\n",
      "Epoch 274/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.5535 - mae: 0.2040\n",
      "Epoch 275/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.5044 - mae: 0.2028\n",
      "Epoch 276/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4942 - mae: 0.1958\n",
      "Epoch 277/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4906 - mae: 0.1915\n",
      "Epoch 278/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4888 - mae: 0.1903\n",
      "Epoch 279/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4893 - mae: 0.1917\n",
      "Epoch 280/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5012 - mae: 0.2078\n",
      "Epoch 281/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4941 - mae: 0.2003\n",
      "Epoch 282/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4879 - mae: 0.1936\n",
      "Epoch 283/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4868 - mae: 0.1941\n",
      "Epoch 284/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4903 - mae: 0.1983\n",
      "Epoch 285/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4879 - mae: 0.1991\n",
      "Epoch 286/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4914 - mae: 0.2027\n",
      "Epoch 287/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4844 - mae: 0.1969\n",
      "Epoch 288/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4857 - mae: 0.1986\n",
      "Epoch 289/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4980 - mae: 0.2104\n",
      "Epoch 290/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.4774 - mae: 0.1915\n",
      "Epoch 291/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4768 - mae: 0.1912\n",
      "Epoch 292/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.4757 - mae: 0.1911\n",
      "Epoch 293/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4829 - mae: 0.2000\n",
      "Epoch 294/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4846 - mae: 0.2024\n",
      "Epoch 295/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4719 - mae: 0.1895\n",
      "Epoch 296/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4720 - mae: 0.1927\n",
      "Epoch 297/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4696 - mae: 0.1891\n",
      "Epoch 298/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4691 - mae: 0.1904\n",
      "Epoch 299/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4676 - mae: 0.1900\n",
      "Epoch 300/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4731 - mae: 0.1976\n",
      "Epoch 301/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4924 - mae: 0.2174\n",
      "Epoch 302/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4680 - mae: 0.1953\n",
      "Epoch 303/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4648 - mae: 0.1922\n",
      "Epoch 304/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4634 - mae: 0.1916\n",
      "Epoch 305/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4655 - mae: 0.1957\n",
      "Epoch 306/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4599 - mae: 0.1912\n",
      "Epoch 307/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4583 - mae: 0.1894\n",
      "Epoch 308/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4561 - mae: 0.1885\n",
      "Epoch 309/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4547 - mae: 0.1880\n",
      "Epoch 310/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4666 - mae: 0.1986\n",
      "Epoch 311/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4560 - mae: 0.1917\n",
      "Epoch 312/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4527 - mae: 0.1903\n",
      "Epoch 313/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4495 - mae: 0.1882\n",
      "Epoch 314/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4483 - mae: 0.1877\n",
      "Epoch 315/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4467 - mae: 0.1868\n",
      "Epoch 316/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4786 - mae: 0.1941\n",
      "Epoch 317/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4462 - mae: 0.1899\n",
      "Epoch 318/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4430 - mae: 0.1879\n",
      "Epoch 319/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4420 - mae: 0.1886\n",
      "Epoch 320/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.4403 - mae: 0.1884\n",
      "Epoch 321/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4387 - mae: 0.1876\n",
      "Epoch 322/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4376 - mae: 0.1880\n",
      "Epoch 323/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4355 - mae: 0.1877\n",
      "Epoch 324/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.4332 - mae: 0.1853\n",
      "Epoch 325/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4349 - mae: 0.1883\n",
      "Epoch 326/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4310 - mae: 0.1854\n",
      "Epoch 327/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4303 - mae: 0.1884\n",
      "Epoch 328/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4281 - mae: 0.1860\n",
      "Epoch 329/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4255 - mae: 0.1838\n",
      "Epoch 330/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4252 - mae: 0.1864\n",
      "Epoch 331/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4234 - mae: 0.1866\n",
      "Epoch 332/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4223 - mae: 0.1862\n",
      "Epoch 333/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4187 - mae: 0.1829\n",
      "Epoch 334/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4190 - mae: 0.1863\n",
      "Epoch 335/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.4160 - mae: 0.1847\n",
      "Epoch 336/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4134 - mae: 0.1827\n",
      "Epoch 337/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4136 - mae: 0.1848\n",
      "Epoch 338/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4116 - mae: 0.1848\n",
      "Epoch 339/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.4094 - mae: 0.1845\n",
      "Epoch 340/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.4126 - mae: 0.1930\n",
      "Epoch 341/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4056 - mae: 0.1841\n",
      "Epoch 342/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4031 - mae: 0.1824\n",
      "Epoch 343/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4015 - mae: 0.1830\n",
      "Epoch 344/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3989 - mae: 0.1817\n",
      "Epoch 345/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3978 - mae: 0.1828\n",
      "Epoch 346/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3952 - mae: 0.1812\n",
      "Epoch 347/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3938 - mae: 0.1813\n",
      "Epoch 348/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.3908 - mae: 0.1802\n",
      "Epoch 349/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3901 - mae: 0.1815\n",
      "Epoch 350/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3870 - mae: 0.1802\n",
      "Epoch 351/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3855 - mae: 0.1800\n",
      "Epoch 352/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.3830 - mae: 0.1796\n",
      "Epoch 353/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3827 - mae: 0.1821\n",
      "Epoch 354/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3795 - mae: 0.1815\n",
      "Epoch 355/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3780 - mae: 0.1807\n",
      "Epoch 356/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3750 - mae: 0.1794\n",
      "Epoch 357/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.3728 - mae: 0.1795\n",
      "Epoch 358/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3704 - mae: 0.1780\n",
      "Epoch 359/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3707 - mae: 0.1824\n",
      "Epoch 360/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3662 - mae: 0.1783\n",
      "Epoch 361/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3640 - mae: 0.1774\n",
      "Epoch 362/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3621 - mae: 0.1782\n",
      "Epoch 363/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3601 - mae: 0.1782\n",
      "Epoch 364/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3580 - mae: 0.1796\n",
      "Epoch 365/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3557 - mae: 0.1785\n",
      "Epoch 366/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3519 - mae: 0.1756\n",
      "Epoch 367/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.3524 - mae: 0.1778\n",
      "Epoch 368/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.3526 - mae: 0.1828\n",
      "Epoch 369/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3458 - mae: 0.1767\n",
      "Epoch 370/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3425 - mae: 0.1748\n",
      "Epoch 371/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3405 - mae: 0.1756\n",
      "Epoch 372/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3376 - mae: 0.1738\n",
      "Epoch 373/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3355 - mae: 0.1742\n",
      "Epoch 374/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3336 - mae: 0.1752\n",
      "Epoch 375/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3316 - mae: 0.1762\n",
      "Epoch 376/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3280 - mae: 0.1740\n",
      "Epoch 377/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4669 - mae: 0.1926\n",
      "Epoch 378/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3394 - mae: 0.1963\n",
      "Epoch 379/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3266 - mae: 0.1831\n",
      "Epoch 380/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3219 - mae: 0.1774\n",
      "Epoch 381/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3196 - mae: 0.1753\n",
      "Epoch 382/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3186 - mae: 0.1802\n",
      "Epoch 383/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3143 - mae: 0.1747\n",
      "Epoch 384/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3128 - mae: 0.1757\n",
      "Epoch 385/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3090 - mae: 0.1735\n",
      "Epoch 386/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3060 - mae: 0.1717\n",
      "Epoch 387/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3036 - mae: 0.1708\n",
      "Epoch 388/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3009 - mae: 0.1710\n",
      "Epoch 389/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2984 - mae: 0.1700\n",
      "Epoch 390/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.2977 - mae: 0.1738\n",
      "Epoch 391/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2942 - mae: 0.1716\n",
      "Epoch 392/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2922 - mae: 0.1720\n",
      "Epoch 393/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2885 - mae: 0.1696\n",
      "Epoch 394/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2854 - mae: 0.1682\n",
      "Epoch 395/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2861 - mae: 0.1716\n",
      "Epoch 396/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2826 - mae: 0.1711\n",
      "Epoch 397/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2787 - mae: 0.1687\n",
      "Epoch 398/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2814 - mae: 0.1783\n",
      "Epoch 399/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2770 - mae: 0.1739\n",
      "Epoch 400/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2750 - mae: 0.1765\n",
      "Epoch 401/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.2696 - mae: 0.1699\n",
      "Epoch 402/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2670 - mae: 0.1699\n",
      "Epoch 403/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.2659 - mae: 0.1748\n",
      "Epoch 404/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2604 - mae: 0.1688\n",
      "Epoch 405/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2575 - mae: 0.1673\n",
      "Epoch 406/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2547 - mae: 0.1667\n",
      "Epoch 407/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2545 - mae: 0.1729\n",
      "Epoch 408/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2503 - mae: 0.1676\n",
      "Epoch 409/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2464 - mae: 0.1653\n",
      "Epoch 410/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2457 - mae: 0.1702\n",
      "Epoch 411/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2413 - mae: 0.1669\n",
      "Epoch 412/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.2383 - mae: 0.1655\n",
      "Epoch 413/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2350 - mae: 0.1644\n",
      "Epoch 414/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.2342 - mae: 0.1678\n",
      "Epoch 415/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2295 - mae: 0.1637\n",
      "Epoch 416/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2274 - mae: 0.1649\n",
      "Epoch 417/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2244 - mae: 0.1647\n",
      "Epoch 418/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2247 - mae: 0.1703\n",
      "Epoch 419/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2218 - mae: 0.1691\n",
      "Epoch 420/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2170 - mae: 0.1649\n",
      "Epoch 421/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2213 - mae: 0.1757\n",
      "Epoch 422/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2127 - mae: 0.1681\n",
      "Epoch 423/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.2078 - mae: 0.1637\n",
      "Epoch 424/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2047 - mae: 0.1630\n",
      "Epoch 425/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.2019 - mae: 0.1629\n",
      "Epoch 426/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1992 - mae: 0.1637\n",
      "Epoch 427/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1958 - mae: 0.1619\n",
      "Epoch 428/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1929 - mae: 0.1609\n",
      "Epoch 429/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1922 - mae: 0.1660\n",
      "Epoch 430/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1889 - mae: 0.1640\n",
      "Epoch 431/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1853 - mae: 0.1621\n",
      "Epoch 432/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1828 - mae: 0.1620\n",
      "Epoch 433/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1787 - mae: 0.1584\n",
      "Epoch 434/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.1773 - mae: 0.1606\n",
      "Epoch 435/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1750 - mae: 0.1612\n",
      "Epoch 436/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.1721 - mae: 0.1620\n",
      "Epoch 437/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1686 - mae: 0.1597\n",
      "Epoch 438/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1665 - mae: 0.1610\n",
      "Epoch 439/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1640 - mae: 0.1622\n",
      "Epoch 440/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1599 - mae: 0.1580\n",
      "Epoch 441/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1580 - mae: 0.1597\n",
      "Epoch 442/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1556 - mae: 0.1602\n",
      "Epoch 443/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1514 - mae: 0.1571\n",
      "Epoch 444/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1506 - mae: 0.1613\n",
      "Epoch 445/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1486 - mae: 0.1635\n",
      "Epoch 446/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1521 - mae: 0.1724\n",
      "Epoch 447/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1436 - mae: 0.1606\n",
      "Epoch 448/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1394 - mae: 0.1581\n",
      "Epoch 449/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1375 - mae: 0.1597\n",
      "Epoch 450/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1343 - mae: 0.1569\n",
      "Epoch 451/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.1326 - mae: 0.1586\n",
      "Epoch 452/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.1287 - mae: 0.1555\n",
      "Epoch 453/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.1271 - mae: 0.1572\n",
      "Epoch 454/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.1258 - mae: 0.1609\n",
      "Epoch 455/2000\n",
      "2019/2019 [==============================] - 0s 99us/sample - loss: 0.1233 - mae: 0.1589\n",
      "Epoch 456/2000\n",
      "2019/2019 [==============================] - 0s 100us/sample - loss: 0.1194 - mae: 0.1558\n",
      "Epoch 457/2000\n",
      "2019/2019 [==============================] - 0s 105us/sample - loss: 0.1177 - mae: 0.1552\n",
      "Epoch 458/2000\n",
      "2019/2019 [==============================] - 0s 99us/sample - loss: 0.1160 - mae: 0.1584\n",
      "Epoch 459/2000\n",
      "2019/2019 [==============================] - 0s 101us/sample - loss: 0.1128 - mae: 0.1556\n",
      "Epoch 460/2000\n",
      "2019/2019 [==============================] - 0s 101us/sample - loss: 0.1100 - mae: 0.1534\n",
      "Epoch 461/2000\n",
      "2019/2019 [==============================] - 0s 95us/sample - loss: 0.1081 - mae: 0.1548\n",
      "Epoch 462/2000\n",
      "2019/2019 [==============================] - 0s 100us/sample - loss: 0.1081 - mae: 0.1589\n",
      "Epoch 463/2000\n",
      "2019/2019 [==============================] - 0s 102us/sample - loss: 0.1040 - mae: 0.1544\n",
      "Epoch 464/2000\n",
      "2019/2019 [==============================] - 0s 102us/sample - loss: 0.1032 - mae: 0.1573\n",
      "Epoch 465/2000\n",
      "2019/2019 [==============================] - 0s 95us/sample - loss: 0.0998 - mae: 0.1548\n",
      "Epoch 466/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0983 - mae: 0.1549\n",
      "Epoch 467/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0963 - mae: 0.1557\n",
      "Epoch 468/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0949 - mae: 0.1566\n",
      "Epoch 469/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0919 - mae: 0.1537\n",
      "Epoch 470/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0916 - mae: 0.1554\n",
      "Epoch 471/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0904 - mae: 0.1571\n",
      "Epoch 472/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0873 - mae: 0.1520\n",
      "Epoch 473/2000\n",
      "2019/2019 [==============================] - 0s 96us/sample - loss: 0.0851 - mae: 0.1514\n",
      "Epoch 474/2000\n",
      "2019/2019 [==============================] - 0s 92us/sample - loss: 0.0832 - mae: 0.1518\n",
      "Epoch 475/2000\n",
      "2019/2019 [==============================] - 0s 102us/sample - loss: 0.0817 - mae: 0.1513\n",
      "Epoch 476/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0810 - mae: 0.1534\n",
      "Epoch 477/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0801 - mae: 0.1571\n",
      "Epoch 478/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0765 - mae: 0.1498\n",
      "Epoch 479/2000\n",
      "2019/2019 [==============================] - 0s 92us/sample - loss: 0.0751 - mae: 0.1504\n",
      "Epoch 480/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0877 - mae: 0.1785\n",
      "Epoch 481/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0801 - mae: 0.1680\n",
      "Epoch 482/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0763 - mae: 0.1633\n",
      "Epoch 483/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0725 - mae: 0.1577\n",
      "Epoch 484/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0686 - mae: 0.1527\n",
      "Epoch 485/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0661 - mae: 0.1492\n",
      "Epoch 486/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0659 - mae: 0.1518\n",
      "Epoch 487/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0643 - mae: 0.1509\n",
      "Epoch 488/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0631 - mae: 0.1498\n",
      "Epoch 489/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0621 - mae: 0.1495\n",
      "Epoch 490/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0600 - mae: 0.1471\n",
      "Epoch 491/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0580 - mae: 0.1465\n",
      "Epoch 492/2000\n",
      "2019/2019 [==============================] - 0s 92us/sample - loss: 0.0573 - mae: 0.1452\n",
      "Epoch 493/2000\n",
      "2019/2019 [==============================] - 0s 94us/sample - loss: 0.0563 - mae: 0.1464\n",
      "Epoch 494/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0544 - mae: 0.1436\n",
      "Epoch 495/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0576 - mae: 0.1527\n",
      "Epoch 496/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0541 - mae: 0.1455\n",
      "Epoch 497/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0541 - mae: 0.1465\n",
      "Epoch 498/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0536 - mae: 0.1486\n",
      "Epoch 499/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0564 - mae: 0.1524\n",
      "Epoch 500/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0556 - mae: 0.1536\n",
      "Epoch 501/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0509 - mae: 0.1453\n",
      "Epoch 502/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0526 - mae: 0.1497\n",
      "Epoch 503/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0524 - mae: 0.1518\n",
      "Epoch 504/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0495 - mae: 0.1466\n",
      "Epoch 505/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0486 - mae: 0.1455\n",
      "Epoch 506/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0490 - mae: 0.1487\n",
      "Epoch 507/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0503 - mae: 0.1508\n",
      "Epoch 508/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0462 - mae: 0.1433\n",
      "Epoch 509/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0467 - mae: 0.1460\n",
      "Epoch 510/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0455 - mae: 0.1455\n",
      "Epoch 511/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0457 - mae: 0.1468\n",
      "Epoch 512/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0442 - mae: 0.1434\n",
      "Epoch 513/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0424 - mae: 0.1393\n",
      "Epoch 514/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0446 - mae: 0.1468\n",
      "Epoch 515/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0412 - mae: 0.1386\n",
      "Epoch 516/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0424 - mae: 0.1416\n",
      "Epoch 517/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0416 - mae: 0.1411\n",
      "Epoch 518/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0414 - mae: 0.1413\n",
      "Epoch 519/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0415 - mae: 0.1418\n",
      "Epoch 520/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0397 - mae: 0.1392\n",
      "Epoch 521/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0394 - mae: 0.1380\n",
      "Epoch 522/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0400 - mae: 0.1415\n",
      "Epoch 523/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0419 - mae: 0.1448\n",
      "Epoch 524/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0394 - mae: 0.1394\n",
      "Epoch 525/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0380 - mae: 0.1369\n",
      "Epoch 526/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0398 - mae: 0.1421\n",
      "Epoch 527/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0394 - mae: 0.1392\n",
      "Epoch 528/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0379 - mae: 0.1388\n",
      "Epoch 529/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0370 - mae: 0.1359\n",
      "Epoch 530/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0476 - mae: 0.1477\n",
      "Epoch 531/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0388 - mae: 0.1397\n",
      "Epoch 532/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0384 - mae: 0.1396\n",
      "Epoch 533/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0420 - mae: 0.1461\n",
      "Epoch 534/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0382 - mae: 0.1394\n",
      "Epoch 535/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0389 - mae: 0.1410\n",
      "Epoch 536/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0367 - mae: 0.1370\n",
      "Epoch 537/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0375 - mae: 0.1396\n",
      "Epoch 538/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0404 - mae: 0.1452\n",
      "Epoch 539/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0453 - mae: 0.1550\n",
      "Epoch 540/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0372 - mae: 0.1388\n",
      "Epoch 541/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0389 - mae: 0.1437\n",
      "Epoch 542/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0357 - mae: 0.1370\n",
      "Epoch 543/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0350 - mae: 0.1344\n",
      "Epoch 544/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0348 - mae: 0.1339\n",
      "Epoch 545/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0351 - mae: 0.1351\n",
      "Epoch 546/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0346 - mae: 0.1330\n",
      "Epoch 547/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0374 - mae: 0.1395\n",
      "Epoch 548/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0347 - mae: 0.1349\n",
      "Epoch 549/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0337 - mae: 0.1314\n",
      "Epoch 550/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0388 - mae: 0.1423\n",
      "Epoch 551/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0355 - mae: 0.1367\n",
      "Epoch 552/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0336 - mae: 0.1321\n",
      "Epoch 553/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0333 - mae: 0.1295\n",
      "Epoch 554/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0418 - mae: 0.1455\n",
      "Epoch 555/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0413 - mae: 0.1475\n",
      "Epoch 556/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0373 - mae: 0.1385\n",
      "Epoch 557/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0360 - mae: 0.1371\n",
      "Epoch 558/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0384 - mae: 0.1405\n",
      "Epoch 559/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0347 - mae: 0.1334\n",
      "Epoch 560/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0346 - mae: 0.1333\n",
      "Epoch 561/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0342 - mae: 0.1336\n",
      "Epoch 562/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0360 - mae: 0.1371\n",
      "Epoch 563/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0332 - mae: 0.1299\n",
      "Epoch 564/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0334 - mae: 0.1314\n",
      "Epoch 565/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0326 - mae: 0.1287\n",
      "Epoch 566/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0323 - mae: 0.1293\n",
      "Epoch 567/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0341 - mae: 0.1330\n",
      "Epoch 568/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0319 - mae: 0.1289\n",
      "Epoch 569/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0331 - mae: 0.1312\n",
      "Epoch 570/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0329 - mae: 0.1311\n",
      "Epoch 571/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0317 - mae: 0.1270\n",
      "Epoch 572/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0327 - mae: 0.1304\n",
      "Epoch 573/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0324 - mae: 0.1302\n",
      "Epoch 574/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0349 - mae: 0.1357\n",
      "Epoch 575/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0313 - mae: 0.1268\n",
      "Epoch 576/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0320 - mae: 0.1280\n",
      "Epoch 577/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0312 - mae: 0.1262\n",
      "Epoch 578/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0311 - mae: 0.1251\n",
      "Epoch 579/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0308 - mae: 0.1248\n",
      "Epoch 580/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0332 - mae: 0.1304\n",
      "Epoch 581/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0306 - mae: 0.1265\n",
      "Epoch 582/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0302 - mae: 0.1250\n",
      "Epoch 583/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0295 - mae: 0.1219\n",
      "Epoch 584/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0292 - mae: 0.1224\n",
      "Epoch 585/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0300 - mae: 0.1237\n",
      "Epoch 586/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0310 - mae: 0.1272\n",
      "Epoch 587/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0289 - mae: 0.1206\n",
      "Epoch 588/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0294 - mae: 0.1224\n",
      "Epoch 589/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0287 - mae: 0.1216\n",
      "Epoch 590/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0281 - mae: 0.1193\n",
      "Epoch 591/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0282 - mae: 0.1204\n",
      "Epoch 592/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0302 - mae: 0.1250\n",
      "Epoch 593/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0288 - mae: 0.1222\n",
      "Epoch 594/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0279 - mae: 0.1194\n",
      "Epoch 595/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0276 - mae: 0.1183\n",
      "Epoch 596/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0289 - mae: 0.1219\n",
      "Epoch 597/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0283 - mae: 0.1209\n",
      "Epoch 598/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0303 - mae: 0.1259\n",
      "Epoch 599/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0290 - mae: 0.1234\n",
      "Epoch 600/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0289 - mae: 0.1218\n",
      "Epoch 601/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0280 - mae: 0.1202\n",
      "Epoch 602/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0293 - mae: 0.1233\n",
      "Epoch 603/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0281 - mae: 0.1201\n",
      "Epoch 604/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0276 - mae: 0.1190\n",
      "Epoch 605/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0320 - mae: 0.1288\n",
      "Epoch 606/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0283 - mae: 0.1210\n",
      "Epoch 607/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0289 - mae: 0.1212\n",
      "Epoch 608/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0285 - mae: 0.1211\n",
      "Epoch 609/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0280 - mae: 0.1196\n",
      "Epoch 610/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0275 - mae: 0.1189\n",
      "Epoch 611/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0326 - mae: 0.1314\n",
      "Epoch 612/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0273 - mae: 0.1198\n",
      "Epoch 613/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0265 - mae: 0.1162\n",
      "Epoch 614/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0279 - mae: 0.1208\n",
      "Epoch 615/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0266 - mae: 0.1162\n",
      "Epoch 616/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0264 - mae: 0.1162\n",
      "Epoch 617/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0268 - mae: 0.1182\n",
      "Epoch 618/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0274 - mae: 0.1193\n",
      "Epoch 619/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0278 - mae: 0.1192\n",
      "Epoch 620/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0273 - mae: 0.1190\n",
      "Epoch 621/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0281 - mae: 0.1208\n",
      "Epoch 622/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0268 - mae: 0.1172\n",
      "Epoch 623/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0264 - mae: 0.1165\n",
      "Epoch 624/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0280 - mae: 0.1199\n",
      "Epoch 625/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0277 - mae: 0.1210\n",
      "Epoch 626/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0269 - mae: 0.1180\n",
      "Epoch 627/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0260 - mae: 0.1149\n",
      "Epoch 628/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0260 - mae: 0.1155\n",
      "Epoch 629/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0269 - mae: 0.1181\n",
      "Epoch 630/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0302 - mae: 0.1263\n",
      "Epoch 631/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0295 - mae: 0.1245\n",
      "Epoch 632/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0261 - mae: 0.1150\n",
      "Epoch 633/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0257 - mae: 0.1140\n",
      "Epoch 634/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0261 - mae: 0.1149\n",
      "Epoch 635/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0275 - mae: 0.1209\n",
      "Epoch 636/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0252 - mae: 0.1129\n",
      "Epoch 637/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0262 - mae: 0.1140\n",
      "Epoch 638/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0293 - mae: 0.1234\n",
      "Epoch 639/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0260 - mae: 0.1145\n",
      "Epoch 640/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0261 - mae: 0.1151\n",
      "Epoch 641/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0269 - mae: 0.1169\n",
      "Epoch 642/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0257 - mae: 0.1147\n",
      "Epoch 643/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0261 - mae: 0.1166\n",
      "Epoch 644/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0261 - mae: 0.1153\n",
      "Epoch 645/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0277 - mae: 0.1183\n",
      "Epoch 646/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0269 - mae: 0.1183\n",
      "Epoch 647/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0267 - mae: 0.1178\n",
      "Epoch 648/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0257 - mae: 0.1137\n",
      "Epoch 649/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0249 - mae: 0.1118\n",
      "Epoch 650/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0250 - mae: 0.1125\n",
      "Epoch 651/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0248 - mae: 0.1126\n",
      "Epoch 652/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0249 - mae: 0.1134\n",
      "Epoch 653/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0272 - mae: 0.1176\n",
      "Epoch 654/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0260 - mae: 0.1157\n",
      "Epoch 655/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0270 - mae: 0.1184\n",
      "Epoch 656/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0242 - mae: 0.1118\n",
      "Epoch 657/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0248 - mae: 0.1124\n",
      "Epoch 658/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0267 - mae: 0.1173\n",
      "Epoch 659/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0253 - mae: 0.1135\n",
      "Epoch 660/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0262 - mae: 0.1153\n",
      "Epoch 661/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0259 - mae: 0.1157\n",
      "Epoch 662/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0249 - mae: 0.1118\n",
      "Epoch 663/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0254 - mae: 0.1143\n",
      "Epoch 664/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0243 - mae: 0.1115\n",
      "Epoch 665/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0247 - mae: 0.1118\n",
      "Epoch 666/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0242 - mae: 0.1102\n",
      "Epoch 667/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0244 - mae: 0.1109\n",
      "Epoch 668/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0256 - mae: 0.1146\n",
      "Epoch 669/2000\n",
      "2019/2019 [==============================] - 0s 153us/sample - loss: 0.0246 - mae: 0.1115\n",
      "Epoch 670/2000\n",
      "2019/2019 [==============================] - 0s 113us/sample - loss: 0.0277 - mae: 0.1178\n",
      "Epoch 671/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0259 - mae: 0.1145\n",
      "Epoch 672/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0248 - mae: 0.1113\n",
      "Epoch 673/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0250 - mae: 0.1126\n",
      "Epoch 674/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0243 - mae: 0.1109\n",
      "Epoch 675/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0236 - mae: 0.1093\n",
      "Epoch 676/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0246 - mae: 0.1123\n",
      "Epoch 677/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0251 - mae: 0.1135\n",
      "Epoch 678/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0240 - mae: 0.1112\n",
      "Epoch 679/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0251 - mae: 0.1120\n",
      "Epoch 680/2000\n",
      "2019/2019 [==============================] - 0s 96us/sample - loss: 0.0239 - mae: 0.1106\n",
      "Epoch 681/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0240 - mae: 0.1098\n",
      "Epoch 682/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0235 - mae: 0.1089\n",
      "Epoch 683/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0241 - mae: 0.1114\n",
      "Epoch 684/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0285 - mae: 0.1233\n",
      "Epoch 685/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0275 - mae: 0.1212\n",
      "Epoch 686/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0257 - mae: 0.1144\n",
      "Epoch 687/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0252 - mae: 0.1137\n",
      "Epoch 688/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0258 - mae: 0.1111\n",
      "Epoch 689/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0247 - mae: 0.1123\n",
      "Epoch 690/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0249 - mae: 0.1130\n",
      "Epoch 691/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0247 - mae: 0.1123\n",
      "Epoch 692/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0237 - mae: 0.1103\n",
      "Epoch 693/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0242 - mae: 0.1108\n",
      "Epoch 694/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0243 - mae: 0.1113\n",
      "Epoch 695/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0246 - mae: 0.1127\n",
      "Epoch 696/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0244 - mae: 0.1124\n",
      "Epoch 697/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0241 - mae: 0.1118\n",
      "Epoch 698/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0249 - mae: 0.1123\n",
      "Epoch 699/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0251 - mae: 0.1140\n",
      "Epoch 700/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0241 - mae: 0.1117\n",
      "Epoch 701/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0237 - mae: 0.1093\n",
      "Epoch 702/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0238 - mae: 0.1100\n",
      "Epoch 703/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0229 - mae: 0.1070\n",
      "Epoch 704/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0235 - mae: 0.1102\n",
      "Epoch 705/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0240 - mae: 0.1106\n",
      "Epoch 706/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0237 - mae: 0.1097\n",
      "Epoch 707/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0241 - mae: 0.1117\n",
      "Epoch 708/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0259 - mae: 0.1162\n",
      "Epoch 709/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0246 - mae: 0.1092\n",
      "Epoch 710/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0230 - mae: 0.1072\n",
      "Epoch 711/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0335 - mae: 0.1342\n",
      "Epoch 712/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0261 - mae: 0.1169\n",
      "Epoch 713/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0248 - mae: 0.1127\n",
      "Epoch 714/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0252 - mae: 0.1148\n",
      "Epoch 715/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0235 - mae: 0.1098\n",
      "Epoch 716/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0242 - mae: 0.1119\n",
      "Epoch 717/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0255 - mae: 0.1161\n",
      "Epoch 718/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0234 - mae: 0.1088\n",
      "Epoch 719/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0231 - mae: 0.1081\n",
      "Epoch 720/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0247 - mae: 0.1133\n",
      "Epoch 721/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0249 - mae: 0.1113\n",
      "Epoch 722/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0235 - mae: 0.1091\n",
      "Epoch 723/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0228 - mae: 0.1074\n",
      "Epoch 724/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0235 - mae: 0.1092\n",
      "Epoch 725/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0235 - mae: 0.1100\n",
      "Epoch 726/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0235 - mae: 0.1088\n",
      "Epoch 727/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0244 - mae: 0.1117\n",
      "Epoch 728/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0269 - mae: 0.1184\n",
      "Epoch 729/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0231 - mae: 0.1077\n",
      "Epoch 730/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0239 - mae: 0.1096\n",
      "Epoch 731/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0239 - mae: 0.1089\n",
      "Epoch 732/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0235 - mae: 0.1083\n",
      "Epoch 733/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0239 - mae: 0.1106\n",
      "Epoch 734/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0229 - mae: 0.1072\n",
      "Epoch 735/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0230 - mae: 0.1078\n",
      "Epoch 736/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0231 - mae: 0.1071\n",
      "Epoch 737/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0231 - mae: 0.1082\n",
      "Epoch 738/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0240 - mae: 0.1122\n",
      "Epoch 739/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0237 - mae: 0.1107\n",
      "Epoch 740/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0250 - mae: 0.1138\n",
      "Epoch 741/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0245 - mae: 0.1132\n",
      "Epoch 742/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0227 - mae: 0.1072\n",
      "Epoch 743/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0232 - mae: 0.1087\n",
      "Epoch 744/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0222 - mae: 0.1062\n",
      "Epoch 745/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0219 - mae: 0.1056\n",
      "Epoch 746/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0220 - mae: 0.1048\n",
      "Epoch 747/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0224 - mae: 0.1063\n",
      "Epoch 748/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0232 - mae: 0.1086\n",
      "Epoch 749/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0233 - mae: 0.1094\n",
      "Epoch 750/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0220 - mae: 0.1057\n",
      "Epoch 751/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0223 - mae: 0.1065\n",
      "Epoch 752/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0238 - mae: 0.1107\n",
      "Epoch 753/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0231 - mae: 0.1085\n",
      "Epoch 754/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0227 - mae: 0.1073\n",
      "Epoch 755/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0225 - mae: 0.1066\n",
      "Epoch 756/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0222 - mae: 0.1053\n",
      "Epoch 757/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0236 - mae: 0.1098\n",
      "Epoch 758/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0222 - mae: 0.1063\n",
      "Epoch 759/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0225 - mae: 0.1067\n",
      "Epoch 760/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0223 - mae: 0.1054\n",
      "Epoch 761/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0246 - mae: 0.1135\n",
      "Epoch 762/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0225 - mae: 0.1060\n",
      "Epoch 763/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0218 - mae: 0.1052\n",
      "Epoch 764/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0227 - mae: 0.1080\n",
      "Epoch 765/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0228 - mae: 0.1077\n",
      "Epoch 766/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0225 - mae: 0.1061\n",
      "Epoch 767/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0219 - mae: 0.1044\n",
      "Epoch 768/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0237 - mae: 0.1119\n",
      "Epoch 769/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0238 - mae: 0.1105\n",
      "Epoch 770/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0222 - mae: 0.1068\n",
      "Epoch 771/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0228 - mae: 0.1081\n",
      "Epoch 772/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0232 - mae: 0.1086\n",
      "Epoch 773/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0238 - mae: 0.1098\n",
      "Epoch 774/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0225 - mae: 0.1070\n",
      "Epoch 775/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0224 - mae: 0.1056\n",
      "Epoch 776/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0233 - mae: 0.1083\n",
      "Epoch 777/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0239 - mae: 0.1111\n",
      "Epoch 778/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0216 - mae: 0.1047\n",
      "Epoch 779/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0217 - mae: 0.1034\n",
      "Epoch 780/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0245 - mae: 0.1064\n",
      "Epoch 781/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0228 - mae: 0.1080\n",
      "Epoch 782/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0230 - mae: 0.1085\n",
      "Epoch 783/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0234 - mae: 0.1095\n",
      "Epoch 784/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0224 - mae: 0.1072\n",
      "Epoch 785/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0220 - mae: 0.1054\n",
      "Epoch 786/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0218 - mae: 0.1047\n",
      "Epoch 787/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0222 - mae: 0.1062\n",
      "Epoch 788/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0219 - mae: 0.1055\n",
      "Epoch 789/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0217 - mae: 0.1057\n",
      "Epoch 790/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0216 - mae: 0.1052\n",
      "Epoch 791/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0218 - mae: 0.1053\n",
      "Epoch 792/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0215 - mae: 0.1035\n",
      "Epoch 793/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0221 - mae: 0.1061\n",
      "Epoch 794/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0223 - mae: 0.1069\n",
      "Epoch 795/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0243 - mae: 0.1111\n",
      "Epoch 796/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0229 - mae: 0.1070\n",
      "Epoch 797/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0234 - mae: 0.1098\n",
      "Epoch 798/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0230 - mae: 0.1093\n",
      "Epoch 799/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0223 - mae: 0.1071\n",
      "Epoch 800/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0234 - mae: 0.1093\n",
      "Epoch 801/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0227 - mae: 0.1084\n",
      "Epoch 802/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0215 - mae: 0.1051\n",
      "Epoch 803/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0223 - mae: 0.1066\n",
      "Epoch 804/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0228 - mae: 0.1085\n",
      "Epoch 805/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0222 - mae: 0.1077\n",
      "Epoch 806/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0221 - mae: 0.1063\n",
      "Epoch 807/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0222 - mae: 0.1061\n",
      "Epoch 808/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0237 - mae: 0.1105\n",
      "Epoch 809/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0224 - mae: 0.1075\n",
      "Epoch 810/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0215 - mae: 0.1034\n",
      "Epoch 811/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0214 - mae: 0.1044\n",
      "Epoch 812/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0239 - mae: 0.1105\n",
      "Epoch 813/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0217 - mae: 0.1046\n",
      "Epoch 814/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0219 - mae: 0.1056\n",
      "Epoch 815/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0230 - mae: 0.1096\n",
      "Epoch 816/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0215 - mae: 0.1035\n",
      "Epoch 817/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0221 - mae: 0.1063\n",
      "Epoch 818/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0219 - mae: 0.1056\n",
      "Epoch 819/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0217 - mae: 0.1045\n",
      "Epoch 820/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0213 - mae: 0.1041\n",
      "Epoch 821/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0219 - mae: 0.1052\n",
      "Epoch 822/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0216 - mae: 0.1042\n",
      "Epoch 823/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0210 - mae: 0.1029\n",
      "Epoch 824/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0209 - mae: 0.1032\n",
      "Epoch 825/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0218 - mae: 0.1052\n",
      "Epoch 826/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0236 - mae: 0.1103\n",
      "Epoch 827/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0220 - mae: 0.1064\n",
      "Epoch 828/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0215 - mae: 0.1046\n",
      "Epoch 829/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0493 - mae: 0.1129\n",
      "Epoch 830/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0238 - mae: 0.1104\n",
      "Epoch 831/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0233 - mae: 0.1082\n",
      "Epoch 832/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0244 - mae: 0.1118\n",
      "Epoch 833/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0269 - mae: 0.1180\n",
      "Epoch 834/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0251 - mae: 0.1150\n",
      "Epoch 835/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0228 - mae: 0.1086\n",
      "Epoch 836/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0232 - mae: 0.1084\n",
      "Epoch 837/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0236 - mae: 0.1097\n",
      "Epoch 838/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0227 - mae: 0.1074\n",
      "Epoch 839/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0226 - mae: 0.1066\n",
      "Epoch 840/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0217 - mae: 0.1049\n",
      "Epoch 841/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0217 - mae: 0.1048\n",
      "Epoch 842/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0217 - mae: 0.1042\n",
      "Epoch 843/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0222 - mae: 0.1055\n",
      "Epoch 844/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0226 - mae: 0.1065\n",
      "Epoch 845/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0213 - mae: 0.1034\n",
      "Epoch 846/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0219 - mae: 0.1046\n",
      "Epoch 847/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0210 - mae: 0.1022\n",
      "Epoch 848/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0223 - mae: 0.1065\n",
      "Epoch 849/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0224 - mae: 0.1068\n",
      "Epoch 850/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0216 - mae: 0.1038\n",
      "Epoch 851/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0252 - mae: 0.1145\n",
      "Epoch 852/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0215 - mae: 0.1050\n",
      "Epoch 853/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0220 - mae: 0.1059\n",
      "Epoch 854/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1062\n",
      "Epoch 855/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0220 - mae: 0.1053\n",
      "Epoch 856/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0226 - mae: 0.1077\n",
      "Epoch 857/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0235 - mae: 0.1093\n",
      "Epoch 858/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0213 - mae: 0.1040\n",
      "Epoch 859/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0214 - mae: 0.1043\n",
      "Epoch 860/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0229 - mae: 0.1080\n",
      "Epoch 861/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0222 - mae: 0.1060\n",
      "Epoch 862/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0231 - mae: 0.1081\n",
      "Epoch 863/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0212 - mae: 0.1022\n",
      "Epoch 864/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0246 - mae: 0.1122\n",
      "Epoch 865/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0258 - mae: 0.1154\n",
      "Epoch 866/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0255 - mae: 0.1161\n",
      "Epoch 867/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0228 - mae: 0.1070\n",
      "Epoch 868/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0257 - mae: 0.1144\n",
      "Epoch 869/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0246 - mae: 0.1125\n",
      "Epoch 870/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0226 - mae: 0.1065\n",
      "Epoch 871/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0249 - mae: 0.1113\n",
      "Epoch 872/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0259 - mae: 0.1171\n",
      "Epoch 873/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0231 - mae: 0.1082\n",
      "Epoch 874/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0229 - mae: 0.1075\n",
      "Epoch 875/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0222 - mae: 0.1047\n",
      "Epoch 876/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0225 - mae: 0.1070\n",
      "Epoch 877/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0217 - mae: 0.1044\n",
      "Epoch 878/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0227 - mae: 0.1073\n",
      "Epoch 879/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1066\n",
      "Epoch 880/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0212 - mae: 0.1034\n",
      "Epoch 881/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1056\n",
      "Epoch 882/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0217 - mae: 0.1060\n",
      "Epoch 883/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0219 - mae: 0.1057\n",
      "Epoch 884/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0217 - mae: 0.1055\n",
      "Epoch 885/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0211 - mae: 0.1035\n",
      "Epoch 886/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0211 - mae: 0.1025\n",
      "Epoch 887/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0214 - mae: 0.1037\n",
      "Epoch 888/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0232 - mae: 0.1091\n",
      "Epoch 889/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0224 - mae: 0.1070\n",
      "Epoch 890/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0205 - mae: 0.1014\n",
      "Epoch 891/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0222 - mae: 0.1058\n",
      "Epoch 892/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0212 - mae: 0.1038\n",
      "Epoch 893/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0204 - mae: 0.1015\n",
      "Epoch 894/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0217 - mae: 0.1055\n",
      "Epoch 895/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0221 - mae: 0.1067\n",
      "Epoch 896/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0217 - mae: 0.1049\n",
      "Epoch 897/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0218 - mae: 0.1048\n",
      "Epoch 898/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0205 - mae: 0.1015\n",
      "Epoch 899/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0212 - mae: 0.1035\n",
      "Epoch 900/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0213 - mae: 0.1050\n",
      "Epoch 901/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0208 - mae: 0.1020\n",
      "Epoch 902/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0211 - mae: 0.1035\n",
      "Epoch 903/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0226 - mae: 0.1088\n",
      "Epoch 904/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0263 - mae: 0.1181\n",
      "Epoch 905/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0218 - mae: 0.1053\n",
      "Epoch 906/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0219 - mae: 0.1049\n",
      "Epoch 907/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0220 - mae: 0.1049\n",
      "Epoch 908/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0214 - mae: 0.1039\n",
      "Epoch 909/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0231 - mae: 0.1088\n",
      "Epoch 910/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0227 - mae: 0.1073\n",
      "Epoch 911/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0218 - mae: 0.1046\n",
      "Epoch 912/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0208 - mae: 0.1025\n",
      "Epoch 913/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0203 - mae: 0.1014\n",
      "Epoch 914/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0216 - mae: 0.1061\n",
      "Epoch 915/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0222 - mae: 0.1063\n",
      "Epoch 916/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0288 - mae: 0.1246\n",
      "Epoch 917/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0224 - mae: 0.1067\n",
      "Epoch 918/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0209 - mae: 0.1020\n",
      "Epoch 919/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0214 - mae: 0.1042\n",
      "Epoch 920/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0244 - mae: 0.1126\n",
      "Epoch 921/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0220 - mae: 0.1066\n",
      "Epoch 922/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0205 - mae: 0.1016\n",
      "Epoch 923/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0200 - mae: 0.1008\n",
      "Epoch 924/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0205 - mae: 0.1025\n",
      "Epoch 925/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0204 - mae: 0.1014\n",
      "Epoch 926/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0202 - mae: 0.1013\n",
      "Epoch 927/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0207 - mae: 0.1024\n",
      "Epoch 928/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0203 - mae: 0.1006\n",
      "Epoch 929/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0208 - mae: 0.1026\n",
      "Epoch 930/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0203 - mae: 0.1009\n",
      "Epoch 931/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0212 - mae: 0.1039\n",
      "Epoch 932/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0214 - mae: 0.1053\n",
      "Epoch 933/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0209 - mae: 0.1019\n",
      "Epoch 934/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0209 - mae: 0.1031\n",
      "Epoch 935/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0200 - mae: 0.1006\n",
      "Epoch 936/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0209 - mae: 0.1029\n",
      "Epoch 937/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0200 - mae: 0.1005\n",
      "Epoch 938/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0206 - mae: 0.1018\n",
      "Epoch 939/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0204 - mae: 0.1013\n",
      "Epoch 940/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0200 - mae: 0.1008\n",
      "Epoch 941/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0202 - mae: 0.1018\n",
      "Epoch 942/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0206 - mae: 0.1021\n",
      "Epoch 943/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0208 - mae: 0.1023\n",
      "Epoch 944/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0209 - mae: 0.1032\n",
      "Epoch 945/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0200 - mae: 0.1006\n",
      "Epoch 946/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0220 - mae: 0.1061\n",
      "Epoch 947/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0222 - mae: 0.1062\n",
      "Epoch 948/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0210 - mae: 0.1036\n",
      "Epoch 949/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0205 - mae: 0.1019\n",
      "Epoch 950/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0200 - mae: 0.1009\n",
      "Epoch 951/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0267 - mae: 0.1168\n",
      "Epoch 952/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0222 - mae: 0.1058\n",
      "Epoch 953/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0214 - mae: 0.1034\n",
      "Epoch 954/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0401 - mae: 0.1337\n",
      "Epoch 955/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0256 - mae: 0.1159\n",
      "Epoch 956/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0233 - mae: 0.1099\n",
      "Epoch 957/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0219 - mae: 0.1073\n",
      "Epoch 958/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0210 - mae: 0.1028\n",
      "Epoch 959/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0233 - mae: 0.1046\n",
      "Epoch 960/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0230 - mae: 0.1078\n",
      "Epoch 961/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0224 - mae: 0.1067\n",
      "Epoch 962/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0215 - mae: 0.1034\n",
      "Epoch 963/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0224 - mae: 0.1068\n",
      "Epoch 964/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0217 - mae: 0.1045\n",
      "Epoch 965/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0223 - mae: 0.1074\n",
      "Epoch 966/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0217 - mae: 0.1044\n",
      "Epoch 967/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0216 - mae: 0.1041\n",
      "Epoch 968/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0211 - mae: 0.1035\n",
      "Epoch 969/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0211 - mae: 0.1042\n",
      "Epoch 970/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0206 - mae: 0.1021\n",
      "Epoch 971/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0202 - mae: 0.1009\n",
      "Epoch 972/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0203 - mae: 0.1014\n",
      "Epoch 973/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0202 - mae: 0.1017\n",
      "Epoch 974/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0198 - mae: 0.0993\n",
      "Epoch 975/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0203 - mae: 0.1011\n",
      "Epoch 976/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0210 - mae: 0.1041\n",
      "Epoch 977/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0213 - mae: 0.1039\n",
      "Epoch 978/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0203 - mae: 0.1015\n",
      "Epoch 979/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0215 - mae: 0.1050\n",
      "Epoch 980/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0208 - mae: 0.1021\n",
      "Epoch 981/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0228 - mae: 0.1093\n",
      "Epoch 982/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0208 - mae: 0.1022\n",
      "Epoch 983/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0206 - mae: 0.1025\n",
      "Epoch 984/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0205 - mae: 0.1022\n",
      "Epoch 985/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0202 - mae: 0.1010\n",
      "Epoch 986/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0199 - mae: 0.1008\n",
      "Epoch 987/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0201 - mae: 0.1009\n",
      "Epoch 988/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0198 - mae: 0.0998\n",
      "Epoch 989/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0213 - mae: 0.1052\n",
      "Epoch 990/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0207 - mae: 0.1026\n",
      "Epoch 991/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0204 - mae: 0.1019\n",
      "Epoch 992/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0204 - mae: 0.1016\n",
      "Epoch 993/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0202 - mae: 0.1012\n",
      "Epoch 994/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0211 - mae: 0.1042\n",
      "Epoch 995/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0195 - mae: 0.0989\n",
      "Epoch 996/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0198 - mae: 0.0994\n",
      "Epoch 997/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0198 - mae: 0.1008\n",
      "Epoch 998/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1000\n",
      "Epoch 999/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0195 - mae: 0.0994\n",
      "Epoch 1000/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0208 - mae: 0.1036\n",
      "Epoch 1001/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0196 - mae: 0.0993\n",
      "Epoch 1002/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0196 - mae: 0.0992\n",
      "Epoch 1003/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0210 - mae: 0.1022\n",
      "Epoch 1004/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0228 - mae: 0.1087\n",
      "Epoch 1005/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0244 - mae: 0.1106\n",
      "Epoch 1006/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0250 - mae: 0.1151\n",
      "Epoch 1007/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0228 - mae: 0.1089\n",
      "Epoch 1008/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0224 - mae: 0.1070\n",
      "Epoch 1009/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0213 - mae: 0.1042\n",
      "Epoch 1010/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0210 - mae: 0.1032\n",
      "Epoch 1011/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0213 - mae: 0.1042\n",
      "Epoch 1012/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0216 - mae: 0.1046\n",
      "Epoch 1013/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0203 - mae: 0.1013\n",
      "Epoch 1014/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0206 - mae: 0.1032\n",
      "Epoch 1015/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0205 - mae: 0.1018\n",
      "Epoch 1016/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0198 - mae: 0.1001\n",
      "Epoch 1017/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0202 - mae: 0.1009\n",
      "Epoch 1018/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0211 - mae: 0.1052\n",
      "Epoch 1019/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0203 - mae: 0.1013\n",
      "Epoch 1020/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0194 - mae: 0.0988\n",
      "Epoch 1021/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0203 - mae: 0.1018\n",
      "Epoch 1022/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0202 - mae: 0.1013\n",
      "Epoch 1023/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0198 - mae: 0.1003\n",
      "Epoch 1024/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.0987\n",
      "Epoch 1025/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0199 - mae: 0.1005\n",
      "Epoch 1026/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0205 - mae: 0.1028\n",
      "Epoch 1027/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0202 - mae: 0.1008\n",
      "Epoch 1028/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0201 - mae: 0.1017\n",
      "Epoch 1029/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0204 - mae: 0.1023\n",
      "Epoch 1030/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0194 - mae: 0.0979\n",
      "Epoch 1031/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0205 - mae: 0.1028\n",
      "Epoch 1032/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0206 - mae: 0.1021\n",
      "Epoch 1033/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0208 - mae: 0.1031\n",
      "Epoch 1034/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0196 - mae: 0.0990\n",
      "Epoch 1035/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0202 - mae: 0.1015\n",
      "Epoch 1036/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0193 - mae: 0.0987\n",
      "Epoch 1037/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0194 - mae: 0.0990\n",
      "Epoch 1038/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0204 - mae: 0.1026\n",
      "Epoch 1039/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0207 - mae: 0.1029\n",
      "Epoch 1040/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0222 - mae: 0.1079\n",
      "Epoch 1041/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0199 - mae: 0.1008\n",
      "Epoch 1042/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0192 - mae: 0.0992\n",
      "Epoch 1043/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.0988\n",
      "Epoch 1044/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0194 - mae: 0.0984\n",
      "Epoch 1045/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0190 - mae: 0.0976\n",
      "Epoch 1046/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.0968\n",
      "Epoch 1047/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0966\n",
      "Epoch 1048/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0193 - mae: 0.0997\n",
      "Epoch 1049/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0208 - mae: 0.1034\n",
      "Epoch 1050/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.0972\n",
      "Epoch 1051/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0199 - mae: 0.1001\n",
      "Epoch 1052/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0210 - mae: 0.1036\n",
      "Epoch 1053/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0191 - mae: 0.0983\n",
      "Epoch 1054/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0198 - mae: 0.1001\n",
      "Epoch 1055/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0195 - mae: 0.0998\n",
      "Epoch 1056/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0206 - mae: 0.1019\n",
      "Epoch 1057/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0202 - mae: 0.1006\n",
      "Epoch 1058/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0213 - mae: 0.1045\n",
      "Epoch 1059/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0216 - mae: 0.1059\n",
      "Epoch 1060/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0221 - mae: 0.1069\n",
      "Epoch 1061/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0199 - mae: 0.1011\n",
      "Epoch 1062/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0200 - mae: 0.1010\n",
      "Epoch 1063/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0192 - mae: 0.0984\n",
      "Epoch 1064/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0199 - mae: 0.1007\n",
      "Epoch 1065/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.0990\n",
      "Epoch 1066/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0189 - mae: 0.0979\n",
      "Epoch 1067/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0288 - mae: 0.1049\n",
      "Epoch 1068/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0248 - mae: 0.1141\n",
      "Epoch 1069/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0235 - mae: 0.1103\n",
      "Epoch 1070/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0221 - mae: 0.1064\n",
      "Epoch 1071/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0231 - mae: 0.1099\n",
      "Epoch 1072/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0202 - mae: 0.1018\n",
      "Epoch 1073/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0207 - mae: 0.1027\n",
      "Epoch 1074/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0203 - mae: 0.1011\n",
      "Epoch 1075/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0200 - mae: 0.1004\n",
      "Epoch 1076/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0207 - mae: 0.1029\n",
      "Epoch 1077/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0203 - mae: 0.1012\n",
      "Epoch 1078/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0232 - mae: 0.1098\n",
      "Epoch 1079/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0422 - mae: 0.1154\n",
      "Epoch 1080/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0249 - mae: 0.1124\n",
      "Epoch 1081/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0218 - mae: 0.1034\n",
      "Epoch 1082/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0223 - mae: 0.1045\n",
      "Epoch 1083/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0220 - mae: 0.1054\n",
      "Epoch 1084/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1048\n",
      "Epoch 1085/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0220 - mae: 0.1055\n",
      "Epoch 1086/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0229 - mae: 0.1069\n",
      "Epoch 1087/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0213 - mae: 0.1037\n",
      "Epoch 1088/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0211 - mae: 0.1027\n",
      "Epoch 1089/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0205 - mae: 0.1003\n",
      "Epoch 1090/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0209 - mae: 0.1008\n",
      "Epoch 1091/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0205 - mae: 0.1015\n",
      "Epoch 1092/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0212 - mae: 0.1029\n",
      "Epoch 1093/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0204 - mae: 0.1003\n",
      "Epoch 1094/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0202 - mae: 0.1004\n",
      "Epoch 1095/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0205 - mae: 0.1012\n",
      "Epoch 1096/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0199 - mae: 0.0996\n",
      "Epoch 1097/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0198 - mae: 0.0986\n",
      "Epoch 1098/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0205 - mae: 0.1016\n",
      "Epoch 1099/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0202 - mae: 0.1008\n",
      "Epoch 1100/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0206 - mae: 0.1022\n",
      "Epoch 1101/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0200 - mae: 0.0998\n",
      "Epoch 1102/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0208 - mae: 0.1018\n",
      "Epoch 1103/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0214 - mae: 0.1036\n",
      "Epoch 1104/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0211 - mae: 0.1036\n",
      "Epoch 1105/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0200 - mae: 0.1001\n",
      "Epoch 1106/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0196 - mae: 0.0977\n",
      "Epoch 1107/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0208 - mae: 0.1037\n",
      "Epoch 1108/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0204 - mae: 0.1007\n",
      "Epoch 1109/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0204 - mae: 0.1008\n",
      "Epoch 1110/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0221 - mae: 0.1072\n",
      "Epoch 1111/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0194 - mae: 0.0985\n",
      "Epoch 1112/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0214 - mae: 0.1050\n",
      "Epoch 1113/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0203 - mae: 0.1023\n",
      "Epoch 1114/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0206 - mae: 0.1017\n",
      "Epoch 1115/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0223 - mae: 0.1063\n",
      "Epoch 1116/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0223 - mae: 0.1073\n",
      "Epoch 1117/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0199 - mae: 0.1007\n",
      "Epoch 1118/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0198 - mae: 0.1001\n",
      "Epoch 1119/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0210 - mae: 0.1039\n",
      "Epoch 1120/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0194 - mae: 0.0989\n",
      "Epoch 1121/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0193 - mae: 0.0990\n",
      "Epoch 1122/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0196 - mae: 0.1002\n",
      "Epoch 1123/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0211 - mae: 0.1028\n",
      "Epoch 1124/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0216 - mae: 0.1053\n",
      "Epoch 1125/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0206 - mae: 0.1023\n",
      "Epoch 1126/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0218 - mae: 0.1065\n",
      "Epoch 1127/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0199 - mae: 0.1002\n",
      "Epoch 1128/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1008\n",
      "Epoch 1129/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0206 - mae: 0.1019\n",
      "Epoch 1130/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0196 - mae: 0.0993\n",
      "Epoch 1131/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0198 - mae: 0.1007\n",
      "Epoch 1132/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0201 - mae: 0.1013\n",
      "Epoch 1133/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.1000\n",
      "Epoch 1134/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0204 - mae: 0.1024\n",
      "Epoch 1135/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0198 - mae: 0.1005\n",
      "Epoch 1136/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0192 - mae: 0.0984\n",
      "Epoch 1137/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.0986\n",
      "Epoch 1138/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0201 - mae: 0.1012\n",
      "Epoch 1139/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0211 - mae: 0.1045\n",
      "Epoch 1140/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0219 - mae: 0.1061\n",
      "Epoch 1141/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0203 - mae: 0.1017\n",
      "Epoch 1142/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0190 - mae: 0.0976\n",
      "Epoch 1143/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0197 - mae: 0.1002\n",
      "Epoch 1144/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0205 - mae: 0.1033\n",
      "Epoch 1145/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0194 - mae: 0.0990\n",
      "Epoch 1146/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0192 - mae: 0.0984\n",
      "Epoch 1147/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0190 - mae: 0.0976\n",
      "Epoch 1148/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0189 - mae: 0.0978\n",
      "Epoch 1149/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.0994\n",
      "Epoch 1150/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0196 - mae: 0.1003\n",
      "Epoch 1151/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0190 - mae: 0.0978\n",
      "Epoch 1152/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0191 - mae: 0.0990\n",
      "Epoch 1153/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0197 - mae: 0.0997\n",
      "Epoch 1154/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.0989\n",
      "Epoch 1155/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.0997\n",
      "Epoch 1156/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0193 - mae: 0.0974\n",
      "Epoch 1157/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0200 - mae: 0.1010\n",
      "Epoch 1158/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0200 - mae: 0.1017\n",
      "Epoch 1159/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0959\n",
      "Epoch 1160/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0190 - mae: 0.0987\n",
      "Epoch 1161/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0189 - mae: 0.0978\n",
      "Epoch 1162/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0190 - mae: 0.0984\n",
      "Epoch 1163/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0195 - mae: 0.1009\n",
      "Epoch 1164/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0224 - mae: 0.1062\n",
      "Epoch 1165/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0200 - mae: 0.1012\n",
      "Epoch 1166/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0191 - mae: 0.0976\n",
      "Epoch 1167/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1014\n",
      "Epoch 1168/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0194 - mae: 0.0990\n",
      "Epoch 1169/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0253 - mae: 0.1171\n",
      "Epoch 1170/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0243 - mae: 0.1130\n",
      "Epoch 1171/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0219 - mae: 0.1064\n",
      "Epoch 1172/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0220 - mae: 0.1074\n",
      "Epoch 1173/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0207 - mae: 0.1033\n",
      "Epoch 1174/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0210 - mae: 0.1041\n",
      "Epoch 1175/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0221 - mae: 0.1067\n",
      "Epoch 1176/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0199 - mae: 0.1012\n",
      "Epoch 1177/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0199 - mae: 0.1014\n",
      "Epoch 1178/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0194 - mae: 0.0993\n",
      "Epoch 1179/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0192 - mae: 0.0994\n",
      "Epoch 1180/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0212 - mae: 0.1051\n",
      "Epoch 1181/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0197 - mae: 0.1000\n",
      "Epoch 1182/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0238 - mae: 0.1130\n",
      "Epoch 1183/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0227 - mae: 0.1104\n",
      "Epoch 1184/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0217 - mae: 0.1076\n",
      "Epoch 1185/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0206 - mae: 0.1037\n",
      "Epoch 1186/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0209 - mae: 0.1048\n",
      "Epoch 1187/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0196 - mae: 0.1014\n",
      "Epoch 1188/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0197 - mae: 0.1009\n",
      "Epoch 1189/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0202 - mae: 0.1020\n",
      "Epoch 1190/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0208 - mae: 0.1049\n",
      "Epoch 1191/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0208 - mae: 0.1042\n",
      "Epoch 1192/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0198 - mae: 0.1023\n",
      "Epoch 1193/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0193 - mae: 0.1005\n",
      "Epoch 1194/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0191 - mae: 0.0996\n",
      "Epoch 1195/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0194 - mae: 0.1003\n",
      "Epoch 1196/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0192 - mae: 0.1003\n",
      "Epoch 1197/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0200 - mae: 0.1017\n",
      "Epoch 1198/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.1008\n",
      "Epoch 1199/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0192 - mae: 0.1006\n",
      "Epoch 1200/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0193 - mae: 0.1004\n",
      "Epoch 1201/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0208 - mae: 0.1043\n",
      "Epoch 1202/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0980\n",
      "Epoch 1203/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0198 - mae: 0.1021\n",
      "Epoch 1204/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0189 - mae: 0.0991\n",
      "Epoch 1205/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0191 - mae: 0.0992\n",
      "Epoch 1206/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0198 - mae: 0.1022\n",
      "Epoch 1207/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0206 - mae: 0.1035\n",
      "Epoch 1208/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0191 - mae: 0.1000\n",
      "Epoch 1209/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0188 - mae: 0.0986\n",
      "Epoch 1210/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0194 - mae: 0.0996\n",
      "Epoch 1211/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0192 - mae: 0.1003\n",
      "Epoch 1212/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0193 - mae: 0.1004\n",
      "Epoch 1213/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0190 - mae: 0.0986\n",
      "Epoch 1214/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0198 - mae: 0.1024\n",
      "Epoch 1215/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0194 - mae: 0.1001\n",
      "Epoch 1216/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0190 - mae: 0.0988\n",
      "Epoch 1217/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0203 - mae: 0.1030\n",
      "Epoch 1218/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0977\n",
      "Epoch 1219/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0189 - mae: 0.0997\n",
      "Epoch 1220/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.0987\n",
      "Epoch 1221/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0192 - mae: 0.0997\n",
      "Epoch 1222/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0188 - mae: 0.0992\n",
      "Epoch 1223/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0208 - mae: 0.1034\n",
      "Epoch 1224/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0193 - mae: 0.1000\n",
      "Epoch 1225/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0198 - mae: 0.1018\n",
      "Epoch 1226/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0193 - mae: 0.1006\n",
      "Epoch 1227/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0188 - mae: 0.0982\n",
      "Epoch 1228/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0186 - mae: 0.0987\n",
      "Epoch 1229/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0194 - mae: 0.1005\n",
      "Epoch 1230/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0195 - mae: 0.1018\n",
      "Epoch 1231/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0212 - mae: 0.1051\n",
      "Epoch 1232/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0196 - mae: 0.1027\n",
      "Epoch 1233/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0206 - mae: 0.1026\n",
      "Epoch 1234/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0245 - mae: 0.1138\n",
      "Epoch 1235/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0191 - mae: 0.0995\n",
      "Epoch 1236/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0978\n",
      "Epoch 1237/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0197 - mae: 0.1019\n",
      "Epoch 1238/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0194 - mae: 0.1004\n",
      "Epoch 1239/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0233 - mae: 0.1112\n",
      "Epoch 1240/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0185 - mae: 0.0976\n",
      "Epoch 1241/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0976\n",
      "Epoch 1242/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0190 - mae: 0.0998\n",
      "Epoch 1243/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0184 - mae: 0.0975\n",
      "Epoch 1244/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0192 - mae: 0.0990\n",
      "Epoch 1245/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.1003\n",
      "Epoch 1246/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0234 - mae: 0.1108\n",
      "Epoch 1247/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0203 - mae: 0.1034\n",
      "Epoch 1248/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0213 - mae: 0.1068\n",
      "Epoch 1249/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0189 - mae: 0.0997\n",
      "Epoch 1250/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0189 - mae: 0.0995\n",
      "Epoch 1251/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0188 - mae: 0.0989\n",
      "Epoch 1252/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0194 - mae: 0.1008\n",
      "Epoch 1253/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0989\n",
      "Epoch 1254/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0190 - mae: 0.0991\n",
      "Epoch 1255/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0995\n",
      "Epoch 1256/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0194 - mae: 0.1000\n",
      "Epoch 1257/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0204 - mae: 0.1044\n",
      "Epoch 1258/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0191 - mae: 0.0996\n",
      "Epoch 1259/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0189 - mae: 0.0999\n",
      "Epoch 1260/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0189 - mae: 0.0992\n",
      "Epoch 1261/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0191 - mae: 0.0989\n",
      "Epoch 1262/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0185 - mae: 0.0981\n",
      "Epoch 1263/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0185 - mae: 0.0975\n",
      "Epoch 1264/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0193 - mae: 0.1012\n",
      "Epoch 1265/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0960\n",
      "Epoch 1266/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0973\n",
      "Epoch 1267/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0197 - mae: 0.1009\n",
      "Epoch 1268/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0192 - mae: 0.1005\n",
      "Epoch 1269/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0187 - mae: 0.0987\n",
      "Epoch 1270/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0191 - mae: 0.1000\n",
      "Epoch 1271/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0183 - mae: 0.0971\n",
      "Epoch 1272/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0202 - mae: 0.1025\n",
      "Epoch 1273/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0203 - mae: 0.1037\n",
      "Epoch 1274/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0187 - mae: 0.0983\n",
      "Epoch 1275/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0187 - mae: 0.0986\n",
      "Epoch 1276/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0974\n",
      "Epoch 1277/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0181 - mae: 0.0968\n",
      "Epoch 1278/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0189 - mae: 0.0975\n",
      "Epoch 1279/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0195 - mae: 0.1011\n",
      "Epoch 1280/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0198 - mae: 0.1025\n",
      "Epoch 1281/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0193 - mae: 0.1006\n",
      "Epoch 1282/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0183 - mae: 0.0968\n",
      "Epoch 1283/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0185 - mae: 0.0978\n",
      "Epoch 1284/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0219 - mae: 0.1047\n",
      "Epoch 1285/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0213 - mae: 0.1057\n",
      "Epoch 1286/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0202 - mae: 0.1020\n",
      "Epoch 1287/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0191 - mae: 0.0997\n",
      "Epoch 1288/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.0975\n",
      "Epoch 1289/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0192 - mae: 0.0996\n",
      "Epoch 1290/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0190 - mae: 0.0986\n",
      "Epoch 1291/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0973\n",
      "Epoch 1292/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0187 - mae: 0.0977\n",
      "Epoch 1293/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0213 - mae: 0.1061\n",
      "Epoch 1294/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0187 - mae: 0.0978\n",
      "Epoch 1295/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0185 - mae: 0.0974\n",
      "Epoch 1296/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0195 - mae: 0.0997\n",
      "Epoch 1297/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0961\n",
      "Epoch 1298/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0194 - mae: 0.0999\n",
      "Epoch 1299/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.0998\n",
      "Epoch 1300/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0189 - mae: 0.0993\n",
      "Epoch 1301/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0192 - mae: 0.1005\n",
      "Epoch 1302/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0982\n",
      "Epoch 1303/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0185 - mae: 0.0977\n",
      "Epoch 1304/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0185 - mae: 0.0969\n",
      "Epoch 1305/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0194 - mae: 0.1000\n",
      "Epoch 1306/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0191 - mae: 0.0993\n",
      "Epoch 1307/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0202 - mae: 0.1031\n",
      "Epoch 1308/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0985\n",
      "Epoch 1309/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0971\n",
      "Epoch 1310/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0192 - mae: 0.1000\n",
      "Epoch 1311/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.0975\n",
      "Epoch 1312/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0189 - mae: 0.0996\n",
      "Epoch 1313/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0192 - mae: 0.0989\n",
      "Epoch 1314/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0183 - mae: 0.0968\n",
      "Epoch 1315/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0189 - mae: 0.0986\n",
      "Epoch 1316/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0197 - mae: 0.1004\n",
      "Epoch 1317/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0184 - mae: 0.0970\n",
      "Epoch 1318/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0179 - mae: 0.0951\n",
      "Epoch 1319/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0181 - mae: 0.0965\n",
      "Epoch 1320/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0181 - mae: 0.0967\n",
      "Epoch 1321/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0186 - mae: 0.0980\n",
      "Epoch 1322/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0972\n",
      "Epoch 1323/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.0997\n",
      "Epoch 1324/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0196 - mae: 0.1003\n",
      "Epoch 1325/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0198 - mae: 0.1016\n",
      "Epoch 1326/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0184 - mae: 0.0982\n",
      "Epoch 1327/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.0985\n",
      "Epoch 1328/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0197 - mae: 0.1025\n",
      "Epoch 1329/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0190 - mae: 0.0988\n",
      "Epoch 1330/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0191 - mae: 0.0992\n",
      "Epoch 1331/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.0977\n",
      "Epoch 1332/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0187 - mae: 0.0984\n",
      "Epoch 1333/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0184 - mae: 0.0968\n",
      "Epoch 1334/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0966\n",
      "Epoch 1335/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0196 - mae: 0.1011\n",
      "Epoch 1336/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0182 - mae: 0.0973\n",
      "Epoch 1337/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0185 - mae: 0.0975\n",
      "Epoch 1338/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0195 - mae: 0.0999\n",
      "Epoch 1339/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0184 - mae: 0.0968\n",
      "Epoch 1340/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0186 - mae: 0.0978\n",
      "Epoch 1341/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0972\n",
      "Epoch 1342/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0207 - mae: 0.1045\n",
      "Epoch 1343/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0193 - mae: 0.0996\n",
      "Epoch 1344/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0191 - mae: 0.1001\n",
      "Epoch 1345/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0191 - mae: 0.1003\n",
      "Epoch 1346/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0180 - mae: 0.0961\n",
      "Epoch 1347/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0181 - mae: 0.0963\n",
      "Epoch 1348/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0210 - mae: 0.1039\n",
      "Epoch 1349/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0190 - mae: 0.0990\n",
      "Epoch 1350/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0183 - mae: 0.0977\n",
      "Epoch 1351/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0963\n",
      "Epoch 1352/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0188 - mae: 0.0972\n",
      "Epoch 1353/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0210 - mae: 0.1057\n",
      "Epoch 1354/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.0990\n",
      "Epoch 1355/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0184 - mae: 0.0978\n",
      "Epoch 1356/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0184 - mae: 0.0965\n",
      "Epoch 1357/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0181 - mae: 0.0964\n",
      "Epoch 1358/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.0985\n",
      "Epoch 1359/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0195 - mae: 0.1012\n",
      "Epoch 1360/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0189 - mae: 0.0993\n",
      "Epoch 1361/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0180 - mae: 0.0955\n",
      "Epoch 1362/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0193 - mae: 0.0999\n",
      "Epoch 1363/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0187 - mae: 0.0989\n",
      "Epoch 1364/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0184 - mae: 0.0970\n",
      "Epoch 1365/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0958\n",
      "Epoch 1366/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0993\n",
      "Epoch 1367/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0179 - mae: 0.0957\n",
      "Epoch 1368/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0194 - mae: 0.1001\n",
      "Epoch 1369/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0194 - mae: 0.1001\n",
      "Epoch 1370/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0181 - mae: 0.0961\n",
      "Epoch 1371/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0191 - mae: 0.0991\n",
      "Epoch 1372/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0195 - mae: 0.1010\n",
      "Epoch 1373/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0187 - mae: 0.0980\n",
      "Epoch 1374/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0178 - mae: 0.0959\n",
      "Epoch 1375/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0181 - mae: 0.0957\n",
      "Epoch 1376/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0184 - mae: 0.0973\n",
      "Epoch 1377/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0196 - mae: 0.1010\n",
      "Epoch 1378/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0191 - mae: 0.0995\n",
      "Epoch 1379/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0185 - mae: 0.0974\n",
      "Epoch 1380/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0180 - mae: 0.0956\n",
      "Epoch 1381/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0193 - mae: 0.0996\n",
      "Epoch 1382/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0184 - mae: 0.0975\n",
      "Epoch 1383/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0187 - mae: 0.0982\n",
      "Epoch 1384/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0980\n",
      "Epoch 1385/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0184 - mae: 0.0983\n",
      "Epoch 1386/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0963\n",
      "Epoch 1387/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0202 - mae: 0.1028\n",
      "Epoch 1388/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0969\n",
      "Epoch 1389/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0180 - mae: 0.0953\n",
      "Epoch 1390/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0949\n",
      "Epoch 1391/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0183 - mae: 0.0965\n",
      "Epoch 1392/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0976\n",
      "Epoch 1393/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0190 - mae: 0.0983\n",
      "Epoch 1394/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0184 - mae: 0.0976\n",
      "Epoch 1395/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0181 - mae: 0.0957\n",
      "Epoch 1396/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0192 - mae: 0.0981\n",
      "Epoch 1397/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0194 - mae: 0.1008\n",
      "Epoch 1398/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0183 - mae: 0.0960\n",
      "Epoch 1399/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0188 - mae: 0.0977\n",
      "Epoch 1400/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0181 - mae: 0.0959\n",
      "Epoch 1401/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0182 - mae: 0.0961\n",
      "Epoch 1402/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0183 - mae: 0.0973\n",
      "Epoch 1403/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0199 - mae: 0.1024\n",
      "Epoch 1404/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0962\n",
      "Epoch 1405/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0190 - mae: 0.0990\n",
      "Epoch 1406/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0181 - mae: 0.0961\n",
      "Epoch 1407/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0179 - mae: 0.0953\n",
      "Epoch 1408/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0182 - mae: 0.0971\n",
      "Epoch 1409/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0178 - mae: 0.0946\n",
      "Epoch 1410/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.0980\n",
      "Epoch 1411/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0980\n",
      "Epoch 1412/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0980\n",
      "Epoch 1413/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0192 - mae: 0.0999\n",
      "Epoch 1414/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0967\n",
      "Epoch 1415/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0188 - mae: 0.0982\n",
      "Epoch 1416/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0183 - mae: 0.0954\n",
      "Epoch 1417/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0975\n",
      "Epoch 1418/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.0997\n",
      "Epoch 1419/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0217 - mae: 0.1062\n",
      "Epoch 1420/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0203 - mae: 0.1029\n",
      "Epoch 1421/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0200 - mae: 0.1018\n",
      "Epoch 1422/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0205 - mae: 0.1034\n",
      "Epoch 1423/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0963\n",
      "Epoch 1424/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0976\n",
      "Epoch 1425/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0187 - mae: 0.0987\n",
      "Epoch 1426/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0964\n",
      "Epoch 1427/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0197 - mae: 0.0998\n",
      "Epoch 1428/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.0968\n",
      "Epoch 1429/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0191 - mae: 0.0986\n",
      "Epoch 1430/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0961\n",
      "Epoch 1431/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0182 - mae: 0.0955\n",
      "Epoch 1432/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.0965\n",
      "Epoch 1433/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0180 - mae: 0.0956\n",
      "Epoch 1434/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0183 - mae: 0.0963\n",
      "Epoch 1435/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0179 - mae: 0.0955\n",
      "Epoch 1436/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0193 - mae: 0.0992\n",
      "Epoch 1437/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0190 - mae: 0.0987\n",
      "Epoch 1438/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0198 - mae: 0.1021\n",
      "Epoch 1439/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0193 - mae: 0.1005\n",
      "Epoch 1440/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0188 - mae: 0.0987\n",
      "Epoch 1441/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0183 - mae: 0.0965\n",
      "Epoch 1442/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0180 - mae: 0.0960\n",
      "Epoch 1443/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0179 - mae: 0.0953\n",
      "Epoch 1444/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0183 - mae: 0.0974\n",
      "Epoch 1445/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0177 - mae: 0.0953\n",
      "Epoch 1446/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0192 - mae: 0.1001\n",
      "Epoch 1447/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0187 - mae: 0.0978\n",
      "Epoch 1448/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0185 - mae: 0.0974\n",
      "Epoch 1449/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0188 - mae: 0.0976\n",
      "Epoch 1450/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0186 - mae: 0.0978\n",
      "Epoch 1451/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0303 - mae: 0.1277\n",
      "Epoch 1452/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0200 - mae: 0.1022\n",
      "Epoch 1453/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0186 - mae: 0.0985\n",
      "Epoch 1454/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0184 - mae: 0.0967\n",
      "Epoch 1455/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0962\n",
      "Epoch 1456/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0178 - mae: 0.0949\n",
      "Epoch 1457/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0971\n",
      "Epoch 1458/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0965\n",
      "Epoch 1459/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0185 - mae: 0.0982\n",
      "Epoch 1460/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0192 - mae: 0.0999\n",
      "Epoch 1461/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0180 - mae: 0.0955\n",
      "Epoch 1462/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0185 - mae: 0.0986\n",
      "Epoch 1463/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0181 - mae: 0.0965\n",
      "Epoch 1464/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0183 - mae: 0.0963\n",
      "Epoch 1465/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0963\n",
      "Epoch 1466/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0178 - mae: 0.0951\n",
      "Epoch 1467/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0190 - mae: 0.1001\n",
      "Epoch 1468/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0177 - mae: 0.0946\n",
      "Epoch 1469/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0986\n",
      "Epoch 1470/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0293 - mae: 0.1059\n",
      "Epoch 1471/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0198 - mae: 0.1025\n",
      "Epoch 1472/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0190 - mae: 0.0998\n",
      "Epoch 1473/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0186 - mae: 0.0985\n",
      "Epoch 1474/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0186 - mae: 0.0988\n",
      "Epoch 1475/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0978\n",
      "Epoch 1476/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0185 - mae: 0.0982\n",
      "Epoch 1477/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0187 - mae: 0.0980\n",
      "Epoch 1478/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0265 - mae: 0.1165\n",
      "Epoch 1479/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0211 - mae: 0.1064\n",
      "Epoch 1480/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0188 - mae: 0.0981\n",
      "Epoch 1481/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0178 - mae: 0.0945\n",
      "Epoch 1482/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0982\n",
      "Epoch 1483/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0193 - mae: 0.1002\n",
      "Epoch 1484/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0197 - mae: 0.1014\n",
      "Epoch 1485/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0188 - mae: 0.0984\n",
      "Epoch 1486/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0185 - mae: 0.0975\n",
      "Epoch 1487/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0192 - mae: 0.0996\n",
      "Epoch 1488/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0200 - mae: 0.1009\n",
      "Epoch 1489/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.0973\n",
      "Epoch 1490/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0199 - mae: 0.1004\n",
      "Epoch 1491/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0189 - mae: 0.0989\n",
      "Epoch 1492/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0199 - mae: 0.1026\n",
      "Epoch 1493/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0189 - mae: 0.0982\n",
      "Epoch 1494/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0975\n",
      "Epoch 1495/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0184 - mae: 0.0973\n",
      "Epoch 1496/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0175 - mae: 0.0938\n",
      "Epoch 1497/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0965\n",
      "Epoch 1498/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0181 - mae: 0.0955\n",
      "Epoch 1499/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0973\n",
      "Epoch 1500/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0970\n",
      "Epoch 1501/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0968\n",
      "Epoch 1502/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0179 - mae: 0.0951\n",
      "Epoch 1503/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0187 - mae: 0.0983\n",
      "Epoch 1504/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0183 - mae: 0.0960\n",
      "Epoch 1505/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.0974\n",
      "Epoch 1506/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0181 - mae: 0.0962\n",
      "Epoch 1507/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0237 - mae: 0.1116\n",
      "Epoch 1508/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0228 - mae: 0.1099\n",
      "Epoch 1509/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0194 - mae: 0.0998\n",
      "Epoch 1510/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0194 - mae: 0.0999\n",
      "Epoch 1511/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0186 - mae: 0.0968\n",
      "Epoch 1512/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0184 - mae: 0.0966\n",
      "Epoch 1513/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0964\n",
      "Epoch 1514/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0197 - mae: 0.1012\n",
      "Epoch 1515/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0182 - mae: 0.0964\n",
      "Epoch 1516/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0975\n",
      "Epoch 1517/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0966\n",
      "Epoch 1518/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0179 - mae: 0.0957\n",
      "Epoch 1519/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0218 - mae: 0.1073\n",
      "Epoch 1520/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0977\n",
      "Epoch 1521/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0179 - mae: 0.0955\n",
      "Epoch 1522/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0188 - mae: 0.0976\n",
      "Epoch 1523/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0182 - mae: 0.0966\n",
      "Epoch 1524/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0191 - mae: 0.1003\n",
      "Epoch 1525/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0185 - mae: 0.0971\n",
      "Epoch 1526/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0979\n",
      "Epoch 1527/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0187 - mae: 0.0985\n",
      "Epoch 1528/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.0971\n",
      "Epoch 1529/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0187 - mae: 0.0979\n",
      "Epoch 1530/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0194 - mae: 0.1013\n",
      "Epoch 1531/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0187 - mae: 0.0986\n",
      "Epoch 1532/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0969\n",
      "Epoch 1533/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0965\n",
      "Epoch 1534/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0195 - mae: 0.1007\n",
      "Epoch 1535/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0185 - mae: 0.0981\n",
      "Epoch 1536/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0197 - mae: 0.1015\n",
      "Epoch 1537/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0183 - mae: 0.0969\n",
      "Epoch 1538/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0177 - mae: 0.0950\n",
      "Epoch 1539/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0974\n",
      "Epoch 1540/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0971\n",
      "Epoch 1541/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0183 - mae: 0.0974\n",
      "Epoch 1542/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0180 - mae: 0.0963\n",
      "Epoch 1543/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0182 - mae: 0.0966\n",
      "Epoch 1544/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0180 - mae: 0.0964\n",
      "Epoch 1545/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0198 - mae: 0.1026\n",
      "Epoch 1546/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0966\n",
      "Epoch 1547/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0176 - mae: 0.0946\n",
      "Epoch 1548/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0182 - mae: 0.0967\n",
      "Epoch 1549/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0178 - mae: 0.0961\n",
      "Epoch 1550/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0180 - mae: 0.0966\n",
      "Epoch 1551/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0175 - mae: 0.0943\n",
      "Epoch 1552/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0195 - mae: 0.1010\n",
      "Epoch 1553/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0194 - mae: 0.1006\n",
      "Epoch 1554/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0190 - mae: 0.1007\n",
      "Epoch 1555/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0989\n",
      "Epoch 1556/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0184 - mae: 0.0972\n",
      "Epoch 1557/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0182 - mae: 0.0985\n",
      "Epoch 1558/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0965\n",
      "Epoch 1559/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.0986\n",
      "Epoch 1560/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0225 - mae: 0.1082\n",
      "Epoch 1561/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0207 - mae: 0.1048\n",
      "Epoch 1562/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0194 - mae: 0.1001\n",
      "Epoch 1563/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0190 - mae: 0.0994\n",
      "Epoch 1564/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0194 - mae: 0.0995\n",
      "Epoch 1565/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0206 - mae: 0.1051\n",
      "Epoch 1566/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0191 - mae: 0.1001\n",
      "Epoch 1567/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0990\n",
      "Epoch 1568/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0977\n",
      "Epoch 1569/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.0972\n",
      "Epoch 1570/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0958\n",
      "Epoch 1571/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0978\n",
      "Epoch 1572/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0180 - mae: 0.0963\n",
      "Epoch 1573/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0180 - mae: 0.0967\n",
      "Epoch 1574/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0182 - mae: 0.0970\n",
      "Epoch 1575/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0190 - mae: 0.0997\n",
      "Epoch 1576/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0189 - mae: 0.0992\n",
      "Epoch 1577/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0179 - mae: 0.0954\n",
      "Epoch 1578/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.0988\n",
      "Epoch 1579/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0178 - mae: 0.0963\n",
      "Epoch 1580/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0179 - mae: 0.0959\n",
      "Epoch 1581/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0984\n",
      "Epoch 1582/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0978\n",
      "Epoch 1583/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0196 - mae: 0.1014\n",
      "Epoch 1584/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0182 - mae: 0.0974\n",
      "Epoch 1585/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0179 - mae: 0.0961\n",
      "Epoch 1586/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0178 - mae: 0.0950\n",
      "Epoch 1587/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0183 - mae: 0.0974\n",
      "Epoch 1588/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0190 - mae: 0.1002\n",
      "Epoch 1589/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0179 - mae: 0.0962\n",
      "Epoch 1590/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0184 - mae: 0.0973\n",
      "Epoch 1591/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0178 - mae: 0.0958\n",
      "Epoch 1592/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0177 - mae: 0.0955\n",
      "Epoch 1593/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0178 - mae: 0.0960\n",
      "Epoch 1594/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0180 - mae: 0.0962\n",
      "Epoch 1595/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0178 - mae: 0.0962\n",
      "Epoch 1596/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0180 - mae: 0.0964\n",
      "Epoch 1597/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0177 - mae: 0.0952\n",
      "Epoch 1598/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0181 - mae: 0.0965\n",
      "Epoch 1599/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0181 - mae: 0.0965\n",
      "Epoch 1600/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.0991\n",
      "Epoch 1601/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0185 - mae: 0.0975\n",
      "Epoch 1602/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0184 - mae: 0.0976\n",
      "Epoch 1603/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0193 - mae: 0.1005\n",
      "Epoch 1604/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0182 - mae: 0.0973\n",
      "Epoch 1605/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0174 - mae: 0.0950\n",
      "Epoch 1606/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0180 - mae: 0.0961\n",
      "Epoch 1607/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0182 - mae: 0.0980\n",
      "Epoch 1608/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0178 - mae: 0.0964\n",
      "Epoch 1609/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0180 - mae: 0.0963\n",
      "Epoch 1610/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0949\n",
      "Epoch 1611/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0184 - mae: 0.0975\n",
      "Epoch 1612/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0183 - mae: 0.0973\n",
      "Epoch 1613/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0243 - mae: 0.1124\n",
      "Epoch 1614/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0208 - mae: 0.1050\n",
      "Epoch 1615/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0198 - mae: 0.1027\n",
      "Epoch 1616/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0185 - mae: 0.0974\n",
      "Epoch 1617/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0189 - mae: 0.0993\n",
      "Epoch 1618/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0182 - mae: 0.0968\n",
      "Epoch 1619/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.0975\n",
      "Epoch 1620/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0190 - mae: 0.1002\n",
      "Epoch 1621/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0182 - mae: 0.0972\n",
      "Epoch 1622/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0188 - mae: 0.0994\n",
      "Epoch 1623/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0971\n",
      "Epoch 1624/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0963\n",
      "Epoch 1625/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0176 - mae: 0.0946\n",
      "Epoch 1626/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0177 - mae: 0.0960\n",
      "Epoch 1627/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0180 - mae: 0.0975\n",
      "Epoch 1628/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0189 - mae: 0.0984\n",
      "Epoch 1629/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0178 - mae: 0.0953\n",
      "Epoch 1630/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0178 - mae: 0.0966\n",
      "Epoch 1631/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0182 - mae: 0.0973\n",
      "Epoch 1632/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0181 - mae: 0.0969\n",
      "Epoch 1633/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0178 - mae: 0.0957\n",
      "Epoch 1634/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0194 - mae: 0.1012\n",
      "Epoch 1635/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0181 - mae: 0.0973\n",
      "Epoch 1636/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0176 - mae: 0.0954\n",
      "Epoch 1637/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0949\n",
      "Epoch 1638/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0178 - mae: 0.0961\n",
      "Epoch 1639/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0980\n",
      "Epoch 1640/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0182 - mae: 0.0976\n",
      "Epoch 1641/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0980\n",
      "Epoch 1642/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0200 - mae: 0.1034\n",
      "Epoch 1643/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0178 - mae: 0.0957\n",
      "Epoch 1644/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0178 - mae: 0.0967\n",
      "Epoch 1645/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0178 - mae: 0.0961\n",
      "Epoch 1646/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0188 - mae: 0.0996\n",
      "Epoch 1647/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0173 - mae: 0.0945\n",
      "Epoch 1648/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0176 - mae: 0.0964\n",
      "Epoch 1649/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0197 - mae: 0.1025\n",
      "Epoch 1650/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0184 - mae: 0.0986\n",
      "Epoch 1651/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0177 - mae: 0.0956\n",
      "Epoch 1652/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0258 - mae: 0.1171\n",
      "Epoch 1653/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0214 - mae: 0.1042\n",
      "Epoch 1654/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0210 - mae: 0.1053\n",
      "Epoch 1655/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0202 - mae: 0.1032\n",
      "Epoch 1656/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.0990\n",
      "Epoch 1657/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0186 - mae: 0.0976\n",
      "Epoch 1658/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0181 - mae: 0.0972\n",
      "Epoch 1659/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0981\n",
      "Epoch 1660/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0182 - mae: 0.0976\n",
      "Epoch 1661/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0176 - mae: 0.0965\n",
      "Epoch 1662/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0178 - mae: 0.0953\n",
      "Epoch 1663/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0189 - mae: 0.1000\n",
      "Epoch 1664/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0175 - mae: 0.0952\n",
      "Epoch 1665/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0186 - mae: 0.0976\n",
      "Epoch 1666/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0981\n",
      "Epoch 1667/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0181 - mae: 0.0975\n",
      "Epoch 1668/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0179 - mae: 0.0976\n",
      "Epoch 1669/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0174 - mae: 0.0946\n",
      "Epoch 1670/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0177 - mae: 0.0949\n",
      "Epoch 1671/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0179 - mae: 0.0963\n",
      "Epoch 1672/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0177 - mae: 0.0952\n",
      "Epoch 1673/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0172 - mae: 0.0945\n",
      "Epoch 1674/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0179 - mae: 0.0963\n",
      "Epoch 1675/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0186 - mae: 0.0991\n",
      "Epoch 1676/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0182 - mae: 0.0964\n",
      "Epoch 1677/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0182 - mae: 0.0966\n",
      "Epoch 1678/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0195 - mae: 0.1026\n",
      "Epoch 1679/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.0975\n",
      "Epoch 1680/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0175 - mae: 0.0955\n",
      "Epoch 1681/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0175 - mae: 0.0949\n",
      "Epoch 1682/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0183 - mae: 0.0976\n",
      "Epoch 1683/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.1002\n",
      "Epoch 1684/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0180 - mae: 0.0969\n",
      "Epoch 1685/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0180 - mae: 0.0972\n",
      "Epoch 1686/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0170 - mae: 0.0937\n",
      "Epoch 1687/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0951\n",
      "Epoch 1688/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0986\n",
      "Epoch 1689/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0943\n",
      "Epoch 1690/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0174 - mae: 0.0944\n",
      "Epoch 1691/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0185 - mae: 0.0981\n",
      "Epoch 1692/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0188 - mae: 0.0989\n",
      "Epoch 1693/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0175 - mae: 0.0949\n",
      "Epoch 1694/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.0968\n",
      "Epoch 1695/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0173 - mae: 0.0943\n",
      "Epoch 1696/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0170 - mae: 0.0931\n",
      "Epoch 1697/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0180 - mae: 0.0969\n",
      "Epoch 1698/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0174 - mae: 0.0953\n",
      "Epoch 1699/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0177 - mae: 0.0959\n",
      "Epoch 1700/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0182 - mae: 0.0977\n",
      "Epoch 1701/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0181 - mae: 0.0966\n",
      "Epoch 1702/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0991\n",
      "Epoch 1703/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0198 - mae: 0.1020\n",
      "Epoch 1704/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0980\n",
      "Epoch 1705/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0187 - mae: 0.0981\n",
      "Epoch 1706/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0172 - mae: 0.0943\n",
      "Epoch 1707/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0182 - mae: 0.0980\n",
      "Epoch 1708/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0184 - mae: 0.0983\n",
      "Epoch 1709/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0173 - mae: 0.0943\n",
      "Epoch 1710/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0961\n",
      "Epoch 1711/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0196 - mae: 0.1012\n",
      "Epoch 1712/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0180 - mae: 0.0969\n",
      "Epoch 1713/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0190 - mae: 0.1007\n",
      "Epoch 1714/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.0995\n",
      "Epoch 1715/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0969\n",
      "Epoch 1716/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0176 - mae: 0.0959\n",
      "Epoch 1717/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0194 - mae: 0.1022\n",
      "Epoch 1718/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0975\n",
      "Epoch 1719/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0176 - mae: 0.0956\n",
      "Epoch 1720/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0172 - mae: 0.0944\n",
      "Epoch 1721/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0181 - mae: 0.0977\n",
      "Epoch 1722/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0190 - mae: 0.0993\n",
      "Epoch 1723/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0197 - mae: 0.1007\n",
      "Epoch 1724/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0184 - mae: 0.0972\n",
      "Epoch 1725/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0963\n",
      "Epoch 1726/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0193 - mae: 0.0998\n",
      "Epoch 1727/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0181 - mae: 0.0963\n",
      "Epoch 1728/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0184 - mae: 0.0982\n",
      "Epoch 1729/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0182 - mae: 0.0974\n",
      "Epoch 1730/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0186 - mae: 0.0979\n",
      "Epoch 1731/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0183 - mae: 0.0976\n",
      "Epoch 1732/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0948\n",
      "Epoch 1733/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0943\n",
      "Epoch 1734/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0173 - mae: 0.0946\n",
      "Epoch 1735/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0172 - mae: 0.0941\n",
      "Epoch 1736/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0172 - mae: 0.0938\n",
      "Epoch 1737/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.0992\n",
      "Epoch 1738/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0189 - mae: 0.1000\n",
      "Epoch 1739/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0177 - mae: 0.0958\n",
      "Epoch 1740/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0178 - mae: 0.0957\n",
      "Epoch 1741/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0954\n",
      "Epoch 1742/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0189 - mae: 0.1000\n",
      "Epoch 1743/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0180 - mae: 0.0969\n",
      "Epoch 1744/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0179 - mae: 0.0960\n",
      "Epoch 1745/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0241 - mae: 0.1104\n",
      "Epoch 1746/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0193 - mae: 0.1003\n",
      "Epoch 1747/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0180 - mae: 0.0961\n",
      "Epoch 1748/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0179 - mae: 0.0963\n",
      "Epoch 1749/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0182 - mae: 0.0981\n",
      "Epoch 1750/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0181 - mae: 0.0972\n",
      "Epoch 1751/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0170 - mae: 0.0931\n",
      "Epoch 1752/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0949\n",
      "Epoch 1753/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0174 - mae: 0.0948\n",
      "Epoch 1754/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.0996\n",
      "Epoch 1755/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0184 - mae: 0.0989\n",
      "Epoch 1756/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0974\n",
      "Epoch 1757/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0202 - mae: 0.1014\n",
      "Epoch 1758/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0198 - mae: 0.1007\n",
      "Epoch 1759/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0182 - mae: 0.0970\n",
      "Epoch 1760/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0181 - mae: 0.0969\n",
      "Epoch 1761/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0991\n",
      "Epoch 1762/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0171 - mae: 0.0936\n",
      "Epoch 1763/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.0996\n",
      "Epoch 1764/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0173 - mae: 0.0943\n",
      "Epoch 1765/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0197 - mae: 0.1011\n",
      "Epoch 1766/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0186 - mae: 0.0983\n",
      "Epoch 1767/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0181 - mae: 0.0976\n",
      "Epoch 1768/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0187 - mae: 0.0993\n",
      "Epoch 1769/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0962\n",
      "Epoch 1770/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0175 - mae: 0.0964\n",
      "Epoch 1771/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0173 - mae: 0.0942\n",
      "Epoch 1772/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0172 - mae: 0.0945\n",
      "Epoch 1773/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0176 - mae: 0.0950\n",
      "Epoch 1774/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0178 - mae: 0.0963\n",
      "Epoch 1775/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0171 - mae: 0.0940\n",
      "Epoch 1776/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0178 - mae: 0.0961\n",
      "Epoch 1777/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0181 - mae: 0.0974\n",
      "Epoch 1778/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0196 - mae: 0.1010\n",
      "Epoch 1779/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0232 - mae: 0.1111\n",
      "Epoch 1780/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0176 - mae: 0.0966\n",
      "Epoch 1781/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0179 - mae: 0.0966\n",
      "Epoch 1782/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0177 - mae: 0.0963\n",
      "Epoch 1783/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0187 - mae: 0.0985\n",
      "Epoch 1784/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0175 - mae: 0.0940\n",
      "Epoch 1785/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0175 - mae: 0.0958\n",
      "Epoch 1786/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0174 - mae: 0.0954\n",
      "Epoch 1787/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0188 - mae: 0.1000\n",
      "Epoch 1788/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0172 - mae: 0.0939\n",
      "Epoch 1789/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0180 - mae: 0.0965\n",
      "Epoch 1790/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0173 - mae: 0.0943\n",
      "Epoch 1791/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0167 - mae: 0.0918\n",
      "Epoch 1792/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0170 - mae: 0.0934\n",
      "Epoch 1793/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0177 - mae: 0.0953\n",
      "Epoch 1794/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0169 - mae: 0.0934\n",
      "Epoch 1795/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0174 - mae: 0.0956\n",
      "Epoch 1796/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0168 - mae: 0.0925\n",
      "Epoch 1797/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0179 - mae: 0.0961\n",
      "Epoch 1798/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0171 - mae: 0.0928\n",
      "Epoch 1799/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0180 - mae: 0.0967\n",
      "Epoch 1800/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0169 - mae: 0.0929\n",
      "Epoch 1801/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0178 - mae: 0.0968\n",
      "Epoch 1802/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0173 - mae: 0.0938\n",
      "Epoch 1803/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0182 - mae: 0.0977\n",
      "Epoch 1804/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0173 - mae: 0.0938\n",
      "Epoch 1805/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0174 - mae: 0.0951\n",
      "Epoch 1806/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0173 - mae: 0.0957\n",
      "Epoch 1807/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0171 - mae: 0.0941\n",
      "Epoch 1808/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0176 - mae: 0.0959\n",
      "Epoch 1809/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0191 - mae: 0.1006\n",
      "Epoch 1810/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0175 - mae: 0.0953\n",
      "Epoch 1811/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0173 - mae: 0.0953\n",
      "Epoch 1812/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0179 - mae: 0.0968\n",
      "Epoch 1813/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0181 - mae: 0.0972\n",
      "Epoch 1814/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0174 - mae: 0.0953\n",
      "Epoch 1815/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0177 - mae: 0.0957\n",
      "Epoch 1816/2000\n",
      "2019/2019 [==============================] - 0s 92us/sample - loss: 0.0177 - mae: 0.0954\n",
      "Epoch 1817/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0191 - mae: 0.1006\n",
      "Epoch 1818/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0173 - mae: 0.0950\n",
      "Epoch 1819/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0180 - mae: 0.0961\n",
      "Epoch 1820/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0169 - mae: 0.0928\n",
      "Epoch 1821/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0167 - mae: 0.0925\n",
      "Epoch 1822/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0173 - mae: 0.0941\n",
      "Epoch 1823/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0180 - mae: 0.0966\n",
      "Epoch 1824/2000\n",
      "2019/2019 [==============================] - 0s 95us/sample - loss: 0.0171 - mae: 0.0944\n",
      "Epoch 1825/2000\n",
      "2019/2019 [==============================] - 0s 98us/sample - loss: 0.0178 - mae: 0.0961\n",
      "Epoch 1826/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0187 - mae: 0.0994\n",
      "Epoch 1827/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0172 - mae: 0.0937\n",
      "Epoch 1828/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0195 - mae: 0.1013\n",
      "Epoch 1829/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0183 - mae: 0.0981\n",
      "Epoch 1830/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0179 - mae: 0.0961\n",
      "Epoch 1831/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0173 - mae: 0.0947\n",
      "Epoch 1832/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0215 - mae: 0.1047\n",
      "Epoch 1833/2000\n",
      "2019/2019 [==============================] - 0s 94us/sample - loss: 0.0208 - mae: 0.1035\n",
      "Epoch 1834/2000\n",
      "2019/2019 [==============================] - 0s 92us/sample - loss: 0.0194 - mae: 0.1015\n",
      "Epoch 1835/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0195 - mae: 0.1013\n",
      "Epoch 1836/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0179 - mae: 0.0963\n",
      "Epoch 1837/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0172 - mae: 0.0944\n",
      "Epoch 1838/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0171 - mae: 0.0933\n",
      "Epoch 1839/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0173 - mae: 0.0940\n",
      "Epoch 1840/2000\n",
      "2019/2019 [==============================] - 0s 95us/sample - loss: 0.0187 - mae: 0.0985\n",
      "Epoch 1841/2000\n",
      "2019/2019 [==============================] - 0s 97us/sample - loss: 0.0176 - mae: 0.0958\n",
      "Epoch 1842/2000\n",
      "2019/2019 [==============================] - 0s 97us/sample - loss: 0.0188 - mae: 0.0998\n",
      "Epoch 1843/2000\n",
      "2019/2019 [==============================] - 0s 95us/sample - loss: 0.0181 - mae: 0.0957\n",
      "Epoch 1844/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0181 - mae: 0.0972\n",
      "Epoch 1845/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0170 - mae: 0.0929\n",
      "Epoch 1846/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0177 - mae: 0.0955\n",
      "Epoch 1847/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0171 - mae: 0.0930\n",
      "Epoch 1848/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0181 - mae: 0.0970\n",
      "Epoch 1849/2000\n",
      "2019/2019 [==============================] - 0s 94us/sample - loss: 0.0189 - mae: 0.0987\n",
      "Epoch 1850/2000\n",
      "2019/2019 [==============================] - 0s 101us/sample - loss: 0.0181 - mae: 0.0967\n",
      "Epoch 1851/2000\n",
      "2019/2019 [==============================] - 0s 102us/sample - loss: 0.0186 - mae: 0.0987\n",
      "Epoch 1852/2000\n",
      "2019/2019 [==============================] - 0s 95us/sample - loss: 0.0177 - mae: 0.0958\n",
      "Epoch 1853/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0185 - mae: 0.0984\n",
      "Epoch 1854/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0174 - mae: 0.0949\n",
      "Epoch 1855/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0174 - mae: 0.0952\n",
      "Epoch 1856/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0172 - mae: 0.0942\n",
      "Epoch 1857/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0173 - mae: 0.0952\n",
      "Epoch 1858/2000\n",
      "2019/2019 [==============================] - 0s 97us/sample - loss: 0.0171 - mae: 0.0940\n",
      "Epoch 1859/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0203 - mae: 0.1027\n",
      "Epoch 1860/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0182 - mae: 0.0980\n",
      "Epoch 1861/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0182 - mae: 0.0980\n",
      "Epoch 1862/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0191 - mae: 0.1009\n",
      "Epoch 1863/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0172 - mae: 0.0944\n",
      "Epoch 1864/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0188 - mae: 0.1000\n",
      "Epoch 1865/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0181 - mae: 0.0976\n",
      "Epoch 1866/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0168 - mae: 0.0933\n",
      "Epoch 1867/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0174 - mae: 0.0951\n",
      "Epoch 1868/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0169 - mae: 0.0934\n",
      "Epoch 1869/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0171 - mae: 0.0945\n",
      "Epoch 1870/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0174 - mae: 0.0946\n",
      "Epoch 1871/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0166 - mae: 0.0934\n",
      "Epoch 1872/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0172 - mae: 0.0945\n",
      "Epoch 1873/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0171 - mae: 0.0942\n",
      "Epoch 1874/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0195 - mae: 0.1000\n",
      "Epoch 1875/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0195 - mae: 0.1004\n",
      "Epoch 1876/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0177 - mae: 0.0949\n",
      "Epoch 1877/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0179 - mae: 0.0957\n",
      "Epoch 1878/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0167 - mae: 0.0925\n",
      "Epoch 1879/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0177 - mae: 0.0965\n",
      "Epoch 1880/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0173 - mae: 0.0951\n",
      "Epoch 1881/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0175 - mae: 0.0951\n",
      "Epoch 1882/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0169 - mae: 0.0931\n",
      "Epoch 1883/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0171 - mae: 0.0936\n",
      "Epoch 1884/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0178 - mae: 0.0956\n",
      "Epoch 1885/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0174 - mae: 0.0944\n",
      "Epoch 1886/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0180 - mae: 0.0975\n",
      "Epoch 1887/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0178 - mae: 0.0971\n",
      "Epoch 1888/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0171 - mae: 0.0939\n",
      "Epoch 1889/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0177 - mae: 0.0959\n",
      "Epoch 1890/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0176 - mae: 0.0952\n",
      "Epoch 1891/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0170 - mae: 0.0933\n",
      "Epoch 1892/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0175 - mae: 0.0946\n",
      "Epoch 1893/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0174 - mae: 0.0952\n",
      "Epoch 1894/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0178 - mae: 0.0965\n",
      "Epoch 1895/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0173 - mae: 0.0949\n",
      "Epoch 1896/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0167 - mae: 0.0930\n",
      "Epoch 1897/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0179 - mae: 0.0962\n",
      "Epoch 1898/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0174 - mae: 0.0940\n",
      "Epoch 1899/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0179 - mae: 0.0968\n",
      "Epoch 1900/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0172 - mae: 0.0949\n",
      "Epoch 1901/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0169 - mae: 0.0934\n",
      "Epoch 1902/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0179 - mae: 0.0962\n",
      "Epoch 1903/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0177 - mae: 0.0949\n",
      "Epoch 1904/2000\n",
      "2019/2019 [==============================] - 0s 103us/sample - loss: 0.0193 - mae: 0.1006\n",
      "Epoch 1905/2000\n",
      "2019/2019 [==============================] - 0s 96us/sample - loss: 0.0175 - mae: 0.0953\n",
      "Epoch 1906/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0169 - mae: 0.0925\n",
      "Epoch 1907/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0178 - mae: 0.0964\n",
      "Epoch 1908/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0170 - mae: 0.0941\n",
      "Epoch 1909/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0177 - mae: 0.0960\n",
      "Epoch 1910/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0183 - mae: 0.0977\n",
      "Epoch 1911/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0180 - mae: 0.0980\n",
      "Epoch 1912/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0169 - mae: 0.0938\n",
      "Epoch 1913/2000\n",
      "2019/2019 [==============================] - 0s 99us/sample - loss: 0.0172 - mae: 0.0942\n",
      "Epoch 1914/2000\n",
      "2019/2019 [==============================] - 0s 97us/sample - loss: 0.0174 - mae: 0.0952\n",
      "Epoch 1915/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0172 - mae: 0.0943\n",
      "Epoch 1916/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0172 - mae: 0.0942\n",
      "Epoch 1917/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0180 - mae: 0.0980\n",
      "Epoch 1918/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0186 - mae: 0.0987\n",
      "Epoch 1919/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0173 - mae: 0.0947\n",
      "Epoch 1920/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0171 - mae: 0.0941\n",
      "Epoch 1921/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0194 - mae: 0.0998\n",
      "Epoch 1922/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0171 - mae: 0.0940\n",
      "Epoch 1923/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0188 - mae: 0.0999\n",
      "Epoch 1924/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0175 - mae: 0.0946\n",
      "Epoch 1925/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0168 - mae: 0.0932\n",
      "Epoch 1926/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0164 - mae: 0.0921\n",
      "Epoch 1927/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0168 - mae: 0.0939\n",
      "Epoch 1928/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0172 - mae: 0.0940\n",
      "Epoch 1929/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0168 - mae: 0.0935\n",
      "Epoch 1930/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0171 - mae: 0.0932\n",
      "Epoch 1931/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0169 - mae: 0.0931\n",
      "Epoch 1932/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0200 - mae: 0.1046\n",
      "Epoch 1933/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0177 - mae: 0.0957\n",
      "Epoch 1934/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0187 - mae: 0.0994\n",
      "Epoch 1935/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0178 - mae: 0.0967\n",
      "Epoch 1936/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0181 - mae: 0.0966\n",
      "Epoch 1937/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0179 - mae: 0.0970\n",
      "Epoch 1938/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0189 - mae: 0.0991\n",
      "Epoch 1939/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0182 - mae: 0.0965\n",
      "Epoch 1940/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0173 - mae: 0.0951\n",
      "Epoch 1941/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0176 - mae: 0.0956\n",
      "Epoch 1942/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0166 - mae: 0.0927\n",
      "Epoch 1943/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0169 - mae: 0.0939\n",
      "Epoch 1944/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0170 - mae: 0.0940\n",
      "Epoch 1945/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0247 - mae: 0.1183\n",
      "Epoch 1946/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0185 - mae: 0.0982\n",
      "Epoch 1947/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0173 - mae: 0.0946\n",
      "Epoch 1948/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0171 - mae: 0.0948\n",
      "Epoch 1949/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0167 - mae: 0.0926\n",
      "Epoch 1950/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0169 - mae: 0.0934\n",
      "Epoch 1951/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0186 - mae: 0.0989\n",
      "Epoch 1952/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0168 - mae: 0.0932\n",
      "Epoch 1953/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0167 - mae: 0.0924\n",
      "Epoch 1954/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0168 - mae: 0.0935\n",
      "Epoch 1955/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0170 - mae: 0.0935\n",
      "Epoch 1956/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0173 - mae: 0.0947\n",
      "Epoch 1957/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0174 - mae: 0.0952\n",
      "Epoch 1958/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0166 - mae: 0.0921\n",
      "Epoch 1959/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0166 - mae: 0.0920\n",
      "Epoch 1960/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0177 - mae: 0.0962\n",
      "Epoch 1961/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0170 - mae: 0.0930\n",
      "Epoch 1962/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0171 - mae: 0.0939\n",
      "Epoch 1963/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0166 - mae: 0.0925\n",
      "Epoch 1964/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0171 - mae: 0.0940\n",
      "Epoch 1965/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0207 - mae: 0.1038\n",
      "Epoch 1966/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0172 - mae: 0.0938\n",
      "Epoch 1967/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0168 - mae: 0.0929\n",
      "Epoch 1968/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0174 - mae: 0.0953\n",
      "Epoch 1969/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0167 - mae: 0.0926\n",
      "Epoch 1970/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0173 - mae: 0.0946\n",
      "Epoch 1971/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0167 - mae: 0.0927\n",
      "Epoch 1972/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0177 - mae: 0.0962\n",
      "Epoch 1973/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0177 - mae: 0.0957\n",
      "Epoch 1974/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0178 - mae: 0.0967\n",
      "Epoch 1975/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0189 - mae: 0.0989\n",
      "Epoch 1976/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0174 - mae: 0.0943\n",
      "Epoch 1977/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0176 - mae: 0.0951\n",
      "Epoch 1978/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0177 - mae: 0.0961\n",
      "Epoch 1979/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0174 - mae: 0.0946\n",
      "Epoch 1980/2000\n",
      "2019/2019 [==============================] - 0s 94us/sample - loss: 0.0174 - mae: 0.0956\n",
      "Epoch 1981/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0176 - mae: 0.0954\n",
      "Epoch 1982/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0171 - mae: 0.0947\n",
      "Epoch 1983/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0166 - mae: 0.0925\n",
      "Epoch 1984/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0173 - mae: 0.0951\n",
      "Epoch 1985/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0177 - mae: 0.0953\n",
      "Epoch 1986/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0277 - mae: 0.1054\n",
      "Epoch 1987/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0181 - mae: 0.0967\n",
      "Epoch 1988/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0173 - mae: 0.0949\n",
      "Epoch 1989/2000\n",
      "2019/2019 [==============================] - 0s 92us/sample - loss: 0.0177 - mae: 0.0954\n",
      "Epoch 1990/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0169 - mae: 0.0928\n",
      "Epoch 1991/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0173 - mae: 0.0945\n",
      "Epoch 1992/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0172 - mae: 0.0936\n",
      "Epoch 1993/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0240 - mae: 0.1139\n",
      "Epoch 1994/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0201 - mae: 0.1021\n",
      "Epoch 1995/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0184 - mae: 0.0979\n",
      "Epoch 1996/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0175 - mae: 0.0955\n",
      "Epoch 1997/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0176 - mae: 0.0952\n",
      "Epoch 1998/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0186 - mae: 0.0979\n",
      "Epoch 1999/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0175 - mae: 0.0950\n",
      "Epoch 2000/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0176 - mae: 0.0954\n",
      "mae: 0.11740435659885406\n",
      "Overfit mae: 0.09276264160871506\n",
      "Train on 2019 samples\n",
      "Epoch 1/2000\n",
      "2019/2019 [==============================] - 1s 539us/sample - loss: 18394.3490 - mae: 31.3568\n",
      "Epoch 2/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 10090.5742 - mae: 25.6069\n",
      "Epoch 3/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 33317.9086 - mae: 26.2302\n",
      "Epoch 4/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 3974.9468 - mae: 14.5911\n",
      "Epoch 5/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 4117.1465 - mae: 13.5966\n",
      "Epoch 6/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 8044.6993 - mae: 15.3535\n",
      "Epoch 7/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 9442.6399 - mae: 12.8767\n",
      "Epoch 8/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 630.4875 - mae: 6.8937\n",
      "Epoch 9/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 151.7623 - mae: 4.0948\n",
      "Epoch 10/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 200.1174 - mae: 4.7486\n",
      "Epoch 11/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 249.3712 - mae: 4.5803\n",
      "Epoch 12/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 101.2425 - mae: 3.7742\n",
      "Epoch 13/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 37.6700 - mae: 3.0010\n",
      "Epoch 14/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 35.7831 - mae: 2.8349\n",
      "Epoch 15/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 33.6944 - mae: 2.7929\n",
      "Epoch 16/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 32.0026 - mae: 2.7184\n",
      "Epoch 17/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 47.8177 - mae: 2.8397\n",
      "Epoch 18/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 78.2845 - mae: 3.1546\n",
      "Epoch 19/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 78.5360 - mae: 3.0859\n",
      "Epoch 20/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 240.5889 - mae: 4.8329\n",
      "Epoch 21/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 3471.1042 - mae: 13.6065\n",
      "Epoch 22/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 10779.2886 - mae: 20.6546\n",
      "Epoch 23/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 64413.2313 - mae: 26.1181\n",
      "Epoch 24/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 19036.7877 - mae: 21.8510\n",
      "Epoch 25/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 4275.5516 - mae: 9.5835\n",
      "Epoch 26/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 2975.0198 - mae: 9.2079\n",
      "Epoch 27/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 81us/sample - loss: 328.5464 - mae: 3.9814\n",
      "Epoch 28/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 449.1078 - mae: 3.7148\n",
      "Epoch 29/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 359.5466 - mae: 3.8290\n",
      "Epoch 30/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 166.2809 - mae: 3.0997\n",
      "Epoch 31/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 92.0208 - mae: 2.5060\n",
      "Epoch 32/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 54.6767 - mae: 2.2436\n",
      "Epoch 33/2000\n",
      "2019/2019 [==============================] - 0s 95us/sample - loss: 63.1054 - mae: 2.2330\n",
      "Epoch 34/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 31.3503 - mae: 1.8868\n",
      "Epoch 35/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 27.4357 - mae: 1.7657\n",
      "Epoch 36/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 20.6997 - mae: 1.7270\n",
      "Epoch 37/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 17.0093 - mae: 1.6262\n",
      "Epoch 38/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 16.2943 - mae: 1.4775\n",
      "Epoch 39/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 13.9728 - mae: 1.4023\n",
      "Epoch 40/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 14.5204 - mae: 1.3481\n",
      "Epoch 41/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 21.6285 - mae: 1.3363\n",
      "Epoch 42/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 15.7102 - mae: 1.2382\n",
      "Epoch 43/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 34.0888 - mae: 1.4303\n",
      "Epoch 44/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 16.1699 - mae: 1.2316\n",
      "Epoch 45/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 12.4670 - mae: 1.1179\n",
      "Epoch 46/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 28.1521 - mae: 1.3076\n",
      "Epoch 47/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 14.9542 - mae: 1.1528\n",
      "Epoch 48/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 31.0778 - mae: 1.2685\n",
      "Epoch 49/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 28.9424 - mae: 1.2332\n",
      "Epoch 50/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 380.5390 - mae: 2.6459\n",
      "Epoch 51/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 357.2798 - mae: 2.4961\n",
      "Epoch 52/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 205.1927 - mae: 1.8877\n",
      "Epoch 53/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 845.0659 - mae: 3.3666\n",
      "Epoch 54/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 2585.6281 - mae: 5.0576\n",
      "Epoch 55/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 682.1634 - mae: 3.0996\n",
      "Epoch 56/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 412.1205 - mae: 2.8765\n",
      "Epoch 57/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 67.1032 - mae: 1.6357\n",
      "Epoch 58/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 625.0094 - mae: 2.7976\n",
      "Epoch 59/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 362.8223 - mae: 1.8454\n",
      "Epoch 60/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 346.2917 - mae: 2.2144\n",
      "Epoch 61/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 57.4787 - mae: 1.3867\n",
      "Epoch 62/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 70.5768 - mae: 1.4096\n",
      "Epoch 63/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 13.9516 - mae: 1.0148\n",
      "Epoch 64/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 12.5101 - mae: 0.9483\n",
      "Epoch 65/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 19.7272 - mae: 1.0027\n",
      "Epoch 66/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 10.1712 - mae: 0.8767\n",
      "Epoch 67/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 8.0917 - mae: 0.8321\n",
      "Epoch 68/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 8.2836 - mae: 0.8196\n",
      "Epoch 69/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 7.0942 - mae: 0.8028\n",
      "Epoch 70/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 8.0540 - mae: 0.7980\n",
      "Epoch 71/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 6.6998 - mae: 0.7717\n",
      "Epoch 72/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 6.1965 - mae: 0.7455\n",
      "Epoch 73/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 5.8495 - mae: 0.7346\n",
      "Epoch 74/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 4.9549 - mae: 0.7187\n",
      "Epoch 75/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 5.7027 - mae: 0.7205\n",
      "Epoch 76/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 5.8775 - mae: 0.7174\n",
      "Epoch 77/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 17.5142 - mae: 0.8483\n",
      "Epoch 78/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 6.4576 - mae: 0.7288\n",
      "Epoch 79/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 5.2927 - mae: 0.6869\n",
      "Epoch 80/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 4.0827 - mae: 0.6507\n",
      "Epoch 81/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 3.9930 - mae: 0.6483\n",
      "Epoch 82/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 4.2751 - mae: 0.6516\n",
      "Epoch 83/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 3.5868 - mae: 0.6220\n",
      "Epoch 84/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 3.6704 - mae: 0.6280\n",
      "Epoch 85/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 3.5826 - mae: 0.6134\n",
      "Epoch 86/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 4.1760 - mae: 0.6125\n",
      "Epoch 87/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 5.1521 - mae: 0.6552\n",
      "Epoch 88/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 3.7900 - mae: 0.6037\n",
      "Epoch 89/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 4.6551 - mae: 0.6301\n",
      "Epoch 90/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 3.7439 - mae: 0.6039\n",
      "Epoch 91/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 5.1521 - mae: 0.6057\n",
      "Epoch 92/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 13.4577 - mae: 0.7436\n",
      "Epoch 93/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 7.4881 - mae: 0.6702\n",
      "Epoch 94/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 5.6013 - mae: 0.6380\n",
      "Epoch 95/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 4.2243 - mae: 0.5830\n",
      "Epoch 96/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 18.9824 - mae: 0.7653\n",
      "Epoch 97/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 13.5009 - mae: 0.7166\n",
      "Epoch 98/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 15.4601 - mae: 0.7123\n",
      "Epoch 99/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 51.1300 - mae: 0.9997\n",
      "Epoch 100/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 19.8845 - mae: 0.7252\n",
      "Epoch 101/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 8.5187 - mae: 0.6412\n",
      "Epoch 102/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 7.9626 - mae: 0.6255\n",
      "Epoch 103/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 10.4126 - mae: 0.6336\n",
      "Epoch 104/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 12.3255 - mae: 0.6423\n",
      "Epoch 105/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 4.9305 - mae: 0.5530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 16.1999 - mae: 0.6868\n",
      "Epoch 107/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 28.0147 - mae: 0.8057\n",
      "Epoch 108/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 3.0181 - mae: 0.5176\n",
      "Epoch 109/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 26.1430 - mae: 0.7950\n",
      "Epoch 110/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 58.9272 - mae: 0.9180\n",
      "Epoch 111/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 23.0369 - mae: 0.7513\n",
      "Epoch 112/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 111.1479 - mae: 1.0452\n",
      "Epoch 113/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 41.3553 - mae: 0.8157\n",
      "Epoch 114/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 37.0175 - mae: 0.7553\n",
      "Epoch 115/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 510.5857 - mae: 1.9831\n",
      "Epoch 116/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 103.7456 - mae: 1.1014\n",
      "Epoch 117/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 73.2500 - mae: 0.9192\n",
      "Epoch 118/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 759.1070 - mae: 2.9592\n",
      "Epoch 119/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 45.4444 - mae: 0.9994\n",
      "Epoch 120/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 62.1976 - mae: 1.0308\n",
      "Epoch 121/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 36.5866 - mae: 0.8382\n",
      "Epoch 122/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 7.3384 - mae: 0.5379\n",
      "Epoch 123/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 42.0134 - mae: 0.7524\n",
      "Epoch 124/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 52.1214 - mae: 0.9142\n",
      "Epoch 125/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 95.0167 - mae: 1.0896\n",
      "Epoch 126/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 54.1600 - mae: 0.6132\n",
      "Epoch 127/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 91.3417 - mae: 0.8354\n",
      "Epoch 128/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 9.8556 - mae: 0.5214\n",
      "Epoch 129/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 6.4629 - mae: 0.4617\n",
      "Epoch 130/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 17.1485 - mae: 0.5722\n",
      "Epoch 131/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 16.7646 - mae: 0.5715\n",
      "Epoch 132/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 6.7249 - mae: 0.4424\n",
      "Epoch 133/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 2.4732 - mae: 0.3961\n",
      "Epoch 134/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 2.3153 - mae: 0.3957\n",
      "Epoch 135/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 4.1561 - mae: 0.4388\n",
      "Epoch 136/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 6.0085 - mae: 0.4269\n",
      "Epoch 137/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 4.2640 - mae: 0.4164\n",
      "Epoch 138/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 7.2597 - mae: 0.4488\n",
      "Epoch 139/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 61.2007 - mae: 0.7653\n",
      "Epoch 140/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 12.5176 - mae: 0.4755\n",
      "Epoch 141/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 47.2141 - mae: 0.6578\n",
      "Epoch 142/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 4.8995 - mae: 0.4115\n",
      "Epoch 143/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 5.5457 - mae: 0.4045\n",
      "Epoch 144/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 3.3870 - mae: 0.3788\n",
      "Epoch 145/2000\n",
      "2019/2019 [==============================] - 0s 92us/sample - loss: 5.5227 - mae: 0.3999\n",
      "Epoch 146/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 16.0542 - mae: 0.5279\n",
      "Epoch 147/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 1.5473 - mae: 0.3266\n",
      "Epoch 148/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 4.3612 - mae: 0.3949\n",
      "Epoch 149/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 1.1434 - mae: 0.3012\n",
      "Epoch 150/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 1.9260 - mae: 0.3250\n",
      "Epoch 151/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 5.3850 - mae: 0.3877\n",
      "Epoch 152/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 1.7378 - mae: 0.3164\n",
      "Epoch 153/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 3.8103 - mae: 0.3340\n",
      "Epoch 154/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 22.2336 - mae: 0.5359\n",
      "Epoch 155/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 5.9583 - mae: 0.3893\n",
      "Epoch 156/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 17.8930 - mae: 0.4442\n",
      "Epoch 157/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 60.8714 - mae: 0.7253\n",
      "Epoch 158/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 15.7222 - mae: 0.4813\n",
      "Epoch 159/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 9.5205 - mae: 0.4607\n",
      "Epoch 160/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 74.3832 - mae: 0.8621\n",
      "Epoch 161/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 114.7028 - mae: 0.8720\n",
      "Epoch 162/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 99.9359 - mae: 1.1348\n",
      "Epoch 163/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 35.3938 - mae: 0.5282\n",
      "Epoch 164/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.5862 - mae: 0.2455\n",
      "Epoch 165/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5452 - mae: 0.2363\n",
      "Epoch 166/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.5406 - mae: 0.2343\n",
      "Epoch 167/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.5407 - mae: 0.2356\n",
      "Epoch 168/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.5391 - mae: 0.2339\n",
      "Epoch 169/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.5369 - mae: 0.2328\n",
      "Epoch 170/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5362 - mae: 0.2322\n",
      "Epoch 171/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5355 - mae: 0.2318\n",
      "Epoch 172/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5420 - mae: 0.2333\n",
      "Epoch 173/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5294 - mae: 0.2303\n",
      "Epoch 174/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5286 - mae: 0.2305\n",
      "Epoch 175/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.5270 - mae: 0.2290\n",
      "Epoch 176/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.5261 - mae: 0.2293\n",
      "Epoch 177/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.5255 - mae: 0.2298\n",
      "Epoch 178/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.5256 - mae: 0.2294\n",
      "Epoch 179/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.5226 - mae: 0.2282\n",
      "Epoch 180/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5207 - mae: 0.2283\n",
      "Epoch 181/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.5266 - mae: 0.2297\n",
      "Epoch 182/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.5210 - mae: 0.2279\n",
      "Epoch 183/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.5182 - mae: 0.2275\n",
      "Epoch 184/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.5201 - mae: 0.2294\n",
      "Epoch 185/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.5205 - mae: 0.2287\n",
      "Epoch 186/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.5161 - mae: 0.2267\n",
      "Epoch 187/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.5151 - mae: 0.2270\n",
      "Epoch 188/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.5158 - mae: 0.2277\n",
      "Epoch 189/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.5120 - mae: 0.2257\n",
      "Epoch 190/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5112 - mae: 0.2255\n",
      "Epoch 191/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.5130 - mae: 0.2278\n",
      "Epoch 192/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.5427 - mae: 0.2400\n",
      "Epoch 193/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.5118 - mae: 0.2266\n",
      "Epoch 194/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.5103 - mae: 0.2225\n",
      "Epoch 195/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.5478 - mae: 0.2250\n",
      "Epoch 196/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.5505 - mae: 0.2241\n",
      "Epoch 197/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.5005 - mae: 0.2175\n",
      "Epoch 198/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.4995 - mae: 0.2182\n",
      "Epoch 199/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4989 - mae: 0.2184\n",
      "Epoch 200/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4979 - mae: 0.2176\n",
      "Epoch 201/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4965 - mae: 0.2173\n",
      "Epoch 202/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4953 - mae: 0.2175\n",
      "Epoch 203/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4938 - mae: 0.2159\n",
      "Epoch 204/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4929 - mae: 0.2167\n",
      "Epoch 205/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4917 - mae: 0.2160\n",
      "Epoch 206/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.4908 - mae: 0.2176\n",
      "Epoch 207/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4897 - mae: 0.2167\n",
      "Epoch 208/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.4888 - mae: 0.2169\n",
      "Epoch 209/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4873 - mae: 0.2160\n",
      "Epoch 210/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4866 - mae: 0.2166\n",
      "Epoch 211/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4849 - mae: 0.2152\n",
      "Epoch 212/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4839 - mae: 0.2157\n",
      "Epoch 213/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4831 - mae: 0.2159\n",
      "Epoch 214/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4827 - mae: 0.2167\n",
      "Epoch 215/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.4806 - mae: 0.2145\n",
      "Epoch 216/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.4798 - mae: 0.2151\n",
      "Epoch 217/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.4793 - mae: 0.2166\n",
      "Epoch 218/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4776 - mae: 0.2157\n",
      "Epoch 219/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4759 - mae: 0.2144\n",
      "Epoch 220/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4748 - mae: 0.2140\n",
      "Epoch 221/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4737 - mae: 0.2137\n",
      "Epoch 222/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4725 - mae: 0.2130\n",
      "Epoch 223/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4721 - mae: 0.2153\n",
      "Epoch 224/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4701 - mae: 0.2132\n",
      "Epoch 225/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4690 - mae: 0.2124\n",
      "Epoch 226/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.4676 - mae: 0.2122\n",
      "Epoch 227/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.4663 - mae: 0.2118\n",
      "Epoch 228/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4653 - mae: 0.2121\n",
      "Epoch 229/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4648 - mae: 0.2119\n",
      "Epoch 230/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4626 - mae: 0.2112\n",
      "Epoch 231/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4620 - mae: 0.2121\n",
      "Epoch 232/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4606 - mae: 0.2107\n",
      "Epoch 233/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4586 - mae: 0.2093\n",
      "Epoch 234/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4581 - mae: 0.2096\n",
      "Epoch 235/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.4556 - mae: 0.2083\n",
      "Epoch 236/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.4567 - mae: 0.2112\n",
      "Epoch 237/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4533 - mae: 0.2070\n",
      "Epoch 238/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4531 - mae: 0.2086\n",
      "Epoch 239/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4518 - mae: 0.2082\n",
      "Epoch 240/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4500 - mae: 0.2074\n",
      "Epoch 241/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4493 - mae: 0.2074\n",
      "Epoch 242/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4476 - mae: 0.2059\n",
      "Epoch 243/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4467 - mae: 0.2065\n",
      "Epoch 244/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4456 - mae: 0.2068\n",
      "Epoch 245/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4457 - mae: 0.2084\n",
      "Epoch 246/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.4428 - mae: 0.2058\n",
      "Epoch 247/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.4421 - mae: 0.2057\n",
      "Epoch 248/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.4414 - mae: 0.2067\n",
      "Epoch 249/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4396 - mae: 0.2051\n",
      "Epoch 250/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4386 - mae: 0.2051\n",
      "Epoch 251/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.4388 - mae: 0.2071\n",
      "Epoch 252/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.4364 - mae: 0.2050\n",
      "Epoch 253/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4347 - mae: 0.2042\n",
      "Epoch 254/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4349 - mae: 0.2054\n",
      "Epoch 255/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.4333 - mae: 0.2046\n",
      "Epoch 256/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.4327 - mae: 0.2046\n",
      "Epoch 257/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.4302 - mae: 0.2028\n",
      "Epoch 258/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.4299 - mae: 0.2032\n",
      "Epoch 259/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.4291 - mae: 0.2035\n",
      "Epoch 260/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4268 - mae: 0.2021\n",
      "Epoch 261/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4252 - mae: 0.2004\n",
      "Epoch 262/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4239 - mae: 0.2002\n",
      "Epoch 263/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4224 - mae: 0.1990\n",
      "Epoch 264/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4323 - mae: 0.2029\n",
      "Epoch 265/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.4217 - mae: 0.2010\n",
      "Epoch 266/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.4195 - mae: 0.1992\n",
      "Epoch 267/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.4246 - mae: 0.2017\n",
      "Epoch 268/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4176 - mae: 0.1979\n",
      "Epoch 269/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.4162 - mae: 0.1979\n",
      "Epoch 270/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4160 - mae: 0.2005\n",
      "Epoch 271/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4134 - mae: 0.1972\n",
      "Epoch 272/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.4129 - mae: 0.1976\n",
      "Epoch 273/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.4113 - mae: 0.1974\n",
      "Epoch 274/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.4107 - mae: 0.1973\n",
      "Epoch 275/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.4093 - mae: 0.1966\n",
      "Epoch 276/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.4091 - mae: 0.1972\n",
      "Epoch 277/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.4072 - mae: 0.1964\n",
      "Epoch 278/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.4058 - mae: 0.1962\n",
      "Epoch 279/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.4056 - mae: 0.1974\n",
      "Epoch 280/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.4038 - mae: 0.1964\n",
      "Epoch 281/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.4022 - mae: 0.1946\n",
      "Epoch 282/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.4005 - mae: 0.1945\n",
      "Epoch 283/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3995 - mae: 0.1945\n",
      "Epoch 284/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3985 - mae: 0.1940\n",
      "Epoch 285/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.3983 - mae: 0.1947\n",
      "Epoch 286/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.3977 - mae: 0.1959\n",
      "Epoch 287/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.3966 - mae: 0.1959\n",
      "Epoch 288/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3946 - mae: 0.1940\n",
      "Epoch 289/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3930 - mae: 0.1921\n",
      "Epoch 290/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3917 - mae: 0.1912\n",
      "Epoch 291/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3902 - mae: 0.1908\n",
      "Epoch 292/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3898 - mae: 0.1917\n",
      "Epoch 293/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3887 - mae: 0.1920\n",
      "Epoch 294/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3866 - mae: 0.1907\n",
      "Epoch 295/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.3852 - mae: 0.1899\n",
      "Epoch 296/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.3839 - mae: 0.1883\n",
      "Epoch 297/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.3824 - mae: 0.1879\n",
      "Epoch 298/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.3815 - mae: 0.1885\n",
      "Epoch 299/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3810 - mae: 0.1897\n",
      "Epoch 300/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3799 - mae: 0.1902\n",
      "Epoch 301/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3774 - mae: 0.1869\n",
      "Epoch 302/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3770 - mae: 0.1885\n",
      "Epoch 303/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3757 - mae: 0.1883\n",
      "Epoch 304/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3755 - mae: 0.1911\n",
      "Epoch 305/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.3718 - mae: 0.1847\n",
      "Epoch 306/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.3700 - mae: 0.1840\n",
      "Epoch 307/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.3692 - mae: 0.1849\n",
      "Epoch 308/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.3678 - mae: 0.1832\n",
      "Epoch 309/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3662 - mae: 0.1836\n",
      "Epoch 310/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3642 - mae: 0.1815\n",
      "Epoch 311/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3632 - mae: 0.1820\n",
      "Epoch 312/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3619 - mae: 0.1814\n",
      "Epoch 313/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3599 - mae: 0.1802\n",
      "Epoch 314/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3600 - mae: 0.1843\n",
      "Epoch 315/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.3577 - mae: 0.1825\n",
      "Epoch 316/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.3554 - mae: 0.1802\n",
      "Epoch 317/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.3534 - mae: 0.1788\n",
      "Epoch 318/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3514 - mae: 0.1769\n",
      "Epoch 319/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3516 - mae: 0.1802\n",
      "Epoch 320/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3504 - mae: 0.1801\n",
      "Epoch 321/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3490 - mae: 0.1811\n",
      "Epoch 322/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3453 - mae: 0.1751\n",
      "Epoch 323/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3458 - mae: 0.1796\n",
      "Epoch 324/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3427 - mae: 0.1759\n",
      "Epoch 325/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3410 - mae: 0.1760\n",
      "Epoch 326/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.3399 - mae: 0.1760\n",
      "Epoch 327/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.3408 - mae: 0.1805\n",
      "Epoch 328/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3366 - mae: 0.1743\n",
      "Epoch 329/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3350 - mae: 0.1734\n",
      "Epoch 330/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3604 - mae: 0.1895\n",
      "Epoch 331/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.3356 - mae: 0.1784\n",
      "Epoch 332/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3323 - mae: 0.1745\n",
      "Epoch 333/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3304 - mae: 0.1733\n",
      "Epoch 334/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3301 - mae: 0.1760\n",
      "Epoch 335/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3280 - mae: 0.1754\n",
      "Epoch 336/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.3252 - mae: 0.1718\n",
      "Epoch 337/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.3244 - mae: 0.1738\n",
      "Epoch 338/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.3228 - mae: 0.1733\n",
      "Epoch 339/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3216 - mae: 0.1748\n",
      "Epoch 340/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3189 - mae: 0.1722\n",
      "Epoch 341/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3204 - mae: 0.1764\n",
      "Epoch 342/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3161 - mae: 0.1714\n",
      "Epoch 343/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3142 - mae: 0.1699\n",
      "Epoch 344/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.3138 - mae: 0.1743\n",
      "Epoch 345/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.3108 - mae: 0.1703\n",
      "Epoch 346/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.3086 - mae: 0.1682\n",
      "Epoch 347/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.3077 - mae: 0.1704\n",
      "Epoch 348/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3055 - mae: 0.1687\n",
      "Epoch 349/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.3028 - mae: 0.1662\n",
      "Epoch 350/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.3032 - mae: 0.1694\n",
      "Epoch 351/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2999 - mae: 0.1674\n",
      "Epoch 352/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2981 - mae: 0.1670\n",
      "Epoch 353/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2980 - mae: 0.1703\n",
      "Epoch 354/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2949 - mae: 0.1662\n",
      "Epoch 355/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2921 - mae: 0.1635\n",
      "Epoch 356/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.2944 - mae: 0.1680\n",
      "Epoch 357/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.2914 - mae: 0.1699\n",
      "Epoch 358/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2949 - mae: 0.1804\n",
      "Epoch 359/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2937 - mae: 0.1819\n",
      "Epoch 360/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3002 - mae: 0.1942\n",
      "Epoch 361/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2927 - mae: 0.1827\n",
      "Epoch 362/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2870 - mae: 0.1766\n",
      "Epoch 363/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2845 - mae: 0.1760\n",
      "Epoch 364/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2810 - mae: 0.1726\n",
      "Epoch 365/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.2787 - mae: 0.1720\n",
      "Epoch 366/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.2770 - mae: 0.1722\n",
      "Epoch 367/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.2753 - mae: 0.1737\n",
      "Epoch 368/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2716 - mae: 0.1692\n",
      "Epoch 369/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2708 - mae: 0.1713\n",
      "Epoch 370/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2674 - mae: 0.1676\n",
      "Epoch 371/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2654 - mae: 0.1681\n",
      "Epoch 372/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2636 - mae: 0.1686\n",
      "Epoch 373/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2621 - mae: 0.1690\n",
      "Epoch 374/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2590 - mae: 0.1670\n",
      "Epoch 375/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2583 - mae: 0.1698\n",
      "Epoch 376/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.2559 - mae: 0.1679\n",
      "Epoch 377/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2533 - mae: 0.1662\n",
      "Epoch 378/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.2523 - mae: 0.1688\n",
      "Epoch 379/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2512 - mae: 0.1718\n",
      "Epoch 380/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2480 - mae: 0.1668\n",
      "Epoch 381/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2467 - mae: 0.1692\n",
      "Epoch 382/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2430 - mae: 0.1660\n",
      "Epoch 383/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2416 - mae: 0.1675\n",
      "Epoch 384/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2436 - mae: 0.1745\n",
      "Epoch 385/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.2386 - mae: 0.1689\n",
      "Epoch 386/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.2367 - mae: 0.1713\n",
      "Epoch 387/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.2328 - mae: 0.1650\n",
      "Epoch 388/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.2298 - mae: 0.1641\n",
      "Epoch 389/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2378 - mae: 0.1754\n",
      "Epoch 390/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2420 - mae: 0.1910\n",
      "Epoch 391/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2329 - mae: 0.1790\n",
      "Epoch 392/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2266 - mae: 0.1697\n",
      "Epoch 393/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2240 - mae: 0.1674\n",
      "Epoch 394/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2249 - mae: 0.1753\n",
      "Epoch 395/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.2214 - mae: 0.1709\n",
      "Epoch 396/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.2164 - mae: 0.1643\n",
      "Epoch 397/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.2145 - mae: 0.1647\n",
      "Epoch 398/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.2177 - mae: 0.1734\n",
      "Epoch 399/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.2146 - mae: 0.1715\n",
      "Epoch 400/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.2112 - mae: 0.1683\n",
      "Epoch 401/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.2075 - mae: 0.1654\n",
      "Epoch 402/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.2042 - mae: 0.1624\n",
      "Epoch 403/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2025 - mae: 0.1643\n",
      "Epoch 404/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.2023 - mae: 0.1669\n",
      "Epoch 405/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.2023 - mae: 0.1706\n",
      "Epoch 406/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.2021 - mae: 0.1757\n",
      "Epoch 407/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1973 - mae: 0.1705\n",
      "Epoch 408/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.1969 - mae: 0.1732\n",
      "Epoch 409/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1941 - mae: 0.1710\n",
      "Epoch 410/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.1924 - mae: 0.1710\n",
      "Epoch 411/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1901 - mae: 0.1690\n",
      "Epoch 412/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1941 - mae: 0.1843\n",
      "Epoch 413/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1838 - mae: 0.1636\n",
      "Epoch 414/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1815 - mae: 0.1641\n",
      "Epoch 415/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1796 - mae: 0.1652\n",
      "Epoch 416/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.1778 - mae: 0.1652\n",
      "Epoch 417/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1749 - mae: 0.1629\n",
      "Epoch 418/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1750 - mae: 0.1683\n",
      "Epoch 419/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.3288 - mae: 0.1860\n",
      "Epoch 420/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1951 - mae: 0.2074\n",
      "Epoch 421/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1867 - mae: 0.1899\n",
      "Epoch 422/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1831 - mae: 0.1855\n",
      "Epoch 423/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1794 - mae: 0.1792\n",
      "Epoch 424/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1764 - mae: 0.1756\n",
      "Epoch 425/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1772 - mae: 0.1795\n",
      "Epoch 426/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.1737 - mae: 0.1764\n",
      "Epoch 427/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.3825 - mae: 0.1963\n",
      "Epoch 428/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1804 - mae: 0.1905\n",
      "Epoch 429/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1742 - mae: 0.1821\n",
      "Epoch 430/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1716 - mae: 0.1804\n",
      "Epoch 431/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1683 - mae: 0.1760\n",
      "Epoch 432/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1696 - mae: 0.1789\n",
      "Epoch 433/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1669 - mae: 0.1780\n",
      "Epoch 434/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1650 - mae: 0.1790\n",
      "Epoch 435/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1615 - mae: 0.1717\n",
      "Epoch 436/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1611 - mae: 0.1751\n",
      "Epoch 437/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1573 - mae: 0.1689\n",
      "Epoch 438/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1577 - mae: 0.1711\n",
      "Epoch 439/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1538 - mae: 0.1669\n",
      "Epoch 440/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1539 - mae: 0.1698\n",
      "Epoch 441/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1520 - mae: 0.1692\n",
      "Epoch 442/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1502 - mae: 0.1669\n",
      "Epoch 443/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1487 - mae: 0.1663\n",
      "Epoch 444/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1474 - mae: 0.1657\n",
      "Epoch 445/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1450 - mae: 0.1630\n",
      "Epoch 446/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.1451 - mae: 0.1664\n",
      "Epoch 447/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.1440 - mae: 0.1659\n",
      "Epoch 448/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.1413 - mae: 0.1638\n",
      "Epoch 449/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1426 - mae: 0.1680\n",
      "Epoch 450/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1376 - mae: 0.1614\n",
      "Epoch 451/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1404 - mae: 0.1724\n",
      "Epoch 452/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1376 - mae: 0.1664\n",
      "Epoch 453/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1363 - mae: 0.1651\n",
      "Epoch 454/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1323 - mae: 0.1598\n",
      "Epoch 455/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1340 - mae: 0.1664\n",
      "Epoch 456/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1432 - mae: 0.1695\n",
      "Epoch 457/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1529 - mae: 0.2035\n",
      "Epoch 458/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1513 - mae: 0.2106\n",
      "Epoch 459/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1548 - mae: 0.2224\n",
      "Epoch 460/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1455 - mae: 0.1992\n",
      "Epoch 461/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1373 - mae: 0.1830\n",
      "Epoch 462/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1319 - mae: 0.1770\n",
      "Epoch 463/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1304 - mae: 0.1772\n",
      "Epoch 464/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1294 - mae: 0.1765\n",
      "Epoch 465/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1258 - mae: 0.1726\n",
      "Epoch 466/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1242 - mae: 0.1714\n",
      "Epoch 467/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1225 - mae: 0.1696\n",
      "Epoch 468/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1224 - mae: 0.1735\n",
      "Epoch 469/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1209 - mae: 0.1714\n",
      "Epoch 470/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1186 - mae: 0.1690\n",
      "Epoch 471/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1171 - mae: 0.1668\n",
      "Epoch 472/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1154 - mae: 0.1650\n",
      "Epoch 473/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1171 - mae: 0.1719\n",
      "Epoch 474/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1136 - mae: 0.1669\n",
      "Epoch 475/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1113 - mae: 0.1627\n",
      "Epoch 476/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1116 - mae: 0.1659\n",
      "Epoch 477/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.1101 - mae: 0.1631\n",
      "Epoch 478/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.1084 - mae: 0.1621\n",
      "Epoch 479/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.1075 - mae: 0.1628\n",
      "Epoch 480/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.1122 - mae: 0.1759\n",
      "Epoch 481/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.1067 - mae: 0.1671\n",
      "Epoch 482/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1041 - mae: 0.1619\n",
      "Epoch 483/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1026 - mae: 0.1598\n",
      "Epoch 484/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1027 - mae: 0.1637\n",
      "Epoch 485/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1019 - mae: 0.1623\n",
      "Epoch 486/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.1086 - mae: 0.1797\n",
      "Epoch 487/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.1070 - mae: 0.1652\n",
      "Epoch 488/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1015 - mae: 0.1660\n",
      "Epoch 489/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0987 - mae: 0.1617\n",
      "Epoch 490/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0988 - mae: 0.1639\n",
      "Epoch 491/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0966 - mae: 0.1617\n",
      "Epoch 492/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0956 - mae: 0.1607\n",
      "Epoch 493/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0945 - mae: 0.1605\n",
      "Epoch 494/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0924 - mae: 0.1576\n",
      "Epoch 495/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0930 - mae: 0.1617\n",
      "Epoch 496/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0915 - mae: 0.1584\n",
      "Epoch 497/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0921 - mae: 0.1627\n",
      "Epoch 498/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0907 - mae: 0.1606\n",
      "Epoch 499/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.7378 - mae: 0.1908\n",
      "Epoch 500/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1010 - mae: 0.1899\n",
      "Epoch 501/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0927 - mae: 0.1724\n",
      "Epoch 502/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0902 - mae: 0.1638\n",
      "Epoch 503/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0875 - mae: 0.1607\n",
      "Epoch 504/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0860 - mae: 0.1588\n",
      "Epoch 505/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0863 - mae: 0.1607\n",
      "Epoch 506/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0846 - mae: 0.1592\n",
      "Epoch 507/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0858 - mae: 0.1634\n",
      "Epoch 508/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0836 - mae: 0.1583\n",
      "Epoch 509/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0816 - mae: 0.1561\n",
      "Epoch 510/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0813 - mae: 0.1562\n",
      "Epoch 511/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0806 - mae: 0.1574\n",
      "Epoch 512/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0800 - mae: 0.1583\n",
      "Epoch 513/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0801 - mae: 0.1577\n",
      "Epoch 514/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0809 - mae: 0.1634\n",
      "Epoch 515/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0776 - mae: 0.1538\n",
      "Epoch 516/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0766 - mae: 0.1540\n",
      "Epoch 517/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0767 - mae: 0.1559\n",
      "Epoch 518/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0766 - mae: 0.1569\n",
      "Epoch 519/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0747 - mae: 0.1516\n",
      "Epoch 520/2000\n",
      "2019/2019 [==============================] - 0s 144us/sample - loss: 0.0762 - mae: 0.1602\n",
      "Epoch 521/2000\n",
      "2019/2019 [==============================] - 0s 210us/sample - loss: 0.0735 - mae: 0.1527\n",
      "Epoch 522/2000\n",
      "2019/2019 [==============================] - 0s 96us/sample - loss: 0.0737 - mae: 0.1555\n",
      "Epoch 523/2000\n",
      "2019/2019 [==============================] - 0s 92us/sample - loss: 0.0849 - mae: 0.1791\n",
      "Epoch 524/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0738 - mae: 0.1568\n",
      "Epoch 525/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0713 - mae: 0.1534\n",
      "Epoch 526/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0707 - mae: 0.1518\n",
      "Epoch 527/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0710 - mae: 0.1561\n",
      "Epoch 528/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0698 - mae: 0.1524\n",
      "Epoch 529/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0697 - mae: 0.1551\n",
      "Epoch 530/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0680 - mae: 0.1500\n",
      "Epoch 531/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0682 - mae: 0.1512\n",
      "Epoch 532/2000\n",
      "2019/2019 [==============================] - 0s 87us/sample - loss: 0.0670 - mae: 0.1501\n",
      "Epoch 533/2000\n",
      "2019/2019 [==============================] - 0s 91us/sample - loss: 0.0688 - mae: 0.1585\n",
      "Epoch 534/2000\n",
      "2019/2019 [==============================] - 0s 89us/sample - loss: 0.0680 - mae: 0.1543\n",
      "Epoch 535/2000\n",
      "2019/2019 [==============================] - 0s 88us/sample - loss: 0.0660 - mae: 0.1504\n",
      "Epoch 536/2000\n",
      "2019/2019 [==============================] - 0s 90us/sample - loss: 0.0655 - mae: 0.1518\n",
      "Epoch 537/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0655 - mae: 0.1517\n",
      "Epoch 538/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0644 - mae: 0.1518\n",
      "Epoch 539/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0656 - mae: 0.1562\n",
      "Epoch 540/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0623 - mae: 0.1499\n",
      "Epoch 541/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0617 - mae: 0.1478\n",
      "Epoch 542/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0610 - mae: 0.1496\n",
      "Epoch 543/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0612 - mae: 0.1491\n",
      "Epoch 544/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0659 - mae: 0.1607\n",
      "Epoch 545/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0607 - mae: 0.1483\n",
      "Epoch 546/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0608 - mae: 0.1511\n",
      "Epoch 547/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0998 - mae: 0.1811\n",
      "Epoch 548/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.1657 - mae: 0.1917\n",
      "Epoch 549/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0658 - mae: 0.1592\n",
      "Epoch 550/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0635 - mae: 0.1558\n",
      "Epoch 551/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0632 - mae: 0.1549\n",
      "Epoch 552/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0616 - mae: 0.1527\n",
      "Epoch 553/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0596 - mae: 0.1501\n",
      "Epoch 554/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0586 - mae: 0.1493\n",
      "Epoch 555/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0589 - mae: 0.1505\n",
      "Epoch 556/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0587 - mae: 0.1519\n",
      "Epoch 557/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0571 - mae: 0.1503\n",
      "Epoch 558/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0549 - mae: 0.1436\n",
      "Epoch 559/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0536 - mae: 0.1430\n",
      "Epoch 560/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0545 - mae: 0.1443\n",
      "Epoch 561/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0541 - mae: 0.1453\n",
      "Epoch 562/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0523 - mae: 0.1424\n",
      "Epoch 563/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0520 - mae: 0.1427\n",
      "Epoch 564/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0532 - mae: 0.1454\n",
      "Epoch 565/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0514 - mae: 0.1421\n",
      "Epoch 566/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0502 - mae: 0.1408\n",
      "Epoch 567/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0541 - mae: 0.1513\n",
      "Epoch 568/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0502 - mae: 0.1430\n",
      "Epoch 569/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0537 - mae: 0.1492\n",
      "Epoch 570/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0521 - mae: 0.1476\n",
      "Epoch 571/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0503 - mae: 0.1440\n",
      "Epoch 572/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0525 - mae: 0.1479\n",
      "Epoch 573/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0548 - mae: 0.1527\n",
      "Epoch 574/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0521 - mae: 0.1490\n",
      "Epoch 575/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0498 - mae: 0.1452\n",
      "Epoch 576/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0505 - mae: 0.1482\n",
      "Epoch 577/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0483 - mae: 0.1433\n",
      "Epoch 578/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0479 - mae: 0.1426\n",
      "Epoch 579/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0467 - mae: 0.1411\n",
      "Epoch 580/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0472 - mae: 0.1419\n",
      "Epoch 581/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0462 - mae: 0.1415\n",
      "Epoch 582/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0454 - mae: 0.1398\n",
      "Epoch 583/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0454 - mae: 0.1407\n",
      "Epoch 584/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0454 - mae: 0.1413\n",
      "Epoch 585/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0442 - mae: 0.1394\n",
      "Epoch 586/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0445 - mae: 0.1414\n",
      "Epoch 587/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0439 - mae: 0.1396\n",
      "Epoch 588/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0429 - mae: 0.1372\n",
      "Epoch 589/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0434 - mae: 0.1406\n",
      "Epoch 590/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0416 - mae: 0.1358\n",
      "Epoch 591/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0416 - mae: 0.1368\n",
      "Epoch 592/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0419 - mae: 0.1381\n",
      "Epoch 593/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0415 - mae: 0.1374\n",
      "Epoch 594/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0408 - mae: 0.1367\n",
      "Epoch 595/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0398 - mae: 0.1341\n",
      "Epoch 596/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0407 - mae: 0.1376\n",
      "Epoch 597/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0397 - mae: 0.1356\n",
      "Epoch 598/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0423 - mae: 0.1409\n",
      "Epoch 599/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0401 - mae: 0.1372\n",
      "Epoch 600/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0400 - mae: 0.1374\n",
      "Epoch 601/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0383 - mae: 0.1332\n",
      "Epoch 602/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0393 - mae: 0.1370\n",
      "Epoch 603/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0387 - mae: 0.1350\n",
      "Epoch 604/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0416 - mae: 0.1416\n",
      "Epoch 605/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0417 - mae: 0.1437\n",
      "Epoch 606/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0373 - mae: 0.1337\n",
      "Epoch 607/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0684 - mae: 0.1648\n",
      "Epoch 608/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0438 - mae: 0.1456\n",
      "Epoch 609/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0416 - mae: 0.1411\n",
      "Epoch 610/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0409 - mae: 0.1389\n",
      "Epoch 611/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0409 - mae: 0.1388\n",
      "Epoch 612/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0392 - mae: 0.1357\n",
      "Epoch 613/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0378 - mae: 0.1315\n",
      "Epoch 614/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0392 - mae: 0.1365\n",
      "Epoch 615/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0368 - mae: 0.1292\n",
      "Epoch 616/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0368 - mae: 0.1299\n",
      "Epoch 617/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0363 - mae: 0.1291\n",
      "Epoch 618/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0370 - mae: 0.1312\n",
      "Epoch 619/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0367 - mae: 0.1310\n",
      "Epoch 620/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0366 - mae: 0.1320\n",
      "Epoch 621/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0365 - mae: 0.1303\n",
      "Epoch 622/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0354 - mae: 0.1279\n",
      "Epoch 623/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0347 - mae: 0.1274\n",
      "Epoch 624/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0342 - mae: 0.1258\n",
      "Epoch 625/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0342 - mae: 0.1263\n",
      "Epoch 626/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0354 - mae: 0.1293\n",
      "Epoch 627/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0348 - mae: 0.1279\n",
      "Epoch 628/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0329 - mae: 0.1231\n",
      "Epoch 629/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0338 - mae: 0.1258\n",
      "Epoch 630/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0355 - mae: 0.1315\n",
      "Epoch 631/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0356 - mae: 0.1307\n",
      "Epoch 632/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0340 - mae: 0.1271\n",
      "Epoch 633/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0348 - mae: 0.1301\n",
      "Epoch 634/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0330 - mae: 0.1249\n",
      "Epoch 635/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0325 - mae: 0.1238\n",
      "Epoch 636/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0318 - mae: 0.1232\n",
      "Epoch 637/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0317 - mae: 0.1228\n",
      "Epoch 638/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0327 - mae: 0.1253\n",
      "Epoch 639/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0317 - mae: 0.1233\n",
      "Epoch 640/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0313 - mae: 0.1222\n",
      "Epoch 641/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0320 - mae: 0.1252\n",
      "Epoch 642/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0313 - mae: 0.1233\n",
      "Epoch 643/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0321 - mae: 0.1249\n",
      "Epoch 644/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0305 - mae: 0.1206\n",
      "Epoch 645/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0325 - mae: 0.1264\n",
      "Epoch 646/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0314 - mae: 0.1244\n",
      "Epoch 647/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0298 - mae: 0.1202\n",
      "Epoch 648/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0297 - mae: 0.1192\n",
      "Epoch 649/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0295 - mae: 0.1191\n",
      "Epoch 650/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0298 - mae: 0.1210\n",
      "Epoch 651/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0301 - mae: 0.1211\n",
      "Epoch 652/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0296 - mae: 0.1203\n",
      "Epoch 653/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0299 - mae: 0.1215\n",
      "Epoch 654/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0289 - mae: 0.1180\n",
      "Epoch 655/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0298 - mae: 0.1216\n",
      "Epoch 656/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0292 - mae: 0.1200\n",
      "Epoch 657/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0292 - mae: 0.1190\n",
      "Epoch 658/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0316 - mae: 0.1263\n",
      "Epoch 659/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0289 - mae: 0.1191\n",
      "Epoch 660/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0288 - mae: 0.1182\n",
      "Epoch 661/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0283 - mae: 0.1180\n",
      "Epoch 662/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0280 - mae: 0.1159\n",
      "Epoch 663/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0294 - mae: 0.1207\n",
      "Epoch 664/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0279 - mae: 0.1168\n",
      "Epoch 665/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0275 - mae: 0.1156\n",
      "Epoch 666/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0287 - mae: 0.1195\n",
      "Epoch 667/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0270 - mae: 0.1142\n",
      "Epoch 668/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0274 - mae: 0.1159\n",
      "Epoch 669/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0280 - mae: 0.1178\n",
      "Epoch 670/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0281 - mae: 0.1179\n",
      "Epoch 671/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0272 - mae: 0.1154\n",
      "Epoch 672/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0334 - mae: 0.1277\n",
      "Epoch 673/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0267 - mae: 0.1144\n",
      "Epoch 674/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0276 - mae: 0.1182\n",
      "Epoch 675/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0282 - mae: 0.1193\n",
      "Epoch 676/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0271 - mae: 0.1169\n",
      "Epoch 677/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0269 - mae: 0.1163\n",
      "Epoch 678/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0265 - mae: 0.1153\n",
      "Epoch 679/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0266 - mae: 0.1148\n",
      "Epoch 680/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0270 - mae: 0.1167\n",
      "Epoch 681/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0269 - mae: 0.1167\n",
      "Epoch 682/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0262 - mae: 0.1141\n",
      "Epoch 683/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0257 - mae: 0.1132\n",
      "Epoch 684/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0277 - mae: 0.1189\n",
      "Epoch 685/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0265 - mae: 0.1163\n",
      "Epoch 686/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0252 - mae: 0.1118\n",
      "Epoch 687/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0253 - mae: 0.1127\n",
      "Epoch 688/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0245 - mae: 0.1103\n",
      "Epoch 689/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0252 - mae: 0.1129\n",
      "Epoch 690/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0253 - mae: 0.1131\n",
      "Epoch 691/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0321 - mae: 0.1257\n",
      "Epoch 692/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0260 - mae: 0.1157\n",
      "Epoch 693/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0254 - mae: 0.1134\n",
      "Epoch 694/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0264 - mae: 0.1163\n",
      "Epoch 695/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0299 - mae: 0.1214\n",
      "Epoch 696/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0273 - mae: 0.1177\n",
      "Epoch 697/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0266 - mae: 0.1161\n",
      "Epoch 698/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0300 - mae: 0.1227\n",
      "Epoch 699/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0267 - mae: 0.1168\n",
      "Epoch 700/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0252 - mae: 0.1120\n",
      "Epoch 701/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0248 - mae: 0.1107\n",
      "Epoch 702/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0254 - mae: 0.1139\n",
      "Epoch 703/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0251 - mae: 0.1131\n",
      "Epoch 704/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0243 - mae: 0.1112\n",
      "Epoch 705/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0247 - mae: 0.1117\n",
      "Epoch 706/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0243 - mae: 0.1106\n",
      "Epoch 707/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0246 - mae: 0.1119\n",
      "Epoch 708/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0240 - mae: 0.1098\n",
      "Epoch 709/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0248 - mae: 0.1119\n",
      "Epoch 710/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0241 - mae: 0.1104\n",
      "Epoch 711/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0251 - mae: 0.1128\n",
      "Epoch 712/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0240 - mae: 0.1102\n",
      "Epoch 713/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0241 - mae: 0.1107\n",
      "Epoch 714/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0238 - mae: 0.1102\n",
      "Epoch 715/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0235 - mae: 0.1094\n",
      "Epoch 716/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0242 - mae: 0.1115\n",
      "Epoch 717/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0244 - mae: 0.1124\n",
      "Epoch 718/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0240 - mae: 0.1101\n",
      "Epoch 719/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0239 - mae: 0.1102\n",
      "Epoch 720/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0239 - mae: 0.1105\n",
      "Epoch 721/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0239 - mae: 0.1103\n",
      "Epoch 722/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0233 - mae: 0.1093\n",
      "Epoch 723/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0239 - mae: 0.1108\n",
      "Epoch 724/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0230 - mae: 0.1079\n",
      "Epoch 725/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0297 - mae: 0.1243\n",
      "Epoch 726/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0247 - mae: 0.1110\n",
      "Epoch 727/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0238 - mae: 0.1103\n",
      "Epoch 728/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0232 - mae: 0.1075\n",
      "Epoch 729/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0234 - mae: 0.1087\n",
      "Epoch 730/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0226 - mae: 0.1061\n",
      "Epoch 731/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0229 - mae: 0.1075\n",
      "Epoch 732/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0239 - mae: 0.1107\n",
      "Epoch 733/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0230 - mae: 0.1083\n",
      "Epoch 734/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0239 - mae: 0.1097\n",
      "Epoch 735/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0231 - mae: 0.1075\n",
      "Epoch 736/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0252 - mae: 0.1136\n",
      "Epoch 737/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0231 - mae: 0.1081\n",
      "Epoch 738/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0235 - mae: 0.1107\n",
      "Epoch 739/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0233 - mae: 0.1084\n",
      "Epoch 740/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0244 - mae: 0.1126\n",
      "Epoch 741/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0227 - mae: 0.1076\n",
      "Epoch 742/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0228 - mae: 0.1078\n",
      "Epoch 743/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0226 - mae: 0.1068\n",
      "Epoch 744/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0225 - mae: 0.1068\n",
      "Epoch 745/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1062\n",
      "Epoch 746/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0227 - mae: 0.1072\n",
      "Epoch 747/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0230 - mae: 0.1087\n",
      "Epoch 748/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0219 - mae: 0.1051\n",
      "Epoch 749/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0225 - mae: 0.1071\n",
      "Epoch 750/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0224 - mae: 0.1069\n",
      "Epoch 751/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1057\n",
      "Epoch 752/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0241 - mae: 0.1133\n",
      "Epoch 753/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0229 - mae: 0.1093\n",
      "Epoch 754/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0239 - mae: 0.1121\n",
      "Epoch 755/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0223 - mae: 0.1059\n",
      "Epoch 756/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0223 - mae: 0.1061\n",
      "Epoch 757/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0223 - mae: 0.1073\n",
      "Epoch 758/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0218 - mae: 0.1047\n",
      "Epoch 759/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0222 - mae: 0.1063\n",
      "Epoch 760/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0226 - mae: 0.1074\n",
      "Epoch 761/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0244 - mae: 0.1120\n",
      "Epoch 762/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0227 - mae: 0.1071\n",
      "Epoch 763/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0228 - mae: 0.1077\n",
      "Epoch 764/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0254 - mae: 0.1169\n",
      "Epoch 765/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0224 - mae: 0.1071\n",
      "Epoch 766/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0223 - mae: 0.1057\n",
      "Epoch 767/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0222 - mae: 0.1059\n",
      "Epoch 768/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0222 - mae: 0.1065\n",
      "Epoch 769/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0217 - mae: 0.1049\n",
      "Epoch 770/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0218 - mae: 0.1048\n",
      "Epoch 771/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0216 - mae: 0.1044\n",
      "Epoch 772/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0216 - mae: 0.1052\n",
      "Epoch 773/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0246 - mae: 0.1118\n",
      "Epoch 774/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0241 - mae: 0.1132\n",
      "Epoch 775/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0226 - mae: 0.1077\n",
      "Epoch 776/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0221 - mae: 0.1056\n",
      "Epoch 777/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0226 - mae: 0.1084\n",
      "Epoch 778/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0218 - mae: 0.1060\n",
      "Epoch 779/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0216 - mae: 0.1039\n",
      "Epoch 780/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0223 - mae: 0.1075\n",
      "Epoch 781/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0222 - mae: 0.1069\n",
      "Epoch 782/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0238 - mae: 0.1114\n",
      "Epoch 783/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0222 - mae: 0.1065\n",
      "Epoch 784/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0213 - mae: 0.1042\n",
      "Epoch 785/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0216 - mae: 0.1051\n",
      "Epoch 786/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0240 - mae: 0.1115\n",
      "Epoch 787/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0227 - mae: 0.1090\n",
      "Epoch 788/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0220 - mae: 0.1060\n",
      "Epoch 789/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0218 - mae: 0.1061\n",
      "Epoch 790/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0217 - mae: 0.1060\n",
      "Epoch 791/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0219 - mae: 0.1063\n",
      "Epoch 792/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0220 - mae: 0.1063\n",
      "Epoch 793/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0218 - mae: 0.1058\n",
      "Epoch 794/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0222 - mae: 0.1068\n",
      "Epoch 795/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0211 - mae: 0.1039\n",
      "Epoch 796/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0207 - mae: 0.1020\n",
      "Epoch 797/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0243 - mae: 0.1130\n",
      "Epoch 798/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0231 - mae: 0.1101\n",
      "Epoch 799/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0240 - mae: 0.1133\n",
      "Epoch 800/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0211 - mae: 0.1039\n",
      "Epoch 801/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0221 - mae: 0.1069\n",
      "Epoch 802/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0211 - mae: 0.1041\n",
      "Epoch 803/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0219 - mae: 0.1065\n",
      "Epoch 804/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0213 - mae: 0.1046\n",
      "Epoch 805/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0206 - mae: 0.1032\n",
      "Epoch 806/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0241 - mae: 0.1121\n",
      "Epoch 807/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0234 - mae: 0.1100\n",
      "Epoch 808/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0234 - mae: 0.1106\n",
      "Epoch 809/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0217 - mae: 0.1051\n",
      "Epoch 810/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0215 - mae: 0.1041\n",
      "Epoch 811/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0215 - mae: 0.1049\n",
      "Epoch 812/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0225 - mae: 0.1065\n",
      "Epoch 813/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0221 - mae: 0.1067\n",
      "Epoch 814/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0223 - mae: 0.1083\n",
      "Epoch 815/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0213 - mae: 0.1049\n",
      "Epoch 816/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0221 - mae: 0.1073\n",
      "Epoch 817/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0235 - mae: 0.1108\n",
      "Epoch 818/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0212 - mae: 0.1037\n",
      "Epoch 819/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0212 - mae: 0.1046\n",
      "Epoch 820/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0213 - mae: 0.1036\n",
      "Epoch 821/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0245 - mae: 0.1142\n",
      "Epoch 822/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0215 - mae: 0.1054\n",
      "Epoch 823/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0208 - mae: 0.1038\n",
      "Epoch 824/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0204 - mae: 0.1018\n",
      "Epoch 825/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0210 - mae: 0.1035\n",
      "Epoch 826/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0212 - mae: 0.1033\n",
      "Epoch 827/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0215 - mae: 0.1050\n",
      "Epoch 828/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0206 - mae: 0.1026\n",
      "Epoch 829/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0206 - mae: 0.1026\n",
      "Epoch 830/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0208 - mae: 0.1030\n",
      "Epoch 831/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0202 - mae: 0.1016\n",
      "Epoch 832/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0209 - mae: 0.1036\n",
      "Epoch 833/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0204 - mae: 0.1020\n",
      "Epoch 834/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0210 - mae: 0.1042\n",
      "Epoch 835/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0215 - mae: 0.1057\n",
      "Epoch 836/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0215 - mae: 0.1057\n",
      "Epoch 837/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0207 - mae: 0.1037\n",
      "Epoch 838/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0202 - mae: 0.1009\n",
      "Epoch 839/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0210 - mae: 0.1034\n",
      "Epoch 840/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0209 - mae: 0.1041\n",
      "Epoch 841/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0204 - mae: 0.1023\n",
      "Epoch 842/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0223 - mae: 0.1083\n",
      "Epoch 843/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0210 - mae: 0.1038\n",
      "Epoch 844/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0224 - mae: 0.1080\n",
      "Epoch 845/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0201 - mae: 0.1014\n",
      "Epoch 846/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0205 - mae: 0.1020\n",
      "Epoch 847/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0202 - mae: 0.1013\n",
      "Epoch 848/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0225 - mae: 0.1072\n",
      "Epoch 849/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0226 - mae: 0.1090\n",
      "Epoch 850/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0204 - mae: 0.1022\n",
      "Epoch 851/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0208 - mae: 0.1038\n",
      "Epoch 852/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0209 - mae: 0.1037\n",
      "Epoch 853/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0212 - mae: 0.1056\n",
      "Epoch 854/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0203 - mae: 0.1029\n",
      "Epoch 855/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0207 - mae: 0.1040\n",
      "Epoch 856/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0214 - mae: 0.1058\n",
      "Epoch 857/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0205 - mae: 0.1027\n",
      "Epoch 858/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0214 - mae: 0.1052\n",
      "Epoch 859/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0209 - mae: 0.1036\n",
      "Epoch 860/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0203 - mae: 0.1025\n",
      "Epoch 861/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0210 - mae: 0.1043\n",
      "Epoch 862/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0200 - mae: 0.1009\n",
      "Epoch 863/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0198 - mae: 0.0999\n",
      "Epoch 864/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0214 - mae: 0.1059\n",
      "Epoch 865/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0213 - mae: 0.1041\n",
      "Epoch 866/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0200 - mae: 0.1012\n",
      "Epoch 867/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0208 - mae: 0.1025\n",
      "Epoch 868/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0205 - mae: 0.1019\n",
      "Epoch 869/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0203 - mae: 0.1023\n",
      "Epoch 870/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0202 - mae: 0.1014\n",
      "Epoch 871/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0205 - mae: 0.1029\n",
      "Epoch 872/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0206 - mae: 0.1032\n",
      "Epoch 873/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0200 - mae: 0.1015\n",
      "Epoch 874/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0211 - mae: 0.1050\n",
      "Epoch 875/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0205 - mae: 0.1020\n",
      "Epoch 876/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0201 - mae: 0.1018\n",
      "Epoch 877/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0204 - mae: 0.1024\n",
      "Epoch 878/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1072\n",
      "Epoch 879/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0200 - mae: 0.1015\n",
      "Epoch 880/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0201 - mae: 0.1016\n",
      "Epoch 881/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0203 - mae: 0.1035\n",
      "Epoch 882/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0217 - mae: 0.1062\n",
      "Epoch 883/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0221 - mae: 0.1072\n",
      "Epoch 884/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0209 - mae: 0.1047\n",
      "Epoch 885/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0203 - mae: 0.1034\n",
      "Epoch 886/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0206 - mae: 0.1029\n",
      "Epoch 887/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0208 - mae: 0.1037\n",
      "Epoch 888/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0236 - mae: 0.1118\n",
      "Epoch 889/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0203 - mae: 0.1024\n",
      "Epoch 890/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0192 - mae: 0.0982\n",
      "Epoch 891/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0217 - mae: 0.1069\n",
      "Epoch 892/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0198 - mae: 0.1011\n",
      "Epoch 893/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0208 - mae: 0.1042\n",
      "Epoch 894/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0215 - mae: 0.1066\n",
      "Epoch 895/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0198 - mae: 0.1017\n",
      "Epoch 896/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0195 - mae: 0.0999\n",
      "Epoch 897/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0195 - mae: 0.0996\n",
      "Epoch 898/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0194 - mae: 0.0995\n",
      "Epoch 899/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0204 - mae: 0.1039\n",
      "Epoch 900/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0207 - mae: 0.1048\n",
      "Epoch 901/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0199 - mae: 0.1012\n",
      "Epoch 902/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0202 - mae: 0.1023\n",
      "Epoch 903/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0200 - mae: 0.1012\n",
      "Epoch 904/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0221 - mae: 0.1090\n",
      "Epoch 905/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0230 - mae: 0.1107\n",
      "Epoch 906/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0202 - mae: 0.1027\n",
      "Epoch 907/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0199 - mae: 0.1017\n",
      "Epoch 908/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0203 - mae: 0.1027\n",
      "Epoch 909/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0205 - mae: 0.1050\n",
      "Epoch 910/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0195 - mae: 0.0997\n",
      "Epoch 911/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0194 - mae: 0.1009\n",
      "Epoch 912/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0230 - mae: 0.1108\n",
      "Epoch 913/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0217 - mae: 0.1056\n",
      "Epoch 914/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1058\n",
      "Epoch 915/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0213 - mae: 0.1051\n",
      "Epoch 916/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0210 - mae: 0.1055\n",
      "Epoch 917/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0208 - mae: 0.1043\n",
      "Epoch 918/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0204 - mae: 0.1030\n",
      "Epoch 919/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0202 - mae: 0.1028\n",
      "Epoch 920/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0194 - mae: 0.1004\n",
      "Epoch 921/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0197 - mae: 0.1007\n",
      "Epoch 922/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0204 - mae: 0.1043\n",
      "Epoch 923/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0207 - mae: 0.1042\n",
      "Epoch 924/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0193 - mae: 0.1001\n",
      "Epoch 925/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0193 - mae: 0.1010\n",
      "Epoch 926/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0193 - mae: 0.1000\n",
      "Epoch 927/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0212 - mae: 0.1065\n",
      "Epoch 928/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0189 - mae: 0.0988\n",
      "Epoch 929/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0194 - mae: 0.1011\n",
      "Epoch 930/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0191 - mae: 0.0993\n",
      "Epoch 931/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0191 - mae: 0.0992\n",
      "Epoch 932/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0194 - mae: 0.1004\n",
      "Epoch 933/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0193 - mae: 0.0999\n",
      "Epoch 934/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.0996\n",
      "Epoch 935/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0192 - mae: 0.1002\n",
      "Epoch 936/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0195 - mae: 0.1004\n",
      "Epoch 937/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0192 - mae: 0.1005\n",
      "Epoch 938/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0190 - mae: 0.0998\n",
      "Epoch 939/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0194 - mae: 0.0996\n",
      "Epoch 940/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0198 - mae: 0.1024\n",
      "Epoch 941/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0188 - mae: 0.0981\n",
      "Epoch 942/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0192 - mae: 0.0998\n",
      "Epoch 943/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0189 - mae: 0.0987\n",
      "Epoch 944/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0190 - mae: 0.0989\n",
      "Epoch 945/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0193 - mae: 0.0995\n",
      "Epoch 946/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0192 - mae: 0.1005\n",
      "Epoch 947/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0189 - mae: 0.0992\n",
      "Epoch 948/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0188 - mae: 0.0983\n",
      "Epoch 949/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0189 - mae: 0.0996\n",
      "Epoch 950/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0192 - mae: 0.1001\n",
      "Epoch 951/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0196 - mae: 0.1005\n",
      "Epoch 952/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0191 - mae: 0.0996\n",
      "Epoch 953/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0202 - mae: 0.1035\n",
      "Epoch 954/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0203 - mae: 0.1030\n",
      "Epoch 955/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0192 - mae: 0.0999\n",
      "Epoch 956/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0195 - mae: 0.1013\n",
      "Epoch 957/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0185 - mae: 0.0978\n",
      "Epoch 958/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0191 - mae: 0.1002\n",
      "Epoch 959/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0191 - mae: 0.0990\n",
      "Epoch 960/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0220 - mae: 0.1082\n",
      "Epoch 961/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.1000\n",
      "Epoch 962/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0207 - mae: 0.1042\n",
      "Epoch 963/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0199 - mae: 0.1014\n",
      "Epoch 964/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0190 - mae: 0.0991\n",
      "Epoch 965/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0197 - mae: 0.1028\n",
      "Epoch 966/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0204 - mae: 0.1043\n",
      "Epoch 967/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0194 - mae: 0.0998\n",
      "Epoch 968/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0198 - mae: 0.1019\n",
      "Epoch 969/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1032\n",
      "Epoch 970/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0190 - mae: 0.0991\n",
      "Epoch 971/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0184 - mae: 0.0980\n",
      "Epoch 972/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0315 - mae: 0.1235\n",
      "Epoch 973/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0261 - mae: 0.1192\n",
      "Epoch 974/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0240 - mae: 0.1117\n",
      "Epoch 975/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0239 - mae: 0.1120\n",
      "Epoch 976/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0221 - mae: 0.1067\n",
      "Epoch 977/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0228 - mae: 0.1087\n",
      "Epoch 978/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0220 - mae: 0.1068\n",
      "Epoch 979/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0222 - mae: 0.1061\n",
      "Epoch 980/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0213 - mae: 0.1042\n",
      "Epoch 981/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0212 - mae: 0.1039\n",
      "Epoch 982/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0212 - mae: 0.1047\n",
      "Epoch 983/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0209 - mae: 0.1033\n",
      "Epoch 984/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0205 - mae: 0.1027\n",
      "Epoch 985/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0199 - mae: 0.1011\n",
      "Epoch 986/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0211 - mae: 0.1044\n",
      "Epoch 987/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0200 - mae: 0.1010\n",
      "Epoch 988/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0203 - mae: 0.1020\n",
      "Epoch 989/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0202 - mae: 0.1024\n",
      "Epoch 990/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0201 - mae: 0.1015\n",
      "Epoch 991/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0197 - mae: 0.1003\n",
      "Epoch 992/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0195 - mae: 0.0998\n",
      "Epoch 993/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0195 - mae: 0.0999\n",
      "Epoch 994/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0249 - mae: 0.1152\n",
      "Epoch 995/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0228 - mae: 0.1085\n",
      "Epoch 996/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0209 - mae: 0.1041\n",
      "Epoch 997/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0205 - mae: 0.1023\n",
      "Epoch 998/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0200 - mae: 0.1017\n",
      "Epoch 999/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0199 - mae: 0.1016\n",
      "Epoch 1000/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0227 - mae: 0.1108\n",
      "Epoch 1001/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0197 - mae: 0.1012\n",
      "Epoch 1002/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0200 - mae: 0.1023\n",
      "Epoch 1003/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0198 - mae: 0.1017\n",
      "Epoch 1004/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0198 - mae: 0.1012\n",
      "Epoch 1005/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0198 - mae: 0.1011\n",
      "Epoch 1006/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0197 - mae: 0.1019\n",
      "Epoch 1007/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0206 - mae: 0.1047\n",
      "Epoch 1008/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0193 - mae: 0.1003\n",
      "Epoch 1009/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0211 - mae: 0.1063\n",
      "Epoch 1010/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0200 - mae: 0.1028\n",
      "Epoch 1011/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0196 - mae: 0.1018\n",
      "Epoch 1012/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0214 - mae: 0.1063\n",
      "Epoch 1013/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0193 - mae: 0.1004\n",
      "Epoch 1014/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0204 - mae: 0.1016\n",
      "Epoch 1015/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0205 - mae: 0.1045\n",
      "Epoch 1016/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0192 - mae: 0.1000\n",
      "Epoch 1017/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.0994\n",
      "Epoch 1018/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0197 - mae: 0.1013\n",
      "Epoch 1019/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0197 - mae: 0.1005\n",
      "Epoch 1020/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0197 - mae: 0.1022\n",
      "Epoch 1021/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0195 - mae: 0.1002\n",
      "Epoch 1022/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0212 - mae: 0.1070\n",
      "Epoch 1023/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0204 - mae: 0.1040\n",
      "Epoch 1024/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.0981\n",
      "Epoch 1025/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0190 - mae: 0.0987\n",
      "Epoch 1026/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0195 - mae: 0.1010\n",
      "Epoch 1027/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.0997\n",
      "Epoch 1028/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0188 - mae: 0.0990\n",
      "Epoch 1029/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0191 - mae: 0.0998\n",
      "Epoch 1030/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0193 - mae: 0.1006\n",
      "Epoch 1031/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0202 - mae: 0.1028\n",
      "Epoch 1032/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0200 - mae: 0.1018\n",
      "Epoch 1033/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0200 - mae: 0.1021\n",
      "Epoch 1034/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0182 - mae: 0.0969\n",
      "Epoch 1035/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0186 - mae: 0.0979\n",
      "Epoch 1036/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0187 - mae: 0.0980\n",
      "Epoch 1037/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0181 - mae: 0.0965\n",
      "Epoch 1038/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0183 - mae: 0.0963\n",
      "Epoch 1039/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0183 - mae: 0.0972\n",
      "Epoch 1040/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0210 - mae: 0.1058\n",
      "Epoch 1041/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0198 - mae: 0.1034\n",
      "Epoch 1042/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0184 - mae: 0.0976\n",
      "Epoch 1043/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0184 - mae: 0.0972\n",
      "Epoch 1044/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0200 - mae: 0.1019\n",
      "Epoch 1045/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0189 - mae: 0.0996\n",
      "Epoch 1046/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0180 - mae: 0.0963\n",
      "Epoch 1047/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0180 - mae: 0.0962\n",
      "Epoch 1048/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0197 - mae: 0.1020\n",
      "Epoch 1049/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0185 - mae: 0.0979\n",
      "Epoch 1050/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0182 - mae: 0.0970\n",
      "Epoch 1051/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0190 - mae: 0.0996\n",
      "Epoch 1052/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0183 - mae: 0.0969\n",
      "Epoch 1053/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0183 - mae: 0.0972\n",
      "Epoch 1054/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0185 - mae: 0.0984\n",
      "Epoch 1055/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0180 - mae: 0.0967\n",
      "Epoch 1056/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0192 - mae: 0.1004\n",
      "Epoch 1057/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0185 - mae: 0.0976\n",
      "Epoch 1058/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0187 - mae: 0.0995\n",
      "Epoch 1059/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0186 - mae: 0.0978\n",
      "Epoch 1060/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0228 - mae: 0.1109\n",
      "Epoch 1061/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0182 - mae: 0.0967\n",
      "Epoch 1062/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0981\n",
      "Epoch 1063/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0183 - mae: 0.0970\n",
      "Epoch 1064/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0187 - mae: 0.0988\n",
      "Epoch 1065/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0182 - mae: 0.0966\n",
      "Epoch 1066/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0179 - mae: 0.0965\n",
      "Epoch 1067/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0195 - mae: 0.1015\n",
      "Epoch 1068/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0195 - mae: 0.1016\n",
      "Epoch 1069/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0193 - mae: 0.1008\n",
      "Epoch 1070/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0190 - mae: 0.0992\n",
      "Epoch 1071/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0180 - mae: 0.0965\n",
      "Epoch 1072/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0177 - mae: 0.0950\n",
      "Epoch 1073/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0182 - mae: 0.0968\n",
      "Epoch 1074/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0183 - mae: 0.0981\n",
      "Epoch 1075/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0180 - mae: 0.0965\n",
      "Epoch 1076/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0191 - mae: 0.0992\n",
      "Epoch 1077/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0190 - mae: 0.0997\n",
      "Epoch 1078/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0190 - mae: 0.1004\n",
      "Epoch 1079/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0177 - mae: 0.0960\n",
      "Epoch 1080/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0184 - mae: 0.0980\n",
      "Epoch 1081/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0176 - mae: 0.0945\n",
      "Epoch 1082/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0177 - mae: 0.0958\n",
      "Epoch 1083/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0194 - mae: 0.1007\n",
      "Epoch 1084/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0219 - mae: 0.1071\n",
      "Epoch 1085/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0200 - mae: 0.1025\n",
      "Epoch 1086/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0192 - mae: 0.1002\n",
      "Epoch 1087/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0192 - mae: 0.0995\n",
      "Epoch 1088/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0201 - mae: 0.1027\n",
      "Epoch 1089/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0187 - mae: 0.0982\n",
      "Epoch 1090/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0194 - mae: 0.1008\n",
      "Epoch 1091/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0183 - mae: 0.0977\n",
      "Epoch 1092/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0188 - mae: 0.0997\n",
      "Epoch 1093/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0188 - mae: 0.0988\n",
      "Epoch 1094/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0178 - mae: 0.0963\n",
      "Epoch 1095/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0180 - mae: 0.0966\n",
      "Epoch 1096/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0184 - mae: 0.0987\n",
      "Epoch 1097/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0199 - mae: 0.1025\n",
      "Epoch 1098/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0193 - mae: 0.1004\n",
      "Epoch 1099/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0198 - mae: 0.1013\n",
      "Epoch 1100/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0190 - mae: 0.0985\n",
      "Epoch 1101/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0191 - mae: 0.0996\n",
      "Epoch 1102/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0206 - mae: 0.1045\n",
      "Epoch 1103/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0186 - mae: 0.0987\n",
      "Epoch 1104/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0180 - mae: 0.0968\n",
      "Epoch 1105/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0176 - mae: 0.0952\n",
      "Epoch 1106/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0178 - mae: 0.0960\n",
      "Epoch 1107/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0179 - mae: 0.0966\n",
      "Epoch 1108/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0177 - mae: 0.0957\n",
      "Epoch 1109/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0186 - mae: 0.0981\n",
      "Epoch 1110/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0195 - mae: 0.1016\n",
      "Epoch 1111/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0187 - mae: 0.0992\n",
      "Epoch 1112/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0192 - mae: 0.1006\n",
      "Epoch 1113/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0176 - mae: 0.0954\n",
      "Epoch 1114/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0180 - mae: 0.0972\n",
      "Epoch 1115/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0181 - mae: 0.0971\n",
      "Epoch 1116/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0202 - mae: 0.1041\n",
      "Epoch 1117/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0191 - mae: 0.1000\n",
      "Epoch 1118/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0174 - mae: 0.0939\n",
      "Epoch 1119/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0182 - mae: 0.0975\n",
      "Epoch 1120/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0175 - mae: 0.0957\n",
      "Epoch 1121/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0188 - mae: 0.0999\n",
      "Epoch 1122/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0183 - mae: 0.0980\n",
      "Epoch 1123/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0185 - mae: 0.0986\n",
      "Epoch 1124/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0188 - mae: 0.1004\n",
      "Epoch 1125/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0177 - mae: 0.0961\n",
      "Epoch 1126/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0178 - mae: 0.0962\n",
      "Epoch 1127/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0958\n",
      "Epoch 1128/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0182 - mae: 0.0980\n",
      "Epoch 1129/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0192 - mae: 0.1008\n",
      "Epoch 1130/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0179 - mae: 0.0970\n",
      "Epoch 1131/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0188 - mae: 0.1002\n",
      "Epoch 1132/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0179 - mae: 0.0957\n",
      "Epoch 1133/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0181 - mae: 0.0977\n",
      "Epoch 1134/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0193 - mae: 0.1022\n",
      "Epoch 1135/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0181 - mae: 0.0976\n",
      "Epoch 1136/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0182 - mae: 0.0970\n",
      "Epoch 1137/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0192 - mae: 0.1000\n",
      "Epoch 1138/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.0982\n",
      "Epoch 1139/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0175 - mae: 0.0949\n",
      "Epoch 1140/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0177 - mae: 0.0956\n",
      "Epoch 1141/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.0994\n",
      "Epoch 1142/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0181 - mae: 0.0973\n",
      "Epoch 1143/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0181 - mae: 0.0965\n",
      "Epoch 1144/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0953\n",
      "Epoch 1145/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0184 - mae: 0.0980\n",
      "Epoch 1146/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0179 - mae: 0.0962\n",
      "Epoch 1147/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0186 - mae: 0.0988\n",
      "Epoch 1148/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0977\n",
      "Epoch 1149/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0175 - mae: 0.0951\n",
      "Epoch 1150/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0174 - mae: 0.0958\n",
      "Epoch 1151/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0175 - mae: 0.0953\n",
      "Epoch 1152/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0201 - mae: 0.1042\n",
      "Epoch 1153/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0180 - mae: 0.0969\n",
      "Epoch 1154/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0177 - mae: 0.0962\n",
      "Epoch 1155/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0960\n",
      "Epoch 1156/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0176 - mae: 0.0955\n",
      "Epoch 1157/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0191 - mae: 0.1013\n",
      "Epoch 1158/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0975\n",
      "Epoch 1159/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0184 - mae: 0.0988\n",
      "Epoch 1160/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0177 - mae: 0.0967\n",
      "Epoch 1161/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0177 - mae: 0.0964\n",
      "Epoch 1162/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0174 - mae: 0.0953\n",
      "Epoch 1163/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0173 - mae: 0.0949\n",
      "Epoch 1164/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0183 - mae: 0.0976\n",
      "Epoch 1165/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.0984\n",
      "Epoch 1166/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0172 - mae: 0.0945\n",
      "Epoch 1167/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0182 - mae: 0.0979\n",
      "Epoch 1168/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0180 - mae: 0.0974\n",
      "Epoch 1169/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0177 - mae: 0.0963\n",
      "Epoch 1170/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0175 - mae: 0.0957\n",
      "Epoch 1171/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0171 - mae: 0.0937\n",
      "Epoch 1172/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0184 - mae: 0.0988\n",
      "Epoch 1173/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0170 - mae: 0.0949\n",
      "Epoch 1174/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0172 - mae: 0.0938\n",
      "Epoch 1175/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0175 - mae: 0.0960\n",
      "Epoch 1176/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0177 - mae: 0.0964\n",
      "Epoch 1177/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0169 - mae: 0.0935\n",
      "Epoch 1178/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0180 - mae: 0.0977\n",
      "Epoch 1179/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0169 - mae: 0.0942\n",
      "Epoch 1180/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0181 - mae: 0.0974\n",
      "Epoch 1181/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0177 - mae: 0.0965\n",
      "Epoch 1182/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0172 - mae: 0.0946\n",
      "Epoch 1183/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0187 - mae: 0.1010\n",
      "Epoch 1184/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0198 - mae: 0.1036\n",
      "Epoch 1185/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0243 - mae: 0.1035\n",
      "Epoch 1186/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0288 - mae: 0.1275\n",
      "Epoch 1187/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0229 - mae: 0.1101\n",
      "Epoch 1188/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0218 - mae: 0.1091\n",
      "Epoch 1189/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0207 - mae: 0.1053\n",
      "Epoch 1190/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0201 - mae: 0.1038\n",
      "Epoch 1191/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0199 - mae: 0.1040\n",
      "Epoch 1192/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0201 - mae: 0.1042\n",
      "Epoch 1193/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0197 - mae: 0.1029\n",
      "Epoch 1194/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0195 - mae: 0.1035\n",
      "Epoch 1195/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0190 - mae: 0.1005\n",
      "Epoch 1196/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0191 - mae: 0.1016\n",
      "Epoch 1197/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0191 - mae: 0.1026\n",
      "Epoch 1198/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0181 - mae: 0.0975\n",
      "Epoch 1199/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0988\n",
      "Epoch 1200/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0189 - mae: 0.1002\n",
      "Epoch 1201/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0181 - mae: 0.0976\n",
      "Epoch 1202/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0180 - mae: 0.0974\n",
      "Epoch 1203/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0177 - mae: 0.0959\n",
      "Epoch 1204/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0177 - mae: 0.0956\n",
      "Epoch 1205/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0182 - mae: 0.0973\n",
      "Epoch 1206/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0179 - mae: 0.0976\n",
      "Epoch 1207/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0178 - mae: 0.0961\n",
      "Epoch 1208/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0177 - mae: 0.0962\n",
      "Epoch 1209/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0174 - mae: 0.0954\n",
      "Epoch 1210/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0177 - mae: 0.0968\n",
      "Epoch 1211/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0212 - mae: 0.1045\n",
      "Epoch 1212/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0199 - mae: 0.1014\n",
      "Epoch 1213/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0974\n",
      "Epoch 1214/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0190 - mae: 0.1001\n",
      "Epoch 1215/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0190 - mae: 0.1003\n",
      "Epoch 1216/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.0987\n",
      "Epoch 1217/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0189 - mae: 0.0994\n",
      "Epoch 1218/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0181 - mae: 0.0972\n",
      "Epoch 1219/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0228 - mae: 0.1101\n",
      "Epoch 1220/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0210 - mae: 0.1065\n",
      "Epoch 1221/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0200 - mae: 0.1032\n",
      "Epoch 1222/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0190 - mae: 0.1008\n",
      "Epoch 1223/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0194 - mae: 0.1026\n",
      "Epoch 1224/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0185 - mae: 0.0986\n",
      "Epoch 1225/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0183 - mae: 0.0984\n",
      "Epoch 1226/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0179 - mae: 0.0969\n",
      "Epoch 1227/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0176 - mae: 0.0962\n",
      "Epoch 1228/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0172 - mae: 0.0940\n",
      "Epoch 1229/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0176 - mae: 0.0958\n",
      "Epoch 1230/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0967\n",
      "Epoch 1231/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0178 - mae: 0.0966\n",
      "Epoch 1232/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0179 - mae: 0.0980\n",
      "Epoch 1233/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0175 - mae: 0.0956\n",
      "Epoch 1234/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0179 - mae: 0.0961\n",
      "Epoch 1235/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0174 - mae: 0.0951\n",
      "Epoch 1236/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0178 - mae: 0.0959\n",
      "Epoch 1237/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0974\n",
      "Epoch 1238/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0948\n",
      "Epoch 1239/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0177 - mae: 0.0957\n",
      "Epoch 1240/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0175 - mae: 0.0960\n",
      "Epoch 1241/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0172 - mae: 0.0939\n",
      "Epoch 1242/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0186 - mae: 0.0986\n",
      "Epoch 1243/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0171 - mae: 0.0945\n",
      "Epoch 1244/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0177 - mae: 0.0955\n",
      "Epoch 1245/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0171 - mae: 0.0934\n",
      "Epoch 1246/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0208 - mae: 0.1036\n",
      "Epoch 1247/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0188 - mae: 0.0991\n",
      "Epoch 1248/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0993\n",
      "Epoch 1249/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0177 - mae: 0.0965\n",
      "Epoch 1250/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0171 - mae: 0.0942\n",
      "Epoch 1251/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0174 - mae: 0.0948\n",
      "Epoch 1252/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0180 - mae: 0.0979\n",
      "Epoch 1253/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.0992\n",
      "Epoch 1254/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0177 - mae: 0.0955\n",
      "Epoch 1255/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0177 - mae: 0.0971\n",
      "Epoch 1256/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0172 - mae: 0.0945\n",
      "Epoch 1257/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0178 - mae: 0.0973\n",
      "Epoch 1258/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0172 - mae: 0.0950\n",
      "Epoch 1259/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0170 - mae: 0.0939\n",
      "Epoch 1260/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0176 - mae: 0.0960\n",
      "Epoch 1261/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0191 - mae: 0.1003\n",
      "Epoch 1262/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0172 - mae: 0.0948\n",
      "Epoch 1263/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0179 - mae: 0.0970\n",
      "Epoch 1264/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0176 - mae: 0.0964\n",
      "Epoch 1265/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0178 - mae: 0.0967\n",
      "Epoch 1266/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0174 - mae: 0.0952\n",
      "Epoch 1267/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0948\n",
      "Epoch 1268/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0178 - mae: 0.0965\n",
      "Epoch 1269/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0173 - mae: 0.0953\n",
      "Epoch 1270/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0175 - mae: 0.0958\n",
      "Epoch 1271/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0174 - mae: 0.0957\n",
      "Epoch 1272/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0170 - mae: 0.0934\n",
      "Epoch 1273/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0177 - mae: 0.0969\n",
      "Epoch 1274/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0173 - mae: 0.0947\n",
      "Epoch 1275/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0167 - mae: 0.0937\n",
      "Epoch 1276/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0176 - mae: 0.0965\n",
      "Epoch 1277/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0170 - mae: 0.0944\n",
      "Epoch 1278/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0173 - mae: 0.0952\n",
      "Epoch 1279/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0166 - mae: 0.0928\n",
      "Epoch 1280/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0169 - mae: 0.0937\n",
      "Epoch 1281/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0940\n",
      "Epoch 1282/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0937\n",
      "Epoch 1283/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0182 - mae: 0.0982\n",
      "Epoch 1284/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0173 - mae: 0.0950\n",
      "Epoch 1285/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0178 - mae: 0.0970\n",
      "Epoch 1286/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0177 - mae: 0.0973\n",
      "Epoch 1287/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0169 - mae: 0.0942\n",
      "Epoch 1288/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0174 - mae: 0.0953\n",
      "Epoch 1289/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0170 - mae: 0.0945\n",
      "Epoch 1290/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0174 - mae: 0.0953\n",
      "Epoch 1291/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0926\n",
      "Epoch 1292/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0174 - mae: 0.0952\n",
      "Epoch 1293/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0171 - mae: 0.0941\n",
      "Epoch 1294/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0215 - mae: 0.1070\n",
      "Epoch 1295/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0200 - mae: 0.1037\n",
      "Epoch 1296/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0190 - mae: 0.1001\n",
      "Epoch 1297/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0197 - mae: 0.1018\n",
      "Epoch 1298/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0205 - mae: 0.1054\n",
      "Epoch 1299/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0182 - mae: 0.0985\n",
      "Epoch 1300/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0183 - mae: 0.0981\n",
      "Epoch 1301/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0182 - mae: 0.0984\n",
      "Epoch 1302/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0219 - mae: 0.1075\n",
      "Epoch 1303/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0208 - mae: 0.1058\n",
      "Epoch 1304/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0198 - mae: 0.1016\n",
      "Epoch 1305/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0190 - mae: 0.0996\n",
      "Epoch 1306/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0188 - mae: 0.0994\n",
      "Epoch 1307/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0189 - mae: 0.1004\n",
      "Epoch 1308/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0186 - mae: 0.0984\n",
      "Epoch 1309/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0182 - mae: 0.0973\n",
      "Epoch 1310/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0182 - mae: 0.0972\n",
      "Epoch 1311/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0183 - mae: 0.0985\n",
      "Epoch 1312/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0185 - mae: 0.0996\n",
      "Epoch 1313/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0184 - mae: 0.0979\n",
      "Epoch 1314/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0176 - mae: 0.0958\n",
      "Epoch 1315/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0175 - mae: 0.0951\n",
      "Epoch 1316/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0176 - mae: 0.0953\n",
      "Epoch 1317/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0175 - mae: 0.0953\n",
      "Epoch 1318/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0173 - mae: 0.0947\n",
      "Epoch 1319/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0171 - mae: 0.0933\n",
      "Epoch 1320/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0951\n",
      "Epoch 1321/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0171 - mae: 0.0947\n",
      "Epoch 1322/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0173 - mae: 0.0958\n",
      "Epoch 1323/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0176 - mae: 0.0958\n",
      "Epoch 1324/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0177 - mae: 0.0961\n",
      "Epoch 1325/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0193 - mae: 0.1013\n",
      "Epoch 1326/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0168 - mae: 0.0935\n",
      "Epoch 1327/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0171 - mae: 0.0946\n",
      "Epoch 1328/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0168 - mae: 0.0941\n",
      "Epoch 1329/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0168 - mae: 0.0933\n",
      "Epoch 1330/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0166 - mae: 0.0930\n",
      "Epoch 1331/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0173 - mae: 0.0945\n",
      "Epoch 1332/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0166 - mae: 0.0928\n",
      "Epoch 1333/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0175 - mae: 0.0956\n",
      "Epoch 1334/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0934\n",
      "Epoch 1335/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0177 - mae: 0.0976\n",
      "Epoch 1336/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0169 - mae: 0.0935\n",
      "Epoch 1337/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0164 - mae: 0.0915\n",
      "Epoch 1338/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0169 - mae: 0.0941\n",
      "Epoch 1339/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0165 - mae: 0.0931\n",
      "Epoch 1340/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0172 - mae: 0.0942\n",
      "Epoch 1341/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0929\n",
      "Epoch 1342/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0169 - mae: 0.0937\n",
      "Epoch 1343/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0180 - mae: 0.0985\n",
      "Epoch 1344/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0168 - mae: 0.0941\n",
      "Epoch 1345/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0171 - mae: 0.0954\n",
      "Epoch 1346/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0167 - mae: 0.0929\n",
      "Epoch 1347/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0166 - mae: 0.0926\n",
      "Epoch 1348/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0166 - mae: 0.0928\n",
      "Epoch 1349/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0167 - mae: 0.0933\n",
      "Epoch 1350/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0165 - mae: 0.0923\n",
      "Epoch 1351/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0164 - mae: 0.0923\n",
      "Epoch 1352/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0172 - mae: 0.0939\n",
      "Epoch 1353/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0178 - mae: 0.0973\n",
      "Epoch 1354/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0192 - mae: 0.0964\n",
      "Epoch 1355/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0178 - mae: 0.0963\n",
      "Epoch 1356/2000\n",
      "2019/2019 [==============================] - 0s 83us/sample - loss: 0.0179 - mae: 0.0965\n",
      "Epoch 1357/2000\n",
      "2019/2019 [==============================] - 0s 97us/sample - loss: 0.0182 - mae: 0.0965\n",
      "Epoch 1358/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0173 - mae: 0.0951\n",
      "Epoch 1359/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0169 - mae: 0.0935\n",
      "Epoch 1360/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0180 - mae: 0.0965\n",
      "Epoch 1361/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0930\n",
      "Epoch 1362/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0169 - mae: 0.0938\n",
      "Epoch 1363/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0170 - mae: 0.0940\n",
      "Epoch 1364/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0931\n",
      "Epoch 1365/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0165 - mae: 0.0926\n",
      "Epoch 1366/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0165 - mae: 0.0920\n",
      "Epoch 1367/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0169 - mae: 0.0942\n",
      "Epoch 1368/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0168 - mae: 0.0931\n",
      "Epoch 1369/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0164 - mae: 0.0923\n",
      "Epoch 1370/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0171 - mae: 0.0941\n",
      "Epoch 1371/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0169 - mae: 0.0934\n",
      "Epoch 1372/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0175 - mae: 0.0960\n",
      "Epoch 1373/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0175 - mae: 0.0954\n",
      "Epoch 1374/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0934\n",
      "Epoch 1375/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0167 - mae: 0.0939\n",
      "Epoch 1376/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0163 - mae: 0.0919\n",
      "Epoch 1377/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0167 - mae: 0.0932\n",
      "Epoch 1378/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0161 - mae: 0.0916\n",
      "Epoch 1379/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0181 - mae: 0.0989\n",
      "Epoch 1380/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0168 - mae: 0.0935\n",
      "Epoch 1381/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0167 - mae: 0.0929\n",
      "Epoch 1382/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0988\n",
      "Epoch 1383/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.1000\n",
      "Epoch 1384/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0184 - mae: 0.0987\n",
      "Epoch 1385/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0173 - mae: 0.0951\n",
      "Epoch 1386/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0163 - mae: 0.0918\n",
      "Epoch 1387/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0173 - mae: 0.0949\n",
      "Epoch 1388/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0176 - mae: 0.0955\n",
      "Epoch 1389/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0172 - mae: 0.0953\n",
      "Epoch 1390/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0185 - mae: 0.0987\n",
      "Epoch 1391/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0183 - mae: 0.0981\n",
      "Epoch 1392/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0176 - mae: 0.0954\n",
      "Epoch 1393/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0172 - mae: 0.0943\n",
      "Epoch 1394/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0168 - mae: 0.0936\n",
      "Epoch 1395/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0186 - mae: 0.0966\n",
      "Epoch 1396/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0183 - mae: 0.0976\n",
      "Epoch 1397/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0170 - mae: 0.0942\n",
      "Epoch 1398/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0165 - mae: 0.0919\n",
      "Epoch 1399/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0164 - mae: 0.0923\n",
      "Epoch 1400/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0168 - mae: 0.0947\n",
      "Epoch 1401/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0163 - mae: 0.0919\n",
      "Epoch 1402/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0163 - mae: 0.0908\n",
      "Epoch 1403/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0169 - mae: 0.0937\n",
      "Epoch 1404/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0165 - mae: 0.0924\n",
      "Epoch 1405/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0169 - mae: 0.0941\n",
      "Epoch 1406/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0167 - mae: 0.0925\n",
      "Epoch 1407/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0163 - mae: 0.0917\n",
      "Epoch 1408/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0167 - mae: 0.0938\n",
      "Epoch 1409/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0174 - mae: 0.0952\n",
      "Epoch 1410/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0163 - mae: 0.0921\n",
      "Epoch 1411/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0161 - mae: 0.0908\n",
      "Epoch 1412/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0165 - mae: 0.0919\n",
      "Epoch 1413/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0171 - mae: 0.0951\n",
      "Epoch 1414/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0170 - mae: 0.0945\n",
      "Epoch 1415/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0167 - mae: 0.0929\n",
      "Epoch 1416/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0171 - mae: 0.0945\n",
      "Epoch 1417/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0166 - mae: 0.0935\n",
      "Epoch 1418/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0164 - mae: 0.0927\n",
      "Epoch 1419/2000\n",
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0179 - mae: 0.0971\n",
      "Epoch 1420/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0167 - mae: 0.0926\n",
      "Epoch 1421/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0162 - mae: 0.0910\n",
      "Epoch 1422/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0174 - mae: 0.0962\n",
      "Epoch 1423/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0166 - mae: 0.0925\n",
      "Epoch 1424/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0170 - mae: 0.0938\n",
      "Epoch 1425/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0165 - mae: 0.0931\n",
      "Epoch 1426/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0159 - mae: 0.0906\n",
      "Epoch 1427/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0210 - mae: 0.1056\n",
      "Epoch 1428/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0186 - mae: 0.0980\n",
      "Epoch 1429/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0179 - mae: 0.0965\n",
      "Epoch 1430/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0175 - mae: 0.0952\n",
      "Epoch 1431/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0172 - mae: 0.0944\n",
      "Epoch 1432/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0180 - mae: 0.0972\n",
      "Epoch 1433/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0171 - mae: 0.0947\n",
      "Epoch 1434/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0169 - mae: 0.0934\n",
      "Epoch 1435/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0168 - mae: 0.0930\n",
      "Epoch 1436/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0165 - mae: 0.0920\n",
      "Epoch 1437/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0217 - mae: 0.1069\n",
      "Epoch 1438/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0188 - mae: 0.0996\n",
      "Epoch 1439/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0175 - mae: 0.0961\n",
      "Epoch 1440/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0169 - mae: 0.0943\n",
      "Epoch 1441/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0167 - mae: 0.0929\n",
      "Epoch 1442/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0169 - mae: 0.0946\n",
      "Epoch 1443/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0163 - mae: 0.0926\n",
      "Epoch 1444/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0164 - mae: 0.0922\n",
      "Epoch 1445/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0164 - mae: 0.0932\n",
      "Epoch 1446/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0167 - mae: 0.0944\n",
      "Epoch 1447/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0164 - mae: 0.0933\n",
      "Epoch 1448/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0168 - mae: 0.0942\n",
      "Epoch 1449/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0166 - mae: 0.0941\n",
      "Epoch 1450/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0169 - mae: 0.0937\n",
      "Epoch 1451/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0196 - mae: 0.1030\n",
      "Epoch 1452/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0164 - mae: 0.0929\n",
      "Epoch 1453/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0168 - mae: 0.0951\n",
      "Epoch 1454/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0173 - mae: 0.0969\n",
      "Epoch 1455/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0167 - mae: 0.0938\n",
      "Epoch 1456/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0168 - mae: 0.0936\n",
      "Epoch 1457/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0171 - mae: 0.0950\n",
      "Epoch 1458/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0169 - mae: 0.0939\n",
      "Epoch 1459/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0165 - mae: 0.0929\n",
      "Epoch 1460/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0171 - mae: 0.0954\n",
      "Epoch 1461/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0161 - mae: 0.0906\n",
      "Epoch 1462/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0165 - mae: 0.0925\n",
      "Epoch 1463/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0165 - mae: 0.0936\n",
      "Epoch 1464/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0162 - mae: 0.0922\n",
      "Epoch 1465/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0163 - mae: 0.0926\n",
      "Epoch 1466/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0162 - mae: 0.0916\n",
      "Epoch 1467/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0165 - mae: 0.0931\n",
      "Epoch 1468/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0166 - mae: 0.0933\n",
      "Epoch 1469/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0168 - mae: 0.0933\n",
      "Epoch 1470/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0170 - mae: 0.0943\n",
      "Epoch 1471/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0163 - mae: 0.0919\n",
      "Epoch 1472/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0164 - mae: 0.0931\n",
      "Epoch 1473/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0168 - mae: 0.0943\n",
      "Epoch 1474/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0167 - mae: 0.0940\n",
      "Epoch 1475/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0169 - mae: 0.0945\n",
      "Epoch 1476/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0162 - mae: 0.0926\n",
      "Epoch 1477/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0173 - mae: 0.0950\n",
      "Epoch 1478/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0174 - mae: 0.0956\n",
      "Epoch 1479/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0167 - mae: 0.0940\n",
      "Epoch 1480/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0167 - mae: 0.0943\n",
      "Epoch 1481/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0159 - mae: 0.0906\n",
      "Epoch 1482/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0160 - mae: 0.0915\n",
      "Epoch 1483/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0166 - mae: 0.0928\n",
      "Epoch 1484/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0197 - mae: 0.1027\n",
      "Epoch 1485/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0191 - mae: 0.1010\n",
      "Epoch 1486/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0967\n",
      "Epoch 1487/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0177 - mae: 0.0966\n",
      "Epoch 1488/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0172 - mae: 0.0946\n",
      "Epoch 1489/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0185 - mae: 0.0993\n",
      "Epoch 1490/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0170 - mae: 0.0934\n",
      "Epoch 1491/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0170 - mae: 0.0941\n",
      "Epoch 1492/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0166 - mae: 0.0922\n",
      "Epoch 1493/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0175 - mae: 0.0950\n",
      "Epoch 1494/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0167 - mae: 0.0930\n",
      "Epoch 1495/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0174 - mae: 0.0953\n",
      "Epoch 1496/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0170 - mae: 0.0940\n",
      "Epoch 1497/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0162 - mae: 0.0913\n",
      "Epoch 1498/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0168 - mae: 0.0931\n",
      "Epoch 1499/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0171 - mae: 0.0948\n",
      "Epoch 1500/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0171 - mae: 0.0947\n",
      "Epoch 1501/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0168 - mae: 0.0935\n",
      "Epoch 1502/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0177 - mae: 0.0961\n",
      "Epoch 1503/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0184 - mae: 0.0989\n",
      "Epoch 1504/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0175 - mae: 0.0952\n",
      "Epoch 1505/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0171 - mae: 0.0937\n",
      "Epoch 1506/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0171 - mae: 0.0936\n",
      "Epoch 1507/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0173 - mae: 0.0956\n",
      "Epoch 1508/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0176 - mae: 0.0958\n",
      "Epoch 1509/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0163 - mae: 0.0914\n",
      "Epoch 1510/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0178 - mae: 0.0977\n",
      "Epoch 1511/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0166 - mae: 0.0933\n",
      "Epoch 1512/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0168 - mae: 0.0934\n",
      "Epoch 1513/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0167 - mae: 0.0937\n",
      "Epoch 1514/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0165 - mae: 0.0927\n",
      "Epoch 1515/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0163 - mae: 0.0920\n",
      "Epoch 1516/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0165 - mae: 0.0941\n",
      "Epoch 1517/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0159 - mae: 0.0905\n",
      "Epoch 1518/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0159 - mae: 0.0907\n",
      "Epoch 1519/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0163 - mae: 0.0920\n",
      "Epoch 1520/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0166 - mae: 0.0927\n",
      "Epoch 1521/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0163 - mae: 0.0918\n",
      "Epoch 1522/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0170 - mae: 0.0938\n",
      "Epoch 1523/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0172 - mae: 0.0942\n",
      "Epoch 1524/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0169 - mae: 0.0938\n",
      "Epoch 1525/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0160 - mae: 0.0911\n",
      "Epoch 1526/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0168 - mae: 0.0939\n",
      "Epoch 1527/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0179 - mae: 0.0986\n",
      "Epoch 1528/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0159 - mae: 0.0905\n",
      "Epoch 1529/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0163 - mae: 0.0918\n",
      "Epoch 1530/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0163 - mae: 0.0922\n",
      "Epoch 1531/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0166 - mae: 0.0933\n",
      "Epoch 1532/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0162 - mae: 0.0915\n",
      "Epoch 1533/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0161 - mae: 0.0915\n",
      "Epoch 1534/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0161 - mae: 0.0913\n",
      "Epoch 1535/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0157 - mae: 0.0896\n",
      "Epoch 1536/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0931\n",
      "Epoch 1537/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0168 - mae: 0.0933\n",
      "Epoch 1538/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0165 - mae: 0.0933\n",
      "Epoch 1539/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0161 - mae: 0.0914\n",
      "Epoch 1540/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0163 - mae: 0.0920\n",
      "Epoch 1541/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0165 - mae: 0.0926\n",
      "Epoch 1542/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0169 - mae: 0.0947\n",
      "Epoch 1543/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0162 - mae: 0.0925\n",
      "Epoch 1544/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0159 - mae: 0.0904\n",
      "Epoch 1545/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0160 - mae: 0.0908\n",
      "Epoch 1546/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0158 - mae: 0.0909\n",
      "Epoch 1547/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0159 - mae: 0.0907\n",
      "Epoch 1548/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0163 - mae: 0.0929\n",
      "Epoch 1549/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0161 - mae: 0.0912\n",
      "Epoch 1550/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0164 - mae: 0.0923\n",
      "Epoch 1551/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0160 - mae: 0.0912\n",
      "Epoch 1552/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0164 - mae: 0.0924\n",
      "Epoch 1553/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0163 - mae: 0.0920\n",
      "Epoch 1554/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0156 - mae: 0.0893\n",
      "Epoch 1555/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0160 - mae: 0.0912\n",
      "Epoch 1556/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0159 - mae: 0.0912\n",
      "Epoch 1557/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0160 - mae: 0.0914\n",
      "Epoch 1558/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0161 - mae: 0.0915\n",
      "Epoch 1559/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0165 - mae: 0.0932\n",
      "Epoch 1560/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0158 - mae: 0.0907\n",
      "Epoch 1561/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0163 - mae: 0.0920\n",
      "Epoch 1562/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0161 - mae: 0.0912\n",
      "Epoch 1563/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0175 - mae: 0.0965\n",
      "Epoch 1564/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0183 - mae: 0.0997\n",
      "Epoch 1565/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0166 - mae: 0.0934\n",
      "Epoch 1566/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0174 - mae: 0.0968\n",
      "Epoch 1567/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0167 - mae: 0.0944\n",
      "Epoch 1568/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0158 - mae: 0.0912\n",
      "Epoch 1569/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0162 - mae: 0.0919\n",
      "Epoch 1570/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0161 - mae: 0.0920\n",
      "Epoch 1571/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0160 - mae: 0.0911\n",
      "Epoch 1572/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0159 - mae: 0.0902\n",
      "Epoch 1573/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0165 - mae: 0.0936\n",
      "Epoch 1574/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0165 - mae: 0.0928\n",
      "Epoch 1575/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0163 - mae: 0.0919\n",
      "Epoch 1576/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0161 - mae: 0.0921\n",
      "Epoch 1577/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0159 - mae: 0.0904\n",
      "Epoch 1578/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0163 - mae: 0.0928\n",
      "Epoch 1579/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0175 - mae: 0.0960\n",
      "Epoch 1580/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0170 - mae: 0.0941\n",
      "Epoch 1581/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0165 - mae: 0.0927\n",
      "Epoch 1582/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0163 - mae: 0.0926\n",
      "Epoch 1583/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0162 - mae: 0.0918\n",
      "Epoch 1584/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0165 - mae: 0.0930\n",
      "Epoch 1585/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0161 - mae: 0.0916\n",
      "Epoch 1586/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0167 - mae: 0.0940\n",
      "Epoch 1587/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0184 - mae: 0.0988\n",
      "Epoch 1588/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0163 - mae: 0.0929\n",
      "Epoch 1589/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0163 - mae: 0.0926\n",
      "Epoch 1590/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0164 - mae: 0.0923\n",
      "Epoch 1591/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0161 - mae: 0.0917\n",
      "Epoch 1592/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0169 - mae: 0.0942\n",
      "Epoch 1593/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0160 - mae: 0.0912\n",
      "Epoch 1594/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0160 - mae: 0.0908\n",
      "Epoch 1595/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0157 - mae: 0.0904\n",
      "Epoch 1596/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0160 - mae: 0.0910\n",
      "Epoch 1597/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0155 - mae: 0.0899\n",
      "Epoch 1598/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0161 - mae: 0.0914\n",
      "Epoch 1599/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0169 - mae: 0.0952\n",
      "Epoch 1600/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0156 - mae: 0.0901\n",
      "Epoch 1601/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0158 - mae: 0.0904\n",
      "Epoch 1602/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0162 - mae: 0.0922\n",
      "Epoch 1603/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0157 - mae: 0.0901\n",
      "Epoch 1604/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0157 - mae: 0.0903\n",
      "Epoch 1605/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0158 - mae: 0.0907\n",
      "Epoch 1606/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0156 - mae: 0.0902\n",
      "Epoch 1607/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0163 - mae: 0.0920\n",
      "Epoch 1608/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0158 - mae: 0.0910\n",
      "Epoch 1609/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0159 - mae: 0.0911\n",
      "Epoch 1610/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0157 - mae: 0.0906\n",
      "Epoch 1611/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0162 - mae: 0.0924\n",
      "Epoch 1612/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0164 - mae: 0.0937\n",
      "Epoch 1613/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0159 - mae: 0.0906\n",
      "Epoch 1614/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0169 - mae: 0.0951\n",
      "Epoch 1615/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0199 - mae: 0.1037\n",
      "Epoch 1616/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0170 - mae: 0.0943\n",
      "Epoch 1617/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0168 - mae: 0.0944\n",
      "Epoch 1618/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0167 - mae: 0.0939\n",
      "Epoch 1619/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0160 - mae: 0.0909\n",
      "Epoch 1620/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0166 - mae: 0.0933\n",
      "Epoch 1621/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0160 - mae: 0.0912\n",
      "Epoch 1622/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0160 - mae: 0.0915\n",
      "Epoch 1623/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0163 - mae: 0.0916\n",
      "Epoch 1624/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0175 - mae: 0.0972\n",
      "Epoch 1625/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0168 - mae: 0.0930\n",
      "Epoch 1626/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0222 - mae: 0.1039\n",
      "Epoch 1627/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0193 - mae: 0.1008\n",
      "Epoch 1628/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0175 - mae: 0.0966\n",
      "Epoch 1629/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0182 - mae: 0.0981\n",
      "Epoch 1630/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0180 - mae: 0.0988\n",
      "Epoch 1631/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0169 - mae: 0.0946\n",
      "Epoch 1632/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0168 - mae: 0.0936\n",
      "Epoch 1633/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0167 - mae: 0.0944\n",
      "Epoch 1634/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0171 - mae: 0.0943\n",
      "Epoch 1635/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0173 - mae: 0.0956\n",
      "Epoch 1636/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0164 - mae: 0.0931\n",
      "Epoch 1637/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0166 - mae: 0.0942\n",
      "Epoch 1638/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0162 - mae: 0.0931\n",
      "Epoch 1639/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0161 - mae: 0.0916\n",
      "Epoch 1640/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0166 - mae: 0.0945\n",
      "Epoch 1641/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0176 - mae: 0.0963\n",
      "Epoch 1642/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0175 - mae: 0.0976\n",
      "Epoch 1643/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0166 - mae: 0.0939\n",
      "Epoch 1644/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0168 - mae: 0.0942\n",
      "Epoch 1645/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0168 - mae: 0.0948\n",
      "Epoch 1646/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0170 - mae: 0.0935\n",
      "Epoch 1647/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0175 - mae: 0.0957\n",
      "Epoch 1648/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0166 - mae: 0.0930\n",
      "Epoch 1649/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0166 - mae: 0.0932\n",
      "Epoch 1650/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0172 - mae: 0.0959\n",
      "Epoch 1651/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0158 - mae: 0.0912\n",
      "Epoch 1652/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0164 - mae: 0.0928\n",
      "Epoch 1653/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0158 - mae: 0.0910\n",
      "Epoch 1654/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0168 - mae: 0.0944\n",
      "Epoch 1655/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0158 - mae: 0.0905\n",
      "Epoch 1656/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0166 - mae: 0.0935\n",
      "Epoch 1657/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0166 - mae: 0.0933\n",
      "Epoch 1658/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0163 - mae: 0.0941\n",
      "Epoch 1659/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0161 - mae: 0.0917\n",
      "Epoch 1660/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0158 - mae: 0.0907\n",
      "Epoch 1661/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0163 - mae: 0.0929\n",
      "Epoch 1662/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0168 - mae: 0.0944\n",
      "Epoch 1663/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0159 - mae: 0.0912\n",
      "Epoch 1664/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0161 - mae: 0.0918\n",
      "Epoch 1665/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0155 - mae: 0.0899\n",
      "Epoch 1666/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0154 - mae: 0.0894\n",
      "Epoch 1667/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0155 - mae: 0.0899\n",
      "Epoch 1668/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0156 - mae: 0.0899\n",
      "Epoch 1669/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0162 - mae: 0.0913\n",
      "Epoch 1670/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0165 - mae: 0.0931\n",
      "Epoch 1671/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0161 - mae: 0.0923\n",
      "Epoch 1672/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0156 - mae: 0.0900\n",
      "Epoch 1673/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0157 - mae: 0.0907\n",
      "Epoch 1674/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0159 - mae: 0.0911\n",
      "Epoch 1675/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0155 - mae: 0.0908\n",
      "Epoch 1676/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0155 - mae: 0.0902\n",
      "Epoch 1677/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0162 - mae: 0.0931\n",
      "Epoch 1678/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0155 - mae: 0.0896\n",
      "Epoch 1679/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0163 - mae: 0.0921\n",
      "Epoch 1680/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0156 - mae: 0.0897\n",
      "Epoch 1681/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0156 - mae: 0.0898\n",
      "Epoch 1682/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0161 - mae: 0.0919\n",
      "Epoch 1683/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0165 - mae: 0.0944\n",
      "Epoch 1684/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0156 - mae: 0.0901\n",
      "Epoch 1685/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0157 - mae: 0.0899\n",
      "Epoch 1686/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0184 - mae: 0.0988\n",
      "Epoch 1687/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0165 - mae: 0.0915\n",
      "Epoch 1688/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0160 - mae: 0.0910\n",
      "Epoch 1689/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0164 - mae: 0.0924\n",
      "Epoch 1690/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0162 - mae: 0.0917\n",
      "Epoch 1691/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0172 - mae: 0.0957\n",
      "Epoch 1692/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0158 - mae: 0.0906\n",
      "Epoch 1693/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0154 - mae: 0.0889\n",
      "Epoch 1694/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0155 - mae: 0.0892\n",
      "Epoch 1695/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0153 - mae: 0.0895\n",
      "Epoch 1696/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0158 - mae: 0.0911\n",
      "Epoch 1697/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0163 - mae: 0.0917\n",
      "Epoch 1698/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0160 - mae: 0.0917\n",
      "Epoch 1699/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0157 - mae: 0.0908\n",
      "Epoch 1700/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0158 - mae: 0.0904\n",
      "Epoch 1701/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0160 - mae: 0.0916\n",
      "Epoch 1702/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0161 - mae: 0.0923\n",
      "Epoch 1703/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0168 - mae: 0.0946\n",
      "Epoch 1704/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0157 - mae: 0.0905\n",
      "Epoch 1705/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0156 - mae: 0.0903\n",
      "Epoch 1706/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0162 - mae: 0.0927\n",
      "Epoch 1707/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0160 - mae: 0.0913\n",
      "Epoch 1708/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0166 - mae: 0.0935\n",
      "Epoch 1709/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0159 - mae: 0.0912\n",
      "Epoch 1710/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0156 - mae: 0.0905\n",
      "Epoch 1711/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0159 - mae: 0.0908\n",
      "Epoch 1712/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0158 - mae: 0.0903\n",
      "Epoch 1713/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0152 - mae: 0.0890\n",
      "Epoch 1714/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0166 - mae: 0.0933\n",
      "Epoch 1715/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0184 - mae: 0.0980\n",
      "Epoch 1716/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0163 - mae: 0.0919\n",
      "Epoch 1717/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0157 - mae: 0.0905\n",
      "Epoch 1718/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0161 - mae: 0.0915\n",
      "Epoch 1719/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0157 - mae: 0.0895\n",
      "Epoch 1720/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0160 - mae: 0.0911\n",
      "Epoch 1721/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0158 - mae: 0.0906\n",
      "Epoch 1722/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0160 - mae: 0.0917\n",
      "Epoch 1723/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0159 - mae: 0.0913\n",
      "Epoch 1724/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0155 - mae: 0.0890\n",
      "Epoch 1725/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0163 - mae: 0.0929\n",
      "Epoch 1726/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0158 - mae: 0.0914\n",
      "Epoch 1727/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0159 - mae: 0.0914\n",
      "Epoch 1728/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0165 - mae: 0.0937\n",
      "Epoch 1729/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0954\n",
      "Epoch 1730/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0164 - mae: 0.0939\n",
      "Epoch 1731/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0162 - mae: 0.0929\n",
      "Epoch 1732/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0154 - mae: 0.0889\n",
      "Epoch 1733/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0155 - mae: 0.0901\n",
      "Epoch 1734/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0156 - mae: 0.0908\n",
      "Epoch 1735/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0172 - mae: 0.0956\n",
      "Epoch 1736/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0163 - mae: 0.0926\n",
      "Epoch 1737/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0156 - mae: 0.0904\n",
      "Epoch 1738/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0153 - mae: 0.0892\n",
      "Epoch 1739/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0162 - mae: 0.0931\n",
      "Epoch 1740/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0155 - mae: 0.0901\n",
      "Epoch 1741/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0203 - mae: 0.1058\n",
      "Epoch 1742/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0163 - mae: 0.0925\n",
      "Epoch 1743/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0154 - mae: 0.0904\n",
      "Epoch 1744/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0154 - mae: 0.0896\n",
      "Epoch 1745/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0156 - mae: 0.0902\n",
      "Epoch 1746/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0170 - mae: 0.0965\n",
      "Epoch 1747/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0155 - mae: 0.0902\n",
      "Epoch 1748/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0156 - mae: 0.0906\n",
      "Epoch 1749/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0157 - mae: 0.0911\n",
      "Epoch 1750/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0952\n",
      "Epoch 1751/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0156 - mae: 0.0897\n",
      "Epoch 1752/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0154 - mae: 0.0894\n",
      "Epoch 1753/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0151 - mae: 0.0892\n",
      "Epoch 1754/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0159 - mae: 0.0918\n",
      "Epoch 1755/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0157 - mae: 0.0912\n",
      "Epoch 1756/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0159 - mae: 0.0914\n",
      "Epoch 1757/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0155 - mae: 0.0899\n",
      "Epoch 1758/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0158 - mae: 0.0913\n",
      "Epoch 1759/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0155 - mae: 0.0902\n",
      "Epoch 1760/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0155 - mae: 0.0896\n",
      "Epoch 1761/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0163 - mae: 0.0930\n",
      "Epoch 1762/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0153 - mae: 0.0893\n",
      "Epoch 1763/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0155 - mae: 0.0897\n",
      "Epoch 1764/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0158 - mae: 0.0921\n",
      "Epoch 1765/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0157 - mae: 0.0911\n",
      "Epoch 1766/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0952\n",
      "Epoch 1767/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0153 - mae: 0.0893\n",
      "Epoch 1768/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0171 - mae: 0.0937\n",
      "Epoch 1769/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0178 - mae: 0.0979\n",
      "Epoch 1770/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0166 - mae: 0.0932\n",
      "Epoch 1771/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0162 - mae: 0.0911\n",
      "Epoch 1772/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0159 - mae: 0.0914\n",
      "Epoch 1773/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0155 - mae: 0.0889\n",
      "Epoch 1774/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0170 - mae: 0.0943\n",
      "Epoch 1775/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0157 - mae: 0.0894\n",
      "Epoch 1776/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0159 - mae: 0.0910\n",
      "Epoch 1777/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0158 - mae: 0.0900\n",
      "Epoch 1778/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0160 - mae: 0.0905\n",
      "Epoch 1779/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0158 - mae: 0.0907\n",
      "Epoch 1780/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0157 - mae: 0.0912\n",
      "Epoch 1781/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0158 - mae: 0.0905\n",
      "Epoch 1782/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0156 - mae: 0.0898\n",
      "Epoch 1783/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0180 - mae: 0.0971\n",
      "Epoch 1784/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0165 - mae: 0.0930\n",
      "Epoch 1785/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0155 - mae: 0.0906\n",
      "Epoch 1786/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0160 - mae: 0.0912\n",
      "Epoch 1787/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0165 - mae: 0.0937\n",
      "Epoch 1788/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0156 - mae: 0.0895\n",
      "Epoch 1789/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0154 - mae: 0.0899\n",
      "Epoch 1790/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0152 - mae: 0.0890\n",
      "Epoch 1791/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0157 - mae: 0.0904\n",
      "Epoch 1792/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0151 - mae: 0.0888\n",
      "Epoch 1793/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0157 - mae: 0.0907\n",
      "Epoch 1794/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0155 - mae: 0.0900\n",
      "Epoch 1795/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0152 - mae: 0.0886\n",
      "Epoch 1796/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0159 - mae: 0.0918\n",
      "Epoch 1797/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0155 - mae: 0.0902\n",
      "Epoch 1798/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0155 - mae: 0.0902\n",
      "Epoch 1799/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0164 - mae: 0.0928\n",
      "Epoch 1800/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0156 - mae: 0.0902\n",
      "Epoch 1801/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0153 - mae: 0.0892\n",
      "Epoch 1802/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0164 - mae: 0.0925\n",
      "Epoch 1803/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0157 - mae: 0.0909\n",
      "Epoch 1804/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0152 - mae: 0.0891\n",
      "Epoch 1805/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0156 - mae: 0.0908\n",
      "Epoch 1806/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0155 - mae: 0.0898\n",
      "Epoch 1807/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0159 - mae: 0.0922\n",
      "Epoch 1808/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0158 - mae: 0.0920\n",
      "Epoch 1809/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0157 - mae: 0.0908\n",
      "Epoch 1810/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0154 - mae: 0.0899\n",
      "Epoch 1811/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0150 - mae: 0.0883\n",
      "Epoch 1812/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0151 - mae: 0.0890\n",
      "Epoch 1813/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0168 - mae: 0.0945\n",
      "Epoch 1814/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0156 - mae: 0.0912\n",
      "Epoch 1815/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0156 - mae: 0.0905\n",
      "Epoch 1816/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0173 - mae: 0.0969\n",
      "Epoch 1817/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0174 - mae: 0.0964\n",
      "Epoch 1818/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0154 - mae: 0.0895\n",
      "Epoch 1819/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0151 - mae: 0.0881\n",
      "Epoch 1820/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0154 - mae: 0.0896\n",
      "Epoch 1821/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0152 - mae: 0.0894\n",
      "Epoch 1822/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0153 - mae: 0.0897\n",
      "Epoch 1823/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0158 - mae: 0.0911\n",
      "Epoch 1824/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0155 - mae: 0.0900\n",
      "Epoch 1825/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0158 - mae: 0.0910\n",
      "Epoch 1826/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0153 - mae: 0.0898\n",
      "Epoch 1827/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0147 - mae: 0.0874\n",
      "Epoch 1828/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0159 - mae: 0.0920\n",
      "Epoch 1829/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0149 - mae: 0.0876\n",
      "Epoch 1830/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0159 - mae: 0.0918\n",
      "Epoch 1831/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0165 - mae: 0.0933\n",
      "Epoch 1832/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0148 - mae: 0.0874\n",
      "Epoch 1833/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0152 - mae: 0.0894\n",
      "Epoch 1834/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0160 - mae: 0.0934\n",
      "Epoch 1835/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0152 - mae: 0.0894\n",
      "Epoch 1836/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0158 - mae: 0.0913\n",
      "Epoch 1837/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0161 - mae: 0.0925\n",
      "Epoch 1838/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0156 - mae: 0.0899\n",
      "Epoch 1839/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0159 - mae: 0.0921\n",
      "Epoch 1840/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0154 - mae: 0.0898\n",
      "Epoch 1841/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0150 - mae: 0.0887\n",
      "Epoch 1842/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0158 - mae: 0.0921\n",
      "Epoch 1843/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0153 - mae: 0.0894\n",
      "Epoch 1844/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0156 - mae: 0.0899\n",
      "Epoch 1845/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0151 - mae: 0.0886\n",
      "Epoch 1846/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0161 - mae: 0.0921\n",
      "Epoch 1847/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0154 - mae: 0.0904\n",
      "Epoch 1848/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0161 - mae: 0.0928\n",
      "Epoch 1849/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0158 - mae: 0.0926\n",
      "Epoch 1850/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0149 - mae: 0.0885\n",
      "Epoch 1851/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0164 - mae: 0.0940\n",
      "Epoch 1852/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0152 - mae: 0.0897\n",
      "Epoch 1853/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0154 - mae: 0.0902\n",
      "Epoch 1854/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0156 - mae: 0.0901\n",
      "Epoch 1855/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0147 - mae: 0.0877\n",
      "Epoch 1856/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0152 - mae: 0.0889\n",
      "Epoch 1857/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0157 - mae: 0.0916\n",
      "Epoch 1858/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0157 - mae: 0.0915\n",
      "Epoch 1859/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0152 - mae: 0.0893\n",
      "Epoch 1860/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0148 - mae: 0.0886\n",
      "Epoch 1861/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0160 - mae: 0.0918\n",
      "Epoch 1862/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0156 - mae: 0.0917\n",
      "Epoch 1863/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0185 - mae: 0.0998\n",
      "Epoch 1864/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0188 - mae: 0.1013\n",
      "Epoch 1865/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0159 - mae: 0.0931\n",
      "Epoch 1866/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0161 - mae: 0.0929\n",
      "Epoch 1867/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0155 - mae: 0.0898\n",
      "Epoch 1868/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0158 - mae: 0.0915\n",
      "Epoch 1869/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0157 - mae: 0.0911\n",
      "Epoch 1870/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0160 - mae: 0.0920\n",
      "Epoch 1871/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0153 - mae: 0.0903\n",
      "Epoch 1872/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0154 - mae: 0.0896\n",
      "Epoch 1873/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0153 - mae: 0.0898\n",
      "Epoch 1874/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0154 - mae: 0.0902\n",
      "Epoch 1875/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0147 - mae: 0.0875\n",
      "Epoch 1876/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0149 - mae: 0.0881\n",
      "Epoch 1877/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0150 - mae: 0.0887\n",
      "Epoch 1878/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0148 - mae: 0.0876\n",
      "Epoch 1879/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0183 - mae: 0.0977\n",
      "Epoch 1880/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0165 - mae: 0.0930\n",
      "Epoch 1881/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0162 - mae: 0.0921\n",
      "Epoch 1882/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0161 - mae: 0.0918\n",
      "Epoch 1883/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0169 - mae: 0.0959\n",
      "Epoch 1884/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0170 - mae: 0.0955\n",
      "Epoch 1885/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0154 - mae: 0.0893\n",
      "Epoch 1886/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0162 - mae: 0.0916\n",
      "Epoch 1887/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0161 - mae: 0.0918\n",
      "Epoch 1888/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0158 - mae: 0.0910\n",
      "Epoch 1889/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0162 - mae: 0.0919\n",
      "Epoch 1890/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0156 - mae: 0.0907\n",
      "Epoch 1891/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0153 - mae: 0.0891\n",
      "Epoch 1892/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0151 - mae: 0.0891\n",
      "Epoch 1893/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0153 - mae: 0.0896\n",
      "Epoch 1894/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0152 - mae: 0.0893\n",
      "Epoch 1895/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0153 - mae: 0.0898\n",
      "Epoch 1896/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0150 - mae: 0.0891\n",
      "Epoch 1897/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0153 - mae: 0.0887\n",
      "Epoch 1898/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0156 - mae: 0.0908\n",
      "Epoch 1899/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0155 - mae: 0.0907\n",
      "Epoch 1900/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0151 - mae: 0.0901\n",
      "Epoch 1901/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0152 - mae: 0.0895\n",
      "Epoch 1902/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0154 - mae: 0.0897\n",
      "Epoch 1903/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0161 - mae: 0.0915\n",
      "Epoch 1904/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0154 - mae: 0.0894\n",
      "Epoch 1905/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0154 - mae: 0.0902\n",
      "Epoch 1906/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0149 - mae: 0.0874\n",
      "Epoch 1907/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0153 - mae: 0.0894\n",
      "Epoch 1908/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0149 - mae: 0.0881\n",
      "Epoch 1909/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0157 - mae: 0.0912\n",
      "Epoch 1910/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0155 - mae: 0.0917\n",
      "Epoch 1911/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0150 - mae: 0.0885\n",
      "Epoch 1912/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0151 - mae: 0.0882\n",
      "Epoch 1913/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0149 - mae: 0.0879\n",
      "Epoch 1914/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0151 - mae: 0.0891\n",
      "Epoch 1915/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0150 - mae: 0.0885\n",
      "Epoch 1916/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0158 - mae: 0.0916\n",
      "Epoch 1917/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0155 - mae: 0.0903\n",
      "Epoch 1918/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0151 - mae: 0.0893\n",
      "Epoch 1919/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0168 - mae: 0.0952\n",
      "Epoch 1920/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0154 - mae: 0.0911\n",
      "Epoch 1921/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0151 - mae: 0.0892\n",
      "Epoch 1922/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0152 - mae: 0.0902\n",
      "Epoch 1923/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0152 - mae: 0.0895\n",
      "Epoch 1924/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0151 - mae: 0.0889\n",
      "Epoch 1925/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0151 - mae: 0.0888\n",
      "Epoch 1926/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0152 - mae: 0.0897\n",
      "Epoch 1927/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0164 - mae: 0.0941\n",
      "Epoch 1928/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0155 - mae: 0.0904\n",
      "Epoch 1929/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0148 - mae: 0.0881\n",
      "Epoch 1930/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0155 - mae: 0.0909\n",
      "Epoch 1931/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0163 - mae: 0.0931\n",
      "Epoch 1932/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0153 - mae: 0.0900\n",
      "Epoch 1933/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0154 - mae: 0.0904\n",
      "Epoch 1934/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0212 - mae: 0.1011\n",
      "Epoch 1935/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0169 - mae: 0.0951\n",
      "Epoch 1936/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0162 - mae: 0.0924\n",
      "Epoch 1937/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0178 - mae: 0.0975\n",
      "Epoch 1938/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0159 - mae: 0.0918\n",
      "Epoch 1939/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0168 - mae: 0.0952\n",
      "Epoch 1940/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0156 - mae: 0.0906\n",
      "Epoch 1941/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0156 - mae: 0.0905\n",
      "Epoch 1942/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0153 - mae: 0.0897\n",
      "Epoch 1943/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0157 - mae: 0.0913\n",
      "Epoch 1944/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0156 - mae: 0.0911\n",
      "Epoch 1945/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0155 - mae: 0.0900\n",
      "Epoch 1946/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0154 - mae: 0.0904\n",
      "Epoch 1947/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0153 - mae: 0.0898\n",
      "Epoch 1948/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0160 - mae: 0.0923\n",
      "Epoch 1949/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0157 - mae: 0.0918\n",
      "Epoch 1950/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0149 - mae: 0.0878\n",
      "Epoch 1951/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0153 - mae: 0.0908\n",
      "Epoch 1952/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0152 - mae: 0.0898\n",
      "Epoch 1953/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0151 - mae: 0.0889\n",
      "Epoch 1954/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0147 - mae: 0.0878\n",
      "Epoch 1955/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0158 - mae: 0.0913\n",
      "Epoch 1956/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0149 - mae: 0.0879\n",
      "Epoch 1957/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0154 - mae: 0.0903\n",
      "Epoch 1958/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0156 - mae: 0.0909\n",
      "Epoch 1959/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0148 - mae: 0.0880\n",
      "Epoch 1960/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0157 - mae: 0.0917\n",
      "Epoch 1961/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0146 - mae: 0.0867\n",
      "Epoch 1962/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0159 - mae: 0.0916\n",
      "Epoch 1963/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0148 - mae: 0.0877\n",
      "Epoch 1964/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0152 - mae: 0.0896\n",
      "Epoch 1965/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0156 - mae: 0.0908\n",
      "Epoch 1966/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0146 - mae: 0.0865\n",
      "Epoch 1967/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0155 - mae: 0.0900\n",
      "Epoch 1968/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0156 - mae: 0.0908\n",
      "Epoch 1969/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0157 - mae: 0.0914\n",
      "Epoch 1970/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0154 - mae: 0.0899\n",
      "Epoch 1971/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0148 - mae: 0.0872\n",
      "Epoch 1972/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0148 - mae: 0.0873\n",
      "Epoch 1973/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0156 - mae: 0.0911\n",
      "Epoch 1974/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0162 - mae: 0.0935\n",
      "Epoch 1975/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0163 - mae: 0.0923\n",
      "Epoch 1976/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0152 - mae: 0.0891\n",
      "Epoch 1977/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0151 - mae: 0.0888\n",
      "Epoch 1978/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0169 - mae: 0.0959\n",
      "Epoch 1979/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0153 - mae: 0.0904\n",
      "Epoch 1980/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0151 - mae: 0.0890\n",
      "Epoch 1981/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0147 - mae: 0.0880\n",
      "Epoch 1982/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0166 - mae: 0.0922\n",
      "Epoch 1983/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0167 - mae: 0.0934\n",
      "Epoch 1984/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0160 - mae: 0.0920\n",
      "Epoch 1985/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0152 - mae: 0.0891\n",
      "Epoch 1986/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0157 - mae: 0.0903\n",
      "Epoch 1987/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0154 - mae: 0.0901\n",
      "Epoch 1988/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0150 - mae: 0.0884\n",
      "Epoch 1989/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0147 - mae: 0.0876\n",
      "Epoch 1990/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0151 - mae: 0.0892\n",
      "Epoch 1991/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0157 - mae: 0.0903\n",
      "Epoch 1992/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0155 - mae: 0.0901\n",
      "Epoch 1993/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0153 - mae: 0.0897\n",
      "Epoch 1994/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0167 - mae: 0.0945\n",
      "Epoch 1995/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0151 - mae: 0.0893\n",
      "Epoch 1996/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0147 - mae: 0.0876\n",
      "Epoch 1997/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0167 - mae: 0.0947\n",
      "Epoch 1998/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0153 - mae: 0.0898\n",
      "Epoch 1999/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0150 - mae: 0.0888\n",
      "Epoch 2000/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0151 - mae: 0.0895\n",
      "mae: 0.11574827134609222\n",
      "Overfit mae: 0.08479391783475876\n",
      "Train on 2019 samples\n",
      "Epoch 1/2000\n",
      "2019/2019 [==============================] - 1s 529us/sample - loss: 11959.0948 - mae: 22.8064\n",
      "Epoch 2/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 2440.4795 - mae: 12.3032\n",
      "Epoch 3/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 21710.5505 - mae: 22.5360\n",
      "Epoch 4/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 7098.2685 - mae: 13.1591\n",
      "Epoch 5/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 19109.3990 - mae: 19.3140\n",
      "Epoch 6/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 43762.5395 - mae: 30.0586\n",
      "Epoch 7/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 23898.7554 - mae: 18.8768\n",
      "Epoch 8/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 3093.7631 - mae: 11.7213\n",
      "Epoch 9/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 1382.6160 - mae: 8.2791\n",
      "Epoch 10/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 854.8542 - mae: 6.9499\n",
      "Epoch 11/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 740.1486 - mae: 6.1695\n",
      "Epoch 12/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 1271.5159 - mae: 8.1545\n",
      "Epoch 13/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 509.1431 - mae: 5.7517\n",
      "Epoch 14/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 652.4792 - mae: 6.1215\n",
      "Epoch 15/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 485.2646 - mae: 5.4732\n",
      "Epoch 16/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 486.0589 - mae: 5.5588\n",
      "Epoch 17/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 725.0097 - mae: 6.1180\n",
      "Epoch 18/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 608.1293 - mae: 5.5326\n",
      "Epoch 19/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 192.6167 - mae: 4.4055\n",
      "Epoch 20/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 361.4511 - mae: 5.2940\n",
      "Epoch 21/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 5428.0757 - mae: 12.3869\n",
      "Epoch 22/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 700.9443 - mae: 6.7642\n",
      "Epoch 23/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 609.5024 - mae: 5.7217\n",
      "Epoch 24/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 3756.0957 - mae: 10.5227\n",
      "Epoch 25/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 937.1248 - mae: 5.6593\n",
      "Epoch 26/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 5232.3920 - mae: 11.5630\n",
      "Epoch 27/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 8026.4512 - mae: 13.8574\n",
      "Epoch 28/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2397.2516 - mae: 9.8928\n",
      "Epoch 29/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 7695.6398 - mae: 11.5904\n",
      "Epoch 30/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1180.1795 - mae: 7.1828\n",
      "Epoch 31/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 2743.6179 - mae: 7.3348\n",
      "Epoch 32/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 552.7318 - mae: 4.5481\n",
      "Epoch 33/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 74.8516 - mae: 2.7742\n",
      "Epoch 34/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 218.0484 - mae: 3.3996\n",
      "Epoch 35/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 166.5964 - mae: 3.3455\n",
      "Epoch 36/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 87.2263 - mae: 2.7825\n",
      "Epoch 37/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 56.0524 - mae: 2.5024\n",
      "Epoch 38/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 69.2554 - mae: 2.5199\n",
      "Epoch 39/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 50.7415 - mae: 2.4073\n",
      "Epoch 40/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 44.2568 - mae: 2.2345\n",
      "Epoch 41/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 40.0695 - mae: 2.1641\n",
      "Epoch 42/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 37.3835 - mae: 2.0589\n",
      "Epoch 43/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 82.1218 - mae: 2.5399\n",
      "Epoch 44/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 517.5507 - mae: 4.5094\n",
      "Epoch 45/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 343.2739 - mae: 3.4105\n",
      "Epoch 46/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1048.6093 - mae: 6.5840\n",
      "Epoch 47/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 2689.9734 - mae: 8.9269\n",
      "Epoch 48/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 1053.9453 - mae: 5.3514\n",
      "Epoch 49/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 253.9795 - mae: 3.1508\n",
      "Epoch 50/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 951.0228 - mae: 5.4378\n",
      "Epoch 51/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 710.4516 - mae: 4.0901\n",
      "Epoch 52/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 57.0923 - mae: 2.3409\n",
      "Epoch 53/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 209.4247 - mae: 2.8386\n",
      "Epoch 54/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 209.1855 - mae: 3.2472\n",
      "Epoch 55/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 67us/sample - loss: 62.7291 - mae: 2.2243\n",
      "Epoch 56/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 512.8390 - mae: 4.2465\n",
      "Epoch 57/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 227.2705 - mae: 3.0237\n",
      "Epoch 58/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 281.9907 - mae: 3.6550\n",
      "Epoch 59/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 238.7181 - mae: 3.3953\n",
      "Epoch 60/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 224.1767 - mae: 2.9989\n",
      "Epoch 61/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2716.5847 - mae: 8.3560\n",
      "Epoch 62/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 2426.9084 - mae: 5.6358\n",
      "Epoch 63/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 1196.9140 - mae: 5.8475\n",
      "Epoch 64/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 1838.9451 - mae: 5.4359\n",
      "Epoch 65/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 183.4989 - mae: 3.0169\n",
      "Epoch 66/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 474.9854 - mae: 3.7048\n",
      "Epoch 67/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 1137.3919 - mae: 4.1003\n",
      "Epoch 68/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 573.3316 - mae: 3.7478\n",
      "Epoch 69/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1337.1354 - mae: 4.5493\n",
      "Epoch 70/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 1924.3761 - mae: 6.3802\n",
      "Epoch 71/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 669.1396 - mae: 3.8817\n",
      "Epoch 72/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 541.6545 - mae: 3.7500\n",
      "Epoch 73/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 3041.5358 - mae: 5.6785\n",
      "Epoch 74/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 628.6140 - mae: 4.0129\n",
      "Epoch 75/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 154.6152 - mae: 2.7309\n",
      "Epoch 76/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 81.7188 - mae: 2.2756\n",
      "Epoch 77/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 299.7951 - mae: 2.8225\n",
      "Epoch 78/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 35.2290 - mae: 1.8999\n",
      "Epoch 79/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 26.2949 - mae: 1.7647\n",
      "Epoch 80/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 30.8678 - mae: 1.6582\n",
      "Epoch 81/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 10.7448 - mae: 1.4579\n",
      "Epoch 82/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 9.0647 - mae: 1.3704\n",
      "Epoch 83/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 8.1501 - mae: 1.3244\n",
      "Epoch 84/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 7.7778 - mae: 1.2881\n",
      "Epoch 85/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 7.4611 - mae: 1.2511\n",
      "Epoch 86/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 6.8505 - mae: 1.2218\n",
      "Epoch 87/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 6.7377 - mae: 1.2023\n",
      "Epoch 88/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 6.5361 - mae: 1.1893\n",
      "Epoch 89/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 6.3200 - mae: 1.1458\n",
      "Epoch 90/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 5.8799 - mae: 1.1232\n",
      "Epoch 91/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 5.8252 - mae: 1.1101\n",
      "Epoch 92/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 7.1369 - mae: 1.1324\n",
      "Epoch 93/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 6.3456 - mae: 1.1137\n",
      "Epoch 94/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 8.8260 - mae: 1.1448\n",
      "Epoch 95/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 7.2175 - mae: 1.1148\n",
      "Epoch 96/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 36.9409 - mae: 1.3399\n",
      "Epoch 97/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 36.4040 - mae: 1.3426\n",
      "Epoch 98/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 17.7251 - mae: 1.2135\n",
      "Epoch 99/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 11.9183 - mae: 1.0883\n",
      "Epoch 100/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 28.3277 - mae: 1.3271\n",
      "Epoch 101/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 54.6742 - mae: 1.4408\n",
      "Epoch 102/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 43.6197 - mae: 1.3854\n",
      "Epoch 103/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 33.8978 - mae: 1.3515\n",
      "Epoch 104/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 44.9339 - mae: 1.4408\n",
      "Epoch 105/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 26.8912 - mae: 1.2648\n",
      "Epoch 106/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 27.3219 - mae: 1.2121\n",
      "Epoch 107/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 210.8308 - mae: 2.0711\n",
      "Epoch 108/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 167.3515 - mae: 2.0685\n",
      "Epoch 109/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 161.9540 - mae: 2.1459\n",
      "Epoch 110/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 343.9532 - mae: 2.4825\n",
      "Epoch 111/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 193.0830 - mae: 2.2304\n",
      "Epoch 112/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 173.9015 - mae: 1.8661\n",
      "Epoch 113/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 217.5838 - mae: 2.2812\n",
      "Epoch 114/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 183.5651 - mae: 2.0647\n",
      "Epoch 115/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 570.4188 - mae: 3.0713\n",
      "Epoch 116/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 757.1045 - mae: 2.8973\n",
      "Epoch 117/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 785.1629 - mae: 3.0373\n",
      "Epoch 118/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 1351.5412 - mae: 4.6860\n",
      "Epoch 119/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 130.6739 - mae: 3.1017\n",
      "Epoch 120/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 42.8778 - mae: 1.9321\n",
      "Epoch 121/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 49.7284 - mae: 1.6701\n",
      "Epoch 122/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 62.4087 - mae: 1.9160\n",
      "Epoch 123/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 47.9843 - mae: 1.9566\n",
      "Epoch 124/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 22.0544 - mae: 1.4244\n",
      "Epoch 125/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 205.1670 - mae: 3.0761\n",
      "Epoch 126/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 317.4137 - mae: 2.8586\n",
      "Epoch 127/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 709.9927 - mae: 3.8478\n",
      "Epoch 128/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 552.0956 - mae: 4.1916\n",
      "Epoch 129/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 29.8253 - mae: 1.7982\n",
      "Epoch 130/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 8.0969 - mae: 1.0706\n",
      "Epoch 131/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 6.2185 - mae: 0.9311\n",
      "Epoch 132/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 6.1901 - mae: 0.8800\n",
      "Epoch 133/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 68us/sample - loss: 5.6531 - mae: 0.8938\n",
      "Epoch 134/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 4.6179 - mae: 0.8212\n",
      "Epoch 135/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 4.3742 - mae: 0.8130\n",
      "Epoch 136/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 4.0817 - mae: 0.7855\n",
      "Epoch 137/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 4.8900 - mae: 0.7804\n",
      "Epoch 138/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 3.2929 - mae: 0.7372\n",
      "Epoch 139/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 3.5049 - mae: 0.7350\n",
      "Epoch 140/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 3.2373 - mae: 0.7462\n",
      "Epoch 141/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2.7824 - mae: 0.6918\n",
      "Epoch 142/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2.5751 - mae: 0.6712\n",
      "Epoch 143/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 2.3255 - mae: 0.6507\n",
      "Epoch 144/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 2.5587 - mae: 0.6502\n",
      "Epoch 145/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 2.6185 - mae: 0.6551\n",
      "Epoch 146/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2.3437 - mae: 0.6436\n",
      "Epoch 147/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 2.1675 - mae: 0.6234\n",
      "Epoch 148/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 2.0870 - mae: 0.6076\n",
      "Epoch 149/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 2.9433 - mae: 0.6444\n",
      "Epoch 150/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 2.3890 - mae: 0.6104\n",
      "Epoch 151/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2.8800 - mae: 0.6505\n",
      "Epoch 152/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 3.0437 - mae: 0.6398\n",
      "Epoch 153/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2.1589 - mae: 0.5969\n",
      "Epoch 154/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 2.0765 - mae: 0.5911\n",
      "Epoch 155/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.7124 - mae: 0.5554\n",
      "Epoch 156/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 1.6430 - mae: 0.5428\n",
      "Epoch 157/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.6133 - mae: 0.5389\n",
      "Epoch 158/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.6003 - mae: 0.5296\n",
      "Epoch 159/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 1.6222 - mae: 0.5400\n",
      "Epoch 160/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 1.6919 - mae: 0.5352\n",
      "Epoch 161/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.5100 - mae: 0.5135\n",
      "Epoch 162/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 1.4861 - mae: 0.5106\n",
      "Epoch 163/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 1.4525 - mae: 0.5011\n",
      "Epoch 164/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 1.4774 - mae: 0.5061\n",
      "Epoch 165/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.6301 - mae: 0.5243\n",
      "Epoch 166/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.4021 - mae: 0.4870\n",
      "Epoch 167/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 1.4470 - mae: 0.4868\n",
      "Epoch 168/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.2988 - mae: 0.4683\n",
      "Epoch 169/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.8852 - mae: 0.5171\n",
      "Epoch 170/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.5908 - mae: 0.4954\n",
      "Epoch 171/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.4964 - mae: 0.4921\n",
      "Epoch 172/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 1.3078 - mae: 0.4646\n",
      "Epoch 173/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 5.9800 - mae: 0.7391\n",
      "Epoch 174/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 2.3007 - mae: 0.5137\n",
      "Epoch 175/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 45.0869 - mae: 1.5331\n",
      "Epoch 176/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 32.4019 - mae: 1.3284\n",
      "Epoch 177/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 12.5987 - mae: 1.1637\n",
      "Epoch 178/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 3.0978 - mae: 0.6037\n",
      "Epoch 179/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 4.3633 - mae: 0.5721\n",
      "Epoch 180/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 98.4288 - mae: 2.1195\n",
      "Epoch 181/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 15.8874 - mae: 0.9843\n",
      "Epoch 182/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 87.4477 - mae: 1.4195\n",
      "Epoch 183/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 66.7793 - mae: 1.5257\n",
      "Epoch 184/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 21.2699 - mae: 1.1733\n",
      "Epoch 185/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 41.9079 - mae: 1.2057\n",
      "Epoch 186/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 18.6403 - mae: 0.8535\n",
      "Epoch 187/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 4.2406 - mae: 0.6429\n",
      "Epoch 188/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 2.1923 - mae: 0.4854\n",
      "Epoch 189/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.4938 - mae: 0.4582\n",
      "Epoch 190/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.3867 - mae: 0.4328\n",
      "Epoch 191/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 1.2007 - mae: 0.4142\n",
      "Epoch 192/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.2089 - mae: 0.4089\n",
      "Epoch 193/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 1.1080 - mae: 0.3925\n",
      "Epoch 194/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 1.0682 - mae: 0.3836\n",
      "Epoch 195/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 1.0581 - mae: 0.3799\n",
      "Epoch 196/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 1.0967 - mae: 0.3767\n",
      "Epoch 197/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.9888 - mae: 0.3650\n",
      "Epoch 198/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.9299 - mae: 0.3538\n",
      "Epoch 199/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.9146 - mae: 0.3492\n",
      "Epoch 200/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.9018 - mae: 0.3465\n",
      "Epoch 201/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.8975 - mae: 0.3411\n",
      "Epoch 202/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.8738 - mae: 0.3358\n",
      "Epoch 203/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.8552 - mae: 0.3316\n",
      "Epoch 204/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.8386 - mae: 0.3298\n",
      "Epoch 205/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.8295 - mae: 0.3238\n",
      "Epoch 206/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.8271 - mae: 0.3249\n",
      "Epoch 207/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.8436 - mae: 0.3247\n",
      "Epoch 208/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.8293 - mae: 0.3208\n",
      "Epoch 209/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.8297 - mae: 0.3237\n",
      "Epoch 210/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.8429 - mae: 0.3223\n",
      "Epoch 211/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.8304 - mae: 0.3222\n",
      "Epoch 212/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.8570 - mae: 0.3261\n",
      "Epoch 213/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.8244 - mae: 0.3179\n",
      "Epoch 214/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.8156 - mae: 0.3130\n",
      "Epoch 215/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.7842 - mae: 0.3069\n",
      "Epoch 216/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.8808 - mae: 0.3199\n",
      "Epoch 217/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.9450 - mae: 0.3261\n",
      "Epoch 218/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.8068 - mae: 0.3110\n",
      "Epoch 219/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.7568 - mae: 0.3002\n",
      "Epoch 220/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.7487 - mae: 0.2976\n",
      "Epoch 221/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.7308 - mae: 0.2941\n",
      "Epoch 222/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.7400 - mae: 0.2938\n",
      "Epoch 223/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.7943 - mae: 0.3002\n",
      "Epoch 224/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.3705 - mae: 0.3565\n",
      "Epoch 225/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.3412 - mae: 0.3544\n",
      "Epoch 226/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.2311 - mae: 0.3568\n",
      "Epoch 227/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 3.3210 - mae: 0.5019\n",
      "Epoch 228/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 8.0834 - mae: 0.6920\n",
      "Epoch 229/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 30.2421 - mae: 0.9662\n",
      "Epoch 230/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 64.2268 - mae: 1.6765\n",
      "Epoch 231/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 14.2052 - mae: 0.7137\n",
      "Epoch 232/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 27.5369 - mae: 0.7978\n",
      "Epoch 233/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 4.3997 - mae: 0.4899\n",
      "Epoch 234/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 1.6228 - mae: 0.3864\n",
      "Epoch 235/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 1.2386 - mae: 0.3568\n",
      "Epoch 236/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 1.0863 - mae: 0.3390\n",
      "Epoch 237/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.9721 - mae: 0.3245\n",
      "Epoch 238/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.8554 - mae: 0.3190\n",
      "Epoch 239/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.7712 - mae: 0.3062\n",
      "Epoch 240/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.7326 - mae: 0.2985\n",
      "Epoch 241/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.7078 - mae: 0.2919\n",
      "Epoch 242/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.6881 - mae: 0.2858\n",
      "Epoch 243/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.6683 - mae: 0.2777\n",
      "Epoch 244/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.6476 - mae: 0.2718\n",
      "Epoch 245/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.6374 - mae: 0.2690\n",
      "Epoch 246/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.6305 - mae: 0.2649\n",
      "Epoch 247/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.6229 - mae: 0.2611\n",
      "Epoch 248/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.6166 - mae: 0.2584\n",
      "Epoch 249/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.6125 - mae: 0.2551\n",
      "Epoch 250/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.6117 - mae: 0.2532\n",
      "Epoch 251/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.6138 - mae: 0.2548\n",
      "Epoch 252/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.6063 - mae: 0.2510\n",
      "Epoch 253/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.6027 - mae: 0.2486\n",
      "Epoch 254/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5921 - mae: 0.2455\n",
      "Epoch 255/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.5876 - mae: 0.2450\n",
      "Epoch 256/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5814 - mae: 0.2412\n",
      "Epoch 257/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5814 - mae: 0.2422\n",
      "Epoch 258/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5781 - mae: 0.2392\n",
      "Epoch 259/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5831 - mae: 0.2374\n",
      "Epoch 260/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5995 - mae: 0.2424\n",
      "Epoch 261/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5948 - mae: 0.2391\n",
      "Epoch 262/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5998 - mae: 0.2387\n",
      "Epoch 263/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.5895 - mae: 0.2361\n",
      "Epoch 264/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.5788 - mae: 0.2346\n",
      "Epoch 265/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5682 - mae: 0.2336\n",
      "Epoch 266/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.5665 - mae: 0.2340\n",
      "Epoch 267/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.5610 - mae: 0.2307\n",
      "Epoch 268/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5618 - mae: 0.2306\n",
      "Epoch 269/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5682 - mae: 0.2342\n",
      "Epoch 270/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5692 - mae: 0.2345\n",
      "Epoch 271/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5733 - mae: 0.2376\n",
      "Epoch 272/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.5725 - mae: 0.2348\n",
      "Epoch 273/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5698 - mae: 0.2377\n",
      "Epoch 274/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5730 - mae: 0.2362\n",
      "Epoch 275/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5718 - mae: 0.2352\n",
      "Epoch 276/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.5832 - mae: 0.2394\n",
      "Epoch 277/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5960 - mae: 0.2385\n",
      "Epoch 278/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.6160 - mae: 0.2387\n",
      "Epoch 279/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.6448 - mae: 0.2531\n",
      "Epoch 280/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.7564 - mae: 0.2910\n",
      "Epoch 281/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.6582 - mae: 0.2676\n",
      "Epoch 282/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.5915 - mae: 0.2411\n",
      "Epoch 283/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5709 - mae: 0.2393\n",
      "Epoch 284/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5651 - mae: 0.2359\n",
      "Epoch 285/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5403 - mae: 0.2256\n",
      "Epoch 286/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5367 - mae: 0.2234\n",
      "Epoch 287/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.5325 - mae: 0.2213\n",
      "Epoch 288/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.5289 - mae: 0.2210\n",
      "Epoch 289/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.5243 - mae: 0.2165\n",
      "Epoch 290/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.5242 - mae: 0.2171\n",
      "Epoch 291/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5228 - mae: 0.2165\n",
      "Epoch 292/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.5206 - mae: 0.2150\n",
      "Epoch 293/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.5243 - mae: 0.2189\n",
      "Epoch 294/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5263 - mae: 0.2183\n",
      "Epoch 295/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5456 - mae: 0.2247\n",
      "Epoch 296/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.5783 - mae: 0.2277\n",
      "Epoch 297/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.6295 - mae: 0.2452\n",
      "Epoch 298/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.6620 - mae: 0.2517\n",
      "Epoch 299/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.6012 - mae: 0.2518\n",
      "Epoch 300/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.5785 - mae: 0.2333\n",
      "Epoch 301/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.5517 - mae: 0.2338\n",
      "Epoch 302/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.5506 - mae: 0.2314\n",
      "Epoch 303/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5258 - mae: 0.2223\n",
      "Epoch 304/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5374 - mae: 0.2328\n",
      "Epoch 305/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5183 - mae: 0.2179\n",
      "Epoch 306/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5230 - mae: 0.2176\n",
      "Epoch 307/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5092 - mae: 0.2146\n",
      "Epoch 308/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5100 - mae: 0.2121\n",
      "Epoch 309/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5093 - mae: 0.2115\n",
      "Epoch 310/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.5069 - mae: 0.2104\n",
      "Epoch 311/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.5134 - mae: 0.2147\n",
      "Epoch 312/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.5385 - mae: 0.2255\n",
      "Epoch 313/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.5115 - mae: 0.2133\n",
      "Epoch 314/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.5249 - mae: 0.2245\n",
      "Epoch 315/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5200 - mae: 0.2176\n",
      "Epoch 316/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5613 - mae: 0.2266\n",
      "Epoch 317/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.4214 - mae: 0.2983\n",
      "Epoch 318/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.9165 - mae: 0.3176\n",
      "Epoch 319/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5560 - mae: 0.2438\n",
      "Epoch 320/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5132 - mae: 0.2262\n",
      "Epoch 321/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5116 - mae: 0.2207\n",
      "Epoch 322/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4979 - mae: 0.2172\n",
      "Epoch 323/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.5066 - mae: 0.2248\n",
      "Epoch 324/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.5170 - mae: 0.2461\n",
      "Epoch 325/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.4999 - mae: 0.2263\n",
      "Epoch 326/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.4882 - mae: 0.2153\n",
      "Epoch 327/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.4750 - mae: 0.2092\n",
      "Epoch 328/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.4704 - mae: 0.2032\n",
      "Epoch 329/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.4646 - mae: 0.2002\n",
      "Epoch 330/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4686 - mae: 0.2061\n",
      "Epoch 331/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4656 - mae: 0.2023\n",
      "Epoch 332/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4580 - mae: 0.1992\n",
      "Epoch 333/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4588 - mae: 0.1975\n",
      "Epoch 334/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4601 - mae: 0.2064\n",
      "Epoch 335/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.4565 - mae: 0.2029\n",
      "Epoch 336/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.4469 - mae: 0.1937\n",
      "Epoch 337/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.4502 - mae: 0.2010\n",
      "Epoch 338/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.4466 - mae: 0.1951\n",
      "Epoch 339/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.4435 - mae: 0.1955\n",
      "Epoch 340/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.4615 - mae: 0.2172\n",
      "Epoch 341/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4461 - mae: 0.1991\n",
      "Epoch 342/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4496 - mae: 0.2088\n",
      "Epoch 343/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.4456 - mae: 0.2045\n",
      "Epoch 344/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4393 - mae: 0.1967\n",
      "Epoch 345/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4316 - mae: 0.1945\n",
      "Epoch 346/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.4274 - mae: 0.1903\n",
      "Epoch 347/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.4211 - mae: 0.1863\n",
      "Epoch 348/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.4196 - mae: 0.1846\n",
      "Epoch 349/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.4170 - mae: 0.1841\n",
      "Epoch 350/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.4154 - mae: 0.1843\n",
      "Epoch 351/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4132 - mae: 0.1849\n",
      "Epoch 352/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.4113 - mae: 0.1839\n",
      "Epoch 353/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.4083 - mae: 0.1822\n",
      "Epoch 354/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.4058 - mae: 0.1810\n",
      "Epoch 355/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.4044 - mae: 0.1812\n",
      "Epoch 356/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.4033 - mae: 0.1831\n",
      "Epoch 357/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4013 - mae: 0.1839\n",
      "Epoch 358/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3996 - mae: 0.1830\n",
      "Epoch 359/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.4048 - mae: 0.1927\n",
      "Epoch 360/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.3972 - mae: 0.1852\n",
      "Epoch 361/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.3935 - mae: 0.1835\n",
      "Epoch 362/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.3975 - mae: 0.1879\n",
      "Epoch 363/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3985 - mae: 0.1937\n",
      "Epoch 364/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3919 - mae: 0.1893\n",
      "Epoch 365/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4758 - mae: 0.2504\n",
      "Epoch 366/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4023 - mae: 0.1992\n",
      "Epoch 367/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4081 - mae: 0.2155\n",
      "Epoch 368/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.3842 - mae: 0.1889\n",
      "Epoch 369/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.3789 - mae: 0.1875\n",
      "Epoch 370/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.3698 - mae: 0.1759\n",
      "Epoch 371/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.3658 - mae: 0.1735\n",
      "Epoch 372/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.3638 - mae: 0.1740\n",
      "Epoch 373/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3641 - mae: 0.1747\n",
      "Epoch 374/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.3591 - mae: 0.1729\n",
      "Epoch 375/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3586 - mae: 0.1768\n",
      "Epoch 376/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3520 - mae: 0.1704\n",
      "Epoch 377/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.3498 - mae: 0.1703\n",
      "Epoch 378/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3483 - mae: 0.1718\n",
      "Epoch 379/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3493 - mae: 0.1767\n",
      "Epoch 380/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3476 - mae: 0.1790\n",
      "Epoch 381/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3438 - mae: 0.1740\n",
      "Epoch 382/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3374 - mae: 0.1714\n",
      "Epoch 383/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.3345 - mae: 0.1702\n",
      "Epoch 384/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.3640 - mae: 0.2024\n",
      "Epoch 385/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.3456 - mae: 0.1876\n",
      "Epoch 386/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.3373 - mae: 0.1842\n",
      "Epoch 387/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.3321 - mae: 0.1781\n",
      "Epoch 388/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.3221 - mae: 0.1703\n",
      "Epoch 389/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3189 - mae: 0.1689\n",
      "Epoch 390/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3184 - mae: 0.1727\n",
      "Epoch 391/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.3124 - mae: 0.1685\n",
      "Epoch 392/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.3103 - mae: 0.1691\n",
      "Epoch 393/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.3065 - mae: 0.1671\n",
      "Epoch 394/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.3040 - mae: 0.1670\n",
      "Epoch 395/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3036 - mae: 0.1702\n",
      "Epoch 396/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.2994 - mae: 0.1677\n",
      "Epoch 397/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.2973 - mae: 0.1690\n",
      "Epoch 398/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.3000 - mae: 0.1717\n",
      "Epoch 399/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2929 - mae: 0.1720\n",
      "Epoch 400/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.2895 - mae: 0.1699\n",
      "Epoch 401/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2858 - mae: 0.1683\n",
      "Epoch 402/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.2887 - mae: 0.1770\n",
      "Epoch 403/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.2843 - mae: 0.1749\n",
      "Epoch 404/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2817 - mae: 0.1764\n",
      "Epoch 405/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2759 - mae: 0.1699\n",
      "Epoch 406/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.2699 - mae: 0.1664\n",
      "Epoch 407/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.2660 - mae: 0.1640\n",
      "Epoch 408/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2634 - mae: 0.1641\n",
      "Epoch 409/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3268 - mae: 0.1922\n",
      "Epoch 410/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.5670 - mae: 0.2976\n",
      "Epoch 411/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 1.9248 - mae: 0.2698\n",
      "Epoch 412/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2979 - mae: 0.2135\n",
      "Epoch 413/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.3128 - mae: 0.2050\n",
      "Epoch 414/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.3300 - mae: 0.2552\n",
      "Epoch 415/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.2561 - mae: 0.1859\n",
      "Epoch 416/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2511 - mae: 0.1839\n",
      "Epoch 417/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2476 - mae: 0.1816\n",
      "Epoch 418/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.2469 - mae: 0.1832\n",
      "Epoch 419/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2412 - mae: 0.1775\n",
      "Epoch 420/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2373 - mae: 0.1758\n",
      "Epoch 421/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2752 - mae: 0.2091\n",
      "Epoch 422/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.3023 - mae: 0.2160\n",
      "Epoch 423/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2367 - mae: 0.1854\n",
      "Epoch 424/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2269 - mae: 0.1743\n",
      "Epoch 425/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.2230 - mae: 0.1727\n",
      "Epoch 426/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2199 - mae: 0.1718\n",
      "Epoch 427/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2177 - mae: 0.1727\n",
      "Epoch 428/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2156 - mae: 0.1724\n",
      "Epoch 429/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2159 - mae: 0.1747\n",
      "Epoch 430/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2088 - mae: 0.1703\n",
      "Epoch 431/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.2060 - mae: 0.1689\n",
      "Epoch 432/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.3070 - mae: 0.2715\n",
      "Epoch 433/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.2099 - mae: 0.1860\n",
      "Epoch 434/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.2022 - mae: 0.1773\n",
      "Epoch 435/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1979 - mae: 0.1741\n",
      "Epoch 436/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.1954 - mae: 0.1744\n",
      "Epoch 437/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.1923 - mae: 0.1731\n",
      "Epoch 438/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1893 - mae: 0.1717\n",
      "Epoch 439/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.1873 - mae: 0.1725\n",
      "Epoch 440/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1839 - mae: 0.1707\n",
      "Epoch 441/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.1808 - mae: 0.1695\n",
      "Epoch 442/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.1789 - mae: 0.1708\n",
      "Epoch 443/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.1763 - mae: 0.1702\n",
      "Epoch 444/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1742 - mae: 0.1691\n",
      "Epoch 445/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.1703 - mae: 0.1662\n",
      "Epoch 446/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1685 - mae: 0.1686\n",
      "Epoch 447/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.1680 - mae: 0.1710\n",
      "Epoch 448/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.1630 - mae: 0.1663\n",
      "Epoch 449/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.1603 - mae: 0.1659\n",
      "Epoch 450/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.1585 - mae: 0.1669\n",
      "Epoch 451/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.1574 - mae: 0.1696\n",
      "Epoch 452/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1543 - mae: 0.1674\n",
      "Epoch 453/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1504 - mae: 0.1641\n",
      "Epoch 454/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1481 - mae: 0.1639\n",
      "Epoch 455/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.1461 - mae: 0.1643\n",
      "Epoch 456/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1446 - mae: 0.1660\n",
      "Epoch 457/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1416 - mae: 0.1637\n",
      "Epoch 458/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.1399 - mae: 0.1648\n",
      "Epoch 459/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1416 - mae: 0.1702\n",
      "Epoch 460/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1397 - mae: 0.1726\n",
      "Epoch 461/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1358 - mae: 0.1661\n",
      "Epoch 462/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.1382 - mae: 0.1702\n",
      "Epoch 463/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1288 - mae: 0.1629\n",
      "Epoch 464/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1272 - mae: 0.1622\n",
      "Epoch 465/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1230 - mae: 0.1586\n",
      "Epoch 466/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.1280 - mae: 0.1711\n",
      "Epoch 467/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.1197 - mae: 0.1586\n",
      "Epoch 468/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1191 - mae: 0.1621\n",
      "Epoch 469/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.1182 - mae: 0.1627\n",
      "Epoch 470/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1150 - mae: 0.1610\n",
      "Epoch 471/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.1173 - mae: 0.1663\n",
      "Epoch 472/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1109 - mae: 0.1591\n",
      "Epoch 473/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.1089 - mae: 0.1599\n",
      "Epoch 474/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.1074 - mae: 0.1590\n",
      "Epoch 475/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.1048 - mae: 0.1574\n",
      "Epoch 476/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1023 - mae: 0.1540\n",
      "Epoch 477/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1015 - mae: 0.1569\n",
      "Epoch 478/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1063 - mae: 0.1685\n",
      "Epoch 479/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.1001 - mae: 0.1574\n",
      "Epoch 480/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1005 - mae: 0.1626\n",
      "Epoch 481/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0952 - mae: 0.1553\n",
      "Epoch 482/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0929 - mae: 0.1534\n",
      "Epoch 483/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0922 - mae: 0.1545\n",
      "Epoch 484/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0930 - mae: 0.1585\n",
      "Epoch 485/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0898 - mae: 0.1553\n",
      "Epoch 486/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0875 - mae: 0.1528\n",
      "Epoch 487/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0920 - mae: 0.1630\n",
      "Epoch 488/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0919 - mae: 0.1649\n",
      "Epoch 489/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0875 - mae: 0.1603\n",
      "Epoch 490/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0834 - mae: 0.1554\n",
      "Epoch 491/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0837 - mae: 0.1574\n",
      "Epoch 492/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0809 - mae: 0.1537\n",
      "Epoch 493/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0793 - mae: 0.1529\n",
      "Epoch 494/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0781 - mae: 0.1530\n",
      "Epoch 495/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0763 - mae: 0.1511\n",
      "Epoch 496/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0766 - mae: 0.1545\n",
      "Epoch 497/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0749 - mae: 0.1518\n",
      "Epoch 498/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0736 - mae: 0.1510\n",
      "Epoch 499/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0733 - mae: 0.1520\n",
      "Epoch 500/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0718 - mae: 0.1506\n",
      "Epoch 501/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0714 - mae: 0.1521\n",
      "Epoch 502/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0730 - mae: 0.1600\n",
      "Epoch 503/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0695 - mae: 0.1508\n",
      "Epoch 504/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0698 - mae: 0.1522\n",
      "Epoch 505/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0684 - mae: 0.1516\n",
      "Epoch 506/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0662 - mae: 0.1499\n",
      "Epoch 507/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0659 - mae: 0.1489\n",
      "Epoch 508/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0652 - mae: 0.1494\n",
      "Epoch 509/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0661 - mae: 0.1524\n",
      "Epoch 510/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0637 - mae: 0.1491\n",
      "Epoch 511/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0700 - mae: 0.1620\n",
      "Epoch 512/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0623 - mae: 0.1503\n",
      "Epoch 513/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0603 - mae: 0.1458\n",
      "Epoch 514/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0619 - mae: 0.1515\n",
      "Epoch 515/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0590 - mae: 0.1460\n",
      "Epoch 516/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0578 - mae: 0.1440\n",
      "Epoch 517/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0578 - mae: 0.1455\n",
      "Epoch 518/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0569 - mae: 0.1442\n",
      "Epoch 519/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0572 - mae: 0.1467\n",
      "Epoch 520/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0566 - mae: 0.1447\n",
      "Epoch 521/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1449 - mae: 0.1548\n",
      "Epoch 522/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0600 - mae: 0.1548\n",
      "Epoch 523/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0596 - mae: 0.1495\n",
      "Epoch 524/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0562 - mae: 0.1481\n",
      "Epoch 525/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0565 - mae: 0.1486\n",
      "Epoch 526/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0542 - mae: 0.1448\n",
      "Epoch 527/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0545 - mae: 0.1461\n",
      "Epoch 528/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0772 - mae: 0.1685\n",
      "Epoch 529/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0556 - mae: 0.1514\n",
      "Epoch 530/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0527 - mae: 0.1443\n",
      "Epoch 531/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0534 - mae: 0.1460\n",
      "Epoch 532/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0532 - mae: 0.1468\n",
      "Epoch 533/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0515 - mae: 0.1442\n",
      "Epoch 534/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0532 - mae: 0.1449\n",
      "Epoch 535/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0496 - mae: 0.1417\n",
      "Epoch 536/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0490 - mae: 0.1410\n",
      "Epoch 537/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0482 - mae: 0.1398\n",
      "Epoch 538/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0483 - mae: 0.1400\n",
      "Epoch 539/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0573 - mae: 0.1532\n",
      "Epoch 540/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0509 - mae: 0.1461\n",
      "Epoch 541/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0491 - mae: 0.1428\n",
      "Epoch 542/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0483 - mae: 0.1424\n",
      "Epoch 543/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.2275 - mae: 0.1624\n",
      "Epoch 544/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0572 - mae: 0.1634\n",
      "Epoch 545/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0578 - mae: 0.1543\n",
      "Epoch 546/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0510 - mae: 0.1499\n",
      "Epoch 547/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0509 - mae: 0.1507\n",
      "Epoch 548/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0507 - mae: 0.1478\n",
      "Epoch 549/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0499 - mae: 0.1465\n",
      "Epoch 550/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0467 - mae: 0.1420\n",
      "Epoch 551/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0474 - mae: 0.1426\n",
      "Epoch 552/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0471 - mae: 0.1436\n",
      "Epoch 553/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0447 - mae: 0.1381\n",
      "Epoch 554/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0445 - mae: 0.1376\n",
      "Epoch 555/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0445 - mae: 0.1399\n",
      "Epoch 556/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0448 - mae: 0.1408\n",
      "Epoch 557/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0441 - mae: 0.1394\n",
      "Epoch 558/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0431 - mae: 0.1369\n",
      "Epoch 559/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0436 - mae: 0.1401\n",
      "Epoch 560/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0417 - mae: 0.1341\n",
      "Epoch 561/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0427 - mae: 0.1376\n",
      "Epoch 562/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0421 - mae: 0.1364\n",
      "Epoch 563/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0414 - mae: 0.1347\n",
      "Epoch 564/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0419 - mae: 0.1377\n",
      "Epoch 565/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0404 - mae: 0.1335\n",
      "Epoch 566/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0464 - mae: 0.1385\n",
      "Epoch 567/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0439 - mae: 0.1436\n",
      "Epoch 568/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0427 - mae: 0.1401\n",
      "Epoch 569/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0425 - mae: 0.1410\n",
      "Epoch 570/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0497 - mae: 0.1494\n",
      "Epoch 571/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0466 - mae: 0.1511\n",
      "Epoch 572/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0428 - mae: 0.1405\n",
      "Epoch 573/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0415 - mae: 0.1374\n",
      "Epoch 574/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0410 - mae: 0.1354\n",
      "Epoch 575/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0395 - mae: 0.1327\n",
      "Epoch 576/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0820 - mae: 0.1448\n",
      "Epoch 577/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0407 - mae: 0.1363\n",
      "Epoch 578/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0397 - mae: 0.1327\n",
      "Epoch 579/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0395 - mae: 0.1338\n",
      "Epoch 580/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0391 - mae: 0.1323\n",
      "Epoch 581/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0380 - mae: 0.1304\n",
      "Epoch 582/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0385 - mae: 0.1317\n",
      "Epoch 583/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0373 - mae: 0.1295\n",
      "Epoch 584/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0367 - mae: 0.1281\n",
      "Epoch 585/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0391 - mae: 0.1321\n",
      "Epoch 586/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0392 - mae: 0.1356\n",
      "Epoch 587/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0364 - mae: 0.1284\n",
      "Epoch 588/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0365 - mae: 0.1281\n",
      "Epoch 589/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0356 - mae: 0.1265\n",
      "Epoch 590/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0363 - mae: 0.1296\n",
      "Epoch 591/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0353 - mae: 0.1265\n",
      "Epoch 592/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0372 - mae: 0.1311\n",
      "Epoch 593/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0368 - mae: 0.1306\n",
      "Epoch 594/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0358 - mae: 0.1277\n",
      "Epoch 595/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0352 - mae: 0.1269\n",
      "Epoch 596/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0355 - mae: 0.1289\n",
      "Epoch 597/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0357 - mae: 0.1291\n",
      "Epoch 598/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0335 - mae: 0.1231\n",
      "Epoch 599/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0338 - mae: 0.1238\n",
      "Epoch 600/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0343 - mae: 0.1254\n",
      "Epoch 601/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0333 - mae: 0.1234\n",
      "Epoch 602/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0341 - mae: 0.1257\n",
      "Epoch 603/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0332 - mae: 0.1232\n",
      "Epoch 604/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0330 - mae: 0.1233\n",
      "Epoch 605/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0322 - mae: 0.1211\n",
      "Epoch 606/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0323 - mae: 0.1219\n",
      "Epoch 607/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0317 - mae: 0.1208\n",
      "Epoch 608/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0321 - mae: 0.1220\n",
      "Epoch 609/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0322 - mae: 0.1221\n",
      "Epoch 610/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0344 - mae: 0.1286\n",
      "Epoch 611/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0323 - mae: 0.1219\n",
      "Epoch 612/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0318 - mae: 0.1218\n",
      "Epoch 613/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0322 - mae: 0.1232\n",
      "Epoch 614/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0325 - mae: 0.1246\n",
      "Epoch 615/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0316 - mae: 0.1218\n",
      "Epoch 616/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0303 - mae: 0.1190\n",
      "Epoch 617/2000\n",
      "2019/2019 [==============================] - 0s 134us/sample - loss: 0.0318 - mae: 0.1236\n",
      "Epoch 618/2000\n",
      "2019/2019 [==============================] - 0s 96us/sample - loss: 0.0310 - mae: 0.1218\n",
      "Epoch 619/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0306 - mae: 0.1193\n",
      "Epoch 620/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0303 - mae: 0.1192\n",
      "Epoch 621/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0299 - mae: 0.1173\n",
      "Epoch 622/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0297 - mae: 0.1181\n",
      "Epoch 623/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0301 - mae: 0.1196\n",
      "Epoch 624/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0308 - mae: 0.1227\n",
      "Epoch 625/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0292 - mae: 0.1175\n",
      "Epoch 626/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0294 - mae: 0.1179\n",
      "Epoch 627/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0286 - mae: 0.1160\n",
      "Epoch 628/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0306 - mae: 0.1224\n",
      "Epoch 629/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0298 - mae: 0.1207\n",
      "Epoch 630/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0295 - mae: 0.1196\n",
      "Epoch 631/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0288 - mae: 0.1173\n",
      "Epoch 632/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0290 - mae: 0.1179\n",
      "Epoch 633/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0290 - mae: 0.1188\n",
      "Epoch 634/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0282 - mae: 0.1167\n",
      "Epoch 635/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0288 - mae: 0.1182\n",
      "Epoch 636/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0293 - mae: 0.1194\n",
      "Epoch 637/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0284 - mae: 0.1163\n",
      "Epoch 638/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0290 - mae: 0.1191\n",
      "Epoch 639/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0288 - mae: 0.1182\n",
      "Epoch 640/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0282 - mae: 0.1166\n",
      "Epoch 641/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0278 - mae: 0.1162\n",
      "Epoch 642/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0275 - mae: 0.1151\n",
      "Epoch 643/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0276 - mae: 0.1161\n",
      "Epoch 644/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0267 - mae: 0.1134\n",
      "Epoch 645/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0289 - mae: 0.1189\n",
      "Epoch 646/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0286 - mae: 0.1196\n",
      "Epoch 647/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0280 - mae: 0.1177\n",
      "Epoch 648/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0267 - mae: 0.1139\n",
      "Epoch 649/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0276 - mae: 0.1167\n",
      "Epoch 650/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0278 - mae: 0.1170\n",
      "Epoch 651/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0272 - mae: 0.1155\n",
      "Epoch 652/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0280 - mae: 0.1184\n",
      "Epoch 653/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0275 - mae: 0.1173\n",
      "Epoch 654/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0268 - mae: 0.1147\n",
      "Epoch 655/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0278 - mae: 0.1172\n",
      "Epoch 656/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0285 - mae: 0.1203\n",
      "Epoch 657/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0280 - mae: 0.1192\n",
      "Epoch 658/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0283 - mae: 0.1199\n",
      "Epoch 659/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0274 - mae: 0.1173\n",
      "Epoch 660/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0275 - mae: 0.1169\n",
      "Epoch 661/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0282 - mae: 0.1206\n",
      "Epoch 662/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0275 - mae: 0.1183\n",
      "Epoch 663/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0274 - mae: 0.1193\n",
      "Epoch 664/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0264 - mae: 0.1159\n",
      "Epoch 665/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0277 - mae: 0.1190\n",
      "Epoch 666/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0267 - mae: 0.1160\n",
      "Epoch 667/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0265 - mae: 0.1152\n",
      "Epoch 668/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0260 - mae: 0.1138\n",
      "Epoch 669/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0279 - mae: 0.1198\n",
      "Epoch 670/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0312 - mae: 0.1278\n",
      "Epoch 671/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0282 - mae: 0.1209\n",
      "Epoch 672/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0290 - mae: 0.1232\n",
      "Epoch 673/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0278 - mae: 0.1196\n",
      "Epoch 674/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0274 - mae: 0.1191\n",
      "Epoch 675/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0267 - mae: 0.1183\n",
      "Epoch 676/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0263 - mae: 0.1155\n",
      "Epoch 677/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0284 - mae: 0.1229\n",
      "Epoch 678/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0262 - mae: 0.1177\n",
      "Epoch 679/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0257 - mae: 0.1149\n",
      "Epoch 680/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0254 - mae: 0.1144\n",
      "Epoch 681/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0256 - mae: 0.1149\n",
      "Epoch 682/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0256 - mae: 0.1161\n",
      "Epoch 683/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0264 - mae: 0.1180\n",
      "Epoch 684/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0259 - mae: 0.1159\n",
      "Epoch 685/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0257 - mae: 0.1158\n",
      "Epoch 686/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0257 - mae: 0.1147\n",
      "Epoch 687/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0423 - mae: 0.1286\n",
      "Epoch 688/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0277 - mae: 0.1209\n",
      "Epoch 689/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0273 - mae: 0.1195\n",
      "Epoch 690/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0292 - mae: 0.1248\n",
      "Epoch 691/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0266 - mae: 0.1192\n",
      "Epoch 692/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0295 - mae: 0.1257\n",
      "Epoch 693/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0284 - mae: 0.1238\n",
      "Epoch 694/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0283 - mae: 0.1225\n",
      "Epoch 695/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0269 - mae: 0.1188\n",
      "Epoch 696/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0260 - mae: 0.1160\n",
      "Epoch 697/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0260 - mae: 0.1167\n",
      "Epoch 698/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0275 - mae: 0.1198\n",
      "Epoch 699/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0264 - mae: 0.1176\n",
      "Epoch 700/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0252 - mae: 0.1151\n",
      "Epoch 701/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0258 - mae: 0.1151\n",
      "Epoch 702/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0259 - mae: 0.1170\n",
      "Epoch 703/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0259 - mae: 0.1165\n",
      "Epoch 704/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0260 - mae: 0.1175\n",
      "Epoch 705/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0254 - mae: 0.1155\n",
      "Epoch 706/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0253 - mae: 0.1143\n",
      "Epoch 707/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0249 - mae: 0.1140\n",
      "Epoch 708/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0246 - mae: 0.1139\n",
      "Epoch 709/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0257 - mae: 0.1170\n",
      "Epoch 710/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0262 - mae: 0.1167\n",
      "Epoch 711/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0254 - mae: 0.1154\n",
      "Epoch 712/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0246 - mae: 0.1136\n",
      "Epoch 713/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0259 - mae: 0.1170\n",
      "Epoch 714/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0251 - mae: 0.1146\n",
      "Epoch 715/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0246 - mae: 0.1143\n",
      "Epoch 716/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0264 - mae: 0.1193\n",
      "Epoch 717/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0270 - mae: 0.1201\n",
      "Epoch 718/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0258 - mae: 0.1164\n",
      "Epoch 719/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0265 - mae: 0.1183\n",
      "Epoch 720/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0256 - mae: 0.1175\n",
      "Epoch 721/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0246 - mae: 0.1135\n",
      "Epoch 722/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0238 - mae: 0.1113\n",
      "Epoch 723/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0265 - mae: 0.1184\n",
      "Epoch 724/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0288 - mae: 0.1263\n",
      "Epoch 725/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0260 - mae: 0.1179\n",
      "Epoch 726/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0255 - mae: 0.1161\n",
      "Epoch 727/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0247 - mae: 0.1135\n",
      "Epoch 728/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0256 - mae: 0.1155\n",
      "Epoch 729/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0283 - mae: 0.1204\n",
      "Epoch 730/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0247 - mae: 0.1151\n",
      "Epoch 731/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0311 - mae: 0.1204\n",
      "Epoch 732/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0260 - mae: 0.1174\n",
      "Epoch 733/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0252 - mae: 0.1146\n",
      "Epoch 734/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0256 - mae: 0.1169\n",
      "Epoch 735/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0247 - mae: 0.1134\n",
      "Epoch 736/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0276 - mae: 0.1226\n",
      "Epoch 737/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0244 - mae: 0.1127\n",
      "Epoch 738/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0248 - mae: 0.1153\n",
      "Epoch 739/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0247 - mae: 0.1129\n",
      "Epoch 740/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0249 - mae: 0.1143\n",
      "Epoch 741/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0240 - mae: 0.1118\n",
      "Epoch 742/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0243 - mae: 0.1134\n",
      "Epoch 743/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0269 - mae: 0.1190\n",
      "Epoch 744/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0358 - mae: 0.1390\n",
      "Epoch 745/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0322 - mae: 0.1303\n",
      "Epoch 746/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0307 - mae: 0.1282\n",
      "Epoch 747/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0281 - mae: 0.1233\n",
      "Epoch 748/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0271 - mae: 0.1195\n",
      "Epoch 749/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0261 - mae: 0.1167\n",
      "Epoch 750/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0260 - mae: 0.1177\n",
      "Epoch 751/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0250 - mae: 0.1139\n",
      "Epoch 752/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0283 - mae: 0.1240\n",
      "Epoch 753/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0257 - mae: 0.1168\n",
      "Epoch 754/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0258 - mae: 0.1175\n",
      "Epoch 755/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0250 - mae: 0.1133\n",
      "Epoch 756/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0257 - mae: 0.1153\n",
      "Epoch 757/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0282 - mae: 0.1252\n",
      "Epoch 758/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0257 - mae: 0.1154\n",
      "Epoch 759/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0238 - mae: 0.1124\n",
      "Epoch 760/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0259 - mae: 0.1186\n",
      "Epoch 761/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0263 - mae: 0.1198\n",
      "Epoch 762/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0254 - mae: 0.1171\n",
      "Epoch 763/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0238 - mae: 0.1121\n",
      "Epoch 764/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0251 - mae: 0.1150\n",
      "Epoch 765/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0246 - mae: 0.1147\n",
      "Epoch 766/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0265 - mae: 0.1180\n",
      "Epoch 767/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0279 - mae: 0.1231\n",
      "Epoch 768/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0268 - mae: 0.1205\n",
      "Epoch 769/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0264 - mae: 0.1189\n",
      "Epoch 770/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0245 - mae: 0.1137\n",
      "Epoch 771/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0245 - mae: 0.1133\n",
      "Epoch 772/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0245 - mae: 0.1133\n",
      "Epoch 773/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0254 - mae: 0.1163\n",
      "Epoch 774/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0250 - mae: 0.1160\n",
      "Epoch 775/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0250 - mae: 0.1158\n",
      "Epoch 776/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0249 - mae: 0.1147\n",
      "Epoch 777/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0262 - mae: 0.1178\n",
      "Epoch 778/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0239 - mae: 0.1109\n",
      "Epoch 779/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0240 - mae: 0.1114\n",
      "Epoch 780/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0242 - mae: 0.1133\n",
      "Epoch 781/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0259 - mae: 0.1141\n",
      "Epoch 782/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0239 - mae: 0.1120\n",
      "Epoch 783/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0239 - mae: 0.1114\n",
      "Epoch 784/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0249 - mae: 0.1151\n",
      "Epoch 785/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0252 - mae: 0.1157\n",
      "Epoch 786/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0239 - mae: 0.1120\n",
      "Epoch 787/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0245 - mae: 0.1142\n",
      "Epoch 788/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0249 - mae: 0.1140\n",
      "Epoch 789/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0261 - mae: 0.1188\n",
      "Epoch 790/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0311 - mae: 0.1274\n",
      "Epoch 791/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0264 - mae: 0.1183\n",
      "Epoch 792/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0307 - mae: 0.1295\n",
      "Epoch 793/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0266 - mae: 0.1198\n",
      "Epoch 794/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0272 - mae: 0.1219\n",
      "Epoch 795/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0257 - mae: 0.1175\n",
      "Epoch 796/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0251 - mae: 0.1159\n",
      "Epoch 797/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0254 - mae: 0.1163\n",
      "Epoch 798/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0255 - mae: 0.1169\n",
      "Epoch 799/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0253 - mae: 0.1155\n",
      "Epoch 800/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0267 - mae: 0.1197\n",
      "Epoch 801/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0252 - mae: 0.1159\n",
      "Epoch 802/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0243 - mae: 0.1129\n",
      "Epoch 803/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0244 - mae: 0.1144\n",
      "Epoch 804/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0238 - mae: 0.1119\n",
      "Epoch 805/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0236 - mae: 0.1127\n",
      "Epoch 806/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0242 - mae: 0.1130\n",
      "Epoch 807/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0268 - mae: 0.1192\n",
      "Epoch 808/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0251 - mae: 0.1165\n",
      "Epoch 809/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0239 - mae: 0.1127\n",
      "Epoch 810/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0243 - mae: 0.1133\n",
      "Epoch 811/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0256 - mae: 0.1163\n",
      "Epoch 812/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0243 - mae: 0.1136\n",
      "Epoch 813/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0243 - mae: 0.1137\n",
      "Epoch 814/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0241 - mae: 0.1127\n",
      "Epoch 815/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0246 - mae: 0.1152\n",
      "Epoch 816/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0249 - mae: 0.1158\n",
      "Epoch 817/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0230 - mae: 0.1102\n",
      "Epoch 818/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0231 - mae: 0.1097\n",
      "Epoch 819/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0257 - mae: 0.1175\n",
      "Epoch 820/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0238 - mae: 0.1127\n",
      "Epoch 821/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0255 - mae: 0.1170\n",
      "Epoch 822/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0241 - mae: 0.1132\n",
      "Epoch 823/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0233 - mae: 0.1111\n",
      "Epoch 824/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0237 - mae: 0.1113\n",
      "Epoch 825/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0229 - mae: 0.1092\n",
      "Epoch 826/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0229 - mae: 0.1095\n",
      "Epoch 827/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0233 - mae: 0.1107\n",
      "Epoch 828/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0240 - mae: 0.1117\n",
      "Epoch 829/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0231 - mae: 0.1109\n",
      "Epoch 830/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0244 - mae: 0.1142\n",
      "Epoch 831/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0231 - mae: 0.1109\n",
      "Epoch 832/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0228 - mae: 0.1092\n",
      "Epoch 833/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0231 - mae: 0.1100\n",
      "Epoch 834/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0234 - mae: 0.1111\n",
      "Epoch 835/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0230 - mae: 0.1101\n",
      "Epoch 836/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0227 - mae: 0.1090\n",
      "Epoch 837/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0232 - mae: 0.1107\n",
      "Epoch 838/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0225 - mae: 0.1097\n",
      "Epoch 839/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0222 - mae: 0.1076\n",
      "Epoch 840/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0234 - mae: 0.1120\n",
      "Epoch 841/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0222 - mae: 0.1079\n",
      "Epoch 842/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0247 - mae: 0.1161\n",
      "Epoch 843/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0232 - mae: 0.1105\n",
      "Epoch 844/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0232 - mae: 0.1100\n",
      "Epoch 845/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1081\n",
      "Epoch 846/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0224 - mae: 0.1090\n",
      "Epoch 847/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0232 - mae: 0.1106\n",
      "Epoch 848/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0239 - mae: 0.1125\n",
      "Epoch 849/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0234 - mae: 0.1120\n",
      "Epoch 850/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0223 - mae: 0.1091\n",
      "Epoch 851/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0236 - mae: 0.1120\n",
      "Epoch 852/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0255 - mae: 0.1179\n",
      "Epoch 853/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0246 - mae: 0.1145\n",
      "Epoch 854/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0260 - mae: 0.1191\n",
      "Epoch 855/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0260 - mae: 0.1188\n",
      "Epoch 856/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0233 - mae: 0.1115\n",
      "Epoch 857/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0237 - mae: 0.1128\n",
      "Epoch 858/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0230 - mae: 0.1103\n",
      "Epoch 859/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0229 - mae: 0.1108\n",
      "Epoch 860/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0239 - mae: 0.1135\n",
      "Epoch 861/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0233 - mae: 0.1122\n",
      "Epoch 862/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0234 - mae: 0.1115\n",
      "Epoch 863/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0227 - mae: 0.1091\n",
      "Epoch 864/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0238 - mae: 0.1134\n",
      "Epoch 865/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0226 - mae: 0.1092\n",
      "Epoch 866/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0237 - mae: 0.1135\n",
      "Epoch 867/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0242 - mae: 0.1121\n",
      "Epoch 868/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0272 - mae: 0.1191\n",
      "Epoch 869/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0239 - mae: 0.1138\n",
      "Epoch 870/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0232 - mae: 0.1119\n",
      "Epoch 871/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0224 - mae: 0.1098\n",
      "Epoch 872/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0224 - mae: 0.1098\n",
      "Epoch 873/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0224 - mae: 0.1091\n",
      "Epoch 874/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0229 - mae: 0.1095\n",
      "Epoch 875/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0222 - mae: 0.1086\n",
      "Epoch 876/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0226 - mae: 0.1104\n",
      "Epoch 877/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0225 - mae: 0.1099\n",
      "Epoch 878/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0253 - mae: 0.1183\n",
      "Epoch 879/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0233 - mae: 0.1112\n",
      "Epoch 880/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0232 - mae: 0.1108\n",
      "Epoch 881/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0245 - mae: 0.1142\n",
      "Epoch 882/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0226 - mae: 0.1101\n",
      "Epoch 883/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0224 - mae: 0.1094\n",
      "Epoch 884/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0230 - mae: 0.1108\n",
      "Epoch 885/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0221 - mae: 0.1088\n",
      "Epoch 886/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0234 - mae: 0.1111\n",
      "Epoch 887/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0241 - mae: 0.1135\n",
      "Epoch 888/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0253 - mae: 0.1177\n",
      "Epoch 889/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0229 - mae: 0.1097\n",
      "Epoch 890/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0222 - mae: 0.1085\n",
      "Epoch 891/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0225 - mae: 0.1092\n",
      "Epoch 892/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0220 - mae: 0.1076\n",
      "Epoch 893/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0220 - mae: 0.1075\n",
      "Epoch 894/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0235 - mae: 0.1118\n",
      "Epoch 895/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0251 - mae: 0.1170\n",
      "Epoch 896/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0219 - mae: 0.1065\n",
      "Epoch 897/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0221 - mae: 0.1079\n",
      "Epoch 898/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0220 - mae: 0.1069\n",
      "Epoch 899/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0226 - mae: 0.1096\n",
      "Epoch 900/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0226 - mae: 0.1102\n",
      "Epoch 901/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0237 - mae: 0.1130\n",
      "Epoch 902/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0241 - mae: 0.1143\n",
      "Epoch 903/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0230 - mae: 0.1111\n",
      "Epoch 904/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0245 - mae: 0.1150\n",
      "Epoch 905/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0226 - mae: 0.1098\n",
      "Epoch 906/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0228 - mae: 0.1088\n",
      "Epoch 907/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0225 - mae: 0.1097\n",
      "Epoch 908/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0237 - mae: 0.1127\n",
      "Epoch 909/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0229 - mae: 0.1105\n",
      "Epoch 910/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0230 - mae: 0.1103\n",
      "Epoch 911/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0230 - mae: 0.1111\n",
      "Epoch 912/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0225 - mae: 0.1089\n",
      "Epoch 913/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0224 - mae: 0.1094\n",
      "Epoch 914/2000\n",
      "2019/2019 [==============================] - 0s 63us/sample - loss: 0.0227 - mae: 0.1101\n",
      "Epoch 915/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0214 - mae: 0.1062\n",
      "Epoch 916/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0231 - mae: 0.1119\n",
      "Epoch 917/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0218 - mae: 0.1068\n",
      "Epoch 918/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0219 - mae: 0.1079\n",
      "Epoch 919/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0222 - mae: 0.1090\n",
      "Epoch 920/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0220 - mae: 0.1078\n",
      "Epoch 921/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0216 - mae: 0.1070\n",
      "Epoch 922/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0231 - mae: 0.1107\n",
      "Epoch 923/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0239 - mae: 0.1131\n",
      "Epoch 924/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0230 - mae: 0.1107\n",
      "Epoch 925/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0233 - mae: 0.1130\n",
      "Epoch 926/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0225 - mae: 0.1100\n",
      "Epoch 927/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0240 - mae: 0.1155\n",
      "Epoch 928/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0232 - mae: 0.1113\n",
      "Epoch 929/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0224 - mae: 0.1100\n",
      "Epoch 930/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0226 - mae: 0.1103\n",
      "Epoch 931/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0230 - mae: 0.1108\n",
      "Epoch 932/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0226 - mae: 0.1096\n",
      "Epoch 933/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0238 - mae: 0.1138\n",
      "Epoch 934/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0291 - mae: 0.1217\n",
      "Epoch 935/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0252 - mae: 0.1176\n",
      "Epoch 936/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0247 - mae: 0.1163\n",
      "Epoch 937/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0233 - mae: 0.1114\n",
      "Epoch 938/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0245 - mae: 0.1153\n",
      "Epoch 939/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0241 - mae: 0.1134\n",
      "Epoch 940/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0517 - mae: 0.1647\n",
      "Epoch 941/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0658 - mae: 0.1540\n",
      "Epoch 942/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0469 - mae: 0.1609\n",
      "Epoch 943/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0407 - mae: 0.1489\n",
      "Epoch 944/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0373 - mae: 0.1405\n",
      "Epoch 945/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0360 - mae: 0.1385\n",
      "Epoch 946/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0337 - mae: 0.1317\n",
      "Epoch 947/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0321 - mae: 0.1295\n",
      "Epoch 948/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0309 - mae: 0.1274\n",
      "Epoch 949/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0311 - mae: 0.1279\n",
      "Epoch 950/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0301 - mae: 0.1252\n",
      "Epoch 951/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0292 - mae: 0.1230\n",
      "Epoch 952/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0285 - mae: 0.1213\n",
      "Epoch 953/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0313 - mae: 0.1296\n",
      "Epoch 954/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0341 - mae: 0.1375\n",
      "Epoch 955/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0326 - mae: 0.1322\n",
      "Epoch 956/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0297 - mae: 0.1253\n",
      "Epoch 957/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0281 - mae: 0.1211\n",
      "Epoch 958/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0280 - mae: 0.1204\n",
      "Epoch 959/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0308 - mae: 0.1267\n",
      "Epoch 960/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0314 - mae: 0.1311\n",
      "Epoch 961/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0287 - mae: 0.1236\n",
      "Epoch 962/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0269 - mae: 0.1190\n",
      "Epoch 963/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0268 - mae: 0.1195\n",
      "Epoch 964/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0265 - mae: 0.1179\n",
      "Epoch 965/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0280 - mae: 0.1225\n",
      "Epoch 966/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0265 - mae: 0.1171\n",
      "Epoch 967/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0251 - mae: 0.1130\n",
      "Epoch 968/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0269 - mae: 0.1196\n",
      "Epoch 969/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0257 - mae: 0.1165\n",
      "Epoch 970/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0247 - mae: 0.1131\n",
      "Epoch 971/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0242 - mae: 0.1118\n",
      "Epoch 972/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0244 - mae: 0.1125\n",
      "Epoch 973/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0234 - mae: 0.1082\n",
      "Epoch 974/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0230 - mae: 0.1078\n",
      "Epoch 975/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0252 - mae: 0.1148\n",
      "Epoch 976/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0255 - mae: 0.1154\n",
      "Epoch 977/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0252 - mae: 0.1147\n",
      "Epoch 978/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0241 - mae: 0.1114\n",
      "Epoch 979/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0236 - mae: 0.1104\n",
      "Epoch 980/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0233 - mae: 0.1086\n",
      "Epoch 981/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0239 - mae: 0.1103\n",
      "Epoch 982/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0227 - mae: 0.1066\n",
      "Epoch 983/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0229 - mae: 0.1075\n",
      "Epoch 984/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0239 - mae: 0.1114\n",
      "Epoch 985/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0230 - mae: 0.1070\n",
      "Epoch 986/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0253 - mae: 0.1150\n",
      "Epoch 987/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0228 - mae: 0.1083\n",
      "Epoch 988/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0243 - mae: 0.1107\n",
      "Epoch 989/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0294 - mae: 0.1279\n",
      "Epoch 990/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0235 - mae: 0.1103\n",
      "Epoch 991/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0227 - mae: 0.1080\n",
      "Epoch 992/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0228 - mae: 0.1079\n",
      "Epoch 993/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0226 - mae: 0.1071\n",
      "Epoch 994/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0256 - mae: 0.1170\n",
      "Epoch 995/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0230 - mae: 0.1092\n",
      "Epoch 996/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0227 - mae: 0.1078\n",
      "Epoch 997/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0227 - mae: 0.1087\n",
      "Epoch 998/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0246 - mae: 0.1142\n",
      "Epoch 999/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0231 - mae: 0.1097\n",
      "Epoch 1000/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0226 - mae: 0.1075\n",
      "Epoch 1001/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0227 - mae: 0.1087\n",
      "Epoch 1002/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0220 - mae: 0.1061\n",
      "Epoch 1003/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0225 - mae: 0.1066\n",
      "Epoch 1004/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0217 - mae: 0.1050\n",
      "Epoch 1005/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0236 - mae: 0.1114\n",
      "Epoch 1006/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0223 - mae: 0.1073\n",
      "Epoch 1007/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0233 - mae: 0.1095\n",
      "Epoch 1008/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0227 - mae: 0.1084\n",
      "Epoch 1009/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0226 - mae: 0.1087\n",
      "Epoch 1010/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0228 - mae: 0.1091\n",
      "Epoch 1011/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0227 - mae: 0.1084\n",
      "Epoch 1012/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0226 - mae: 0.1071\n",
      "Epoch 1013/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0248 - mae: 0.1150\n",
      "Epoch 1014/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0232 - mae: 0.1112\n",
      "Epoch 1015/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0228 - mae: 0.1088\n",
      "Epoch 1016/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0224 - mae: 0.1079\n",
      "Epoch 1017/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0220 - mae: 0.1065\n",
      "Epoch 1018/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0228 - mae: 0.1087\n",
      "Epoch 1019/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0227 - mae: 0.1090\n",
      "Epoch 1020/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0221 - mae: 0.1071\n",
      "Epoch 1021/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0250 - mae: 0.1155\n",
      "Epoch 1022/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0259 - mae: 0.1174\n",
      "Epoch 1023/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0242 - mae: 0.1151\n",
      "Epoch 1024/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0225 - mae: 0.1077\n",
      "Epoch 1025/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0252 - mae: 0.1146\n",
      "Epoch 1026/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0235 - mae: 0.1096\n",
      "Epoch 1027/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0235 - mae: 0.1108\n",
      "Epoch 1028/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0223 - mae: 0.1065\n",
      "Epoch 1029/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0237 - mae: 0.1115\n",
      "Epoch 1030/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0227 - mae: 0.1086\n",
      "Epoch 1031/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0243 - mae: 0.1129\n",
      "Epoch 1032/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0227 - mae: 0.1078\n",
      "Epoch 1033/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0220 - mae: 0.1076\n",
      "Epoch 1034/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0221 - mae: 0.1066\n",
      "Epoch 1035/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0225 - mae: 0.1090\n",
      "Epoch 1036/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0214 - mae: 0.1051\n",
      "Epoch 1037/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0335 - mae: 0.1368\n",
      "Epoch 1038/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0300 - mae: 0.1254\n",
      "Epoch 1039/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0246 - mae: 0.1135\n",
      "Epoch 1040/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0262 - mae: 0.1168\n",
      "Epoch 1041/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0236 - mae: 0.1115\n",
      "Epoch 1042/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0236 - mae: 0.1108\n",
      "Epoch 1043/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0239 - mae: 0.1103\n",
      "Epoch 1044/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0241 - mae: 0.1124\n",
      "Epoch 1045/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0231 - mae: 0.1104\n",
      "Epoch 1046/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0221 - mae: 0.1074\n",
      "Epoch 1047/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0219 - mae: 0.1063\n",
      "Epoch 1048/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0228 - mae: 0.1089\n",
      "Epoch 1049/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0303 - mae: 0.1250\n",
      "Epoch 1050/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0238 - mae: 0.1139\n",
      "Epoch 1051/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0228 - mae: 0.1111\n",
      "Epoch 1052/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0225 - mae: 0.1079\n",
      "Epoch 1053/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0238 - mae: 0.1127\n",
      "Epoch 1054/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0233 - mae: 0.1117\n",
      "Epoch 1055/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0218 - mae: 0.1069\n",
      "Epoch 1056/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0224 - mae: 0.1090\n",
      "Epoch 1057/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0216 - mae: 0.1057\n",
      "Epoch 1058/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0290 - mae: 0.1260\n",
      "Epoch 1059/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0247 - mae: 0.1149\n",
      "Epoch 1060/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0256 - mae: 0.1188\n",
      "Epoch 1061/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0235 - mae: 0.1118\n",
      "Epoch 1062/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0236 - mae: 0.1119\n",
      "Epoch 1063/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0226 - mae: 0.1083\n",
      "Epoch 1064/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0259 - mae: 0.1174\n",
      "Epoch 1065/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0236 - mae: 0.1102\n",
      "Epoch 1066/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0222 - mae: 0.1076\n",
      "Epoch 1067/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0225 - mae: 0.1085\n",
      "Epoch 1068/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0218 - mae: 0.1071\n",
      "Epoch 1069/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0241 - mae: 0.1142\n",
      "Epoch 1070/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0230 - mae: 0.1095\n",
      "Epoch 1071/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0241 - mae: 0.1151\n",
      "Epoch 1072/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0223 - mae: 0.1098\n",
      "Epoch 1073/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0214 - mae: 0.1058\n",
      "Epoch 1074/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0211 - mae: 0.1043\n",
      "Epoch 1075/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0225 - mae: 0.1104\n",
      "Epoch 1076/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0231 - mae: 0.1108\n",
      "Epoch 1077/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0236 - mae: 0.1123\n",
      "Epoch 1078/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0218 - mae: 0.1075\n",
      "Epoch 1079/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0215 - mae: 0.1064\n",
      "Epoch 1080/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0211 - mae: 0.1045\n",
      "Epoch 1081/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0218 - mae: 0.1059\n",
      "Epoch 1082/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0225 - mae: 0.1099\n",
      "Epoch 1083/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0209 - mae: 0.1041\n",
      "Epoch 1084/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0242 - mae: 0.1146\n",
      "Epoch 1085/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0223 - mae: 0.1083\n",
      "Epoch 1086/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0232 - mae: 0.1119\n",
      "Epoch 1087/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0218 - mae: 0.1062\n",
      "Epoch 1088/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0213 - mae: 0.1060\n",
      "Epoch 1089/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0233 - mae: 0.1117\n",
      "Epoch 1090/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0214 - mae: 0.1061\n",
      "Epoch 1091/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0232 - mae: 0.1124\n",
      "Epoch 1092/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0222 - mae: 0.1088\n",
      "Epoch 1093/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0219 - mae: 0.1080\n",
      "Epoch 1094/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0218 - mae: 0.1070\n",
      "Epoch 1095/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0220 - mae: 0.1075\n",
      "Epoch 1096/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0224 - mae: 0.1093\n",
      "Epoch 1097/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0222 - mae: 0.1084\n",
      "Epoch 1098/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0225 - mae: 0.1095\n",
      "Epoch 1099/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0232 - mae: 0.1123\n",
      "Epoch 1100/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0217 - mae: 0.1071\n",
      "Epoch 1101/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0229 - mae: 0.1109\n",
      "Epoch 1102/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0216 - mae: 0.1068\n",
      "Epoch 1103/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0215 - mae: 0.1061\n",
      "Epoch 1104/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0213 - mae: 0.1055\n",
      "Epoch 1105/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1074\n",
      "Epoch 1106/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0225 - mae: 0.1101\n",
      "Epoch 1107/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0216 - mae: 0.1071\n",
      "Epoch 1108/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0222 - mae: 0.1089\n",
      "Epoch 1109/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0223 - mae: 0.1092\n",
      "Epoch 1110/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0218 - mae: 0.1086\n",
      "Epoch 1111/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0226 - mae: 0.1105\n",
      "Epoch 1112/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0218 - mae: 0.1080\n",
      "Epoch 1113/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0209 - mae: 0.1039\n",
      "Epoch 1114/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0210 - mae: 0.1047\n",
      "Epoch 1115/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0202 - mae: 0.1016\n",
      "Epoch 1116/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0237 - mae: 0.1126\n",
      "Epoch 1117/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0235 - mae: 0.1133\n",
      "Epoch 1118/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0216 - mae: 0.1072\n",
      "Epoch 1119/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0221 - mae: 0.1088\n",
      "Epoch 1120/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0230 - mae: 0.1122\n",
      "Epoch 1121/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0209 - mae: 0.1045\n",
      "Epoch 1122/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0209 - mae: 0.1049\n",
      "Epoch 1123/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0214 - mae: 0.1067\n",
      "Epoch 1124/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0233 - mae: 0.1134\n",
      "Epoch 1125/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0209 - mae: 0.1048\n",
      "Epoch 1126/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0243 - mae: 0.1143\n",
      "Epoch 1127/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0246 - mae: 0.1163\n",
      "Epoch 1128/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0224 - mae: 0.1090\n",
      "Epoch 1129/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0221 - mae: 0.1078\n",
      "Epoch 1130/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0221 - mae: 0.1084\n",
      "Epoch 1131/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0218 - mae: 0.1075\n",
      "Epoch 1132/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0221 - mae: 0.1088\n",
      "Epoch 1133/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0287 - mae: 0.1232\n",
      "Epoch 1134/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0270 - mae: 0.1220\n",
      "Epoch 1135/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0234 - mae: 0.1113\n",
      "Epoch 1136/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0226 - mae: 0.1101\n",
      "Epoch 1137/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0219 - mae: 0.1082\n",
      "Epoch 1138/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0210 - mae: 0.1053\n",
      "Epoch 1139/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0212 - mae: 0.1050\n",
      "Epoch 1140/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0205 - mae: 0.1036\n",
      "Epoch 1141/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0208 - mae: 0.1048\n",
      "Epoch 1142/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0210 - mae: 0.1044\n",
      "Epoch 1143/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0210 - mae: 0.1050\n",
      "Epoch 1144/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0210 - mae: 0.1055\n",
      "Epoch 1145/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0207 - mae: 0.1045\n",
      "Epoch 1146/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0214 - mae: 0.1063\n",
      "Epoch 1147/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0213 - mae: 0.1059\n",
      "Epoch 1148/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0210 - mae: 0.1050\n",
      "Epoch 1149/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0204 - mae: 0.1029\n",
      "Epoch 1150/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0213 - mae: 0.1051\n",
      "Epoch 1151/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0204 - mae: 0.1031\n",
      "Epoch 1152/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0246 - mae: 0.1160\n",
      "Epoch 1153/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0210 - mae: 0.1055\n",
      "Epoch 1154/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0214 - mae: 0.1066\n",
      "Epoch 1155/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0216 - mae: 0.1075\n",
      "Epoch 1156/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0210 - mae: 0.1048\n",
      "Epoch 1157/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0206 - mae: 0.1039\n",
      "Epoch 1158/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0221 - mae: 0.1082\n",
      "Epoch 1159/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0205 - mae: 0.1036\n",
      "Epoch 1160/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0208 - mae: 0.1040\n",
      "Epoch 1161/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0211 - mae: 0.1047\n",
      "Epoch 1162/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0202 - mae: 0.1024\n",
      "Epoch 1163/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1025\n",
      "Epoch 1164/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0218 - mae: 0.1070\n",
      "Epoch 1165/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1026\n",
      "Epoch 1166/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0214 - mae: 0.1072\n",
      "Epoch 1167/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0220 - mae: 0.1083\n",
      "Epoch 1168/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0215 - mae: 0.1066\n",
      "Epoch 1169/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0215 - mae: 0.1071\n",
      "Epoch 1170/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0203 - mae: 0.1033\n",
      "Epoch 1171/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0212 - mae: 0.1058\n",
      "Epoch 1172/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0198 - mae: 0.1011\n",
      "Epoch 1173/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0949 - mae: 0.2115\n",
      "Epoch 1174/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0501 - mae: 0.1777\n",
      "Epoch 1175/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0827 - mae: 0.2092\n",
      "Epoch 1176/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0629 - mae: 0.2017\n",
      "Epoch 1177/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0498 - mae: 0.1753\n",
      "Epoch 1178/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0434 - mae: 0.1598\n",
      "Epoch 1179/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0397 - mae: 0.1510\n",
      "Epoch 1180/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0377 - mae: 0.1459\n",
      "Epoch 1181/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0368 - mae: 0.1434\n",
      "Epoch 1182/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0365 - mae: 0.1442\n",
      "Epoch 1183/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0342 - mae: 0.1376\n",
      "Epoch 1184/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0525 - mae: 0.1771\n",
      "Epoch 1185/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0504 - mae: 0.1772\n",
      "Epoch 1186/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0433 - mae: 0.1610\n",
      "Epoch 1187/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0392 - mae: 0.1494\n",
      "Epoch 1188/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0371 - mae: 0.1435\n",
      "Epoch 1189/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0355 - mae: 0.1389\n",
      "Epoch 1190/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0344 - mae: 0.1369\n",
      "Epoch 1191/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0338 - mae: 0.1360\n",
      "Epoch 1192/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0320 - mae: 0.1311\n",
      "Epoch 1193/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0322 - mae: 0.1330\n",
      "Epoch 1194/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0306 - mae: 0.1276\n",
      "Epoch 1195/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0305 - mae: 0.1269\n",
      "Epoch 1196/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0297 - mae: 0.1264\n",
      "Epoch 1197/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0288 - mae: 0.1233\n",
      "Epoch 1198/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0290 - mae: 0.1239\n",
      "Epoch 1199/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0279 - mae: 0.1216\n",
      "Epoch 1200/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0310 - mae: 0.1304\n",
      "Epoch 1201/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0334 - mae: 0.1342\n",
      "Epoch 1202/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0282 - mae: 0.1233\n",
      "Epoch 1203/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0269 - mae: 0.1200\n",
      "Epoch 1204/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0261 - mae: 0.1175\n",
      "Epoch 1205/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0276 - mae: 0.1213\n",
      "Epoch 1206/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0267 - mae: 0.1202\n",
      "Epoch 1207/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0270 - mae: 0.1205\n",
      "Epoch 1208/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0258 - mae: 0.1175\n",
      "Epoch 1209/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0266 - mae: 0.1186\n",
      "Epoch 1210/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0294 - mae: 0.1268\n",
      "Epoch 1211/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0265 - mae: 0.1204\n",
      "Epoch 1212/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0267 - mae: 0.1196\n",
      "Epoch 1213/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0264 - mae: 0.1196\n",
      "Epoch 1214/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0251 - mae: 0.1164\n",
      "Epoch 1215/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0254 - mae: 0.1166\n",
      "Epoch 1216/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0249 - mae: 0.1145\n",
      "Epoch 1217/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0259 - mae: 0.1181\n",
      "Epoch 1218/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0260 - mae: 0.1176\n",
      "Epoch 1219/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0268 - mae: 0.1202\n",
      "Epoch 1220/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0253 - mae: 0.1167\n",
      "Epoch 1221/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0267 - mae: 0.1191\n",
      "Epoch 1222/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0272 - mae: 0.1215\n",
      "Epoch 1223/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0260 - mae: 0.1170\n",
      "Epoch 1224/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0247 - mae: 0.1148\n",
      "Epoch 1225/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0257 - mae: 0.1180\n",
      "Epoch 1226/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0245 - mae: 0.1142\n",
      "Epoch 1227/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0245 - mae: 0.1153\n",
      "Epoch 1228/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0239 - mae: 0.1127\n",
      "Epoch 1229/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0285 - mae: 0.1240\n",
      "Epoch 1230/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0242 - mae: 0.1145\n",
      "Epoch 1231/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0274 - mae: 0.1214\n",
      "Epoch 1232/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0239 - mae: 0.1130\n",
      "Epoch 1233/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0234 - mae: 0.1110\n",
      "Epoch 1234/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0252 - mae: 0.1164\n",
      "Epoch 1235/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0245 - mae: 0.1154\n",
      "Epoch 1236/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0244 - mae: 0.1140\n",
      "Epoch 1237/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0228 - mae: 0.1099\n",
      "Epoch 1238/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0232 - mae: 0.1116\n",
      "Epoch 1239/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0234 - mae: 0.1112\n",
      "Epoch 1240/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0230 - mae: 0.1088\n",
      "Epoch 1241/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0264 - mae: 0.1184\n",
      "Epoch 1242/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0251 - mae: 0.1156\n",
      "Epoch 1243/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0241 - mae: 0.1143\n",
      "Epoch 1244/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0252 - mae: 0.1158\n",
      "Epoch 1245/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0298 - mae: 0.1257\n",
      "Epoch 1246/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0270 - mae: 0.1197\n",
      "Epoch 1247/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0243 - mae: 0.1127\n",
      "Epoch 1248/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0244 - mae: 0.1136\n",
      "Epoch 1249/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0240 - mae: 0.1124\n",
      "Epoch 1250/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0226 - mae: 0.1082\n",
      "Epoch 1251/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0243 - mae: 0.1139\n",
      "Epoch 1252/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0253 - mae: 0.1152\n",
      "Epoch 1253/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0269 - mae: 0.1217\n",
      "Epoch 1254/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0327 - mae: 0.1245\n",
      "Epoch 1255/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0278 - mae: 0.1240\n",
      "Epoch 1256/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0244 - mae: 0.1137\n",
      "Epoch 1257/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0245 - mae: 0.1132\n",
      "Epoch 1258/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0233 - mae: 0.1111\n",
      "Epoch 1259/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0230 - mae: 0.1104\n",
      "Epoch 1260/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0227 - mae: 0.1095\n",
      "Epoch 1261/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0227 - mae: 0.1090\n",
      "Epoch 1262/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0225 - mae: 0.1092\n",
      "Epoch 1263/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0232 - mae: 0.1108\n",
      "Epoch 1264/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0255 - mae: 0.1168\n",
      "Epoch 1265/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0221 - mae: 0.1063\n",
      "Epoch 1266/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0241 - mae: 0.1126\n",
      "Epoch 1267/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0240 - mae: 0.1124\n",
      "Epoch 1268/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0237 - mae: 0.1127\n",
      "Epoch 1269/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0256 - mae: 0.1173\n",
      "Epoch 1270/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0238 - mae: 0.1131\n",
      "Epoch 1271/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0263 - mae: 0.1114\n",
      "Epoch 1272/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0541 - mae: 0.1805\n",
      "Epoch 1273/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0422 - mae: 0.1597\n",
      "Epoch 1274/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0366 - mae: 0.1438\n",
      "Epoch 1275/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0339 - mae: 0.1367\n",
      "Epoch 1276/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0327 - mae: 0.1335\n",
      "Epoch 1277/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0322 - mae: 0.1325\n",
      "Epoch 1278/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0315 - mae: 0.1304\n",
      "Epoch 1279/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0295 - mae: 0.1255\n",
      "Epoch 1280/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0297 - mae: 0.1246\n",
      "Epoch 1281/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0278 - mae: 0.1204\n",
      "Epoch 1282/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0276 - mae: 0.1203\n",
      "Epoch 1283/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0265 - mae: 0.1180\n",
      "Epoch 1284/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0268 - mae: 0.1193\n",
      "Epoch 1285/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0268 - mae: 0.1169\n",
      "Epoch 1286/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0268 - mae: 0.1198\n",
      "Epoch 1287/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0252 - mae: 0.1157\n",
      "Epoch 1288/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0252 - mae: 0.1147\n",
      "Epoch 1289/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0259 - mae: 0.1158\n",
      "Epoch 1290/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0247 - mae: 0.1142\n",
      "Epoch 1291/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0250 - mae: 0.1139\n",
      "Epoch 1292/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0243 - mae: 0.1123\n",
      "Epoch 1293/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0242 - mae: 0.1128\n",
      "Epoch 1294/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0239 - mae: 0.1109\n",
      "Epoch 1295/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0240 - mae: 0.1123\n",
      "Epoch 1296/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0255 - mae: 0.1159\n",
      "Epoch 1297/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0242 - mae: 0.1124\n",
      "Epoch 1298/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0238 - mae: 0.1120\n",
      "Epoch 1299/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0239 - mae: 0.1112\n",
      "Epoch 1300/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0241 - mae: 0.1129\n",
      "Epoch 1301/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0234 - mae: 0.1111\n",
      "Epoch 1302/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0230 - mae: 0.1087\n",
      "Epoch 1303/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0245 - mae: 0.1137\n",
      "Epoch 1304/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0229 - mae: 0.1091\n",
      "Epoch 1305/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0234 - mae: 0.1112\n",
      "Epoch 1306/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0235 - mae: 0.1109\n",
      "Epoch 1307/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0235 - mae: 0.1113\n",
      "Epoch 1308/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0219 - mae: 0.1060\n",
      "Epoch 1309/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0220 - mae: 0.1073\n",
      "Epoch 1310/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0217 - mae: 0.1062\n",
      "Epoch 1311/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0224 - mae: 0.1087\n",
      "Epoch 1312/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0232 - mae: 0.1110\n",
      "Epoch 1313/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0220 - mae: 0.1070\n",
      "Epoch 1314/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0224 - mae: 0.1088\n",
      "Epoch 1315/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0208 - mae: 0.1040\n",
      "Epoch 1316/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0219 - mae: 0.1072\n",
      "Epoch 1317/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0210 - mae: 0.1042\n",
      "Epoch 1318/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0241 - mae: 0.1122\n",
      "Epoch 1319/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0231 - mae: 0.1109\n",
      "Epoch 1320/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0221 - mae: 0.1085\n",
      "Epoch 1321/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0211 - mae: 0.1053\n",
      "Epoch 1322/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0206 - mae: 0.1038\n",
      "Epoch 1323/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0210 - mae: 0.1048\n",
      "Epoch 1324/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0210 - mae: 0.1048\n",
      "Epoch 1325/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0217 - mae: 0.1061\n",
      "Epoch 1326/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0216 - mae: 0.1066\n",
      "Epoch 1327/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0212 - mae: 0.1052\n",
      "Epoch 1328/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0212 - mae: 0.1052\n",
      "Epoch 1329/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0221 - mae: 0.1079\n",
      "Epoch 1330/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0208 - mae: 0.1034\n",
      "Epoch 1331/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0204 - mae: 0.1029\n",
      "Epoch 1332/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1014\n",
      "Epoch 1333/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0221 - mae: 0.1076\n",
      "Epoch 1334/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0236 - mae: 0.1129\n",
      "Epoch 1335/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0290 - mae: 0.1252\n",
      "Epoch 1336/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0228 - mae: 0.1105\n",
      "Epoch 1337/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0222 - mae: 0.1079\n",
      "Epoch 1338/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0204 - mae: 0.1026\n",
      "Epoch 1339/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0214 - mae: 0.1068\n",
      "Epoch 1340/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0222 - mae: 0.1090\n",
      "Epoch 1341/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0206 - mae: 0.1028\n",
      "Epoch 1342/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1027\n",
      "Epoch 1343/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0215 - mae: 0.1061\n",
      "Epoch 1344/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0202 - mae: 0.1023\n",
      "Epoch 1345/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0238 - mae: 0.1130\n",
      "Epoch 1346/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0204 - mae: 0.1037\n",
      "Epoch 1347/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0210 - mae: 0.1043\n",
      "Epoch 1348/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0209 - mae: 0.1053\n",
      "Epoch 1349/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0203 - mae: 0.1026\n",
      "Epoch 1350/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0206 - mae: 0.1045\n",
      "Epoch 1351/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0200 - mae: 0.1018\n",
      "Epoch 1352/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0204 - mae: 0.1019\n",
      "Epoch 1353/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0249 - mae: 0.1167\n",
      "Epoch 1354/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1034\n",
      "Epoch 1355/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1017\n",
      "Epoch 1356/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0292 - mae: 0.1264\n",
      "Epoch 1357/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0275 - mae: 0.1222\n",
      "Epoch 1358/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0328 - mae: 0.1331\n",
      "Epoch 1359/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0282 - mae: 0.1216\n",
      "Epoch 1360/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0255 - mae: 0.1156\n",
      "Epoch 1361/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0251 - mae: 0.1149\n",
      "Epoch 1362/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0243 - mae: 0.1138\n",
      "Epoch 1363/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0228 - mae: 0.1082\n",
      "Epoch 1364/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0232 - mae: 0.1109\n",
      "Epoch 1365/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0214 - mae: 0.1051\n",
      "Epoch 1366/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0219 - mae: 0.1064\n",
      "Epoch 1367/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0211 - mae: 0.1048\n",
      "Epoch 1368/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0212 - mae: 0.1043\n",
      "Epoch 1369/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0207 - mae: 0.1035\n",
      "Epoch 1370/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0218 - mae: 0.1065\n",
      "Epoch 1371/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0208 - mae: 0.1038\n",
      "Epoch 1372/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0227 - mae: 0.1102\n",
      "Epoch 1373/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0207 - mae: 0.1029\n",
      "Epoch 1374/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0203 - mae: 0.1028\n",
      "Epoch 1375/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0204 - mae: 0.1025\n",
      "Epoch 1376/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0206 - mae: 0.1040\n",
      "Epoch 1377/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0211 - mae: 0.1051\n",
      "Epoch 1378/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1025\n",
      "Epoch 1379/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0198 - mae: 0.1020\n",
      "Epoch 1380/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0197 - mae: 0.1009\n",
      "Epoch 1381/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0217 - mae: 0.1064\n",
      "Epoch 1382/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0272 - mae: 0.1197\n",
      "Epoch 1383/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0222 - mae: 0.1083\n",
      "Epoch 1384/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0217 - mae: 0.1077\n",
      "Epoch 1385/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0210 - mae: 0.1041\n",
      "Epoch 1386/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0200 - mae: 0.1020\n",
      "Epoch 1387/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0217 - mae: 0.1073\n",
      "Epoch 1388/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0203 - mae: 0.1035\n",
      "Epoch 1389/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0217 - mae: 0.1075\n",
      "Epoch 1390/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0238 - mae: 0.1118\n",
      "Epoch 1391/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0204 - mae: 0.1030\n",
      "Epoch 1392/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0218 - mae: 0.1071\n",
      "Epoch 1393/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0198 - mae: 0.1013\n",
      "Epoch 1394/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1013\n",
      "Epoch 1395/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0227 - mae: 0.1099\n",
      "Epoch 1396/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0210 - mae: 0.1049\n",
      "Epoch 1397/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0214 - mae: 0.1062\n",
      "Epoch 1398/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0208 - mae: 0.1046\n",
      "Epoch 1399/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0204 - mae: 0.1036\n",
      "Epoch 1400/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0202 - mae: 0.1027\n",
      "Epoch 1401/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0206 - mae: 0.1037\n",
      "Epoch 1402/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1025\n",
      "Epoch 1403/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0205 - mae: 0.1030\n",
      "Epoch 1404/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0210 - mae: 0.1050\n",
      "Epoch 1405/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1029\n",
      "Epoch 1406/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0204 - mae: 0.1036\n",
      "Epoch 1407/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1023\n",
      "Epoch 1408/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0214 - mae: 0.1077\n",
      "Epoch 1409/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0196 - mae: 0.1014\n",
      "Epoch 1410/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0193 - mae: 0.0995\n",
      "Epoch 1411/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0198 - mae: 0.1028\n",
      "Epoch 1412/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.1003\n",
      "Epoch 1413/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0194 - mae: 0.1004\n",
      "Epoch 1414/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0203 - mae: 0.1042\n",
      "Epoch 1415/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0201 - mae: 0.1023\n",
      "Epoch 1416/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0198 - mae: 0.1020\n",
      "Epoch 1417/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0193 - mae: 0.1004\n",
      "Epoch 1418/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0193 - mae: 0.1006\n",
      "Epoch 1419/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1020\n",
      "Epoch 1420/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0241 - mae: 0.1087\n",
      "Epoch 1421/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0255 - mae: 0.1164\n",
      "Epoch 1422/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0280 - mae: 0.1221\n",
      "Epoch 1423/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0241 - mae: 0.1135\n",
      "Epoch 1424/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0230 - mae: 0.1108\n",
      "Epoch 1425/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0215 - mae: 0.1073\n",
      "Epoch 1426/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0230 - mae: 0.1118\n",
      "Epoch 1427/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0220 - mae: 0.1080\n",
      "Epoch 1428/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0213 - mae: 0.1059\n",
      "Epoch 1429/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0213 - mae: 0.1061\n",
      "Epoch 1430/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0247 - mae: 0.1119\n",
      "Epoch 1431/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0253 - mae: 0.1145\n",
      "Epoch 1432/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0218 - mae: 0.1071\n",
      "Epoch 1433/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0216 - mae: 0.1063\n",
      "Epoch 1434/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0207 - mae: 0.1055\n",
      "Epoch 1435/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0212 - mae: 0.1067\n",
      "Epoch 1436/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0204 - mae: 0.1035\n",
      "Epoch 1437/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1030\n",
      "Epoch 1438/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0205 - mae: 0.1038\n",
      "Epoch 1439/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0208 - mae: 0.1041\n",
      "Epoch 1440/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0196 - mae: 0.1004\n",
      "Epoch 1441/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0197 - mae: 0.1020\n",
      "Epoch 1442/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0213 - mae: 0.1055\n",
      "Epoch 1443/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0207 - mae: 0.1047\n",
      "Epoch 1444/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0204 - mae: 0.1034\n",
      "Epoch 1445/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0219 - mae: 0.1079\n",
      "Epoch 1446/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0202 - mae: 0.1023\n",
      "Epoch 1447/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0300 - mae: 0.1252\n",
      "Epoch 1448/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0497 - mae: 0.1367\n",
      "Epoch 1449/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0611 - mae: 0.1846\n",
      "Epoch 1450/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0452 - mae: 0.1614\n",
      "Epoch 1451/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0335 - mae: 0.1357\n",
      "Epoch 1452/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0405 - mae: 0.1435\n",
      "Epoch 1453/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0310 - mae: 0.1298\n",
      "Epoch 1454/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0295 - mae: 0.1265\n",
      "Epoch 1455/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0282 - mae: 0.1233\n",
      "Epoch 1456/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0270 - mae: 0.1188\n",
      "Epoch 1457/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0275 - mae: 0.1206\n",
      "Epoch 1458/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0259 - mae: 0.1164\n",
      "Epoch 1459/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0256 - mae: 0.1154\n",
      "Epoch 1460/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0261 - mae: 0.1171\n",
      "Epoch 1461/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0348 - mae: 0.1371\n",
      "Epoch 1462/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0283 - mae: 0.1222\n",
      "Epoch 1463/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0272 - mae: 0.1200\n",
      "Epoch 1464/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0260 - mae: 0.1164\n",
      "Epoch 1465/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0251 - mae: 0.1154\n",
      "Epoch 1466/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0259 - mae: 0.1173\n",
      "Epoch 1467/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0244 - mae: 0.1139\n",
      "Epoch 1468/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0240 - mae: 0.1127\n",
      "Epoch 1469/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0250 - mae: 0.1151\n",
      "Epoch 1470/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0236 - mae: 0.1112\n",
      "Epoch 1471/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0236 - mae: 0.1112\n",
      "Epoch 1472/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0234 - mae: 0.1108\n",
      "Epoch 1473/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0244 - mae: 0.1132\n",
      "Epoch 1474/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0239 - mae: 0.1123\n",
      "Epoch 1475/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0241 - mae: 0.1113\n",
      "Epoch 1476/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0233 - mae: 0.1106\n",
      "Epoch 1477/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0228 - mae: 0.1086\n",
      "Epoch 1478/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0272 - mae: 0.1187\n",
      "Epoch 1479/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0235 - mae: 0.1114\n",
      "Epoch 1480/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0233 - mae: 0.1105\n",
      "Epoch 1481/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0324 - mae: 0.1274\n",
      "Epoch 1482/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0365 - mae: 0.1452\n",
      "Epoch 1483/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0315 - mae: 0.1315\n",
      "Epoch 1484/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0297 - mae: 0.1270\n",
      "Epoch 1485/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0289 - mae: 0.1244\n",
      "Epoch 1486/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0283 - mae: 0.1233\n",
      "Epoch 1487/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0266 - mae: 0.1190\n",
      "Epoch 1488/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0261 - mae: 0.1169\n",
      "Epoch 1489/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0258 - mae: 0.1164\n",
      "Epoch 1490/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0258 - mae: 0.1169\n",
      "Epoch 1491/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0250 - mae: 0.1143\n",
      "Epoch 1492/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0267 - mae: 0.1193\n",
      "Epoch 1493/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0265 - mae: 0.1190\n",
      "Epoch 1494/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0239 - mae: 0.1117\n",
      "Epoch 1495/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0234 - mae: 0.1106\n",
      "Epoch 1496/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0235 - mae: 0.1115\n",
      "Epoch 1497/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0235 - mae: 0.1112\n",
      "Epoch 1498/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0235 - mae: 0.1118\n",
      "Epoch 1499/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0232 - mae: 0.1104\n",
      "Epoch 1500/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0230 - mae: 0.1096\n",
      "Epoch 1501/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0227 - mae: 0.1092\n",
      "Epoch 1502/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0229 - mae: 0.1095\n",
      "Epoch 1503/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0249 - mae: 0.1161\n",
      "Epoch 1504/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0222 - mae: 0.1079\n",
      "Epoch 1505/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0222 - mae: 0.1066\n",
      "Epoch 1506/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0240 - mae: 0.1128\n",
      "Epoch 1507/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0218 - mae: 0.1060\n",
      "Epoch 1508/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0222 - mae: 0.1086\n",
      "Epoch 1509/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0211 - mae: 0.1044\n",
      "Epoch 1510/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0219 - mae: 0.1068\n",
      "Epoch 1511/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0210 - mae: 0.1045\n",
      "Epoch 1512/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0209 - mae: 0.1033\n",
      "Epoch 1513/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0207 - mae: 0.1036\n",
      "Epoch 1514/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0206 - mae: 0.1034\n",
      "Epoch 1515/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0212 - mae: 0.1048\n",
      "Epoch 1516/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0212 - mae: 0.1050\n",
      "Epoch 1517/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0207 - mae: 0.1037\n",
      "Epoch 1518/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0206 - mae: 0.1033\n",
      "Epoch 1519/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0221 - mae: 0.1086\n",
      "Epoch 1520/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0214 - mae: 0.1056\n",
      "Epoch 1521/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0220 - mae: 0.1087\n",
      "Epoch 1522/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0212 - mae: 0.1062\n",
      "Epoch 1523/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0216 - mae: 0.1060\n",
      "Epoch 1524/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0220 - mae: 0.1078\n",
      "Epoch 1525/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1025\n",
      "Epoch 1526/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0203 - mae: 0.1026\n",
      "Epoch 1527/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0211 - mae: 0.1058\n",
      "Epoch 1528/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0205 - mae: 0.1032\n",
      "Epoch 1529/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0209 - mae: 0.1039\n",
      "Epoch 1530/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0208 - mae: 0.1047\n",
      "Epoch 1531/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0207 - mae: 0.1046\n",
      "Epoch 1532/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0208 - mae: 0.1046\n",
      "Epoch 1533/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0207 - mae: 0.1036\n",
      "Epoch 1534/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0213 - mae: 0.1057\n",
      "Epoch 1535/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0207 - mae: 0.1044\n",
      "Epoch 1536/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0209 - mae: 0.1051\n",
      "Epoch 1537/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0208 - mae: 0.1039\n",
      "Epoch 1538/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0207 - mae: 0.1040\n",
      "Epoch 1539/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0206 - mae: 0.1041\n",
      "Epoch 1540/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0207 - mae: 0.1045\n",
      "Epoch 1541/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0206 - mae: 0.1034\n",
      "Epoch 1542/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0200 - mae: 0.1029\n",
      "Epoch 1543/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1032\n",
      "Epoch 1544/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0199 - mae: 0.1019\n",
      "Epoch 1545/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0194 - mae: 0.1005\n",
      "Epoch 1546/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0217 - mae: 0.1082\n",
      "Epoch 1547/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0204 - mae: 0.1037\n",
      "Epoch 1548/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0212 - mae: 0.1060\n",
      "Epoch 1549/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0528 - mae: 0.1321\n",
      "Epoch 1550/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0261 - mae: 0.1179\n",
      "Epoch 1551/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0234 - mae: 0.1103\n",
      "Epoch 1552/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0219 - mae: 0.1074\n",
      "Epoch 1553/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0217 - mae: 0.1070\n",
      "Epoch 1554/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0220 - mae: 0.1070\n",
      "Epoch 1555/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0218 - mae: 0.1070\n",
      "Epoch 1556/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0214 - mae: 0.1072\n",
      "Epoch 1557/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0207 - mae: 0.1049\n",
      "Epoch 1558/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0207 - mae: 0.1048\n",
      "Epoch 1559/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0222 - mae: 0.1088\n",
      "Epoch 1560/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0209 - mae: 0.1044\n",
      "Epoch 1561/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0204 - mae: 0.1029\n",
      "Epoch 1562/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0205 - mae: 0.1040\n",
      "Epoch 1563/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0213 - mae: 0.1064\n",
      "Epoch 1564/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0203 - mae: 0.1029\n",
      "Epoch 1565/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0200 - mae: 0.1023\n",
      "Epoch 1566/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0210 - mae: 0.1046\n",
      "Epoch 1567/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0207 - mae: 0.1053\n",
      "Epoch 1568/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0205 - mae: 0.1043\n",
      "Epoch 1569/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0211 - mae: 0.1052\n",
      "Epoch 1570/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0208 - mae: 0.1051\n",
      "Epoch 1571/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0203 - mae: 0.1040\n",
      "Epoch 1572/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0215 - mae: 0.1074\n",
      "Epoch 1573/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0218 - mae: 0.1085\n",
      "Epoch 1574/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0201 - mae: 0.1032\n",
      "Epoch 1575/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0203 - mae: 0.1035\n",
      "Epoch 1576/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0214 - mae: 0.1071\n",
      "Epoch 1577/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0203 - mae: 0.1026\n",
      "Epoch 1578/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0213 - mae: 0.1058\n",
      "Epoch 1579/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0226 - mae: 0.1095\n",
      "Epoch 1580/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0211 - mae: 0.1050\n",
      "Epoch 1581/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0199 - mae: 0.1022\n",
      "Epoch 1582/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0208 - mae: 0.1050\n",
      "Epoch 1583/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0217 - mae: 0.1077\n",
      "Epoch 1584/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0200 - mae: 0.1033\n",
      "Epoch 1585/2000\n",
      "2019/2019 [==============================] - 0s 77us/sample - loss: 0.0201 - mae: 0.1036\n",
      "Epoch 1586/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0201 - mae: 0.1027\n",
      "Epoch 1587/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0235 - mae: 0.1114\n",
      "Epoch 1588/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0217 - mae: 0.1069\n",
      "Epoch 1589/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0201 - mae: 0.1035\n",
      "Epoch 1590/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0199 - mae: 0.1017\n",
      "Epoch 1591/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0224 - mae: 0.1104\n",
      "Epoch 1592/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0204 - mae: 0.1042\n",
      "Epoch 1593/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0220 - mae: 0.1079\n",
      "Epoch 1594/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0216 - mae: 0.1069\n",
      "Epoch 1595/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0242 - mae: 0.1133\n",
      "Epoch 1596/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0210 - mae: 0.1047\n",
      "Epoch 1597/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0216 - mae: 0.1062\n",
      "Epoch 1598/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0220 - mae: 0.1089\n",
      "Epoch 1599/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0235 - mae: 0.1113\n",
      "Epoch 1600/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0217 - mae: 0.1063\n",
      "Epoch 1601/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0282 - mae: 0.1220\n",
      "Epoch 1602/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0237 - mae: 0.1111\n",
      "Epoch 1603/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0211 - mae: 0.1065\n",
      "Epoch 1604/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1021\n",
      "Epoch 1605/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0213 - mae: 0.1057\n",
      "Epoch 1606/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0201 - mae: 0.1024\n",
      "Epoch 1607/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0203 - mae: 0.1036\n",
      "Epoch 1608/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0212 - mae: 0.1048\n",
      "Epoch 1609/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0200 - mae: 0.1021\n",
      "Epoch 1610/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1002\n",
      "Epoch 1611/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0204 - mae: 0.1038\n",
      "Epoch 1612/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0211 - mae: 0.1046\n",
      "Epoch 1613/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0202 - mae: 0.1031\n",
      "Epoch 1614/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0206 - mae: 0.1045\n",
      "Epoch 1615/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0209 - mae: 0.1056\n",
      "Epoch 1616/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0199 - mae: 0.1017\n",
      "Epoch 1617/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0196 - mae: 0.1011\n",
      "Epoch 1618/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0210 - mae: 0.1048\n",
      "Epoch 1619/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0223 - mae: 0.1090\n",
      "Epoch 1620/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0206 - mae: 0.1044\n",
      "Epoch 1621/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0234 - mae: 0.1111\n",
      "Epoch 1622/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0228 - mae: 0.1104\n",
      "Epoch 1623/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0201 - mae: 0.1034\n",
      "Epoch 1624/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0203 - mae: 0.1028\n",
      "Epoch 1625/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0260 - mae: 0.1081\n",
      "Epoch 1626/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0287 - mae: 0.1235\n",
      "Epoch 1627/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0238 - mae: 0.1128\n",
      "Epoch 1628/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0233 - mae: 0.1128\n",
      "Epoch 1629/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0258 - mae: 0.1171\n",
      "Epoch 1630/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0225 - mae: 0.1092\n",
      "Epoch 1631/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0228 - mae: 0.1109\n",
      "Epoch 1632/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0385 - mae: 0.1125\n",
      "Epoch 1633/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0654 - mae: 0.1881\n",
      "Epoch 1634/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0318 - mae: 0.1348\n",
      "Epoch 1635/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0290 - mae: 0.1255\n",
      "Epoch 1636/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0246 - mae: 0.1146\n",
      "Epoch 1637/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0259 - mae: 0.1177\n",
      "Epoch 1638/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0245 - mae: 0.1149\n",
      "Epoch 1639/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0265 - mae: 0.1178\n",
      "Epoch 1640/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0252 - mae: 0.1150\n",
      "Epoch 1641/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0254 - mae: 0.1173\n",
      "Epoch 1642/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0247 - mae: 0.1148\n",
      "Epoch 1643/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0240 - mae: 0.1145\n",
      "Epoch 1644/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0236 - mae: 0.1116\n",
      "Epoch 1645/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0228 - mae: 0.1100\n",
      "Epoch 1646/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0229 - mae: 0.1102\n",
      "Epoch 1647/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0222 - mae: 0.1088\n",
      "Epoch 1648/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0221 - mae: 0.1096\n",
      "Epoch 1649/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0223 - mae: 0.1093\n",
      "Epoch 1650/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0222 - mae: 0.1089\n",
      "Epoch 1651/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0232 - mae: 0.1106\n",
      "Epoch 1652/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0224 - mae: 0.1086\n",
      "Epoch 1653/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0241 - mae: 0.1131\n",
      "Epoch 1654/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0232 - mae: 0.1112\n",
      "Epoch 1655/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0224 - mae: 0.1097\n",
      "Epoch 1656/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0225 - mae: 0.1090\n",
      "Epoch 1657/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0214 - mae: 0.1068\n",
      "Epoch 1658/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0210 - mae: 0.1060\n",
      "Epoch 1659/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0222 - mae: 0.1086\n",
      "Epoch 1660/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0211 - mae: 0.1068\n",
      "Epoch 1661/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0216 - mae: 0.1066\n",
      "Epoch 1662/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0227 - mae: 0.1089\n",
      "Epoch 1663/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0227 - mae: 0.1107\n",
      "Epoch 1664/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0219 - mae: 0.1089\n",
      "Epoch 1665/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0287 - mae: 0.1248\n",
      "Epoch 1666/2000\n",
      "2019/2019 [==============================] - 0s 85us/sample - loss: 0.0242 - mae: 0.1136\n",
      "Epoch 1667/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0225 - mae: 0.1091\n",
      "Epoch 1668/2000\n",
      "2019/2019 [==============================] - 0s 79us/sample - loss: 0.0216 - mae: 0.1065\n",
      "Epoch 1669/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0220 - mae: 0.1081\n",
      "Epoch 1670/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0253 - mae: 0.1163\n",
      "Epoch 1671/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0214 - mae: 0.1065\n",
      "Epoch 1672/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0219 - mae: 0.1077\n",
      "Epoch 1673/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0226 - mae: 0.1102\n",
      "Epoch 1674/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0276 - mae: 0.1227\n",
      "Epoch 1675/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0225 - mae: 0.1102\n",
      "Epoch 1676/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0223 - mae: 0.1086\n",
      "Epoch 1677/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0215 - mae: 0.1079\n",
      "Epoch 1678/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0211 - mae: 0.1063\n",
      "Epoch 1679/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0220 - mae: 0.1090\n",
      "Epoch 1680/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0212 - mae: 0.1055\n",
      "Epoch 1681/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0234 - mae: 0.1114\n",
      "Epoch 1682/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0221 - mae: 0.1087\n",
      "Epoch 1683/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0210 - mae: 0.1061\n",
      "Epoch 1684/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0212 - mae: 0.1058\n",
      "Epoch 1685/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0211 - mae: 0.1057\n",
      "Epoch 1686/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0210 - mae: 0.1060\n",
      "Epoch 1687/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1035\n",
      "Epoch 1688/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0214 - mae: 0.1080\n",
      "Epoch 1689/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0205 - mae: 0.1040\n",
      "Epoch 1690/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0203 - mae: 0.1037\n",
      "Epoch 1691/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0208 - mae: 0.1052\n",
      "Epoch 1692/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0210 - mae: 0.1052\n",
      "Epoch 1693/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0211 - mae: 0.1059\n",
      "Epoch 1694/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0199 - mae: 0.1017\n",
      "Epoch 1695/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0207 - mae: 0.1047\n",
      "Epoch 1696/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0216 - mae: 0.1076\n",
      "Epoch 1697/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0201 - mae: 0.1023\n",
      "Epoch 1698/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0215 - mae: 0.1063\n",
      "Epoch 1699/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0207 - mae: 0.1041\n",
      "Epoch 1700/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0199 - mae: 0.1033\n",
      "Epoch 1701/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0199 - mae: 0.1012\n",
      "Epoch 1702/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0208 - mae: 0.1054\n",
      "Epoch 1703/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0206 - mae: 0.1033\n",
      "Epoch 1704/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0203 - mae: 0.1037\n",
      "Epoch 1705/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0208 - mae: 0.1046\n",
      "Epoch 1706/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0214 - mae: 0.1061\n",
      "Epoch 1707/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0206 - mae: 0.1042\n",
      "Epoch 1708/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0205 - mae: 0.1042\n",
      "Epoch 1709/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0210 - mae: 0.1047\n",
      "Epoch 1710/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0211 - mae: 0.1051\n",
      "Epoch 1711/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0212 - mae: 0.1068\n",
      "Epoch 1712/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0214 - mae: 0.1066\n",
      "Epoch 1713/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0219 - mae: 0.1089\n",
      "Epoch 1714/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0336 - mae: 0.1379\n",
      "Epoch 1715/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0242 - mae: 0.1151\n",
      "Epoch 1716/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0237 - mae: 0.1125\n",
      "Epoch 1717/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0228 - mae: 0.1116\n",
      "Epoch 1718/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0227 - mae: 0.1107\n",
      "Epoch 1719/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0212 - mae: 0.1057\n",
      "Epoch 1720/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0213 - mae: 0.1067\n",
      "Epoch 1721/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0207 - mae: 0.1047\n",
      "Epoch 1722/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0206 - mae: 0.1042\n",
      "Epoch 1723/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1030\n",
      "Epoch 1724/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0217 - mae: 0.1059\n",
      "Epoch 1725/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0218 - mae: 0.1087\n",
      "Epoch 1726/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0206 - mae: 0.1050\n",
      "Epoch 1727/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0205 - mae: 0.1038\n",
      "Epoch 1728/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0207 - mae: 0.1051\n",
      "Epoch 1729/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0202 - mae: 0.1027\n",
      "Epoch 1730/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0203 - mae: 0.1034\n",
      "Epoch 1731/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0206 - mae: 0.1045\n",
      "Epoch 1732/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0212 - mae: 0.1050\n",
      "Epoch 1733/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1032\n",
      "Epoch 1734/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0202 - mae: 0.1033\n",
      "Epoch 1735/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0202 - mae: 0.1030\n",
      "Epoch 1736/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0233 - mae: 0.1121\n",
      "Epoch 1737/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0210 - mae: 0.1046\n",
      "Epoch 1738/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0205 - mae: 0.1032\n",
      "Epoch 1739/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0208 - mae: 0.1047\n",
      "Epoch 1740/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0198 - mae: 0.1018\n",
      "Epoch 1741/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0222 - mae: 0.1076\n",
      "Epoch 1742/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0219 - mae: 0.1080\n",
      "Epoch 1743/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0208 - mae: 0.1042\n",
      "Epoch 1744/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0213 - mae: 0.1062\n",
      "Epoch 1745/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1017\n",
      "Epoch 1746/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0222 - mae: 0.1081\n",
      "Epoch 1747/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0212 - mae: 0.1060\n",
      "Epoch 1748/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0199 - mae: 0.1023\n",
      "Epoch 1749/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0196 - mae: 0.1018\n",
      "Epoch 1750/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1026\n",
      "Epoch 1751/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0198 - mae: 0.1016\n",
      "Epoch 1752/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0228 - mae: 0.1103\n",
      "Epoch 1753/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0206 - mae: 0.1039\n",
      "Epoch 1754/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0211 - mae: 0.1060\n",
      "Epoch 1755/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0205 - mae: 0.1037\n",
      "Epoch 1756/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0198 - mae: 0.1019\n",
      "Epoch 1757/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0325 - mae: 0.1363\n",
      "Epoch 1758/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0261 - mae: 0.1214\n",
      "Epoch 1759/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0218 - mae: 0.1078\n",
      "Epoch 1760/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0206 - mae: 0.1051\n",
      "Epoch 1761/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0206 - mae: 0.1044\n",
      "Epoch 1762/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0201 - mae: 0.1025\n",
      "Epoch 1763/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0202 - mae: 0.1027\n",
      "Epoch 1764/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0203 - mae: 0.1031\n",
      "Epoch 1765/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0235 - mae: 0.1115\n",
      "Epoch 1766/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0205 - mae: 0.1027\n",
      "Epoch 1767/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0198 - mae: 0.1016\n",
      "Epoch 1768/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0215 - mae: 0.1068\n",
      "Epoch 1769/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0202 - mae: 0.1038\n",
      "Epoch 1770/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1033\n",
      "Epoch 1771/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1042\n",
      "Epoch 1772/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0197 - mae: 0.1018\n",
      "Epoch 1773/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0195 - mae: 0.1009\n",
      "Epoch 1774/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0204 - mae: 0.1037\n",
      "Epoch 1775/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0194 - mae: 0.1004\n",
      "Epoch 1776/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0196 - mae: 0.1014\n",
      "Epoch 1777/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0204 - mae: 0.1034\n",
      "Epoch 1778/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0202 - mae: 0.1028\n",
      "Epoch 1779/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0232 - mae: 0.1141\n",
      "Epoch 1780/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0213 - mae: 0.1068\n",
      "Epoch 1781/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0196 - mae: 0.1023\n",
      "Epoch 1782/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.1009\n",
      "Epoch 1783/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0201 - mae: 0.1033\n",
      "Epoch 1784/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0245 - mae: 0.1119\n",
      "Epoch 1785/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0234 - mae: 0.1131\n",
      "Epoch 1786/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0329 - mae: 0.1149\n",
      "Epoch 1787/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0271 - mae: 0.1217\n",
      "Epoch 1788/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0226 - mae: 0.1084\n",
      "Epoch 1789/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0293 - mae: 0.1232\n",
      "Epoch 1790/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0298 - mae: 0.1286\n",
      "Epoch 1791/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0261 - mae: 0.1203\n",
      "Epoch 1792/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0250 - mae: 0.1171\n",
      "Epoch 1793/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0215 - mae: 0.1075\n",
      "Epoch 1794/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0208 - mae: 0.1052\n",
      "Epoch 1795/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0209 - mae: 0.1052\n",
      "Epoch 1796/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0203 - mae: 0.1034\n",
      "Epoch 1797/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0210 - mae: 0.1057\n",
      "Epoch 1798/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0208 - mae: 0.1042\n",
      "Epoch 1799/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0201 - mae: 0.1028\n",
      "Epoch 1800/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0198 - mae: 0.1013\n",
      "Epoch 1801/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0198 - mae: 0.1023\n",
      "Epoch 1802/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0209 - mae: 0.1045\n",
      "Epoch 1803/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0201 - mae: 0.1030\n",
      "Epoch 1804/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0206 - mae: 0.1045\n",
      "Epoch 1805/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0200 - mae: 0.1026\n",
      "Epoch 1806/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0205 - mae: 0.1035\n",
      "Epoch 1807/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0215 - mae: 0.1071\n",
      "Epoch 1808/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0194 - mae: 0.1009\n",
      "Epoch 1809/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0196 - mae: 0.1007\n",
      "Epoch 1810/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0199 - mae: 0.1026\n",
      "Epoch 1811/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0202 - mae: 0.1047\n",
      "Epoch 1812/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0198 - mae: 0.1021\n",
      "Epoch 1813/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0197 - mae: 0.1010\n",
      "Epoch 1814/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0191 - mae: 0.0994\n",
      "Epoch 1815/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1029\n",
      "Epoch 1816/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.1014\n",
      "Epoch 1817/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0199 - mae: 0.1019\n",
      "Epoch 1818/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0247 - mae: 0.1158\n",
      "Epoch 1819/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0228 - mae: 0.1088\n",
      "Epoch 1820/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1092\n",
      "Epoch 1821/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0220 - mae: 0.1082\n",
      "Epoch 1822/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0207 - mae: 0.1040\n",
      "Epoch 1823/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0242 - mae: 0.1137\n",
      "Epoch 1824/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0201 - mae: 0.1024\n",
      "Epoch 1825/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1011\n",
      "Epoch 1826/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0199 - mae: 0.1031\n",
      "Epoch 1827/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0195 - mae: 0.1008\n",
      "Epoch 1828/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0195 - mae: 0.1011\n",
      "Epoch 1829/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1006\n",
      "Epoch 1830/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0196 - mae: 0.1021\n",
      "Epoch 1831/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0245 - mae: 0.1143\n",
      "Epoch 1832/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0202 - mae: 0.1023\n",
      "Epoch 1833/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0202 - mae: 0.1034\n",
      "Epoch 1834/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0199 - mae: 0.1029\n",
      "Epoch 1835/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0193 - mae: 0.1005\n",
      "Epoch 1836/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1002\n",
      "Epoch 1837/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0197 - mae: 0.1029\n",
      "Epoch 1838/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1044\n",
      "Epoch 1839/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0229 - mae: 0.1084\n",
      "Epoch 1840/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0242 - mae: 0.1144\n",
      "Epoch 1841/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0214 - mae: 0.1058\n",
      "Epoch 1842/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0421 - mae: 0.1323\n",
      "Epoch 1843/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0269 - mae: 0.1190\n",
      "Epoch 1844/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0222 - mae: 0.1089\n",
      "Epoch 1845/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0213 - mae: 0.1068\n",
      "Epoch 1846/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0212 - mae: 0.1067\n",
      "Epoch 1847/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1029\n",
      "Epoch 1848/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0216 - mae: 0.1072\n",
      "Epoch 1849/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0221 - mae: 0.1089\n",
      "Epoch 1850/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0212 - mae: 0.1071\n",
      "Epoch 1851/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0199 - mae: 0.1021\n",
      "Epoch 1852/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0214 - mae: 0.1054\n",
      "Epoch 1853/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0211 - mae: 0.1067\n",
      "Epoch 1854/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0214 - mae: 0.1072\n",
      "Epoch 1855/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0221 - mae: 0.1084\n",
      "Epoch 1856/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0204 - mae: 0.1040\n",
      "Epoch 1857/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0201 - mae: 0.1034\n",
      "Epoch 1858/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0216 - mae: 0.1079\n",
      "Epoch 1859/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0203 - mae: 0.1039\n",
      "Epoch 1860/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1031\n",
      "Epoch 1861/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0207 - mae: 0.1047\n",
      "Epoch 1862/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0213 - mae: 0.1065\n",
      "Epoch 1863/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0226 - mae: 0.1100\n",
      "Epoch 1864/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0208 - mae: 0.1053\n",
      "Epoch 1865/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0203 - mae: 0.1045\n",
      "Epoch 1866/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0199 - mae: 0.1034\n",
      "Epoch 1867/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0211 - mae: 0.1062\n",
      "Epoch 1868/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0212 - mae: 0.1063\n",
      "Epoch 1869/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0221 - mae: 0.1096\n",
      "Epoch 1870/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0211 - mae: 0.1049\n",
      "Epoch 1871/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0204 - mae: 0.1041\n",
      "Epoch 1872/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0219 - mae: 0.1086\n",
      "Epoch 1873/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0218 - mae: 0.1072\n",
      "Epoch 1874/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0214 - mae: 0.1073\n",
      "Epoch 1875/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0200 - mae: 0.1037\n",
      "Epoch 1876/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1030\n",
      "Epoch 1877/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0194 - mae: 0.1008\n",
      "Epoch 1878/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0204 - mae: 0.1039\n",
      "Epoch 1879/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1024\n",
      "Epoch 1880/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0201 - mae: 0.1028\n",
      "Epoch 1881/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0203 - mae: 0.1036\n",
      "Epoch 1882/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0208 - mae: 0.1043\n",
      "Epoch 1883/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0274 - mae: 0.1216\n",
      "Epoch 1884/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0270 - mae: 0.1226\n",
      "Epoch 1885/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0224 - mae: 0.1108\n",
      "Epoch 1886/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0210 - mae: 0.1062\n",
      "Epoch 1887/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0205 - mae: 0.1049\n",
      "Epoch 1888/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0208 - mae: 0.1053\n",
      "Epoch 1889/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0208 - mae: 0.1056\n",
      "Epoch 1890/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0201 - mae: 0.1042\n",
      "Epoch 1891/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0200 - mae: 0.1026\n",
      "Epoch 1892/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0197 - mae: 0.1010\n",
      "Epoch 1893/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0197 - mae: 0.1019\n",
      "Epoch 1894/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0192 - mae: 0.1006\n",
      "Epoch 1895/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0212 - mae: 0.1068\n",
      "Epoch 1896/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0223 - mae: 0.1092\n",
      "Epoch 1897/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0238 - mae: 0.1132\n",
      "Epoch 1898/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0209 - mae: 0.1057\n",
      "Epoch 1899/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0227 - mae: 0.1081\n",
      "Epoch 1900/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0223 - mae: 0.1093\n",
      "Epoch 1901/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0205 - mae: 0.1036\n",
      "Epoch 1902/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0215 - mae: 0.1070\n",
      "Epoch 1903/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0211 - mae: 0.1055\n",
      "Epoch 1904/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0214 - mae: 0.1069\n",
      "Epoch 1905/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0214 - mae: 0.1061\n",
      "Epoch 1906/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0207 - mae: 0.1054\n",
      "Epoch 1907/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0210 - mae: 0.1051\n",
      "Epoch 1908/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0197 - mae: 0.1025\n",
      "Epoch 1909/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0207 - mae: 0.1040\n",
      "Epoch 1910/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0214 - mae: 0.1060\n",
      "Epoch 1911/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1026\n",
      "Epoch 1912/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0215 - mae: 0.1063\n",
      "Epoch 1913/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0216 - mae: 0.1081\n",
      "Epoch 1914/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0202 - mae: 0.1032\n",
      "Epoch 1915/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0215 - mae: 0.1071\n",
      "Epoch 1916/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0200 - mae: 0.1025\n",
      "Epoch 1917/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1020\n",
      "Epoch 1918/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0285 - mae: 0.1230\n",
      "Epoch 1919/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0222 - mae: 0.1087\n",
      "Epoch 1920/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0200 - mae: 0.1028\n",
      "Epoch 1921/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0206 - mae: 0.1039\n",
      "Epoch 1922/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0214 - mae: 0.1073\n",
      "Epoch 1923/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.1011\n",
      "Epoch 1924/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.0995\n",
      "Epoch 1925/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0189 - mae: 0.0995\n",
      "Epoch 1926/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1013\n",
      "Epoch 1927/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0195 - mae: 0.1017\n",
      "Epoch 1928/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0210 - mae: 0.1063\n",
      "Epoch 1929/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0206 - mae: 0.1050\n",
      "Epoch 1930/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0203 - mae: 0.1036\n",
      "Epoch 1931/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0196 - mae: 0.1008\n",
      "Epoch 1932/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0231 - mae: 0.1121\n",
      "Epoch 1933/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0217 - mae: 0.1079\n",
      "Epoch 1934/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0203 - mae: 0.1043\n",
      "Epoch 1935/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0192 - mae: 0.1014\n",
      "Epoch 1936/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0215 - mae: 0.1081\n",
      "Epoch 1937/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0194 - mae: 0.1013\n",
      "Epoch 1938/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0286 - mae: 0.1220\n",
      "Epoch 1939/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0218 - mae: 0.1078\n",
      "Epoch 1940/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0216 - mae: 0.1079\n",
      "Epoch 1941/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0310 - mae: 0.1199\n",
      "Epoch 1942/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0223 - mae: 0.1073\n",
      "Epoch 1943/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0211 - mae: 0.1059\n",
      "Epoch 1944/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1033\n",
      "Epoch 1945/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0198 - mae: 0.1011\n",
      "Epoch 1946/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1006\n",
      "Epoch 1947/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1021\n",
      "Epoch 1948/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0225 - mae: 0.1096\n",
      "Epoch 1949/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0208 - mae: 0.1048\n",
      "Epoch 1950/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0196 - mae: 0.1014\n",
      "Epoch 1951/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1019\n",
      "Epoch 1952/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0196 - mae: 0.1014\n",
      "Epoch 1953/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0201 - mae: 0.1027\n",
      "Epoch 1954/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0200 - mae: 0.1029\n",
      "Epoch 1955/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0223 - mae: 0.1106\n",
      "Epoch 1956/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0204 - mae: 0.1035\n",
      "Epoch 1957/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0193 - mae: 0.1013\n",
      "Epoch 1958/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0192 - mae: 0.1006\n",
      "Epoch 1959/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1015\n",
      "Epoch 1960/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0193 - mae: 0.1010\n",
      "Epoch 1961/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0191 - mae: 0.0999\n",
      "Epoch 1962/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1018\n",
      "Epoch 1963/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0192 - mae: 0.0996\n",
      "Epoch 1964/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0189 - mae: 0.0998\n",
      "Epoch 1965/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0187 - mae: 0.1000\n",
      "Epoch 1966/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0192 - mae: 0.1002\n",
      "Epoch 1967/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0190 - mae: 0.0994\n",
      "Epoch 1968/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0196 - mae: 0.1025\n",
      "Epoch 1969/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0217 - mae: 0.1088\n",
      "Epoch 1970/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1048\n",
      "Epoch 1971/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0193 - mae: 0.1008\n",
      "Epoch 1972/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1030\n",
      "Epoch 1973/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.1011\n",
      "Epoch 1974/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1007\n",
      "Epoch 1975/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1021\n",
      "Epoch 1976/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0203 - mae: 0.1040\n",
      "Epoch 1977/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0212 - mae: 0.1070\n",
      "Epoch 1978/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0194 - mae: 0.1015\n",
      "Epoch 1979/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0220 - mae: 0.1094\n",
      "Epoch 1980/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0196 - mae: 0.1015\n",
      "Epoch 1981/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0191 - mae: 0.1004\n",
      "Epoch 1982/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0198 - mae: 0.1022\n",
      "Epoch 1983/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0193 - mae: 0.1001\n",
      "Epoch 1984/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0194 - mae: 0.1013\n",
      "Epoch 1985/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0221 - mae: 0.1072\n",
      "Epoch 1986/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0226 - mae: 0.1096\n",
      "Epoch 1987/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0208 - mae: 0.1051\n",
      "Epoch 1988/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0189 - mae: 0.1000\n",
      "Epoch 1989/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0187 - mae: 0.0985\n",
      "Epoch 1990/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0188 - mae: 0.0991\n",
      "Epoch 1991/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0206 - mae: 0.1051\n",
      "Epoch 1992/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1032\n",
      "Epoch 1993/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0188 - mae: 0.0993\n",
      "Epoch 1994/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0190 - mae: 0.0999\n",
      "Epoch 1995/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0187 - mae: 0.1001\n",
      "Epoch 1996/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0184 - mae: 0.0978\n",
      "Epoch 1997/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0198 - mae: 0.1027\n",
      "Epoch 1998/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0202 - mae: 0.1037\n",
      "Epoch 1999/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0219 - mae: 0.1059\n",
      "Epoch 2000/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0214 - mae: 0.1059\n",
      "mae: 0.11130362004041672\n",
      "Overfit mae: 0.10154563188552856\n",
      "Train on 2019 samples\n",
      "Epoch 1/2000\n",
      "2019/2019 [==============================] - 1s 413us/sample - loss: 7920.2990 - mae: 20.6511\n",
      "Epoch 2/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 31154.2528 - mae: 22.5630\n",
      "Epoch 3/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 62693.6836 - mae: 19.3065\n",
      "Epoch 4/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 72us/sample - loss: 7961.6612 - mae: 14.7264\n",
      "Epoch 5/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 4047.4505 - mae: 14.7483\n",
      "Epoch 6/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 5308.0343 - mae: 12.8727\n",
      "Epoch 7/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 1428.3948 - mae: 10.5617\n",
      "Epoch 8/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 4301.9923 - mae: 8.8903\n",
      "Epoch 9/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 1916.3793 - mae: 7.2183\n",
      "Epoch 10/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 2211.0182 - mae: 8.1165\n",
      "Epoch 11/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 2980.5106 - mae: 7.6814\n",
      "Epoch 12/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 238.7595 - mae: 5.2556\n",
      "Epoch 13/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 231.6598 - mae: 4.3114\n",
      "Epoch 14/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 369.9466 - mae: 4.6295\n",
      "Epoch 15/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 378.8715 - mae: 4.7842\n",
      "Epoch 16/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 540.6433 - mae: 5.3326\n",
      "Epoch 17/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 1330.0842 - mae: 7.6997\n",
      "Epoch 18/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 3451.9472 - mae: 8.8202\n",
      "Epoch 19/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 546.8397 - mae: 4.8582\n",
      "Epoch 20/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1816.4794 - mae: 7.7574\n",
      "Epoch 21/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 19135.1215 - mae: 23.8592\n",
      "Epoch 22/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 3647.7897 - mae: 14.1269\n",
      "Epoch 23/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 4364.0258 - mae: 10.6516\n",
      "Epoch 24/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1864.6179 - mae: 10.8134\n",
      "Epoch 25/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 298.9362 - mae: 5.8126\n",
      "Epoch 26/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 628.0417 - mae: 5.7936\n",
      "Epoch 27/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 561.9290 - mae: 5.9574\n",
      "Epoch 28/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 485.4109 - mae: 5.3637\n",
      "Epoch 29/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 1753.3351 - mae: 6.7302\n",
      "Epoch 30/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 3780.4649 - mae: 12.4848\n",
      "Epoch 31/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 9676.4436 - mae: 12.5454\n",
      "Epoch 32/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 14990.3423 - mae: 16.5927\n",
      "Epoch 33/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 8576.7146 - mae: 14.9209\n",
      "Epoch 34/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 468.0876 - mae: 4.7403\n",
      "Epoch 35/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 299.6007 - mae: 4.0050\n",
      "Epoch 36/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 1184.9174 - mae: 5.3454\n",
      "Epoch 37/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 1085.7866 - mae: 6.3202\n",
      "Epoch 38/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 629.5927 - mae: 3.9058\n",
      "Epoch 39/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 344.5464 - mae: 3.1310\n",
      "Epoch 40/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 88.6195 - mae: 2.8705\n",
      "Epoch 41/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 82.2923 - mae: 2.5855\n",
      "Epoch 42/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 96.0318 - mae: 2.5900\n",
      "Epoch 43/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 139.2652 - mae: 2.5251\n",
      "Epoch 44/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2563.6246 - mae: 7.2931\n",
      "Epoch 45/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 926.5047 - mae: 5.0977\n",
      "Epoch 46/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 6123.3843 - mae: 11.5709\n",
      "Epoch 47/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 7677.3990 - mae: 11.7600\n",
      "Epoch 48/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 7722.8198 - mae: 10.8162\n",
      "Epoch 49/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1448.6334 - mae: 6.2908\n",
      "Epoch 50/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 3492.3776 - mae: 7.1086\n",
      "Epoch 51/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 3657.6900 - mae: 7.9392\n",
      "Epoch 52/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 217.4258 - mae: 3.4384\n",
      "Epoch 53/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 739.1030 - mae: 3.2436\n",
      "Epoch 54/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 364.6941 - mae: 3.0512\n",
      "Epoch 55/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 368.0852 - mae: 2.4684\n",
      "Epoch 56/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 494.0786 - mae: 3.3938\n",
      "Epoch 57/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 279.8207 - mae: 2.6113\n",
      "Epoch 58/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 191.0895 - mae: 3.0791\n",
      "Epoch 59/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 660.4410 - mae: 2.6866\n",
      "Epoch 60/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 152.4118 - mae: 2.6628\n",
      "Epoch 61/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 204.9685 - mae: 2.4834\n",
      "Epoch 62/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 60.2118 - mae: 1.5883\n",
      "Epoch 63/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 42.6752 - mae: 1.4363\n",
      "Epoch 64/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 52.2363 - mae: 1.5568\n",
      "Epoch 65/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 121.7818 - mae: 1.9117\n",
      "Epoch 66/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 98.9064 - mae: 1.8426\n",
      "Epoch 67/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 75.6227 - mae: 1.7376\n",
      "Epoch 68/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 78.6633 - mae: 1.6963\n",
      "Epoch 69/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 38.6719 - mae: 1.5709\n",
      "Epoch 70/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 61.3364 - mae: 1.6634\n",
      "Epoch 71/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 70.1350 - mae: 1.7259\n",
      "Epoch 72/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 211.3612 - mae: 2.3050\n",
      "Epoch 73/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 372.5007 - mae: 3.1620\n",
      "Epoch 74/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 143.7416 - mae: 2.3826\n",
      "Epoch 75/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 65.8963 - mae: 1.4799\n",
      "Epoch 76/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 169.5330 - mae: 1.8003\n",
      "Epoch 77/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 3077.5836 - mae: 5.5718\n",
      "Epoch 78/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1830.5460 - mae: 6.4777\n",
      "Epoch 79/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1076.5117 - mae: 5.6087\n",
      "Epoch 80/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 4516.4088 - mae: 8.8080\n",
      "Epoch 81/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 65us/sample - loss: 682.9160 - mae: 3.6072\n",
      "Epoch 82/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 947.1756 - mae: 4.4083\n",
      "Epoch 83/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2163.0202 - mae: 5.0112\n",
      "Epoch 84/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 1353.7814 - mae: 4.1825\n",
      "Epoch 85/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 1483.9557 - mae: 3.6424\n",
      "Epoch 86/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 1386.0218 - mae: 3.3378\n",
      "Epoch 87/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 253.5104 - mae: 2.1739\n",
      "Epoch 88/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 129.0464 - mae: 1.5058\n",
      "Epoch 89/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 43.1639 - mae: 1.1871\n",
      "Epoch 90/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 16.6764 - mae: 0.9491\n",
      "Epoch 91/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 18.0018 - mae: 0.9943\n",
      "Epoch 92/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 17.3279 - mae: 0.9803\n",
      "Epoch 93/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 18.9420 - mae: 0.9757\n",
      "Epoch 94/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 8.3366 - mae: 0.8392\n",
      "Epoch 95/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 5.8347 - mae: 0.8002\n",
      "Epoch 96/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 6.4549 - mae: 0.8191\n",
      "Epoch 97/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 6.2290 - mae: 0.7927\n",
      "Epoch 98/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 5.2257 - mae: 0.8129\n",
      "Epoch 99/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 5.8326 - mae: 0.7998\n",
      "Epoch 100/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 6.1093 - mae: 0.7921\n",
      "Epoch 101/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 7.2504 - mae: 0.8102\n",
      "Epoch 102/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 7.5016 - mae: 0.7750\n",
      "Epoch 103/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 7.6729 - mae: 0.7899\n",
      "Epoch 104/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 11.9287 - mae: 0.8356\n",
      "Epoch 105/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 25.1235 - mae: 1.0166\n",
      "Epoch 106/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 21.5167 - mae: 0.9033\n",
      "Epoch 107/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 40.7121 - mae: 0.9819\n",
      "Epoch 108/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 27.9949 - mae: 0.8654\n",
      "Epoch 109/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 119.1808 - mae: 1.3049\n",
      "Epoch 110/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 78.4521 - mae: 1.3510\n",
      "Epoch 111/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 199.9072 - mae: 1.7093\n",
      "Epoch 112/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 172.8279 - mae: 1.7051\n",
      "Epoch 113/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 369.2097 - mae: 2.5040\n",
      "Epoch 114/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 372.8982 - mae: 2.3746\n",
      "Epoch 115/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 368.6154 - mae: 2.2616\n",
      "Epoch 116/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 483.7348 - mae: 2.4373\n",
      "Epoch 117/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 704.8275 - mae: 2.3835\n",
      "Epoch 118/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 372.6463 - mae: 2.2923\n",
      "Epoch 119/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 131.4110 - mae: 1.4285\n",
      "Epoch 120/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 222.2970 - mae: 1.5858\n",
      "Epoch 121/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 313.1824 - mae: 1.8350\n",
      "Epoch 122/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 90.9996 - mae: 1.1900\n",
      "Epoch 123/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 635.2464 - mae: 1.9357\n",
      "Epoch 124/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 105.9820 - mae: 1.2218\n",
      "Epoch 125/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 101.1325 - mae: 1.2036\n",
      "Epoch 126/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 20.0536 - mae: 0.8575\n",
      "Epoch 127/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 4.6310 - mae: 0.6503\n",
      "Epoch 128/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 3.3506 - mae: 0.6038\n",
      "Epoch 129/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 3.2420 - mae: 0.5857\n",
      "Epoch 130/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 2.7742 - mae: 0.5666\n",
      "Epoch 131/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2.4344 - mae: 0.5449\n",
      "Epoch 132/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2.3406 - mae: 0.5381\n",
      "Epoch 133/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 2.1182 - mae: 0.5224\n",
      "Epoch 134/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 2.3864 - mae: 0.5208\n",
      "Epoch 135/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 2.8550 - mae: 0.5269\n",
      "Epoch 136/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 4.0544 - mae: 0.5377\n",
      "Epoch 137/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.8268 - mae: 0.4880\n",
      "Epoch 138/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.9121 - mae: 0.4776\n",
      "Epoch 139/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.7551 - mae: 0.4635\n",
      "Epoch 140/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.9335 - mae: 0.4720\n",
      "Epoch 141/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2.2304 - mae: 0.4707\n",
      "Epoch 142/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2.6771 - mae: 0.4769\n",
      "Epoch 143/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.8843 - mae: 0.4566\n",
      "Epoch 144/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.9267 - mae: 0.4552\n",
      "Epoch 145/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 1.7553 - mae: 0.4461\n",
      "Epoch 146/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 1.5875 - mae: 0.4342\n",
      "Epoch 147/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 1.8126 - mae: 0.4469\n",
      "Epoch 148/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 2.3839 - mae: 0.4594\n",
      "Epoch 149/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 3.3537 - mae: 0.4612\n",
      "Epoch 150/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 4.9889 - mae: 0.4958\n",
      "Epoch 151/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 5.8262 - mae: 0.5196\n",
      "Epoch 152/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 15.7885 - mae: 0.6629\n",
      "Epoch 153/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 24.4279 - mae: 0.6597\n",
      "Epoch 154/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 54.9978 - mae: 0.8915\n",
      "Epoch 155/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 92.2075 - mae: 1.0355\n",
      "Epoch 156/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 120.3815 - mae: 1.2347\n",
      "Epoch 157/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 147.2344 - mae: 1.1064\n",
      "Epoch 158/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 150.5933 - mae: 1.1242\n",
      "Epoch 159/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 67us/sample - loss: 133.5565 - mae: 0.9692\n",
      "Epoch 160/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 33.1535 - mae: 0.6155\n",
      "Epoch 161/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 3.6539 - mae: 0.4781\n",
      "Epoch 162/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 2.0755 - mae: 0.4140\n",
      "Epoch 163/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.4702 - mae: 0.3796\n",
      "Epoch 164/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.3930 - mae: 0.3786\n",
      "Epoch 165/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 3.4744 - mae: 0.4253\n",
      "Epoch 166/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2.2090 - mae: 0.4038\n",
      "Epoch 167/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 24.5368 - mae: 0.5722\n",
      "Epoch 168/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 3.2005 - mae: 0.4209\n",
      "Epoch 169/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 11.3938 - mae: 0.4894\n",
      "Epoch 170/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 24.4162 - mae: 0.5969\n",
      "Epoch 171/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 8.2525 - mae: 0.4590\n",
      "Epoch 172/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 2.4085 - mae: 0.3877\n",
      "Epoch 173/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.9378 - mae: 0.3618\n",
      "Epoch 174/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2.4664 - mae: 0.3731\n",
      "Epoch 175/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.3642 - mae: 0.3451\n",
      "Epoch 176/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.3836 - mae: 0.3409\n",
      "Epoch 177/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.5365 - mae: 0.3372\n",
      "Epoch 178/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.9861 - mae: 0.3198\n",
      "Epoch 179/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.9151 - mae: 0.3124\n",
      "Epoch 180/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.8199 - mae: 0.3038\n",
      "Epoch 181/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 1.0885 - mae: 0.3181\n",
      "Epoch 182/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.9324 - mae: 0.3107\n",
      "Epoch 183/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.0751 - mae: 0.3121\n",
      "Epoch 184/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 2.9832 - mae: 0.3632\n",
      "Epoch 185/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 1.8629 - mae: 0.3516\n",
      "Epoch 186/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2.4546 - mae: 0.3549\n",
      "Epoch 187/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 3.0863 - mae: 0.3665\n",
      "Epoch 188/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 4.6261 - mae: 0.3889\n",
      "Epoch 189/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 9.3909 - mae: 0.4251\n",
      "Epoch 190/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 28.5450 - mae: 0.5076\n",
      "Epoch 191/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 251.4102 - mae: 1.0765\n",
      "Epoch 192/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 56.8250 - mae: 0.8679\n",
      "Epoch 193/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 104.5874 - mae: 1.3617\n",
      "Epoch 194/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 335.1897 - mae: 1.7253\n",
      "Epoch 195/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 30.4283 - mae: 0.7271\n",
      "Epoch 196/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 221.6665 - mae: 1.0787\n",
      "Epoch 197/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 8.3705 - mae: 0.3860\n",
      "Epoch 198/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 34.3095 - mae: 0.5793\n",
      "Epoch 199/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 10.6006 - mae: 0.4075\n",
      "Epoch 200/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 7.2167 - mae: 0.3680\n",
      "Epoch 201/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 1.9074 - mae: 0.2990\n",
      "Epoch 202/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.5305 - mae: 0.2818\n",
      "Epoch 203/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.3919 - mae: 0.2755\n",
      "Epoch 204/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.0807 - mae: 0.2688\n",
      "Epoch 205/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 1.0759 - mae: 0.2652\n",
      "Epoch 206/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 1.6240 - mae: 0.2805\n",
      "Epoch 207/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 1.2596 - mae: 0.2719\n",
      "Epoch 208/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 1.0487 - mae: 0.2660\n",
      "Epoch 209/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.9364 - mae: 0.2599\n",
      "Epoch 210/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.0987 - mae: 0.2643\n",
      "Epoch 211/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.8192 - mae: 0.2598\n",
      "Epoch 212/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.8872 - mae: 0.2603\n",
      "Epoch 213/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.6987 - mae: 0.2525\n",
      "Epoch 214/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.9692 - mae: 0.2634\n",
      "Epoch 215/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.8046 - mae: 0.2639\n",
      "Epoch 216/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.7661 - mae: 0.2579\n",
      "Epoch 217/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.8235 - mae: 0.2591\n",
      "Epoch 218/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.8161 - mae: 0.2617\n",
      "Epoch 219/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.6140 - mae: 0.2467\n",
      "Epoch 220/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.6443 - mae: 0.2467\n",
      "Epoch 221/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.6592 - mae: 0.2490\n",
      "Epoch 222/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.6467 - mae: 0.2483\n",
      "Epoch 223/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.6715 - mae: 0.2477\n",
      "Epoch 224/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.6174 - mae: 0.2460\n",
      "Epoch 225/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.5819 - mae: 0.2424\n",
      "Epoch 226/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.6134 - mae: 0.2454\n",
      "Epoch 227/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.6260 - mae: 0.2462\n",
      "Epoch 228/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.6869 - mae: 0.2490\n",
      "Epoch 229/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.5777 - mae: 0.2410\n",
      "Epoch 230/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.5847 - mae: 0.2435\n",
      "Epoch 231/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.6053 - mae: 0.2455\n",
      "Epoch 232/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.5978 - mae: 0.2449\n",
      "Epoch 233/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5736 - mae: 0.2396\n",
      "Epoch 234/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.6640 - mae: 0.2477\n",
      "Epoch 235/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 1.2791 - mae: 0.2796\n",
      "Epoch 236/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.9675 - mae: 0.2721\n",
      "Epoch 237/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5948 - mae: 0.2462\n",
      "Epoch 238/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.5815 - mae: 0.2443\n",
      "Epoch 239/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.6045 - mae: 0.2485\n",
      "Epoch 240/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5765 - mae: 0.2433\n",
      "Epoch 241/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.5494 - mae: 0.2392\n",
      "Epoch 242/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.5391 - mae: 0.2363\n",
      "Epoch 243/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.5294 - mae: 0.2335\n",
      "Epoch 244/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5269 - mae: 0.2333\n",
      "Epoch 245/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.5239 - mae: 0.2332\n",
      "Epoch 246/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5187 - mae: 0.2323\n",
      "Epoch 247/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.5176 - mae: 0.2317\n",
      "Epoch 248/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5141 - mae: 0.2292\n",
      "Epoch 249/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5130 - mae: 0.2292\n",
      "Epoch 250/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.5100 - mae: 0.2283\n",
      "Epoch 251/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.5082 - mae: 0.2267\n",
      "Epoch 252/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.6367 - mae: 0.2439\n",
      "Epoch 253/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.7260 - mae: 0.2438\n",
      "Epoch 254/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.6340 - mae: 0.2454\n",
      "Epoch 255/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.6640 - mae: 0.2547\n",
      "Epoch 256/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.9556 - mae: 0.2863\n",
      "Epoch 257/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.7834 - mae: 0.3076\n",
      "Epoch 258/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.8197 - mae: 0.2617\n",
      "Epoch 259/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 1.9811 - mae: 0.3331\n",
      "Epoch 260/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2.4556 - mae: 0.3256\n",
      "Epoch 261/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.9547 - mae: 0.2701\n",
      "Epoch 262/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.7395 - mae: 0.2583\n",
      "Epoch 263/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.1493 - mae: 0.2933\n",
      "Epoch 264/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.9748 - mae: 0.2874\n",
      "Epoch 265/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.8720 - mae: 0.2623\n",
      "Epoch 266/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.5590 - mae: 0.2396\n",
      "Epoch 267/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.6852 - mae: 0.2509\n",
      "Epoch 268/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.6523 - mae: 0.2466\n",
      "Epoch 269/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.5314 - mae: 0.2340\n",
      "Epoch 270/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.5071 - mae: 0.2285\n",
      "Epoch 271/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.4973 - mae: 0.2240\n",
      "Epoch 272/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5240 - mae: 0.2276\n",
      "Epoch 273/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.5231 - mae: 0.2300\n",
      "Epoch 274/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.5047 - mae: 0.2298\n",
      "Epoch 275/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.4997 - mae: 0.2254\n",
      "Epoch 276/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.5036 - mae: 0.2263\n",
      "Epoch 277/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.5172 - mae: 0.2320\n",
      "Epoch 278/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.7723 - mae: 0.2626\n",
      "Epoch 279/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.7561 - mae: 0.2710\n",
      "Epoch 280/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 2.1290 - mae: 0.3401\n",
      "Epoch 281/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 9.7137 - mae: 0.3576\n",
      "Epoch 282/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 121.9885 - mae: 0.7860\n",
      "Epoch 283/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 87.3511 - mae: 0.5793\n",
      "Epoch 284/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 6.8795 - mae: 0.3368\n",
      "Epoch 285/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.8534 - mae: 0.2566\n",
      "Epoch 286/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 9.0923 - mae: 0.3250\n",
      "Epoch 287/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.7218 - mae: 0.2737\n",
      "Epoch 288/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.6244 - mae: 0.2386\n",
      "Epoch 289/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.5275 - mae: 0.2321\n",
      "Epoch 290/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5162 - mae: 0.2298\n",
      "Epoch 291/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.5095 - mae: 0.2269\n",
      "Epoch 292/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5060 - mae: 0.2262\n",
      "Epoch 293/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5020 - mae: 0.2249\n",
      "Epoch 294/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.4998 - mae: 0.2229\n",
      "Epoch 295/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.4955 - mae: 0.2205\n",
      "Epoch 296/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4933 - mae: 0.2193\n",
      "Epoch 297/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4910 - mae: 0.2173\n",
      "Epoch 298/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.4863 - mae: 0.2150\n",
      "Epoch 299/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4845 - mae: 0.2145\n",
      "Epoch 300/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.4827 - mae: 0.2128\n",
      "Epoch 301/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.4784 - mae: 0.2115\n",
      "Epoch 302/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.4793 - mae: 0.2112\n",
      "Epoch 303/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.4750 - mae: 0.2098\n",
      "Epoch 304/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.4752 - mae: 0.2106\n",
      "Epoch 305/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.4715 - mae: 0.2088\n",
      "Epoch 306/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.4711 - mae: 0.2093\n",
      "Epoch 307/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 3.8440 - mae: 0.2582\n",
      "Epoch 308/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 1.0961 - mae: 0.2356\n",
      "Epoch 309/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 4.1703 - mae: 0.2690\n",
      "Epoch 310/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.3948 - mae: 0.2313\n",
      "Epoch 311/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5449 - mae: 0.2144\n",
      "Epoch 312/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.7357 - mae: 0.2222\n",
      "Epoch 313/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.6421 - mae: 0.2131\n",
      "Epoch 314/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.5276 - mae: 0.2105\n",
      "Epoch 315/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.5347 - mae: 0.2091\n",
      "Epoch 316/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5083 - mae: 0.2070\n",
      "Epoch 317/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.4889 - mae: 0.2057\n",
      "Epoch 318/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.4732 - mae: 0.2035\n",
      "Epoch 319/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.4691 - mae: 0.2034\n",
      "Epoch 320/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.4732 - mae: 0.2038\n",
      "Epoch 321/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4944 - mae: 0.2048\n",
      "Epoch 322/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5118 - mae: 0.2040\n",
      "Epoch 323/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5756 - mae: 0.2142\n",
      "Epoch 324/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.7701 - mae: 0.2196\n",
      "Epoch 325/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 1.0982 - mae: 0.2276\n",
      "Epoch 326/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.5675 - mae: 0.2081\n",
      "Epoch 327/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.4498 - mae: 0.2000\n",
      "Epoch 328/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.5463 - mae: 0.2050\n",
      "Epoch 329/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4489 - mae: 0.1997\n",
      "Epoch 330/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4407 - mae: 0.1999\n",
      "Epoch 331/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4337 - mae: 0.1979\n",
      "Epoch 332/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.4315 - mae: 0.1967\n",
      "Epoch 333/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.4296 - mae: 0.1951\n",
      "Epoch 334/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4310 - mae: 0.1983\n",
      "Epoch 335/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4278 - mae: 0.1964\n",
      "Epoch 336/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.4258 - mae: 0.1950\n",
      "Epoch 337/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.4251 - mae: 0.1958\n",
      "Epoch 338/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.4238 - mae: 0.1954\n",
      "Epoch 339/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.4219 - mae: 0.1949\n",
      "Epoch 340/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.4400 - mae: 0.2221\n",
      "Epoch 341/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4212 - mae: 0.1998\n",
      "Epoch 342/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.4172 - mae: 0.1952\n",
      "Epoch 343/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.4153 - mae: 0.1938\n",
      "Epoch 344/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.4136 - mae: 0.1929\n",
      "Epoch 345/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4121 - mae: 0.1925\n",
      "Epoch 346/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4102 - mae: 0.1918\n",
      "Epoch 347/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.4086 - mae: 0.1910\n",
      "Epoch 348/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.4070 - mae: 0.1908\n",
      "Epoch 349/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.4051 - mae: 0.1895\n",
      "Epoch 350/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.4044 - mae: 0.1909\n",
      "Epoch 351/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.4020 - mae: 0.1896\n",
      "Epoch 352/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4016 - mae: 0.1908\n",
      "Epoch 353/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3992 - mae: 0.1895\n",
      "Epoch 354/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3971 - mae: 0.1891\n",
      "Epoch 355/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.3958 - mae: 0.1892\n",
      "Epoch 356/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3946 - mae: 0.1892\n",
      "Epoch 357/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3943 - mae: 0.1897\n",
      "Epoch 358/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3975 - mae: 0.1908\n",
      "Epoch 359/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.4038 - mae: 0.1932\n",
      "Epoch 360/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.4117 - mae: 0.1965\n",
      "Epoch 361/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.4113 - mae: 0.1928\n",
      "Epoch 362/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.4496 - mae: 0.1955\n",
      "Epoch 363/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.8487 - mae: 0.2082\n",
      "Epoch 364/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 1.4321 - mae: 0.2133\n",
      "Epoch 365/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.7019 - mae: 0.2085\n",
      "Epoch 366/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 1.1411 - mae: 0.2141\n",
      "Epoch 367/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.7371 - mae: 0.2005\n",
      "Epoch 368/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.6718 - mae: 0.1971\n",
      "Epoch 369/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.3764 - mae: 0.1860\n",
      "Epoch 370/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3673 - mae: 0.1836\n",
      "Epoch 371/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.3650 - mae: 0.1827\n",
      "Epoch 372/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.3623 - mae: 0.1816\n",
      "Epoch 373/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.3604 - mae: 0.1813\n",
      "Epoch 374/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.3670 - mae: 0.1933\n",
      "Epoch 375/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3578 - mae: 0.1833\n",
      "Epoch 376/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3538 - mae: 0.1806\n",
      "Epoch 377/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3525 - mae: 0.1812\n",
      "Epoch 378/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3504 - mae: 0.1809\n",
      "Epoch 379/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3474 - mae: 0.1791\n",
      "Epoch 380/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.3447 - mae: 0.1778\n",
      "Epoch 381/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3440 - mae: 0.1788\n",
      "Epoch 382/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3441 - mae: 0.1816\n",
      "Epoch 383/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.3392 - mae: 0.1780\n",
      "Epoch 384/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.3364 - mae: 0.1766\n",
      "Epoch 385/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3335 - mae: 0.1750\n",
      "Epoch 386/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.3345 - mae: 0.1792\n",
      "Epoch 387/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3313 - mae: 0.1781\n",
      "Epoch 388/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3272 - mae: 0.1753\n",
      "Epoch 389/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.3281 - mae: 0.1778\n",
      "Epoch 390/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.3233 - mae: 0.1748\n",
      "Epoch 391/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.3209 - mae: 0.1746\n",
      "Epoch 392/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3190 - mae: 0.1756\n",
      "Epoch 393/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3175 - mae: 0.1761\n",
      "Epoch 394/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.3178 - mae: 0.1770\n",
      "Epoch 395/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.3208 - mae: 0.1739\n",
      "Epoch 396/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.3102 - mae: 0.1736\n",
      "Epoch 397/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.3070 - mae: 0.1717\n",
      "Epoch 398/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.3074 - mae: 0.1760\n",
      "Epoch 399/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.3028 - mae: 0.1720\n",
      "Epoch 400/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.3049 - mae: 0.1796\n",
      "Epoch 401/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.2983 - mae: 0.1734\n",
      "Epoch 402/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.2952 - mae: 0.1707\n",
      "Epoch 403/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.2938 - mae: 0.1729\n",
      "Epoch 404/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.2914 - mae: 0.1723\n",
      "Epoch 405/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.2882 - mae: 0.1707\n",
      "Epoch 406/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.2855 - mae: 0.1694\n",
      "Epoch 407/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2860 - mae: 0.1750\n",
      "Epoch 408/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2817 - mae: 0.1714\n",
      "Epoch 409/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.2788 - mae: 0.1702\n",
      "Epoch 410/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.2804 - mae: 0.1756\n",
      "Epoch 411/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2738 - mae: 0.1704\n",
      "Epoch 412/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2711 - mae: 0.1704\n",
      "Epoch 413/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.2693 - mae: 0.1691\n",
      "Epoch 414/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2661 - mae: 0.1691\n",
      "Epoch 415/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2652 - mae: 0.1709\n",
      "Epoch 416/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.2615 - mae: 0.1686\n",
      "Epoch 417/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2589 - mae: 0.1673\n",
      "Epoch 418/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2584 - mae: 0.1700\n",
      "Epoch 419/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.2545 - mae: 0.1675\n",
      "Epoch 420/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.2529 - mae: 0.1695\n",
      "Epoch 421/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2515 - mae: 0.1697\n",
      "Epoch 422/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.2506 - mae: 0.1726\n",
      "Epoch 423/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.2446 - mae: 0.1666\n",
      "Epoch 424/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.2450 - mae: 0.1674\n",
      "Epoch 425/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2428 - mae: 0.1663\n",
      "Epoch 426/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2713 - mae: 0.1690\n",
      "Epoch 427/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.2596 - mae: 0.1754\n",
      "Epoch 428/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2342 - mae: 0.1670\n",
      "Epoch 429/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2313 - mae: 0.1667\n",
      "Epoch 430/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.2309 - mae: 0.1714\n",
      "Epoch 431/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.2258 - mae: 0.1654\n",
      "Epoch 432/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.2268 - mae: 0.1724\n",
      "Epoch 433/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.2240 - mae: 0.1671\n",
      "Epoch 434/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.2416 - mae: 0.1921\n",
      "Epoch 435/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2210 - mae: 0.1754\n",
      "Epoch 436/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.2172 - mae: 0.1714\n",
      "Epoch 437/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.2140 - mae: 0.1696\n",
      "Epoch 438/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2115 - mae: 0.1689\n",
      "Epoch 439/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2088 - mae: 0.1682\n",
      "Epoch 440/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2062 - mae: 0.1672\n",
      "Epoch 441/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2034 - mae: 0.1661\n",
      "Epoch 442/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.2022 - mae: 0.1680\n",
      "Epoch 443/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.2006 - mae: 0.1666\n",
      "Epoch 444/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.2018 - mae: 0.1711\n",
      "Epoch 445/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.2032 - mae: 0.1822\n",
      "Epoch 446/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1942 - mae: 0.1695\n",
      "Epoch 447/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.1909 - mae: 0.1654\n",
      "Epoch 448/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1891 - mae: 0.1661\n",
      "Epoch 449/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2220 - mae: 0.1753\n",
      "Epoch 450/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1922 - mae: 0.1680\n",
      "Epoch 451/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2277 - mae: 0.1761\n",
      "Epoch 452/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.2033 - mae: 0.1736\n",
      "Epoch 453/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1814 - mae: 0.1691\n",
      "Epoch 454/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1784 - mae: 0.1676\n",
      "Epoch 455/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1759 - mae: 0.1647\n",
      "Epoch 456/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1739 - mae: 0.1654\n",
      "Epoch 457/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1718 - mae: 0.1651\n",
      "Epoch 458/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.1706 - mae: 0.1660\n",
      "Epoch 459/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.1663 - mae: 0.1623\n",
      "Epoch 460/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1660 - mae: 0.1640\n",
      "Epoch 461/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1622 - mae: 0.1617\n",
      "Epoch 462/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1602 - mae: 0.1625\n",
      "Epoch 463/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1571 - mae: 0.1602\n",
      "Epoch 464/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.1554 - mae: 0.1603\n",
      "Epoch 465/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1529 - mae: 0.1586\n",
      "Epoch 466/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.1514 - mae: 0.1584\n",
      "Epoch 467/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1510 - mae: 0.1606\n",
      "Epoch 468/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1483 - mae: 0.1606\n",
      "Epoch 469/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1469 - mae: 0.1602\n",
      "Epoch 470/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1437 - mae: 0.1586\n",
      "Epoch 471/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.1442 - mae: 0.1632\n",
      "Epoch 472/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.1400 - mae: 0.1578\n",
      "Epoch 473/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1388 - mae: 0.1585\n",
      "Epoch 474/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.1370 - mae: 0.1586\n",
      "Epoch 475/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.1351 - mae: 0.1589\n",
      "Epoch 476/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.1336 - mae: 0.1581\n",
      "Epoch 477/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.1386 - mae: 0.1717\n",
      "Epoch 478/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1307 - mae: 0.1590\n",
      "Epoch 479/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1283 - mae: 0.1577\n",
      "Epoch 480/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1418 - mae: 0.1840\n",
      "Epoch 481/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.1256 - mae: 0.1600\n",
      "Epoch 482/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1234 - mae: 0.1568\n",
      "Epoch 483/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1223 - mae: 0.1570\n",
      "Epoch 484/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.1193 - mae: 0.1535\n",
      "Epoch 485/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1180 - mae: 0.1542\n",
      "Epoch 486/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1162 - mae: 0.1533\n",
      "Epoch 487/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.1154 - mae: 0.1542\n",
      "Epoch 488/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1134 - mae: 0.1531\n",
      "Epoch 489/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.1517 - mae: 0.1878\n",
      "Epoch 490/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1165 - mae: 0.1661\n",
      "Epoch 491/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.1128 - mae: 0.1610\n",
      "Epoch 492/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.1109 - mae: 0.1599\n",
      "Epoch 493/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.1091 - mae: 0.1582\n",
      "Epoch 494/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.1071 - mae: 0.1562\n",
      "Epoch 495/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.1049 - mae: 0.1548\n",
      "Epoch 496/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1035 - mae: 0.1543\n",
      "Epoch 497/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1010 - mae: 0.1509\n",
      "Epoch 498/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1008 - mae: 0.1557\n",
      "Epoch 499/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0991 - mae: 0.1516\n",
      "Epoch 500/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0975 - mae: 0.1515\n",
      "Epoch 501/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0964 - mae: 0.1525\n",
      "Epoch 502/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0964 - mae: 0.1542\n",
      "Epoch 503/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0937 - mae: 0.1505\n",
      "Epoch 504/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0917 - mae: 0.1491\n",
      "Epoch 505/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0916 - mae: 0.1509\n",
      "Epoch 506/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.1994 - mae: 0.1567\n",
      "Epoch 507/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 4.6941 - mae: 0.2334\n",
      "Epoch 508/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.1331 - mae: 0.1856\n",
      "Epoch 509/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0961 - mae: 0.1664\n",
      "Epoch 510/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0937 - mae: 0.1627\n",
      "Epoch 511/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0915 - mae: 0.1611\n",
      "Epoch 512/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0912 - mae: 0.1618\n",
      "Epoch 513/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0893 - mae: 0.1591\n",
      "Epoch 514/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0895 - mae: 0.1614\n",
      "Epoch 515/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0875 - mae: 0.1581\n",
      "Epoch 516/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0872 - mae: 0.1602\n",
      "Epoch 517/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0864 - mae: 0.1587\n",
      "Epoch 518/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0862 - mae: 0.1599\n",
      "Epoch 519/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0864 - mae: 0.1608\n",
      "Epoch 520/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0850 - mae: 0.1605\n",
      "Epoch 521/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0931 - mae: 0.1757\n",
      "Epoch 522/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0845 - mae: 0.1607\n",
      "Epoch 523/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.1143 - mae: 0.2103\n",
      "Epoch 524/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0892 - mae: 0.1747\n",
      "Epoch 525/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0905 - mae: 0.1732\n",
      "Epoch 526/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0898 - mae: 0.1737\n",
      "Epoch 527/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0878 - mae: 0.1719\n",
      "Epoch 528/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0852 - mae: 0.1692\n",
      "Epoch 529/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0841 - mae: 0.1692\n",
      "Epoch 530/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0830 - mae: 0.1674\n",
      "Epoch 531/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0823 - mae: 0.1669\n",
      "Epoch 532/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0809 - mae: 0.1662\n",
      "Epoch 533/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0793 - mae: 0.1630\n",
      "Epoch 534/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0785 - mae: 0.1619\n",
      "Epoch 535/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0771 - mae: 0.1611\n",
      "Epoch 536/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0763 - mae: 0.1607\n",
      "Epoch 537/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0751 - mae: 0.1585\n",
      "Epoch 538/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0751 - mae: 0.1600\n",
      "Epoch 539/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0751 - mae: 0.1612\n",
      "Epoch 540/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0730 - mae: 0.1574\n",
      "Epoch 541/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0721 - mae: 0.1563\n",
      "Epoch 542/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0716 - mae: 0.1561\n",
      "Epoch 543/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0708 - mae: 0.1557\n",
      "Epoch 544/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0700 - mae: 0.1550\n",
      "Epoch 545/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0688 - mae: 0.1518\n",
      "Epoch 546/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0689 - mae: 0.1530\n",
      "Epoch 547/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0683 - mae: 0.1542\n",
      "Epoch 548/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0698 - mae: 0.1569\n",
      "Epoch 549/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0670 - mae: 0.1521\n",
      "Epoch 550/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0668 - mae: 0.1522\n",
      "Epoch 551/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0661 - mae: 0.1515\n",
      "Epoch 552/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0664 - mae: 0.1540\n",
      "Epoch 553/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0677 - mae: 0.1553\n",
      "Epoch 554/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0651 - mae: 0.1514\n",
      "Epoch 555/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0641 - mae: 0.1509\n",
      "Epoch 556/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0690 - mae: 0.1612\n",
      "Epoch 557/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0641 - mae: 0.1526\n",
      "Epoch 558/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0620 - mae: 0.1481\n",
      "Epoch 559/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0621 - mae: 0.1492\n",
      "Epoch 560/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0642 - mae: 0.1527\n",
      "Epoch 561/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0694 - mae: 0.1621\n",
      "Epoch 562/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0624 - mae: 0.1538\n",
      "Epoch 563/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0615 - mae: 0.1515\n",
      "Epoch 564/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0626 - mae: 0.1549\n",
      "Epoch 565/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0610 - mae: 0.1515\n",
      "Epoch 566/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0606 - mae: 0.1521\n",
      "Epoch 567/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0594 - mae: 0.1489\n",
      "Epoch 568/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0581 - mae: 0.1473\n",
      "Epoch 569/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0588 - mae: 0.1492\n",
      "Epoch 570/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0594 - mae: 0.1507\n",
      "Epoch 571/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0575 - mae: 0.1474\n",
      "Epoch 572/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0594 - mae: 0.1522\n",
      "Epoch 573/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0575 - mae: 0.1479\n",
      "Epoch 574/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0578 - mae: 0.1505\n",
      "Epoch 575/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0614 - mae: 0.1552\n",
      "Epoch 576/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0576 - mae: 0.1515\n",
      "Epoch 577/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0561 - mae: 0.1482\n",
      "Epoch 578/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0562 - mae: 0.1485\n",
      "Epoch 579/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0558 - mae: 0.1484\n",
      "Epoch 580/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0546 - mae: 0.1462\n",
      "Epoch 581/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0551 - mae: 0.1484\n",
      "Epoch 582/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0553 - mae: 0.1484\n",
      "Epoch 583/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0573 - mae: 0.1510\n",
      "Epoch 584/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0547 - mae: 0.1483\n",
      "Epoch 585/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0536 - mae: 0.1461\n",
      "Epoch 586/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0557 - mae: 0.1509\n",
      "Epoch 587/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0529 - mae: 0.1462\n",
      "Epoch 588/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0541 - mae: 0.1474\n",
      "Epoch 589/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0539 - mae: 0.1479\n",
      "Epoch 590/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0537 - mae: 0.1483\n",
      "Epoch 591/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0516 - mae: 0.1439\n",
      "Epoch 592/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0528 - mae: 0.1463\n",
      "Epoch 593/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0525 - mae: 0.1471\n",
      "Epoch 594/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0509 - mae: 0.1441\n",
      "Epoch 595/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0512 - mae: 0.1459\n",
      "Epoch 596/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0517 - mae: 0.1454\n",
      "Epoch 597/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0509 - mae: 0.1447\n",
      "Epoch 598/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0531 - mae: 0.1516\n",
      "Epoch 599/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0504 - mae: 0.1444\n",
      "Epoch 600/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0534 - mae: 0.1504\n",
      "Epoch 601/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0519 - mae: 0.1491\n",
      "Epoch 602/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0515 - mae: 0.1487\n",
      "Epoch 603/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0525 - mae: 0.1514\n",
      "Epoch 604/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0499 - mae: 0.1460\n",
      "Epoch 605/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0505 - mae: 0.1470\n",
      "Epoch 606/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0509 - mae: 0.1487\n",
      "Epoch 607/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0493 - mae: 0.1448\n",
      "Epoch 608/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0485 - mae: 0.1430\n",
      "Epoch 609/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0495 - mae: 0.1465\n",
      "Epoch 610/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0492 - mae: 0.1455\n",
      "Epoch 611/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0491 - mae: 0.1458\n",
      "Epoch 612/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0509 - mae: 0.1508\n",
      "Epoch 613/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0473 - mae: 0.1430\n",
      "Epoch 614/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0556 - mae: 0.1598\n",
      "Epoch 615/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0493 - mae: 0.1476\n",
      "Epoch 616/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0473 - mae: 0.1432\n",
      "Epoch 617/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0477 - mae: 0.1436\n",
      "Epoch 618/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0473 - mae: 0.1440\n",
      "Epoch 619/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0464 - mae: 0.1426\n",
      "Epoch 620/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0533 - mae: 0.1531\n",
      "Epoch 621/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0489 - mae: 0.1482\n",
      "Epoch 622/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0477 - mae: 0.1451\n",
      "Epoch 623/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0476 - mae: 0.1462\n",
      "Epoch 624/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0486 - mae: 0.1481\n",
      "Epoch 625/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0464 - mae: 0.1433\n",
      "Epoch 626/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0473 - mae: 0.1456\n",
      "Epoch 627/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0461 - mae: 0.1428\n",
      "Epoch 628/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0474 - mae: 0.1453\n",
      "Epoch 629/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0474 - mae: 0.1447\n",
      "Epoch 630/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0462 - mae: 0.1445\n",
      "Epoch 631/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0461 - mae: 0.1442\n",
      "Epoch 632/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0458 - mae: 0.1428\n",
      "Epoch 633/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0458 - mae: 0.1435\n",
      "Epoch 634/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0448 - mae: 0.1423\n",
      "Epoch 635/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0447 - mae: 0.1416\n",
      "Epoch 636/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0458 - mae: 0.1446\n",
      "Epoch 637/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0448 - mae: 0.1415\n",
      "Epoch 638/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0438 - mae: 0.1402\n",
      "Epoch 639/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0454 - mae: 0.1439\n",
      "Epoch 640/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0468 - mae: 0.1466\n",
      "Epoch 641/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0449 - mae: 0.1429\n",
      "Epoch 642/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0434 - mae: 0.1400\n",
      "Epoch 643/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0441 - mae: 0.1407\n",
      "Epoch 644/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0483 - mae: 0.1484\n",
      "Epoch 645/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0459 - mae: 0.1458\n",
      "Epoch 646/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0447 - mae: 0.1433\n",
      "Epoch 647/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0440 - mae: 0.1427\n",
      "Epoch 648/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0446 - mae: 0.1426\n",
      "Epoch 649/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0442 - mae: 0.1424\n",
      "Epoch 650/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0441 - mae: 0.1420\n",
      "Epoch 651/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0427 - mae: 0.1384\n",
      "Epoch 652/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0443 - mae: 0.1429\n",
      "Epoch 653/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0419 - mae: 0.1391\n",
      "Epoch 654/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0426 - mae: 0.1401\n",
      "Epoch 655/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0416 - mae: 0.1371\n",
      "Epoch 656/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0544 - mae: 0.1559\n",
      "Epoch 657/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0431 - mae: 0.1405\n",
      "Epoch 658/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0415 - mae: 0.1374\n",
      "Epoch 659/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0416 - mae: 0.1380\n",
      "Epoch 660/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0420 - mae: 0.1386\n",
      "Epoch 661/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0403 - mae: 0.1347\n",
      "Epoch 662/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0397 - mae: 0.1332\n",
      "Epoch 663/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0407 - mae: 0.1362\n",
      "Epoch 664/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0395 - mae: 0.1339\n",
      "Epoch 665/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0394 - mae: 0.1333\n",
      "Epoch 666/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0398 - mae: 0.1355\n",
      "Epoch 667/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0389 - mae: 0.1328\n",
      "Epoch 668/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0388 - mae: 0.1325\n",
      "Epoch 669/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0389 - mae: 0.1328\n",
      "Epoch 670/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0387 - mae: 0.1336\n",
      "Epoch 671/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0378 - mae: 0.1309\n",
      "Epoch 672/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0389 - mae: 0.1363\n",
      "Epoch 673/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0377 - mae: 0.1313\n",
      "Epoch 674/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0378 - mae: 0.1332\n",
      "Epoch 675/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0373 - mae: 0.1302\n",
      "Epoch 676/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0395 - mae: 0.1360\n",
      "Epoch 677/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0374 - mae: 0.1312\n",
      "Epoch 678/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0375 - mae: 0.1324\n",
      "Epoch 679/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0375 - mae: 0.1313\n",
      "Epoch 680/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0382 - mae: 0.1354\n",
      "Epoch 681/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0374 - mae: 0.1324\n",
      "Epoch 682/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0371 - mae: 0.1327\n",
      "Epoch 683/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0378 - mae: 0.1330\n",
      "Epoch 684/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0436 - mae: 0.1462\n",
      "Epoch 685/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0386 - mae: 0.1366\n",
      "Epoch 686/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0373 - mae: 0.1327\n",
      "Epoch 687/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0362 - mae: 0.1316\n",
      "Epoch 688/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0366 - mae: 0.1330\n",
      "Epoch 689/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0355 - mae: 0.1310\n",
      "Epoch 690/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0357 - mae: 0.1309\n",
      "Epoch 691/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0379 - mae: 0.1354\n",
      "Epoch 692/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0437 - mae: 0.1455\n",
      "Epoch 693/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0466 - mae: 0.1528\n",
      "Epoch 694/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0695 - mae: 0.1909\n",
      "Epoch 695/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0596 - mae: 0.1836\n",
      "Epoch 696/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0446 - mae: 0.1528\n",
      "Epoch 697/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0418 - mae: 0.1454\n",
      "Epoch 698/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0395 - mae: 0.1389\n",
      "Epoch 699/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0446 - mae: 0.1487\n",
      "Epoch 700/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0416 - mae: 0.1427\n",
      "Epoch 701/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0389 - mae: 0.1380\n",
      "Epoch 702/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0376 - mae: 0.1359\n",
      "Epoch 703/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0365 - mae: 0.1328\n",
      "Epoch 704/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0365 - mae: 0.1334\n",
      "Epoch 705/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0360 - mae: 0.1330\n",
      "Epoch 706/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0358 - mae: 0.1320\n",
      "Epoch 707/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0366 - mae: 0.1360\n",
      "Epoch 708/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0347 - mae: 0.1311\n",
      "Epoch 709/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0350 - mae: 0.1321\n",
      "Epoch 710/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0345 - mae: 0.1306\n",
      "Epoch 711/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0344 - mae: 0.1306\n",
      "Epoch 712/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0343 - mae: 0.1307\n",
      "Epoch 713/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0336 - mae: 0.1287\n",
      "Epoch 714/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0332 - mae: 0.1282\n",
      "Epoch 715/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0330 - mae: 0.1278\n",
      "Epoch 716/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0328 - mae: 0.1272\n",
      "Epoch 717/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0328 - mae: 0.1285\n",
      "Epoch 718/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0328 - mae: 0.1290\n",
      "Epoch 719/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0331 - mae: 0.1303\n",
      "Epoch 720/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0332 - mae: 0.1308\n",
      "Epoch 721/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0326 - mae: 0.1281\n",
      "Epoch 722/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0315 - mae: 0.1268\n",
      "Epoch 723/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0668 - mae: 0.1572\n",
      "Epoch 724/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0394 - mae: 0.1423\n",
      "Epoch 725/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0369 - mae: 0.1374\n",
      "Epoch 726/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0368 - mae: 0.1384\n",
      "Epoch 727/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0358 - mae: 0.1361\n",
      "Epoch 728/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0363 - mae: 0.1382\n",
      "Epoch 729/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0348 - mae: 0.1338\n",
      "Epoch 730/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0342 - mae: 0.1315\n",
      "Epoch 731/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0339 - mae: 0.1307\n",
      "Epoch 732/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0350 - mae: 0.1356\n",
      "Epoch 733/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0340 - mae: 0.1324\n",
      "Epoch 734/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0342 - mae: 0.1336\n",
      "Epoch 735/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0355 - mae: 0.1368\n",
      "Epoch 736/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0341 - mae: 0.1341\n",
      "Epoch 737/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0333 - mae: 0.1320\n",
      "Epoch 738/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0321 - mae: 0.1297\n",
      "Epoch 739/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0332 - mae: 0.1310\n",
      "Epoch 740/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0333 - mae: 0.1329\n",
      "Epoch 741/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0320 - mae: 0.1287\n",
      "Epoch 742/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0321 - mae: 0.1293\n",
      "Epoch 743/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0312 - mae: 0.1269\n",
      "Epoch 744/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0332 - mae: 0.1312\n",
      "Epoch 745/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0322 - mae: 0.1298\n",
      "Epoch 746/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0317 - mae: 0.1290\n",
      "Epoch 747/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0309 - mae: 0.1262\n",
      "Epoch 748/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0305 - mae: 0.1248\n",
      "Epoch 749/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0319 - mae: 0.1299\n",
      "Epoch 750/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0314 - mae: 0.1286\n",
      "Epoch 751/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0308 - mae: 0.1272\n",
      "Epoch 752/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0301 - mae: 0.1247\n",
      "Epoch 753/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0298 - mae: 0.1247\n",
      "Epoch 754/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0295 - mae: 0.1243\n",
      "Epoch 755/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0292 - mae: 0.1229\n",
      "Epoch 756/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0297 - mae: 0.1246\n",
      "Epoch 757/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0287 - mae: 0.1232\n",
      "Epoch 758/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0300 - mae: 0.1265\n",
      "Epoch 759/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0289 - mae: 0.1236\n",
      "Epoch 760/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0289 - mae: 0.1230\n",
      "Epoch 761/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0301 - mae: 0.1272\n",
      "Epoch 762/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0289 - mae: 0.1244\n",
      "Epoch 763/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0296 - mae: 0.1260\n",
      "Epoch 764/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0591 - mae: 0.1507\n",
      "Epoch 765/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0329 - mae: 0.1353\n",
      "Epoch 766/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0322 - mae: 0.1331\n",
      "Epoch 767/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0319 - mae: 0.1311\n",
      "Epoch 768/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0317 - mae: 0.1310\n",
      "Epoch 769/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0312 - mae: 0.1296\n",
      "Epoch 770/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0306 - mae: 0.1283\n",
      "Epoch 771/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0302 - mae: 0.1264\n",
      "Epoch 772/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0298 - mae: 0.1256\n",
      "Epoch 773/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0298 - mae: 0.1264\n",
      "Epoch 774/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0298 - mae: 0.1253\n",
      "Epoch 775/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0300 - mae: 0.1259\n",
      "Epoch 776/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0290 - mae: 0.1231\n",
      "Epoch 777/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0286 - mae: 0.1230\n",
      "Epoch 778/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0280 - mae: 0.1210\n",
      "Epoch 779/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0280 - mae: 0.1208\n",
      "Epoch 780/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0313 - mae: 0.1322\n",
      "Epoch 781/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0290 - mae: 0.1244\n",
      "Epoch 782/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0273 - mae: 0.1202\n",
      "Epoch 783/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0274 - mae: 0.1199\n",
      "Epoch 784/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0276 - mae: 0.1205\n",
      "Epoch 785/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0282 - mae: 0.1232\n",
      "Epoch 786/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0276 - mae: 0.1211\n",
      "Epoch 787/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0272 - mae: 0.1199\n",
      "Epoch 788/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0276 - mae: 0.1206\n",
      "Epoch 789/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0284 - mae: 0.1240\n",
      "Epoch 790/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0271 - mae: 0.1195\n",
      "Epoch 791/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0274 - mae: 0.1200\n",
      "Epoch 792/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0279 - mae: 0.1214\n",
      "Epoch 793/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0275 - mae: 0.1204\n",
      "Epoch 794/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0275 - mae: 0.1209\n",
      "Epoch 795/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0263 - mae: 0.1183\n",
      "Epoch 796/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0267 - mae: 0.1185\n",
      "Epoch 797/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0278 - mae: 0.1222\n",
      "Epoch 798/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0276 - mae: 0.1221\n",
      "Epoch 799/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0264 - mae: 0.1186\n",
      "Epoch 800/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0264 - mae: 0.1179\n",
      "Epoch 801/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0268 - mae: 0.1200\n",
      "Epoch 802/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0273 - mae: 0.1215\n",
      "Epoch 803/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0267 - mae: 0.1197\n",
      "Epoch 804/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0266 - mae: 0.1190\n",
      "Epoch 805/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0264 - mae: 0.1202\n",
      "Epoch 806/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0272 - mae: 0.1216\n",
      "Epoch 807/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0272 - mae: 0.1218\n",
      "Epoch 808/2000\n",
      "2019/2019 [==============================] - 0s 120us/sample - loss: 0.0283 - mae: 0.1243\n",
      "Epoch 809/2000\n",
      "2019/2019 [==============================] - 0s 151us/sample - loss: 0.0271 - mae: 0.1222\n",
      "Epoch 810/2000\n",
      "2019/2019 [==============================] - 0s 114us/sample - loss: 0.0263 - mae: 0.1192\n",
      "Epoch 811/2000\n",
      "2019/2019 [==============================] - 0s 80us/sample - loss: 0.0255 - mae: 0.1172\n",
      "Epoch 812/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0263 - mae: 0.1187\n",
      "Epoch 813/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0264 - mae: 0.1199\n",
      "Epoch 814/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0261 - mae: 0.1178\n",
      "Epoch 815/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0260 - mae: 0.1191\n",
      "Epoch 816/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0261 - mae: 0.1192\n",
      "Epoch 817/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0254 - mae: 0.1167\n",
      "Epoch 818/2000\n",
      "2019/2019 [==============================] - 0s 129us/sample - loss: 0.0271 - mae: 0.1215\n",
      "Epoch 819/2000\n",
      "2019/2019 [==============================] - 0s 86us/sample - loss: 0.0279 - mae: 0.1243\n",
      "Epoch 820/2000\n",
      "2019/2019 [==============================] - 0s 164us/sample - loss: 0.0335 - mae: 0.1331\n",
      "Epoch 821/2000\n",
      "2019/2019 [==============================] - 0s 84us/sample - loss: 0.0295 - mae: 0.1259\n",
      "Epoch 822/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0283 - mae: 0.1240\n",
      "Epoch 823/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0264 - mae: 0.1196\n",
      "Epoch 824/2000\n",
      "2019/2019 [==============================] - 0s 143us/sample - loss: 0.0265 - mae: 0.1194s - loss: 0.0265 - mae: 0.1\n",
      "Epoch 825/2000\n",
      "2019/2019 [==============================] - 0s 122us/sample - loss: 0.0258 - mae: 0.1176\n",
      "Epoch 826/2000\n",
      "2019/2019 [==============================] - 0s 96us/sample - loss: 0.0260 - mae: 0.1172\n",
      "Epoch 827/2000\n",
      "2019/2019 [==============================] - 0s 93us/sample - loss: 0.0254 - mae: 0.1167\n",
      "Epoch 828/2000\n",
      "2019/2019 [==============================] - 0s 82us/sample - loss: 0.0255 - mae: 0.1169\n",
      "Epoch 829/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0251 - mae: 0.1171\n",
      "Epoch 830/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0266 - mae: 0.1201\n",
      "Epoch 831/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0251 - mae: 0.1173\n",
      "Epoch 832/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0251 - mae: 0.1160\n",
      "Epoch 833/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0248 - mae: 0.1161\n",
      "Epoch 834/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0261 - mae: 0.1204\n",
      "Epoch 835/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0255 - mae: 0.1178\n",
      "Epoch 836/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0564 - mae: 0.1300\n",
      "Epoch 837/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0329 - mae: 0.1386\n",
      "Epoch 838/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0282 - mae: 0.1257\n",
      "Epoch 839/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0269 - mae: 0.1220\n",
      "Epoch 840/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0267 - mae: 0.1214\n",
      "Epoch 841/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0262 - mae: 0.1194\n",
      "Epoch 842/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0261 - mae: 0.1194\n",
      "Epoch 843/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0259 - mae: 0.1187\n",
      "Epoch 844/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0261 - mae: 0.1195\n",
      "Epoch 845/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0252 - mae: 0.1172\n",
      "Epoch 846/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0251 - mae: 0.1168\n",
      "Epoch 847/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0251 - mae: 0.1170\n",
      "Epoch 848/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0257 - mae: 0.1181\n",
      "Epoch 849/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0264 - mae: 0.1198\n",
      "Epoch 850/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0247 - mae: 0.1153\n",
      "Epoch 851/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0254 - mae: 0.1179\n",
      "Epoch 852/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0255 - mae: 0.1188\n",
      "Epoch 853/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0248 - mae: 0.1160\n",
      "Epoch 854/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0247 - mae: 0.1158\n",
      "Epoch 855/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0249 - mae: 0.1169\n",
      "Epoch 856/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0251 - mae: 0.1175\n",
      "Epoch 857/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0244 - mae: 0.1151\n",
      "Epoch 858/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0247 - mae: 0.1158\n",
      "Epoch 859/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0247 - mae: 0.1156\n",
      "Epoch 860/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0246 - mae: 0.1150\n",
      "Epoch 861/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0243 - mae: 0.1155\n",
      "Epoch 862/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0241 - mae: 0.1139\n",
      "Epoch 863/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0241 - mae: 0.1144\n",
      "Epoch 864/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0245 - mae: 0.1151\n",
      "Epoch 865/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0239 - mae: 0.1141\n",
      "Epoch 866/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0237 - mae: 0.1129\n",
      "Epoch 867/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0247 - mae: 0.1162\n",
      "Epoch 868/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0242 - mae: 0.1146\n",
      "Epoch 869/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0248 - mae: 0.1169\n",
      "Epoch 870/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0240 - mae: 0.1137\n",
      "Epoch 871/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0242 - mae: 0.1138\n",
      "Epoch 872/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0242 - mae: 0.1150\n",
      "Epoch 873/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0572 - mae: 0.1442\n",
      "Epoch 874/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0340 - mae: 0.1385\n",
      "Epoch 875/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0301 - mae: 0.1292\n",
      "Epoch 876/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0295 - mae: 0.1275\n",
      "Epoch 877/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0309 - mae: 0.1292\n",
      "Epoch 878/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0282 - mae: 0.1231\n",
      "Epoch 879/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0294 - mae: 0.1259\n",
      "Epoch 880/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0276 - mae: 0.1223\n",
      "Epoch 881/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0270 - mae: 0.1213\n",
      "Epoch 882/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0278 - mae: 0.1225\n",
      "Epoch 883/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0268 - mae: 0.1199\n",
      "Epoch 884/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0268 - mae: 0.1202\n",
      "Epoch 885/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0264 - mae: 0.1189\n",
      "Epoch 886/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0261 - mae: 0.1179\n",
      "Epoch 887/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0273 - mae: 0.1208\n",
      "Epoch 888/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0272 - mae: 0.1211\n",
      "Epoch 889/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0261 - mae: 0.1186\n",
      "Epoch 890/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0260 - mae: 0.1182\n",
      "Epoch 891/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0253 - mae: 0.1159\n",
      "Epoch 892/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0255 - mae: 0.1163\n",
      "Epoch 893/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0254 - mae: 0.1176\n",
      "Epoch 894/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0246 - mae: 0.1139\n",
      "Epoch 895/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0246 - mae: 0.1153\n",
      "Epoch 896/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0244 - mae: 0.1137\n",
      "Epoch 897/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0243 - mae: 0.1133\n",
      "Epoch 898/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0252 - mae: 0.1162\n",
      "Epoch 899/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0242 - mae: 0.1147\n",
      "Epoch 900/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0251 - mae: 0.1168\n",
      "Epoch 901/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0240 - mae: 0.1127\n",
      "Epoch 902/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0241 - mae: 0.1141\n",
      "Epoch 903/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0242 - mae: 0.1140\n",
      "Epoch 904/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0250 - mae: 0.1166\n",
      "Epoch 905/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0241 - mae: 0.1137\n",
      "Epoch 906/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0248 - mae: 0.1156\n",
      "Epoch 907/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0247 - mae: 0.1159\n",
      "Epoch 908/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0256 - mae: 0.1186\n",
      "Epoch 909/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0243 - mae: 0.1149\n",
      "Epoch 910/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0266 - mae: 0.1180\n",
      "Epoch 911/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0260 - mae: 0.1175\n",
      "Epoch 912/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0253 - mae: 0.1175\n",
      "Epoch 913/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0247 - mae: 0.1155\n",
      "Epoch 914/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0245 - mae: 0.1147\n",
      "Epoch 915/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0244 - mae: 0.1142\n",
      "Epoch 916/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0252 - mae: 0.1171\n",
      "Epoch 917/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0242 - mae: 0.1142\n",
      "Epoch 918/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0245 - mae: 0.1154\n",
      "Epoch 919/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0241 - mae: 0.1139\n",
      "Epoch 920/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0248 - mae: 0.1158\n",
      "Epoch 921/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0247 - mae: 0.1156\n",
      "Epoch 922/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0248 - mae: 0.1154\n",
      "Epoch 923/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0243 - mae: 0.1154\n",
      "Epoch 924/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0239 - mae: 0.1126\n",
      "Epoch 925/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0233 - mae: 0.1121\n",
      "Epoch 926/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0245 - mae: 0.1152\n",
      "Epoch 927/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0251 - mae: 0.1157\n",
      "Epoch 928/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0235 - mae: 0.1117\n",
      "Epoch 929/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0236 - mae: 0.1127\n",
      "Epoch 930/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0235 - mae: 0.1124\n",
      "Epoch 931/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0237 - mae: 0.1129\n",
      "Epoch 932/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0237 - mae: 0.1137\n",
      "Epoch 933/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0248 - mae: 0.1160\n",
      "Epoch 934/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0234 - mae: 0.1128\n",
      "Epoch 935/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0240 - mae: 0.1142\n",
      "Epoch 936/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0239 - mae: 0.1144\n",
      "Epoch 937/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0227 - mae: 0.1102\n",
      "Epoch 938/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0234 - mae: 0.1126\n",
      "Epoch 939/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0226 - mae: 0.1099\n",
      "Epoch 940/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0229 - mae: 0.1110\n",
      "Epoch 941/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0230 - mae: 0.1126\n",
      "Epoch 942/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0225 - mae: 0.1100\n",
      "Epoch 943/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0230 - mae: 0.1106\n",
      "Epoch 944/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0234 - mae: 0.1123\n",
      "Epoch 945/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0243 - mae: 0.1151\n",
      "Epoch 946/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0226 - mae: 0.1102\n",
      "Epoch 947/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0227 - mae: 0.1107\n",
      "Epoch 948/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0261 - mae: 0.1173\n",
      "Epoch 949/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0231 - mae: 0.1115\n",
      "Epoch 950/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0233 - mae: 0.1119\n",
      "Epoch 951/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0233 - mae: 0.1124\n",
      "Epoch 952/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0234 - mae: 0.1125\n",
      "Epoch 953/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0229 - mae: 0.1110\n",
      "Epoch 954/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0227 - mae: 0.1105\n",
      "Epoch 955/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0235 - mae: 0.1123\n",
      "Epoch 956/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0227 - mae: 0.1106\n",
      "Epoch 957/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0223 - mae: 0.1087\n",
      "Epoch 958/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0230 - mae: 0.1104\n",
      "Epoch 959/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0242 - mae: 0.1144\n",
      "Epoch 960/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0234 - mae: 0.1123\n",
      "Epoch 961/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0226 - mae: 0.1099\n",
      "Epoch 962/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0223 - mae: 0.1085\n",
      "Epoch 963/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0232 - mae: 0.1120\n",
      "Epoch 964/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0222 - mae: 0.1090\n",
      "Epoch 965/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0227 - mae: 0.1114\n",
      "Epoch 966/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0220 - mae: 0.1084\n",
      "Epoch 967/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0221 - mae: 0.1091\n",
      "Epoch 968/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0223 - mae: 0.1092\n",
      "Epoch 969/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0236 - mae: 0.1138\n",
      "Epoch 970/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0222 - mae: 0.1086\n",
      "Epoch 971/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0220 - mae: 0.1090\n",
      "Epoch 972/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0219 - mae: 0.1077\n",
      "Epoch 973/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0222 - mae: 0.1083\n",
      "Epoch 974/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0223 - mae: 0.1090\n",
      "Epoch 975/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0222 - mae: 0.1088\n",
      "Epoch 976/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0225 - mae: 0.1105\n",
      "Epoch 977/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0227 - mae: 0.1114\n",
      "Epoch 978/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0221 - mae: 0.1085\n",
      "Epoch 979/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0218 - mae: 0.1075\n",
      "Epoch 980/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0219 - mae: 0.1079\n",
      "Epoch 981/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0235 - mae: 0.1126\n",
      "Epoch 982/2000\n",
      "2019/2019 [==============================] - 0s 78us/sample - loss: 0.0223 - mae: 0.1085\n",
      "Epoch 983/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0226 - mae: 0.1108\n",
      "Epoch 984/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0215 - mae: 0.1072\n",
      "Epoch 985/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0218 - mae: 0.1081\n",
      "Epoch 986/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0220 - mae: 0.1082\n",
      "Epoch 987/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0220 - mae: 0.1085\n",
      "Epoch 988/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0226 - mae: 0.1102\n",
      "Epoch 989/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0218 - mae: 0.1078\n",
      "Epoch 990/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0241 - mae: 0.1144\n",
      "Epoch 991/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0218 - mae: 0.1075\n",
      "Epoch 992/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0217 - mae: 0.1070\n",
      "Epoch 993/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0228 - mae: 0.1113\n",
      "Epoch 994/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0230 - mae: 0.1118\n",
      "Epoch 995/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0221 - mae: 0.1092\n",
      "Epoch 996/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0224 - mae: 0.1097\n",
      "Epoch 997/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0220 - mae: 0.1092\n",
      "Epoch 998/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0222 - mae: 0.1097\n",
      "Epoch 999/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0224 - mae: 0.1095\n",
      "Epoch 1000/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0220 - mae: 0.1090\n",
      "Epoch 1001/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0250 - mae: 0.1189\n",
      "Epoch 1002/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0221 - mae: 0.1086\n",
      "Epoch 1003/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0228 - mae: 0.1106\n",
      "Epoch 1004/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0221 - mae: 0.1086\n",
      "Epoch 1005/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0220 - mae: 0.1085\n",
      "Epoch 1006/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0218 - mae: 0.1078\n",
      "Epoch 1007/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0221 - mae: 0.1090\n",
      "Epoch 1008/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0222 - mae: 0.1096\n",
      "Epoch 1009/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0223 - mae: 0.1099\n",
      "Epoch 1010/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0222 - mae: 0.1091\n",
      "Epoch 1011/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0216 - mae: 0.1074\n",
      "Epoch 1012/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0217 - mae: 0.1075\n",
      "Epoch 1013/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0215 - mae: 0.1066\n",
      "Epoch 1014/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0224 - mae: 0.1106\n",
      "Epoch 1015/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0215 - mae: 0.1063\n",
      "Epoch 1016/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0218 - mae: 0.1082\n",
      "Epoch 1017/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0216 - mae: 0.1071\n",
      "Epoch 1018/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0217 - mae: 0.1080\n",
      "Epoch 1019/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0229 - mae: 0.1116\n",
      "Epoch 1020/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0215 - mae: 0.1077\n",
      "Epoch 1021/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0223 - mae: 0.1088\n",
      "Epoch 1022/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0216 - mae: 0.1076\n",
      "Epoch 1023/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0223 - mae: 0.1098\n",
      "Epoch 1024/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0227 - mae: 0.1106\n",
      "Epoch 1025/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0219 - mae: 0.1074\n",
      "Epoch 1026/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0211 - mae: 0.1055\n",
      "Epoch 1027/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0220 - mae: 0.1086\n",
      "Epoch 1028/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0216 - mae: 0.1073\n",
      "Epoch 1029/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0222 - mae: 0.1095\n",
      "Epoch 1030/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0219 - mae: 0.1079\n",
      "Epoch 1031/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0220 - mae: 0.1084\n",
      "Epoch 1032/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0216 - mae: 0.1084\n",
      "Epoch 1033/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0234 - mae: 0.1130\n",
      "Epoch 1034/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0214 - mae: 0.1076\n",
      "Epoch 1035/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0215 - mae: 0.1077\n",
      "Epoch 1036/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0213 - mae: 0.1059\n",
      "Epoch 1037/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0214 - mae: 0.1070\n",
      "Epoch 1038/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0221 - mae: 0.1087\n",
      "Epoch 1039/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0216 - mae: 0.1076\n",
      "Epoch 1040/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0254 - mae: 0.1173\n",
      "Epoch 1041/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0229 - mae: 0.1114\n",
      "Epoch 1042/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0215 - mae: 0.1069\n",
      "Epoch 1043/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0220 - mae: 0.1084\n",
      "Epoch 1044/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0218 - mae: 0.1085\n",
      "Epoch 1045/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0212 - mae: 0.1064\n",
      "Epoch 1046/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0212 - mae: 0.1068\n",
      "Epoch 1047/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0214 - mae: 0.1070\n",
      "Epoch 1048/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0274 - mae: 0.1196\n",
      "Epoch 1049/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0248 - mae: 0.1156\n",
      "Epoch 1050/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0242 - mae: 0.1149\n",
      "Epoch 1051/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0230 - mae: 0.1107\n",
      "Epoch 1052/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0232 - mae: 0.1119\n",
      "Epoch 1053/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0222 - mae: 0.1093\n",
      "Epoch 1054/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0218 - mae: 0.1081\n",
      "Epoch 1055/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0217 - mae: 0.1083\n",
      "Epoch 1056/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0228 - mae: 0.1119\n",
      "Epoch 1057/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0222 - mae: 0.1089\n",
      "Epoch 1058/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0219 - mae: 0.1089\n",
      "Epoch 1059/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0213 - mae: 0.1069\n",
      "Epoch 1060/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0253 - mae: 0.1187\n",
      "Epoch 1061/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0214 - mae: 0.1075\n",
      "Epoch 1062/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0231 - mae: 0.1112\n",
      "Epoch 1063/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0215 - mae: 0.1065\n",
      "Epoch 1064/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0237 - mae: 0.1155\n",
      "Epoch 1065/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0213 - mae: 0.1060\n",
      "Epoch 1066/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0210 - mae: 0.1064\n",
      "Epoch 1067/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0214 - mae: 0.1069\n",
      "Epoch 1068/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0215 - mae: 0.1080\n",
      "Epoch 1069/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0223 - mae: 0.1098\n",
      "Epoch 1070/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0217 - mae: 0.1082\n",
      "Epoch 1071/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0230 - mae: 0.1125\n",
      "Epoch 1072/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0221 - mae: 0.1098\n",
      "Epoch 1073/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0222 - mae: 0.1096\n",
      "Epoch 1074/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0211 - mae: 0.1055\n",
      "Epoch 1075/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0211 - mae: 0.1064\n",
      "Epoch 1076/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0218 - mae: 0.1091\n",
      "Epoch 1077/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0211 - mae: 0.1071\n",
      "Epoch 1078/2000\n",
      "2019/2019 [==============================] - 0s 74us/sample - loss: 0.0211 - mae: 0.1059\n",
      "Epoch 1079/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0207 - mae: 0.1056\n",
      "Epoch 1080/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0222 - mae: 0.1097\n",
      "Epoch 1081/2000\n",
      "2019/2019 [==============================] - 0s 115us/sample - loss: 0.0207 - mae: 0.1047\n",
      "Epoch 1082/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0214 - mae: 0.1065\n",
      "Epoch 1083/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0210 - mae: 0.1056\n",
      "Epoch 1084/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0219 - mae: 0.1092\n",
      "Epoch 1085/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0227 - mae: 0.1116\n",
      "Epoch 1086/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0231 - mae: 0.1133\n",
      "Epoch 1087/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0238 - mae: 0.1135\n",
      "Epoch 1088/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0209 - mae: 0.1053\n",
      "Epoch 1089/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0209 - mae: 0.1062\n",
      "Epoch 1090/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0214 - mae: 0.1080\n",
      "Epoch 1091/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0209 - mae: 0.1062\n",
      "Epoch 1092/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0209 - mae: 0.1046\n",
      "Epoch 1093/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0212 - mae: 0.1066\n",
      "Epoch 1094/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0208 - mae: 0.1054\n",
      "Epoch 1095/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0218 - mae: 0.1087\n",
      "Epoch 1096/2000\n",
      "2019/2019 [==============================] - 0s 76us/sample - loss: 0.0215 - mae: 0.1079\n",
      "Epoch 1097/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0223 - mae: 0.1108\n",
      "Epoch 1098/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0218 - mae: 0.1086\n",
      "Epoch 1099/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0213 - mae: 0.1082\n",
      "Epoch 1100/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0214 - mae: 0.1070\n",
      "Epoch 1101/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0218 - mae: 0.1086\n",
      "Epoch 1102/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0215 - mae: 0.1067\n",
      "Epoch 1103/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0209 - mae: 0.1060\n",
      "Epoch 1104/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0212 - mae: 0.1068\n",
      "Epoch 1105/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0235 - mae: 0.1103\n",
      "Epoch 1106/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0217 - mae: 0.1079\n",
      "Epoch 1107/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0300 - mae: 0.1254\n",
      "Epoch 1108/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0275 - mae: 0.1228\n",
      "Epoch 1109/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0272 - mae: 0.1215\n",
      "Epoch 1110/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0257 - mae: 0.1176\n",
      "Epoch 1111/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0280 - mae: 0.1239\n",
      "Epoch 1112/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0330 - mae: 0.1404\n",
      "Epoch 1113/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0264 - mae: 0.1185\n",
      "Epoch 1114/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0250 - mae: 0.1161\n",
      "Epoch 1115/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0243 - mae: 0.1140\n",
      "Epoch 1116/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0255 - mae: 0.1174\n",
      "Epoch 1117/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0238 - mae: 0.1133\n",
      "Epoch 1118/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0239 - mae: 0.1133\n",
      "Epoch 1119/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0232 - mae: 0.1118\n",
      "Epoch 1120/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0231 - mae: 0.1115\n",
      "Epoch 1121/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0231 - mae: 0.1112\n",
      "Epoch 1122/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0230 - mae: 0.1114\n",
      "Epoch 1123/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0228 - mae: 0.1111\n",
      "Epoch 1124/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0236 - mae: 0.1140\n",
      "Epoch 1125/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0221 - mae: 0.1094\n",
      "Epoch 1126/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0224 - mae: 0.1092\n",
      "Epoch 1127/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0225 - mae: 0.1100\n",
      "Epoch 1128/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0222 - mae: 0.1092\n",
      "Epoch 1129/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0230 - mae: 0.1111\n",
      "Epoch 1130/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0220 - mae: 0.1097\n",
      "Epoch 1131/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0219 - mae: 0.1080\n",
      "Epoch 1132/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0219 - mae: 0.1086\n",
      "Epoch 1133/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0220 - mae: 0.1093\n",
      "Epoch 1134/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0221 - mae: 0.1090\n",
      "Epoch 1135/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0212 - mae: 0.1064\n",
      "Epoch 1136/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0212 - mae: 0.1061\n",
      "Epoch 1137/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0211 - mae: 0.1058\n",
      "Epoch 1138/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0211 - mae: 0.1062\n",
      "Epoch 1139/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0213 - mae: 0.1078\n",
      "Epoch 1140/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0215 - mae: 0.1082\n",
      "Epoch 1141/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0221 - mae: 0.1100\n",
      "Epoch 1142/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0218 - mae: 0.1073\n",
      "Epoch 1143/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0213 - mae: 0.1068\n",
      "Epoch 1144/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0213 - mae: 0.1083\n",
      "Epoch 1145/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0208 - mae: 0.1053\n",
      "Epoch 1146/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0213 - mae: 0.1073\n",
      "Epoch 1147/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0214 - mae: 0.1074\n",
      "Epoch 1148/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0215 - mae: 0.1084\n",
      "Epoch 1149/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0214 - mae: 0.1074\n",
      "Epoch 1150/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0213 - mae: 0.1070\n",
      "Epoch 1151/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0208 - mae: 0.1053\n",
      "Epoch 1152/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0215 - mae: 0.1082\n",
      "Epoch 1153/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0209 - mae: 0.1058\n",
      "Epoch 1154/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0223 - mae: 0.1109\n",
      "Epoch 1155/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0222 - mae: 0.1105\n",
      "Epoch 1156/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0212 - mae: 0.1061\n",
      "Epoch 1157/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0219 - mae: 0.1094\n",
      "Epoch 1158/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0222 - mae: 0.1095\n",
      "Epoch 1159/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0219 - mae: 0.1085\n",
      "Epoch 1160/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0215 - mae: 0.1077\n",
      "Epoch 1161/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0209 - mae: 0.1055\n",
      "Epoch 1162/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0209 - mae: 0.1059\n",
      "Epoch 1163/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0210 - mae: 0.1059\n",
      "Epoch 1164/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0208 - mae: 0.1045\n",
      "Epoch 1165/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0213 - mae: 0.1079\n",
      "Epoch 1166/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0274 - mae: 0.1148\n",
      "Epoch 1167/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0221 - mae: 0.1083\n",
      "Epoch 1168/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0219 - mae: 0.1087\n",
      "Epoch 1169/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0219 - mae: 0.1090\n",
      "Epoch 1170/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0221 - mae: 0.1088\n",
      "Epoch 1171/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0220 - mae: 0.1086\n",
      "Epoch 1172/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0212 - mae: 0.1057\n",
      "Epoch 1173/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0220 - mae: 0.1097\n",
      "Epoch 1174/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0221 - mae: 0.1091\n",
      "Epoch 1175/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0218 - mae: 0.1088\n",
      "Epoch 1176/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0215 - mae: 0.1066\n",
      "Epoch 1177/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0227 - mae: 0.1121\n",
      "Epoch 1178/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0212 - mae: 0.1072\n",
      "Epoch 1179/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0208 - mae: 0.1054\n",
      "Epoch 1180/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0211 - mae: 0.1066\n",
      "Epoch 1181/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0210 - mae: 0.1057\n",
      "Epoch 1182/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0216 - mae: 0.1076\n",
      "Epoch 1183/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0211 - mae: 0.1063\n",
      "Epoch 1184/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0211 - mae: 0.1072\n",
      "Epoch 1185/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0211 - mae: 0.1064\n",
      "Epoch 1186/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0211 - mae: 0.1071\n",
      "Epoch 1187/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0213 - mae: 0.1070\n",
      "Epoch 1188/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0219 - mae: 0.1071\n",
      "Epoch 1189/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0215 - mae: 0.1073\n",
      "Epoch 1190/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0215 - mae: 0.1073\n",
      "Epoch 1191/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0214 - mae: 0.1069\n",
      "Epoch 1192/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0209 - mae: 0.1060\n",
      "Epoch 1193/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0212 - mae: 0.1069\n",
      "Epoch 1194/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0216 - mae: 0.1086\n",
      "Epoch 1195/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0220 - mae: 0.1091\n",
      "Epoch 1196/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0214 - mae: 0.1081\n",
      "Epoch 1197/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0212 - mae: 0.1073\n",
      "Epoch 1198/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0204 - mae: 0.1040\n",
      "Epoch 1199/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0204 - mae: 0.1047\n",
      "Epoch 1200/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0225 - mae: 0.1102\n",
      "Epoch 1201/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0211 - mae: 0.1063\n",
      "Epoch 1202/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0206 - mae: 0.1051\n",
      "Epoch 1203/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0209 - mae: 0.1057\n",
      "Epoch 1204/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0206 - mae: 0.1040\n",
      "Epoch 1205/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0204 - mae: 0.1042\n",
      "Epoch 1206/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0219 - mae: 0.1081\n",
      "Epoch 1207/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0234 - mae: 0.1125\n",
      "Epoch 1208/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0224 - mae: 0.1111\n",
      "Epoch 1209/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0210 - mae: 0.1058\n",
      "Epoch 1210/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0234 - mae: 0.1127\n",
      "Epoch 1211/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0212 - mae: 0.1067\n",
      "Epoch 1212/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1038\n",
      "Epoch 1213/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0205 - mae: 0.1040\n",
      "Epoch 1214/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0213 - mae: 0.1070\n",
      "Epoch 1215/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0213 - mae: 0.1073\n",
      "Epoch 1216/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0202 - mae: 0.1031\n",
      "Epoch 1217/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0205 - mae: 0.1041\n",
      "Epoch 1218/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0205 - mae: 0.1045\n",
      "Epoch 1219/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0211 - mae: 0.1065\n",
      "Epoch 1220/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0212 - mae: 0.1068\n",
      "Epoch 1221/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0203 - mae: 0.1032\n",
      "Epoch 1222/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0204 - mae: 0.1045\n",
      "Epoch 1223/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0205 - mae: 0.1044\n",
      "Epoch 1224/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1035\n",
      "Epoch 1225/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0204 - mae: 0.1045\n",
      "Epoch 1226/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0212 - mae: 0.1078\n",
      "Epoch 1227/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0208 - mae: 0.1055\n",
      "Epoch 1228/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0200 - mae: 0.1029\n",
      "Epoch 1229/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0202 - mae: 0.1034\n",
      "Epoch 1230/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0208 - mae: 0.1059\n",
      "Epoch 1231/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0233 - mae: 0.1124\n",
      "Epoch 1232/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0212 - mae: 0.1062\n",
      "Epoch 1233/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0201 - mae: 0.1035\n",
      "Epoch 1234/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0242 - mae: 0.1147\n",
      "Epoch 1235/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0204 - mae: 0.1045\n",
      "Epoch 1236/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0211 - mae: 0.1059\n",
      "Epoch 1237/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0221 - mae: 0.1098\n",
      "Epoch 1238/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0204 - mae: 0.1038\n",
      "Epoch 1239/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0228 - mae: 0.1120\n",
      "Epoch 1240/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0205 - mae: 0.1052\n",
      "Epoch 1241/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0203 - mae: 0.1036\n",
      "Epoch 1242/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0208 - mae: 0.1044\n",
      "Epoch 1243/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0205 - mae: 0.1052\n",
      "Epoch 1244/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0217 - mae: 0.1074\n",
      "Epoch 1245/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1034\n",
      "Epoch 1246/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0220 - mae: 0.1090\n",
      "Epoch 1247/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0208 - mae: 0.1053\n",
      "Epoch 1248/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0207 - mae: 0.1047\n",
      "Epoch 1249/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0202 - mae: 0.1039\n",
      "Epoch 1250/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0199 - mae: 0.1035\n",
      "Epoch 1251/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0207 - mae: 0.1059\n",
      "Epoch 1252/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0227 - mae: 0.1103\n",
      "Epoch 1253/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0212 - mae: 0.1074\n",
      "Epoch 1254/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0212 - mae: 0.1062\n",
      "Epoch 1255/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0201 - mae: 0.1030\n",
      "Epoch 1256/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0204 - mae: 0.1042\n",
      "Epoch 1257/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0205 - mae: 0.1050\n",
      "Epoch 1258/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0201 - mae: 0.1029\n",
      "Epoch 1259/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0205 - mae: 0.1040\n",
      "Epoch 1260/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0203 - mae: 0.1039\n",
      "Epoch 1261/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0203 - mae: 0.1038\n",
      "Epoch 1262/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0212 - mae: 0.1068\n",
      "Epoch 1263/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0208 - mae: 0.1061\n",
      "Epoch 1264/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0202 - mae: 0.1042\n",
      "Epoch 1265/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0255 - mae: 0.1165\n",
      "Epoch 1266/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0276 - mae: 0.1240\n",
      "Epoch 1267/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0220 - mae: 0.1094\n",
      "Epoch 1268/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0214 - mae: 0.1075\n",
      "Epoch 1269/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0205 - mae: 0.1050\n",
      "Epoch 1270/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0212 - mae: 0.1069\n",
      "Epoch 1271/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0207 - mae: 0.1052\n",
      "Epoch 1272/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0202 - mae: 0.1038\n",
      "Epoch 1273/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0213 - mae: 0.1071\n",
      "Epoch 1274/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0206 - mae: 0.1053\n",
      "Epoch 1275/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0200 - mae: 0.1027\n",
      "Epoch 1276/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0206 - mae: 0.1044\n",
      "Epoch 1277/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0205 - mae: 0.1032\n",
      "Epoch 1278/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0201 - mae: 0.1025\n",
      "Epoch 1279/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0201 - mae: 0.1029\n",
      "Epoch 1280/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0199 - mae: 0.1028\n",
      "Epoch 1281/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0205 - mae: 0.1047\n",
      "Epoch 1282/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0202 - mae: 0.1028\n",
      "Epoch 1283/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0200 - mae: 0.1023\n",
      "Epoch 1284/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0206 - mae: 0.1057\n",
      "Epoch 1285/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0202 - mae: 0.1036\n",
      "Epoch 1286/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0203 - mae: 0.1041\n",
      "Epoch 1287/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0200 - mae: 0.1026\n",
      "Epoch 1288/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0196 - mae: 0.1019\n",
      "Epoch 1289/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0213 - mae: 0.1069\n",
      "Epoch 1290/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0213 - mae: 0.1071\n",
      "Epoch 1291/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0201 - mae: 0.1030\n",
      "Epoch 1292/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0210 - mae: 0.1059\n",
      "Epoch 1293/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0205 - mae: 0.1048\n",
      "Epoch 1294/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1030\n",
      "Epoch 1295/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1034\n",
      "Epoch 1296/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0215 - mae: 0.1073\n",
      "Epoch 1297/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0201 - mae: 0.1028\n",
      "Epoch 1298/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0210 - mae: 0.1051\n",
      "Epoch 1299/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0203 - mae: 0.1039\n",
      "Epoch 1300/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0207 - mae: 0.1044\n",
      "Epoch 1301/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0203 - mae: 0.1046\n",
      "Epoch 1302/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0215 - mae: 0.1087\n",
      "Epoch 1303/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0212 - mae: 0.1059\n",
      "Epoch 1304/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0214 - mae: 0.1076\n",
      "Epoch 1305/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0201 - mae: 0.1028\n",
      "Epoch 1306/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0214 - mae: 0.1075\n",
      "Epoch 1307/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0209 - mae: 0.1049\n",
      "Epoch 1308/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0204 - mae: 0.1047\n",
      "Epoch 1309/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0204 - mae: 0.1040\n",
      "Epoch 1310/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0215 - mae: 0.1079\n",
      "Epoch 1311/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0207 - mae: 0.1053\n",
      "Epoch 1312/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1025\n",
      "Epoch 1313/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0207 - mae: 0.1052\n",
      "Epoch 1314/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0200 - mae: 0.1027\n",
      "Epoch 1315/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0267 - mae: 0.1133\n",
      "Epoch 1316/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0214 - mae: 0.1070\n",
      "Epoch 1317/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0218 - mae: 0.1080\n",
      "Epoch 1318/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0212 - mae: 0.1062\n",
      "Epoch 1319/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0220 - mae: 0.1090\n",
      "Epoch 1320/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0208 - mae: 0.1056\n",
      "Epoch 1321/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0211 - mae: 0.1060\n",
      "Epoch 1322/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0206 - mae: 0.1045\n",
      "Epoch 1323/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0206 - mae: 0.1040\n",
      "Epoch 1324/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0215 - mae: 0.1075\n",
      "Epoch 1325/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0201 - mae: 0.1020\n",
      "Epoch 1326/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1037\n",
      "Epoch 1327/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1023\n",
      "Epoch 1328/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0220 - mae: 0.1093\n",
      "Epoch 1329/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 81us/sample - loss: 0.0204 - mae: 0.1036\n",
      "Epoch 1330/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0208 - mae: 0.1052\n",
      "Epoch 1331/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0199 - mae: 0.1023\n",
      "Epoch 1332/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0202 - mae: 0.1042\n",
      "Epoch 1333/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0209 - mae: 0.1060\n",
      "Epoch 1334/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0204 - mae: 0.1043\n",
      "Epoch 1335/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0207 - mae: 0.1058\n",
      "Epoch 1336/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1021\n",
      "Epoch 1337/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0202 - mae: 0.1037\n",
      "Epoch 1338/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0195 - mae: 0.1015\n",
      "Epoch 1339/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0197 - mae: 0.1021\n",
      "Epoch 1340/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0214 - mae: 0.1062\n",
      "Epoch 1341/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0206 - mae: 0.1043\n",
      "Epoch 1342/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0205 - mae: 0.1046\n",
      "Epoch 1343/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0207 - mae: 0.1046\n",
      "Epoch 1344/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0203 - mae: 0.1036\n",
      "Epoch 1345/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0220 - mae: 0.1094\n",
      "Epoch 1346/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0200 - mae: 0.1029\n",
      "Epoch 1347/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0204 - mae: 0.1039\n",
      "Epoch 1348/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0199 - mae: 0.1030\n",
      "Epoch 1349/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0210 - mae: 0.1050\n",
      "Epoch 1350/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0213 - mae: 0.1067\n",
      "Epoch 1351/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0205 - mae: 0.1041\n",
      "Epoch 1352/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0201 - mae: 0.1027\n",
      "Epoch 1353/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0209 - mae: 0.1058\n",
      "Epoch 1354/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0207 - mae: 0.1054\n",
      "Epoch 1355/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0196 - mae: 0.1016\n",
      "Epoch 1356/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0202 - mae: 0.1035\n",
      "Epoch 1357/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0202 - mae: 0.1040\n",
      "Epoch 1358/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1031\n",
      "Epoch 1359/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0204 - mae: 0.1045\n",
      "Epoch 1360/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0201 - mae: 0.1025\n",
      "Epoch 1361/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0211 - mae: 0.1050\n",
      "Epoch 1362/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0215 - mae: 0.1074\n",
      "Epoch 1363/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0220 - mae: 0.1092\n",
      "Epoch 1364/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0212 - mae: 0.1060\n",
      "Epoch 1365/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0205 - mae: 0.1042\n",
      "Epoch 1366/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0209 - mae: 0.1053\n",
      "Epoch 1367/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0202 - mae: 0.1039\n",
      "Epoch 1368/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0202 - mae: 0.1030\n",
      "Epoch 1369/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1040\n",
      "Epoch 1370/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0214 - mae: 0.1071\n",
      "Epoch 1371/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0209 - mae: 0.1062\n",
      "Epoch 1372/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0205 - mae: 0.1044\n",
      "Epoch 1373/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0204 - mae: 0.1035\n",
      "Epoch 1374/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0199 - mae: 0.1024\n",
      "Epoch 1375/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0198 - mae: 0.1023\n",
      "Epoch 1376/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.1009\n",
      "Epoch 1377/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0206 - mae: 0.1056\n",
      "Epoch 1378/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0204 - mae: 0.1051\n",
      "Epoch 1379/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0216 - mae: 0.1082\n",
      "Epoch 1380/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0197 - mae: 0.1025\n",
      "Epoch 1381/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1034\n",
      "Epoch 1382/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0193 - mae: 0.1007\n",
      "Epoch 1383/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0202 - mae: 0.1037\n",
      "Epoch 1384/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0213 - mae: 0.1066\n",
      "Epoch 1385/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0198 - mae: 0.1021\n",
      "Epoch 1386/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0195 - mae: 0.1013\n",
      "Epoch 1387/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1036\n",
      "Epoch 1388/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0198 - mae: 0.1018\n",
      "Epoch 1389/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0223 - mae: 0.1101\n",
      "Epoch 1390/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0196 - mae: 0.1021\n",
      "Epoch 1391/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0198 - mae: 0.1016\n",
      "Epoch 1392/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0194 - mae: 0.1015\n",
      "Epoch 1393/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1037\n",
      "Epoch 1394/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0251 - mae: 0.1149\n",
      "Epoch 1395/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0210 - mae: 0.1062\n",
      "Epoch 1396/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0202 - mae: 0.1035\n",
      "Epoch 1397/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0204 - mae: 0.1052\n",
      "Epoch 1398/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0198 - mae: 0.1030\n",
      "Epoch 1399/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1031\n",
      "Epoch 1400/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0206 - mae: 0.1049\n",
      "Epoch 1401/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0196 - mae: 0.1018\n",
      "Epoch 1402/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0199 - mae: 0.1021\n",
      "Epoch 1403/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0221 - mae: 0.1107\n",
      "Epoch 1404/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0200 - mae: 0.1034\n",
      "Epoch 1405/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0198 - mae: 0.1021\n",
      "Epoch 1406/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.1012\n",
      "Epoch 1407/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0194 - mae: 0.1008\n",
      "Epoch 1408/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0212 - mae: 0.1065\n",
      "Epoch 1409/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1011\n",
      "Epoch 1410/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0219 - mae: 0.1082\n",
      "Epoch 1411/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0206 - mae: 0.1050\n",
      "Epoch 1412/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1029\n",
      "Epoch 1413/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0198 - mae: 0.1031\n",
      "Epoch 1414/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0211 - mae: 0.1066\n",
      "Epoch 1415/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0201 - mae: 0.1035\n",
      "Epoch 1416/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0198 - mae: 0.1017\n",
      "Epoch 1417/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0195 - mae: 0.1015\n",
      "Epoch 1418/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0211 - mae: 0.1072\n",
      "Epoch 1419/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1012\n",
      "Epoch 1420/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0214 - mae: 0.1066\n",
      "Epoch 1421/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0205 - mae: 0.1046\n",
      "Epoch 1422/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0205 - mae: 0.1039\n",
      "Epoch 1423/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1016\n",
      "Epoch 1424/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0197 - mae: 0.1021\n",
      "Epoch 1425/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0201 - mae: 0.1038\n",
      "Epoch 1426/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0213 - mae: 0.1081\n",
      "Epoch 1427/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0193 - mae: 0.1003\n",
      "Epoch 1428/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0296 - mae: 0.1279\n",
      "Epoch 1429/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0252 - mae: 0.1178\n",
      "Epoch 1430/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0241 - mae: 0.1139\n",
      "Epoch 1431/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0226 - mae: 0.1118\n",
      "Epoch 1432/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0217 - mae: 0.1086\n",
      "Epoch 1433/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0214 - mae: 0.1069\n",
      "Epoch 1434/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0212 - mae: 0.1073\n",
      "Epoch 1435/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0222 - mae: 0.1092\n",
      "Epoch 1436/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0205 - mae: 0.1046\n",
      "Epoch 1437/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0207 - mae: 0.1057\n",
      "Epoch 1438/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0204 - mae: 0.1044\n",
      "Epoch 1439/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0207 - mae: 0.1055\n",
      "Epoch 1440/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0200 - mae: 0.1032\n",
      "Epoch 1441/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0207 - mae: 0.1057\n",
      "Epoch 1442/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0211 - mae: 0.1067\n",
      "Epoch 1443/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0202 - mae: 0.1037\n",
      "Epoch 1444/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0196 - mae: 0.1017\n",
      "Epoch 1445/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0204 - mae: 0.1050\n",
      "Epoch 1446/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1035\n",
      "Epoch 1447/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1029\n",
      "Epoch 1448/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1018\n",
      "Epoch 1449/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0198 - mae: 0.1018\n",
      "Epoch 1450/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0198 - mae: 0.1031\n",
      "Epoch 1451/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0202 - mae: 0.1041\n",
      "Epoch 1452/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0206 - mae: 0.1051\n",
      "Epoch 1453/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0201 - mae: 0.1031\n",
      "Epoch 1454/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1027\n",
      "Epoch 1455/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0196 - mae: 0.1020\n",
      "Epoch 1456/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0206 - mae: 0.1052\n",
      "Epoch 1457/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1020\n",
      "Epoch 1458/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1022\n",
      "Epoch 1459/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.1014\n",
      "Epoch 1460/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1005\n",
      "Epoch 1461/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0209 - mae: 0.1066\n",
      "Epoch 1462/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0194 - mae: 0.1007\n",
      "Epoch 1463/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0203 - mae: 0.1047\n",
      "Epoch 1464/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0197 - mae: 0.1017\n",
      "Epoch 1465/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0202 - mae: 0.1030\n",
      "Epoch 1466/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1034\n",
      "Epoch 1467/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0198 - mae: 0.1021\n",
      "Epoch 1468/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0208 - mae: 0.1051\n",
      "Epoch 1469/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0193 - mae: 0.1006\n",
      "Epoch 1470/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1035\n",
      "Epoch 1471/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1031\n",
      "Epoch 1472/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1041\n",
      "Epoch 1473/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0202 - mae: 0.1040\n",
      "Epoch 1474/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0200 - mae: 0.1040\n",
      "Epoch 1475/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0194 - mae: 0.1009\n",
      "Epoch 1476/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0195 - mae: 0.1012\n",
      "Epoch 1477/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0194 - mae: 0.1013\n",
      "Epoch 1478/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0198 - mae: 0.1016\n",
      "Epoch 1479/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0193 - mae: 0.1008\n",
      "Epoch 1480/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0196 - mae: 0.1021\n",
      "Epoch 1481/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1039\n",
      "Epoch 1482/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0193 - mae: 0.1009\n",
      "Epoch 1483/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1013\n",
      "Epoch 1484/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0200 - mae: 0.1035\n",
      "Epoch 1485/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0196 - mae: 0.1017\n",
      "Epoch 1486/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0197 - mae: 0.1016\n",
      "Epoch 1487/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0199 - mae: 0.1030\n",
      "Epoch 1488/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0193 - mae: 0.1013\n",
      "Epoch 1489/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1016\n",
      "Epoch 1490/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0194 - mae: 0.1014\n",
      "Epoch 1491/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1050\n",
      "Epoch 1492/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1024\n",
      "Epoch 1493/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0204 - mae: 0.1047\n",
      "Epoch 1494/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0211 - mae: 0.1067\n",
      "Epoch 1495/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0191 - mae: 0.0995\n",
      "Epoch 1496/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1007\n",
      "Epoch 1497/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0202 - mae: 0.1040\n",
      "Epoch 1498/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0193 - mae: 0.1005\n",
      "Epoch 1499/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0202 - mae: 0.1044\n",
      "Epoch 1500/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0214 - mae: 0.1074\n",
      "Epoch 1501/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1014\n",
      "Epoch 1502/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0199 - mae: 0.1027\n",
      "Epoch 1503/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0217 - mae: 0.1089\n",
      "Epoch 1504/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0196 - mae: 0.1016\n",
      "Epoch 1505/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0194 - mae: 0.1007\n",
      "Epoch 1506/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0209 - mae: 0.1055\n",
      "Epoch 1507/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1047\n",
      "Epoch 1508/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1048\n",
      "Epoch 1509/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0205 - mae: 0.1054\n",
      "Epoch 1510/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0218 - mae: 0.1088\n",
      "Epoch 1511/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0199 - mae: 0.1035\n",
      "Epoch 1512/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0199 - mae: 0.1019\n",
      "Epoch 1513/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0220 - mae: 0.1091\n",
      "Epoch 1514/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0199 - mae: 0.1028\n",
      "Epoch 1515/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0199 - mae: 0.1037\n",
      "Epoch 1516/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0199 - mae: 0.1027\n",
      "Epoch 1517/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0193 - mae: 0.1004\n",
      "Epoch 1518/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0196 - mae: 0.1025\n",
      "Epoch 1519/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0197 - mae: 0.1022\n",
      "Epoch 1520/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0199 - mae: 0.1025\n",
      "Epoch 1521/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0192 - mae: 0.1006\n",
      "Epoch 1522/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0206 - mae: 0.1053\n",
      "Epoch 1523/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0193 - mae: 0.1009\n",
      "Epoch 1524/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0197 - mae: 0.1033\n",
      "Epoch 1525/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0194 - mae: 0.1012\n",
      "Epoch 1526/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0191 - mae: 0.0999\n",
      "Epoch 1527/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1011\n",
      "Epoch 1528/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0201 - mae: 0.1039\n",
      "Epoch 1529/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.0992\n",
      "Epoch 1530/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0201 - mae: 0.1036\n",
      "Epoch 1531/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1029\n",
      "Epoch 1532/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0194 - mae: 0.1014\n",
      "Epoch 1533/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0199 - mae: 0.1028\n",
      "Epoch 1534/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0201 - mae: 0.1036\n",
      "Epoch 1535/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0196 - mae: 0.1022\n",
      "Epoch 1536/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0201 - mae: 0.1037\n",
      "Epoch 1537/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1024\n",
      "Epoch 1538/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0201 - mae: 0.1025\n",
      "Epoch 1539/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1018\n",
      "Epoch 1540/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.1002\n",
      "Epoch 1541/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0196 - mae: 0.1020\n",
      "Epoch 1542/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0191 - mae: 0.1004\n",
      "Epoch 1543/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1039\n",
      "Epoch 1544/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0193 - mae: 0.1006\n",
      "Epoch 1545/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0189 - mae: 0.0990\n",
      "Epoch 1546/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0193 - mae: 0.1016\n",
      "Epoch 1547/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0194 - mae: 0.1006\n",
      "Epoch 1548/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0194 - mae: 0.1014\n",
      "Epoch 1549/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1009\n",
      "Epoch 1550/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0220 - mae: 0.1087\n",
      "Epoch 1551/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0204 - mae: 0.1033\n",
      "Epoch 1552/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1048\n",
      "Epoch 1553/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0203 - mae: 0.1034\n",
      "Epoch 1554/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0193 - mae: 0.1006\n",
      "Epoch 1555/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1003\n",
      "Epoch 1556/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0193 - mae: 0.1011\n",
      "Epoch 1557/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0191 - mae: 0.1002\n",
      "Epoch 1558/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0202 - mae: 0.1049\n",
      "Epoch 1559/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0193 - mae: 0.1009\n",
      "Epoch 1560/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0191 - mae: 0.1004\n",
      "Epoch 1561/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0201 - mae: 0.1036\n",
      "Epoch 1562/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0189 - mae: 0.0991\n",
      "Epoch 1563/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0194 - mae: 0.1013\n",
      "Epoch 1564/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0210 - mae: 0.1060\n",
      "Epoch 1565/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1018\n",
      "Epoch 1566/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1041\n",
      "Epoch 1567/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0189 - mae: 0.0996\n",
      "Epoch 1568/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0186 - mae: 0.0992\n",
      "Epoch 1569/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0194 - mae: 0.1018\n",
      "Epoch 1570/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0202 - mae: 0.1033\n",
      "Epoch 1571/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0207 - mae: 0.1058\n",
      "Epoch 1572/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0213 - mae: 0.1079\n",
      "Epoch 1573/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0198 - mae: 0.1030\n",
      "Epoch 1574/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1033\n",
      "Epoch 1575/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0205 - mae: 0.1042\n",
      "Epoch 1576/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1034\n",
      "Epoch 1577/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0199 - mae: 0.1033\n",
      "Epoch 1578/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0197 - mae: 0.1014\n",
      "Epoch 1579/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0197 - mae: 0.1024\n",
      "Epoch 1580/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0203 - mae: 0.1036\n",
      "Epoch 1581/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0196 - mae: 0.1014\n",
      "Epoch 1582/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1017\n",
      "Epoch 1583/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0203 - mae: 0.1041\n",
      "Epoch 1584/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1032\n",
      "Epoch 1585/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0196 - mae: 0.1015\n",
      "Epoch 1586/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1015\n",
      "Epoch 1587/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0191 - mae: 0.1002\n",
      "Epoch 1588/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0196 - mae: 0.1013\n",
      "Epoch 1589/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1008\n",
      "Epoch 1590/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0193 - mae: 0.1007\n",
      "Epoch 1591/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0193 - mae: 0.1005\n",
      "Epoch 1592/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0198 - mae: 0.1017\n",
      "Epoch 1593/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0188 - mae: 0.0997\n",
      "Epoch 1594/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0187 - mae: 0.0991\n",
      "Epoch 1595/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0192 - mae: 0.1011\n",
      "Epoch 1596/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0205 - mae: 0.1048\n",
      "Epoch 1597/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0196 - mae: 0.1013\n",
      "Epoch 1598/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0229 - mae: 0.1124\n",
      "Epoch 1599/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0211 - mae: 0.1063\n",
      "Epoch 1600/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1026\n",
      "Epoch 1601/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0193 - mae: 0.1006\n",
      "Epoch 1602/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0208 - mae: 0.1069\n",
      "Epoch 1603/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0212 - mae: 0.1068\n",
      "Epoch 1604/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0201 - mae: 0.1033\n",
      "Epoch 1605/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0198 - mae: 0.1027\n",
      "Epoch 1606/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1029\n",
      "Epoch 1607/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0189 - mae: 0.0997\n",
      "Epoch 1608/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0200 - mae: 0.1041\n",
      "Epoch 1609/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1017\n",
      "Epoch 1610/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0191 - mae: 0.1007\n",
      "Epoch 1611/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1033\n",
      "Epoch 1612/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0201 - mae: 0.1034\n",
      "Epoch 1613/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1023\n",
      "Epoch 1614/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0217 - mae: 0.1080\n",
      "Epoch 1615/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.0992\n",
      "Epoch 1616/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0194 - mae: 0.1011\n",
      "Epoch 1617/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0189 - mae: 0.0990\n",
      "Epoch 1618/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0208 - mae: 0.1050\n",
      "Epoch 1619/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0204 - mae: 0.1040\n",
      "Epoch 1620/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0197 - mae: 0.1026\n",
      "Epoch 1621/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0206 - mae: 0.1053\n",
      "Epoch 1622/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0198 - mae: 0.1022\n",
      "Epoch 1623/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0191 - mae: 0.1010\n",
      "Epoch 1624/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0192 - mae: 0.0998\n",
      "Epoch 1625/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0191 - mae: 0.0999\n",
      "Epoch 1626/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0191 - mae: 0.0998\n",
      "Epoch 1627/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1028\n",
      "Epoch 1628/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0192 - mae: 0.1005\n",
      "Epoch 1629/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0190 - mae: 0.1004\n",
      "Epoch 1630/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0188 - mae: 0.0989\n",
      "Epoch 1631/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0187 - mae: 0.0985\n",
      "Epoch 1632/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.0994\n",
      "Epoch 1633/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0191 - mae: 0.1005\n",
      "Epoch 1634/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0187 - mae: 0.0990\n",
      "Epoch 1635/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0186 - mae: 0.0994\n",
      "Epoch 1636/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.1010\n",
      "Epoch 1637/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0196 - mae: 0.1020\n",
      "Epoch 1638/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1021\n",
      "Epoch 1639/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1026\n",
      "Epoch 1640/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0190 - mae: 0.0997\n",
      "Epoch 1641/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0208 - mae: 0.1053\n",
      "Epoch 1642/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0202 - mae: 0.1044\n",
      "Epoch 1643/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0196 - mae: 0.1023\n",
      "Epoch 1644/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0192 - mae: 0.1007\n",
      "Epoch 1645/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1004\n",
      "Epoch 1646/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0190 - mae: 0.1000\n",
      "Epoch 1647/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0187 - mae: 0.0989\n",
      "Epoch 1648/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1035\n",
      "Epoch 1649/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1018\n",
      "Epoch 1650/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0207 - mae: 0.1055\n",
      "Epoch 1651/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0191 - mae: 0.1000\n",
      "Epoch 1652/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0240 - mae: 0.1122\n",
      "Epoch 1653/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0254 - mae: 0.1188\n",
      "Epoch 1654/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0230 - mae: 0.1120\n",
      "Epoch 1655/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0208 - mae: 0.1057\n",
      "Epoch 1656/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0201 - mae: 0.1032\n",
      "Epoch 1657/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0208 - mae: 0.1051\n",
      "Epoch 1658/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0205 - mae: 0.1053\n",
      "Epoch 1659/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0208 - mae: 0.1063\n",
      "Epoch 1660/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0198 - mae: 0.1025\n",
      "Epoch 1661/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0196 - mae: 0.1012\n",
      "Epoch 1662/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0202 - mae: 0.1031\n",
      "Epoch 1663/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0199 - mae: 0.1024\n",
      "Epoch 1664/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0199 - mae: 0.1022\n",
      "Epoch 1665/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0191 - mae: 0.1003\n",
      "Epoch 1666/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0201 - mae: 0.1036\n",
      "Epoch 1667/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0191 - mae: 0.1002\n",
      "Epoch 1668/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1020\n",
      "Epoch 1669/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0192 - mae: 0.1011\n",
      "Epoch 1670/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0187 - mae: 0.0980\n",
      "Epoch 1671/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0192 - mae: 0.1008\n",
      "Epoch 1672/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0190 - mae: 0.1004\n",
      "Epoch 1673/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0191 - mae: 0.1007\n",
      "Epoch 1674/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0198 - mae: 0.1029\n",
      "Epoch 1675/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1025\n",
      "Epoch 1676/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0195 - mae: 0.1012\n",
      "Epoch 1677/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0194 - mae: 0.1013\n",
      "Epoch 1678/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0196 - mae: 0.1022\n",
      "Epoch 1679/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0199 - mae: 0.1023\n",
      "Epoch 1680/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0191 - mae: 0.1000\n",
      "Epoch 1681/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.0995\n",
      "Epoch 1682/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0191 - mae: 0.0996\n",
      "Epoch 1683/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0191 - mae: 0.1000\n",
      "Epoch 1684/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0214 - mae: 0.1076\n",
      "Epoch 1685/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.0991\n",
      "Epoch 1686/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.0991\n",
      "Epoch 1687/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0208 - mae: 0.1052\n",
      "Epoch 1688/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0205 - mae: 0.1051\n",
      "Epoch 1689/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0195 - mae: 0.1014\n",
      "Epoch 1690/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0194 - mae: 0.1009\n",
      "Epoch 1691/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0193 - mae: 0.1011\n",
      "Epoch 1692/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0198 - mae: 0.1023\n",
      "Epoch 1693/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0193 - mae: 0.1014\n",
      "Epoch 1694/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0191 - mae: 0.0999\n",
      "Epoch 1695/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.0999\n",
      "Epoch 1696/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.1009\n",
      "Epoch 1697/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0188 - mae: 0.0997\n",
      "Epoch 1698/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0191 - mae: 0.1000\n",
      "Epoch 1699/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0193 - mae: 0.1007\n",
      "Epoch 1700/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0197 - mae: 0.1019\n",
      "Epoch 1701/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0195 - mae: 0.1018\n",
      "Epoch 1702/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0192 - mae: 0.1012\n",
      "Epoch 1703/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0201 - mae: 0.1037\n",
      "Epoch 1704/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.0992\n",
      "Epoch 1705/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1013\n",
      "Epoch 1706/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0192 - mae: 0.1009\n",
      "Epoch 1707/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0189 - mae: 0.0997\n",
      "Epoch 1708/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.1000\n",
      "Epoch 1709/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0244 - mae: 0.1096\n",
      "Epoch 1710/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0263 - mae: 0.1204\n",
      "Epoch 1711/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0211 - mae: 0.1067\n",
      "Epoch 1712/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0199 - mae: 0.1016\n",
      "Epoch 1713/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0198 - mae: 0.1024\n",
      "Epoch 1714/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0196 - mae: 0.1015\n",
      "Epoch 1715/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0202 - mae: 0.1028\n",
      "Epoch 1716/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0196 - mae: 0.1006\n",
      "Epoch 1717/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1010\n",
      "Epoch 1718/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0207 - mae: 0.1061\n",
      "Epoch 1719/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0192 - mae: 0.1001\n",
      "Epoch 1720/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0193 - mae: 0.1005\n",
      "Epoch 1721/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0197 - mae: 0.1021\n",
      "Epoch 1722/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1027\n",
      "Epoch 1723/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0191 - mae: 0.0998\n",
      "Epoch 1724/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0191 - mae: 0.0996\n",
      "Epoch 1725/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0188 - mae: 0.0983\n",
      "Epoch 1726/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0188 - mae: 0.0989\n",
      "Epoch 1727/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0189 - mae: 0.0989\n",
      "Epoch 1728/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0200 - mae: 0.1032\n",
      "Epoch 1729/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0200 - mae: 0.1026\n",
      "Epoch 1730/2000\n",
      "2019/2019 [==============================] - 0s 63us/sample - loss: 0.0196 - mae: 0.1018\n",
      "Epoch 1731/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0208 - mae: 0.1057\n",
      "Epoch 1732/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0196 - mae: 0.1016\n",
      "Epoch 1733/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0193 - mae: 0.1007\n",
      "Epoch 1734/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0191 - mae: 0.1004\n",
      "Epoch 1735/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.0994\n",
      "Epoch 1736/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0205 - mae: 0.1044\n",
      "Epoch 1737/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0196 - mae: 0.1011\n",
      "Epoch 1738/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0192 - mae: 0.1003\n",
      "Epoch 1739/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0190 - mae: 0.0996\n",
      "Epoch 1740/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0188 - mae: 0.0996\n",
      "Epoch 1741/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1038\n",
      "Epoch 1742/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0194 - mae: 0.1017\n",
      "Epoch 1743/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0192 - mae: 0.1001\n",
      "Epoch 1744/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0190 - mae: 0.0999\n",
      "Epoch 1745/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0191 - mae: 0.1000\n",
      "Epoch 1746/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1048\n",
      "Epoch 1747/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0188 - mae: 0.0990\n",
      "Epoch 1748/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0190 - mae: 0.0994\n",
      "Epoch 1749/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0195 - mae: 0.1014\n",
      "Epoch 1750/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0209 - mae: 0.1065\n",
      "Epoch 1751/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0195 - mae: 0.1024\n",
      "Epoch 1752/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.0987\n",
      "Epoch 1753/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0198 - mae: 0.1025\n",
      "Epoch 1754/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0198 - mae: 0.1029\n",
      "Epoch 1755/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0190 - mae: 0.0996\n",
      "Epoch 1756/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0199 - mae: 0.1032\n",
      "Epoch 1757/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0200 - mae: 0.1035\n",
      "Epoch 1758/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0189 - mae: 0.0994\n",
      "Epoch 1759/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0187 - mae: 0.0985\n",
      "Epoch 1760/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0187 - mae: 0.0986\n",
      "Epoch 1761/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0192 - mae: 0.1010\n",
      "Epoch 1762/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0192 - mae: 0.0999\n",
      "Epoch 1763/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.1015\n",
      "Epoch 1764/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.1011\n",
      "Epoch 1765/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0186 - mae: 0.0987\n",
      "Epoch 1766/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0193 - mae: 0.1010\n",
      "Epoch 1767/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0190 - mae: 0.1001\n",
      "Epoch 1768/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.1017\n",
      "Epoch 1769/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1005\n",
      "Epoch 1770/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0198 - mae: 0.1035\n",
      "Epoch 1771/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0222 - mae: 0.1096\n",
      "Epoch 1772/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0201 - mae: 0.1037\n",
      "Epoch 1773/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0198 - mae: 0.1022\n",
      "Epoch 1774/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0206 - mae: 0.1049\n",
      "Epoch 1775/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1015\n",
      "Epoch 1776/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.0997\n",
      "Epoch 1777/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0208 - mae: 0.1062\n",
      "Epoch 1778/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0192 - mae: 0.1003\n",
      "Epoch 1779/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0207 - mae: 0.1065\n",
      "Epoch 1780/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0189 - mae: 0.1001\n",
      "Epoch 1781/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1008\n",
      "Epoch 1782/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.1004\n",
      "Epoch 1783/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0203 - mae: 0.1045\n",
      "Epoch 1784/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0200 - mae: 0.1028\n",
      "Epoch 1785/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0193 - mae: 0.1006\n",
      "Epoch 1786/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0196 - mae: 0.1022\n",
      "Epoch 1787/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0203 - mae: 0.1050\n",
      "Epoch 1788/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0187 - mae: 0.0987\n",
      "Epoch 1789/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0196 - mae: 0.1018\n",
      "Epoch 1790/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0186 - mae: 0.0979\n",
      "Epoch 1791/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0200 - mae: 0.1033\n",
      "Epoch 1792/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0192 - mae: 0.1007\n",
      "Epoch 1793/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0190 - mae: 0.0995\n",
      "Epoch 1794/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.1001\n",
      "Epoch 1795/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0195 - mae: 0.1012\n",
      "Epoch 1796/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0194 - mae: 0.1017\n",
      "Epoch 1797/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0191 - mae: 0.1011\n",
      "Epoch 1798/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0198 - mae: 0.1025\n",
      "Epoch 1799/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.1000\n",
      "Epoch 1800/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0186 - mae: 0.0985\n",
      "Epoch 1801/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0189 - mae: 0.1001\n",
      "Epoch 1802/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0190 - mae: 0.1000\n",
      "Epoch 1803/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0197 - mae: 0.1026\n",
      "Epoch 1804/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.0997\n",
      "Epoch 1805/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0184 - mae: 0.0982\n",
      "Epoch 1806/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0190 - mae: 0.1007\n",
      "Epoch 1807/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0197 - mae: 0.1016\n",
      "Epoch 1808/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0252 - mae: 0.1155\n",
      "Epoch 1809/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0238 - mae: 0.1132\n",
      "Epoch 1810/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0226 - mae: 0.1113\n",
      "Epoch 1811/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0209 - mae: 0.1074\n",
      "Epoch 1812/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0207 - mae: 0.1055\n",
      "Epoch 1813/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0204 - mae: 0.1039\n",
      "Epoch 1814/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1015\n",
      "Epoch 1815/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0196 - mae: 0.1022\n",
      "Epoch 1816/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0201 - mae: 0.1047\n",
      "Epoch 1817/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0201 - mae: 0.1033\n",
      "Epoch 1818/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0196 - mae: 0.1025\n",
      "Epoch 1819/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0193 - mae: 0.1010\n",
      "Epoch 1820/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0192 - mae: 0.1009\n",
      "Epoch 1821/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0188 - mae: 0.0999\n",
      "Epoch 1822/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0186 - mae: 0.0984\n",
      "Epoch 1823/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.0998\n",
      "Epoch 1824/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0195 - mae: 0.1011\n",
      "Epoch 1825/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0193 - mae: 0.1005\n",
      "Epoch 1826/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1011\n",
      "Epoch 1827/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0186 - mae: 0.0989\n",
      "Epoch 1828/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.1001\n",
      "Epoch 1829/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0193 - mae: 0.1013\n",
      "Epoch 1830/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0188 - mae: 0.0992\n",
      "Epoch 1831/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0190 - mae: 0.1002\n",
      "Epoch 1832/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0187 - mae: 0.0986\n",
      "Epoch 1833/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0183 - mae: 0.0977\n",
      "Epoch 1834/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0190 - mae: 0.1008\n",
      "Epoch 1835/2000\n",
      "2019/2019 [==============================] - 0s 63us/sample - loss: 0.0187 - mae: 0.0988\n",
      "Epoch 1836/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0193 - mae: 0.1008\n",
      "Epoch 1837/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1018\n",
      "Epoch 1838/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1018\n",
      "Epoch 1839/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1018\n",
      "Epoch 1840/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0205 - mae: 0.1046\n",
      "Epoch 1841/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0190 - mae: 0.0996\n",
      "Epoch 1842/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0191 - mae: 0.1011\n",
      "Epoch 1843/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0190 - mae: 0.1007\n",
      "Epoch 1844/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0187 - mae: 0.0986\n",
      "Epoch 1845/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0187 - mae: 0.0985\n",
      "Epoch 1846/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0186 - mae: 0.0986\n",
      "Epoch 1847/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.0997\n",
      "Epoch 1848/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0189 - mae: 0.0993\n",
      "Epoch 1849/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0223 - mae: 0.1097\n",
      "Epoch 1850/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0193 - mae: 0.1007\n",
      "Epoch 1851/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0188 - mae: 0.0990\n",
      "Epoch 1852/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.0991\n",
      "Epoch 1853/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0194 - mae: 0.1020\n",
      "Epoch 1854/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0191 - mae: 0.1008\n",
      "Epoch 1855/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0189 - mae: 0.0993\n",
      "Epoch 1856/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0187 - mae: 0.0991\n",
      "Epoch 1857/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0186 - mae: 0.0986\n",
      "Epoch 1858/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0194 - mae: 0.1016\n",
      "Epoch 1859/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0207 - mae: 0.1057\n",
      "Epoch 1860/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0192 - mae: 0.1013\n",
      "Epoch 1861/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0194 - mae: 0.1016\n",
      "Epoch 1862/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0196 - mae: 0.1023\n",
      "Epoch 1863/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1019\n",
      "Epoch 1864/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0211 - mae: 0.1070\n",
      "Epoch 1865/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0192 - mae: 0.1014\n",
      "Epoch 1866/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0991\n",
      "Epoch 1867/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0190 - mae: 0.0992\n",
      "Epoch 1868/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0188 - mae: 0.0999\n",
      "Epoch 1869/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0197 - mae: 0.1033\n",
      "Epoch 1870/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0192 - mae: 0.1003\n",
      "Epoch 1871/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.1001\n",
      "Epoch 1872/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0196 - mae: 0.1022\n",
      "Epoch 1873/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0189 - mae: 0.0994\n",
      "Epoch 1874/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0199 - mae: 0.1033\n",
      "Epoch 1875/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0185 - mae: 0.0992\n",
      "Epoch 1876/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.1001\n",
      "Epoch 1877/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0255 - mae: 0.1176\n",
      "Epoch 1878/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0206 - mae: 0.1046\n",
      "Epoch 1879/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0222 - mae: 0.1102\n",
      "Epoch 1880/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0203 - mae: 0.1035\n",
      "Epoch 1881/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0205 - mae: 0.1054\n",
      "Epoch 1882/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0193 - mae: 0.1011\n",
      "Epoch 1883/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0201 - mae: 0.1032\n",
      "Epoch 1884/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0195 - mae: 0.1011\n",
      "Epoch 1885/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.1010\n",
      "Epoch 1886/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0187 - mae: 0.0989\n",
      "Epoch 1887/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0185 - mae: 0.0982\n",
      "Epoch 1888/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0191 - mae: 0.1003\n",
      "Epoch 1889/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0196 - mae: 0.1023\n",
      "Epoch 1890/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0982\n",
      "Epoch 1891/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0196 - mae: 0.1011\n",
      "Epoch 1892/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0213 - mae: 0.1067\n",
      "Epoch 1893/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0206 - mae: 0.1041\n",
      "Epoch 1894/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0196 - mae: 0.1019\n",
      "Epoch 1895/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1026\n",
      "Epoch 1896/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0193 - mae: 0.1023\n",
      "Epoch 1897/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0188 - mae: 0.0995\n",
      "Epoch 1898/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0187 - mae: 0.0996\n",
      "Epoch 1899/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0194 - mae: 0.1013\n",
      "Epoch 1900/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0193 - mae: 0.1017\n",
      "Epoch 1901/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0189 - mae: 0.0992\n",
      "Epoch 1902/2000\n",
      "2019/2019 [==============================] - 0s 72us/sample - loss: 0.0188 - mae: 0.0990\n",
      "Epoch 1903/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0190 - mae: 0.1000\n",
      "Epoch 1904/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0189 - mae: 0.0995\n",
      "Epoch 1905/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0189 - mae: 0.0996\n",
      "Epoch 1906/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0196 - mae: 0.1022\n",
      "Epoch 1907/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0191 - mae: 0.1007\n",
      "Epoch 1908/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0186 - mae: 0.0983\n",
      "Epoch 1909/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1033\n",
      "Epoch 1910/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0191 - mae: 0.1003\n",
      "Epoch 1911/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0192 - mae: 0.1010\n",
      "Epoch 1912/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0187 - mae: 0.0991\n",
      "Epoch 1913/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0188 - mae: 0.0994\n",
      "Epoch 1914/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0192 - mae: 0.1010\n",
      "Epoch 1915/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0188 - mae: 0.0990\n",
      "Epoch 1916/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0187 - mae: 0.0986\n",
      "Epoch 1917/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0188 - mae: 0.0997\n",
      "Epoch 1918/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0188 - mae: 0.0995\n",
      "Epoch 1919/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0188 - mae: 0.1002\n",
      "Epoch 1920/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0185 - mae: 0.0984\n",
      "Epoch 1921/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0191 - mae: 0.1008\n",
      "Epoch 1922/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.1018\n",
      "Epoch 1923/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0201 - mae: 0.1041\n",
      "Epoch 1924/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0189 - mae: 0.0990\n",
      "Epoch 1925/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0188 - mae: 0.1002\n",
      "Epoch 1926/2000\n",
      "2019/2019 [==============================] - 0s 70us/sample - loss: 0.0185 - mae: 0.0987\n",
      "Epoch 1927/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0196 - mae: 0.1023\n",
      "Epoch 1928/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0199 - mae: 0.1030\n",
      "Epoch 1929/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.1000\n",
      "Epoch 1930/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0215 - mae: 0.1079\n",
      "Epoch 1931/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0195 - mae: 0.1016\n",
      "Epoch 1932/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0186 - mae: 0.0987\n",
      "Epoch 1933/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0187 - mae: 0.0994\n",
      "Epoch 1934/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0192 - mae: 0.1005\n",
      "Epoch 1935/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1020\n",
      "Epoch 1936/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0194 - mae: 0.1018\n",
      "Epoch 1937/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0189 - mae: 0.0994\n",
      "Epoch 1938/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0195 - mae: 0.1020\n",
      "Epoch 1939/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0193 - mae: 0.1012\n",
      "Epoch 1940/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0194 - mae: 0.1016\n",
      "Epoch 1941/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0189 - mae: 0.0992\n",
      "Epoch 1942/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0189 - mae: 0.1000\n",
      "Epoch 1943/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0182 - mae: 0.0971\n",
      "Epoch 1944/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0188 - mae: 0.0998\n",
      "Epoch 1945/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0183 - mae: 0.0975\n",
      "Epoch 1946/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0187 - mae: 0.0999\n",
      "Epoch 1947/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0188 - mae: 0.0994\n",
      "Epoch 1948/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0193 - mae: 0.1018\n",
      "Epoch 1949/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0187 - mae: 0.0995\n",
      "Epoch 1950/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0235 - mae: 0.1136\n",
      "Epoch 1951/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0229 - mae: 0.1117\n",
      "Epoch 1952/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0226 - mae: 0.1108\n",
      "Epoch 1953/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0217 - mae: 0.1088\n",
      "Epoch 1954/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0205 - mae: 0.1036\n",
      "Epoch 1955/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0219 - mae: 0.1084\n",
      "Epoch 1956/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0200 - mae: 0.1037\n",
      "Epoch 1957/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0198 - mae: 0.1026\n",
      "Epoch 1958/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0202 - mae: 0.1041\n",
      "Epoch 1959/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0200 - mae: 0.1043\n",
      "Epoch 1960/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0200 - mae: 0.1038\n",
      "Epoch 1961/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0197 - mae: 0.1023\n",
      "Epoch 1962/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0186 - mae: 0.0985\n",
      "Epoch 1963/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0198 - mae: 0.1021\n",
      "Epoch 1964/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0185 - mae: 0.0981\n",
      "Epoch 1965/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0199 - mae: 0.1041\n",
      "Epoch 1966/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0185 - mae: 0.0983\n",
      "Epoch 1967/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0195 - mae: 0.1017\n",
      "Epoch 1968/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0191 - mae: 0.1009\n",
      "Epoch 1969/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0188 - mae: 0.0987\n",
      "Epoch 1970/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0197 - mae: 0.1022\n",
      "Epoch 1971/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.1002\n",
      "Epoch 1972/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0184 - mae: 0.0980\n",
      "Epoch 1973/2000\n",
      "2019/2019 [==============================] - 0s 73us/sample - loss: 0.0185 - mae: 0.0981\n",
      "Epoch 1974/2000\n",
      "2019/2019 [==============================] - 0s 75us/sample - loss: 0.0197 - mae: 0.1027\n",
      "Epoch 1975/2000\n",
      "2019/2019 [==============================] - 0s 68us/sample - loss: 0.0190 - mae: 0.1005\n",
      "Epoch 1976/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0191 - mae: 0.1006\n",
      "Epoch 1977/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0216 - mae: 0.1093\n",
      "Epoch 1978/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0188 - mae: 0.0996\n",
      "Epoch 1979/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0193 - mae: 0.1018\n",
      "Epoch 1980/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0184 - mae: 0.0981\n",
      "Epoch 1981/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0187 - mae: 0.0989\n",
      "Epoch 1982/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0183 - mae: 0.0978\n",
      "Epoch 1983/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.0999\n",
      "Epoch 1984/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0192 - mae: 0.1010\n",
      "Epoch 1985/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0190 - mae: 0.1005\n",
      "Epoch 1986/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0191 - mae: 0.1001\n",
      "Epoch 1987/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0190 - mae: 0.1000\n",
      "Epoch 1988/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0187 - mae: 0.0987\n",
      "Epoch 1989/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0186 - mae: 0.0988\n",
      "Epoch 1990/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0189 - mae: 0.0991\n",
      "Epoch 1991/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0185 - mae: 0.0983\n",
      "Epoch 1992/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0185 - mae: 0.0973\n",
      "Epoch 1993/2000\n",
      "2019/2019 [==============================] - 0s 65us/sample - loss: 0.0190 - mae: 0.1003\n",
      "Epoch 1994/2000\n",
      "2019/2019 [==============================] - 0s 64us/sample - loss: 0.0193 - mae: 0.1010\n",
      "Epoch 1995/2000\n",
      "2019/2019 [==============================] - 0s 67us/sample - loss: 0.0190 - mae: 0.1008\n",
      "Epoch 1996/2000\n",
      "2019/2019 [==============================] - 0s 71us/sample - loss: 0.0186 - mae: 0.0989\n",
      "Epoch 1997/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0189 - mae: 0.1004\n",
      "Epoch 1998/2000\n",
      "2019/2019 [==============================] - 0s 69us/sample - loss: 0.0188 - mae: 0.1003\n",
      "Epoch 1999/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0186 - mae: 0.0991\n",
      "Epoch 2000/2000\n",
      "2019/2019 [==============================] - 0s 66us/sample - loss: 0.0188 - mae: 0.1001\n",
      "mae: 0.1137886568903923\n",
      "Overfit mae: 0.09860623627901077\n",
      "-------------------------------------------\n",
      "Final results\n",
      "0.11620642989873886 (+/- 0.01029099989682436)\n",
      "And overfit of 0.09518933296203613 (+/- 0.006693280767649412)\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "\n",
    "frame = load_frame()\n",
    "data_x, data_y, number_of_features = load_meaningful_subset(frame)\n",
    "data_y = pd.concat([frame.mutation], axis = 1).round(2) #.mul(10)\n",
    "\n",
    "\n",
    "data_x = data_x.values\n",
    "data_y = data_y.values\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = KFold(n_splits=10, shuffle=False, random_state=seed)\n",
    "cvscores = []\n",
    "overscores = []\n",
    "\n",
    "for train, test in kfold.split(data_x, data_y):\n",
    "\n",
    "    #x_validation, x_test, y_validation, y_test = train_test_split(data_x[validation_and_test], data_y[validation_and_test], test_size=.5, random_state=seed)\n",
    "\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(number_of_features, activation='relu', input_dim=number_of_features))\n",
    "    model.add(keras.layers.Dense(40, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(20, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mae'])\n",
    "\n",
    "\n",
    "    #early_stopping_monitor = keras.callbacks.EarlyStopping(patience=1,restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(data_x[train], data_y[train], epochs=2000, verbose=1)#,\n",
    "                        #validation_data=(x_validation, y_validation), callbacks=[early_stopping_monitor])\n",
    "\n",
    "\n",
    "        \n",
    "    scores = model.evaluate(data_x[test], data_y[test], verbose=0)\n",
    "    overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "    print('{}: {}'.format(model.metrics_names[1], scores[1]))\n",
    "    print('Overfit {}: {}'.format(model.metrics_names[1], overfit[1]))\n",
    "    #print(\"-------------------------------------------\")\n",
    "\n",
    "    cvscores.append(scores[1])\n",
    "    overscores.append(overfit[1])\n",
    "    \n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Final results\")\n",
    "print('{} (+/- {})'.format(np.mean(cvscores), np.std(cvscores)))\n",
    "print('And overfit of {} (+/- {})'.format(np.mean(overscores), np.std(overscores)))\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 0.17803551256656647\n",
      "Overfit mae: 0.116717129945755\n",
      "mae: 0.1444447785615921\n",
      "Overfit mae: 0.11726092547178268\n",
      "mae: 0.1400212049484253\n",
      "Overfit mae: 0.11928663402795792\n",
      "mae: 0.14020882546901703\n",
      "Overfit mae: 0.12419606000185013\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "\n",
    "frame = load_frame()\n",
    "data_x, data_y, number_of_features = load_meaningful_subset_static(frame)\n",
    "data_y = pd.concat([frame.mutation], axis = 1).round(2) #.mul(10)\n",
    "\n",
    "\n",
    "data_x = data_x.values\n",
    "data_y = data_y.values\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = KFold(n_splits=10, shuffle=False, random_state=seed)\n",
    "cvscores = []\n",
    "overscores = []\n",
    "\n",
    "for train, test in kfold.split(data_x, data_y):\n",
    "\n",
    "    #x_validation, x_test, y_validation, y_test = train_test_split(data_x[validation_and_test], data_y[validation_and_test], test_size=.5, random_state=seed)\n",
    "\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(number_of_features, activation='relu', input_dim=number_of_features))\n",
    "    model.add(keras.layers.Dense(40, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(20, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mae'])\n",
    "\n",
    "\n",
    "    #early_stopping_monitor = keras.callbacks.EarlyStopping(patience=1,restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(data_x[train], data_y[train], epochs=2000, verbose=0)#,\n",
    "                        #validation_data=(x_validation, y_validation), callbacks=[early_stopping_monitor])\n",
    "\n",
    "\n",
    "        \n",
    "    scores = model.evaluate(data_x[test], data_y[test], verbose=0)\n",
    "    overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "    print('{}: {}'.format(model.metrics_names[1], scores[1]))\n",
    "    print('Overfit {}: {}'.format(model.metrics_names[1], overfit[1]))\n",
    "    #print(\"-------------------------------------------\")\n",
    "\n",
    "    cvscores.append(scores[1])\n",
    "    overscores.append(overfit[1])\n",
    "    \n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Final results\")\n",
    "print('{} (+/- {})'.format(np.mean(cvscores), np.std(cvscores)))\n",
    "print('And overfit of {} (+/- {})'.format(np.mean(overscores), np.std(overscores)))\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 0.1314028799533844\n",
      "Overfit mae: 0.07021105289459229\n",
      "mae: 0.21424807608127594\n",
      "Overfit mae: 0.228338822722435\n",
      "mae: 0.22971144318580627\n",
      "Overfit mae: 0.22590132057666779\n",
      "mae: 0.1088959127664566\n",
      "Overfit mae: 0.07069027423858643\n",
      "mae: 0.13539524376392365\n",
      "Overfit mae: 0.0757928192615509\n",
      "mae: 0.2409801036119461\n",
      "Overfit mae: 0.226371631026268\n",
      "mae: 0.12477190792560577\n",
      "Overfit mae: 0.08184517174959183\n",
      "mae: 0.12933433055877686\n",
      "Overfit mae: 0.10059206187725067\n",
      "mae: 0.13084401190280914\n",
      "Overfit mae: 0.08997262269258499\n",
      "mae: 0.21518519520759583\n",
      "Overfit mae: 0.22836452722549438\n",
      "-------------------------------------------\n",
      "Final results\n",
      "0.1660769134759903 (+/- 0.04909452423453331)\n",
      "And overfit of 0.1398080289363861 (+/- 0.07189254462718964)\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "\n",
    "frame = load_frame()\n",
    "data_x, data_y, number_of_features = load_all_data(frame)\n",
    "data_y = pd.concat([frame.mutation], axis = 1).round(2) #.mul(10)\n",
    "\n",
    "\n",
    "data_x = data_x.values\n",
    "data_y = data_y.values\n",
    "\n",
    "\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = KFold(n_splits=10, shuffle=False, random_state=seed)\n",
    "cvscores = []\n",
    "overscores = []\n",
    "\n",
    "for train, test in kfold.split(data_x, data_y):\n",
    "\n",
    "    #x_validation, x_test, y_validation, y_test = train_test_split(data_x[validation_and_test], data_y[validation_and_test], test_size=.5, random_state=seed)\n",
    "\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(number_of_features, activation='relu', input_dim=number_of_features))\n",
    "    model.add(keras.layers.Dense(40, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(20, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mae'])\n",
    "\n",
    "\n",
    "    #early_stopping_monitor = keras.callbacks.EarlyStopping(patience=1,restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(data_x[train], data_y[train], epochs=2000, verbose=0)#,\n",
    "                        #validation_data=(x_validation, y_validation), callbacks=[early_stopping_monitor])\n",
    "\n",
    "\n",
    "        \n",
    "    scores = model.evaluate(data_x[test], data_y[test], verbose=0)\n",
    "    overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "    print('{}: {}'.format(model.metrics_names[1], scores[1]))\n",
    "    print('Overfit {}: {}'.format(model.metrics_names[1], overfit[1]))\n",
    "    #print(\"-------------------------------------------\")\n",
    "\n",
    "    cvscores.append(scores[1])\n",
    "    overscores.append(overfit[1])\n",
    "    \n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Final results\")\n",
    "print('{} (+/- {})'.format(np.mean(cvscores), np.std(cvscores)))\n",
    "print('And overfit of {} (+/- {})'.format(np.mean(overscores), np.std(overscores)))\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 0.12075492739677429\n",
      "Overfit mae: 0.02110026590526104\n",
      "mae: 0.1198657751083374\n",
      "Overfit mae: 0.020394645631313324\n",
      "mae: 0.10871081799268723\n",
      "Overfit mae: 0.036748338490724564\n",
      "mae: 0.1047818660736084\n",
      "Overfit mae: 0.019902387633919716\n",
      "mae: 0.11269520223140717\n",
      "Overfit mae: 0.01975231245160103\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "\n",
    "frame = load_frame()\n",
    "data_x, data_y, number_of_features = load_all_data(frame)\n",
    "data_y = pd.concat([frame.mutation], axis = 1).round(2) #.mul(10)\n",
    "\n",
    "\n",
    "data_x = data_x.values\n",
    "data_y = data_y.values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_x)\n",
    "data_x = scaler.transform(data_x)\n",
    "\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = KFold(n_splits=10, shuffle=False, random_state=seed)\n",
    "cvscores = []\n",
    "overscores = []\n",
    "\n",
    "for train, test in kfold.split(data_x, data_y):\n",
    "\n",
    "    #x_validation, x_test, y_validation, y_test = train_test_split(data_x[validation_and_test], data_y[validation_and_test], test_size=.5, random_state=seed)\n",
    "\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(number_of_features, activation='relu', input_dim=number_of_features))\n",
    "    model.add(keras.layers.Dense(40, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(20, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mae'])\n",
    "\n",
    "\n",
    "    #early_stopping_monitor = keras.callbacks.EarlyStopping(patience=1,restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(data_x[train], data_y[train], epochs=2000, verbose=0)#,\n",
    "                        #validation_data=(x_validation, y_validation), callbacks=[early_stopping_monitor])\n",
    "\n",
    "\n",
    "        \n",
    "    scores = model.evaluate(data_x[test], data_y[test], verbose=0)\n",
    "    overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "    print('{}: {}'.format(model.metrics_names[1], scores[1]))\n",
    "    print('Overfit {}: {}'.format(model.metrics_names[1], overfit[1]))\n",
    "    #print(\"-------------------------------------------\")\n",
    "\n",
    "    cvscores.append(scores[1])\n",
    "    overscores.append(overfit[1])\n",
    "    \n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Final results\")\n",
    "print('{} (+/- {})'.format(np.mean(cvscores), np.std(cvscores)))\n",
    "print('And overfit of {} (+/- {})'.format(np.mean(overscores), np.std(overscores)))\n",
    "print(\"-------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 0.13801375031471252\n",
      "Overfit mae: 0.10524167120456696\n",
      "mae: 0.21424807608127594\n",
      "Overfit mae: 0.228338822722435\n",
      "mae: 0.22972698509693146\n",
      "Overfit mae: 0.22603189945220947\n",
      "mae: 0.11298079788684845\n",
      "Overfit mae: 0.10451611131429672\n",
      "mae: 0.1342080533504486\n",
      "Overfit mae: 0.09862365573644638\n",
      "mae: 0.23940403759479523\n",
      "Overfit mae: 0.22563159465789795\n",
      "mae: 0.1273709237575531\n",
      "Overfit mae: 0.1181560531258583\n",
      "mae: 0.2184688299894333\n",
      "Overfit mae: 0.22797422111034393\n",
      "mae: 0.12014524638652802\n",
      "Overfit mae: 0.10427050292491913\n",
      "mae: 0.21518519520759583\n",
      "Overfit mae: 0.22836452722549438\n",
      "-------------------------------------------\n",
      "Final results\n",
      "0.17497518658638 (+/- 0.04933927208185196)\n",
      "And overfit of 0.16671490669250488 (+/- 0.0607304722070694)\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "\n",
    "frame = load_frame()\n",
    "data_x, data_y, number_of_features = load_meaningful_subset(frame)\n",
    "data_y = pd.concat([frame.mutation], axis = 1).round(2) #.mul(10)\n",
    "\n",
    "\n",
    "data_x = data_x.values\n",
    "data_y = data_y.values\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = KFold(n_splits=10, shuffle=False, random_state=seed)\n",
    "cvscores = []\n",
    "overscores = []\n",
    "\n",
    "for train, test in kfold.split(data_x, data_y):\n",
    "\n",
    "    #x_validation, x_test, y_validation, y_test = train_test_split(data_x[validation_and_test], data_y[validation_and_test], test_size=.5, random_state=seed)\n",
    "\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(number_of_features, activation='relu', input_dim=number_of_features))\n",
    "    model.add(keras.layers.Dense(number_of_features / 2.0, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(number_of_features /4.0, activation='relu', kernel_regularizer= keras.regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mae'])\n",
    "\n",
    "\n",
    "    #early_stopping_monitor = keras.callbacks.EarlyStopping(patience=1,restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(data_x[train], data_y[train], epochs=2000, verbose=0)#,\n",
    "                        #validation_data=(x_validation, y_validation), callbacks=[early_stopping_monitor])\n",
    "\n",
    "\n",
    "        \n",
    "    scores = model.evaluate(data_x[test], data_y[test], verbose=0)\n",
    "    overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "    print('{}: {}'.format(model.metrics_names[1], scores[1]))\n",
    "    print('Overfit {}: {}'.format(model.metrics_names[1], overfit[1]))\n",
    "    #print(\"-------------------------------------------\")\n",
    "\n",
    "    cvscores.append(scores[1])\n",
    "    overscores.append(overfit[1])\n",
    "    \n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Final results\")\n",
    "print('{} (+/- {})'.format(np.mean(cvscores), np.std(cvscores)))\n",
    "print('And overfit of {} (+/- {})'.format(np.mean(overscores), np.std(overscores)))\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.39%\n",
      "Overfit: 94.63%\n",
      "accuracy: 90.18%\n",
      "Overfit: 90.85%\n",
      "accuracy: 91.07%\n",
      "Overfit: 95.13%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-37709f71ddd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m           metrics=['accuracy'])\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Only dropout \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow\n",
    "from numpy.random import seed\n",
    "\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "\n",
    "frame = load_frame()\n",
    "frame = load_quartile(frame)\n",
    "\n",
    "data_x, data_y, number_of_features = load_all_data_with_mine_static(frame)\n",
    "\n",
    "data_x = data_x.values\n",
    "data_y = data_y.values\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed)\n",
    "cvscores = []\n",
    "overscores = []\n",
    "\n",
    "for train, test in kfold.split(data_x, data_y):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Dropout(0.15, input_shape=(number_of_features,)))\n",
    "    model.add(keras.layers.Dense(40, activation='relu'))\n",
    "    model.add(keras.layers.Dense(20, activation='relu'))\n",
    "    model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "          loss='sparse_categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(data_x[train], data_y[train], epochs=2000, verbose=0)\n",
    "\n",
    "    scores = model.evaluate(data_x[test], data_y[test], verbose=0)\n",
    "    overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"Overfit: %.2f%%\" % (overfit[1]*100))\n",
    "    #print(\"-------------------------------------------\")\n",
    "\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    overscores.append(overfit[1]*100)\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"The result, with a patience of {} is:\".format(p))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "print(\"And overfit of %.2f%% (+/- %.2f%%)\" % (np.mean(overscores), np.std(overscores)))\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "With StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 91.96%\n",
      "Overfit: 100.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-27a0741b652e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m           metrics=['accuracy'])\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Only dropout \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow\n",
    "from numpy.random import seed\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "\n",
    "frame = load_frame()\n",
    "frame = load_quartile(frame)\n",
    "\n",
    "data_x, data_y, number_of_features = load_all_data_with_mine_static(frame)\n",
    "\n",
    "data_x = data_x.values\n",
    "data_y = data_y.values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_x)\n",
    "data_x = scaler.transform(data_x)\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed)\n",
    "cvscores = []\n",
    "overscores = []\n",
    "\n",
    "for train, test in kfold.split(data_x, data_y):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Dropout(0.15, input_shape=(number_of_features,)))\n",
    "    model.add(keras.layers.Dense(40, activation='relu'))\n",
    "    model.add(keras.layers.Dense(20, activation='relu'))\n",
    "    model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "          loss='sparse_categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(data_x[train], data_y[train], epochs=2000, verbose=0)\n",
    "\n",
    "    scores = model.evaluate(data_x[test], data_y[test], verbose=0)\n",
    "    overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"Overfit: %.2f%%\" % (overfit[1]*100))\n",
    "    #print(\"-------------------------------------------\")\n",
    "\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    overscores.append(overfit[1]*100)\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"The result, with a patience of {} is:\".format(p))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "print(\"And overfit of %.2f%% (+/- %.2f%%)\" % (np.mean(overscores), np.std(overscores)))\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yossi:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Dor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-01ac9ad50d66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mdata_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mdata_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "#Only dropout \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "pa = [0,0.02,0.04,0.05,0.11,0.15,0.17,0.19,0.20,0.21,0.23,0.25,0.28,0.33,0.38,0.44,0.50,0.55,0.60,0.65,0.70,0.75,0.80,0.85,0.9,0.95,0.97]\n",
    "\n",
    "\n",
    "for p in pa:\n",
    "\n",
    "    import tensorflow\n",
    "\n",
    "    from numpy.random import seed\n",
    "    seed(1)\n",
    "    tensorflow.random.set_seed(2)\n",
    "\n",
    "\n",
    "    frame = load_frame()\n",
    "    frame = load_quartile(frame)\n",
    "\n",
    "    data_x, data_y, number_of_features = load_all_data_with_mine_static(frame)\n",
    "\n",
    "    data_x = data_x.values\n",
    "    data_y = data_y.values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data_x)\n",
    "    data_x = scaler.transform(data_x)\n",
    "       \n",
    "    seed = 7\n",
    "    np.random.seed(seed)\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed)\n",
    "    cvscores = []\n",
    "    overscores = []\n",
    "\n",
    "    for train, test in kfold.split(data_x, data_y):\n",
    "\n",
    "        model = keras.Sequential()\n",
    "\n",
    "        model.add(keras.layers.Dropout(p, input_shape=(number_of_features,)))\n",
    "        model.add(keras.layers.Dense(40, activation='relu'))\n",
    "        model.add(keras.layers.Dense(20, activation='relu'))\n",
    "        model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "        early_stopping_monitor = keras.callbacks.EarlyStopping(monitor='accuracy', min_delta=0.0003, patience=40, verbose=1, mode='max', restore_best_weights=True)\n",
    "\n",
    "        history = model.fit(data_x[train], data_y[train], epochs=2000, verbose=0,\n",
    "                            callbacks=[early_stopping_monitor])\n",
    "        \n",
    "        scores = model.evaluate(data_x[test], data_y[test], verbose=0)\n",
    "        overfit = model.evaluate(data_x[train], data_y[train], verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        print(\"Overfit: %.2f%%\" % (overfit[1]*100))\n",
    "        #print(\"-------------------------------------------\")\n",
    "\n",
    "        cvscores.append(scores[1] * 100)\n",
    "        overscores.append(overfit[1]*100)\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"The result, with a Dropout of {} is:\".format(p))\n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "    print(\"And overfit of %.2f%% (+/- %.2f%%)\" % (np.mean(overscores), np.std(overscores)))\n",
    "    print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
