{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2412, 111)\n",
      "Train on 2412 samples\n",
      "Epoch 1/400\n",
      "2412/2412 [==============================] - 1s 565us/sample - loss: 0.1232 - mae: 0.2507 - mse: 0.1232\n",
      "Epoch 2/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0376 - mae: 0.1397 - mse: 0.0376\n",
      "Epoch 3/400\n",
      "2412/2412 [==============================] - 0s 91us/sample - loss: 0.0293 - mae: 0.1188 - mse: 0.0293\n",
      "Epoch 4/400\n",
      "2412/2412 [==============================] - 0s 91us/sample - loss: 0.0201 - mae: 0.1032 - mse: 0.0201\n",
      "Epoch 5/400\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0159 - mae: 0.0924 - mse: 0.0159\n",
      "Epoch 6/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0139 - mae: 0.0872 - mse: 0.0139\n",
      "Epoch 7/400\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0135 - mae: 0.0817 - mse: 0.0135\n",
      "Epoch 8/400\n",
      "2412/2412 [==============================] - 0s 88us/sample - loss: 0.0105 - mae: 0.0752 - mse: 0.0105\n",
      "Epoch 9/400\n",
      "2412/2412 [==============================] - 0s 89us/sample - loss: 0.0091 - mae: 0.0704 - mse: 0.0091\n",
      "Epoch 10/400\n",
      "2412/2412 [==============================] - 0s 87us/sample - loss: 0.0084 - mae: 0.0674 - mse: 0.0084\n",
      "Epoch 11/400\n",
      "2412/2412 [==============================] - 0s 89us/sample - loss: 0.0078 - mae: 0.0650 - mse: 0.0078\n",
      "Epoch 12/400\n",
      "2412/2412 [==============================] - 0s 89us/sample - loss: 0.0071 - mae: 0.0617 - mse: 0.0071\n",
      "Epoch 13/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0069 - mae: 0.0609 - mse: 0.0069\n",
      "Epoch 14/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0071 - mae: 0.0607 - mse: 0.0071\n",
      "Epoch 15/400\n",
      "2412/2412 [==============================] - 0s 90us/sample - loss: 0.0074 - mae: 0.0620 - mse: 0.0074\n",
      "Epoch 16/400\n",
      "2412/2412 [==============================] - 0s 88us/sample - loss: 0.0066 - mae: 0.0574 - mse: 0.0066\n",
      "Epoch 17/400\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0077 - mae: 0.0618 - mse: 0.0077\n",
      "Epoch 18/400\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0074 - mae: 0.0622 - mse: 0.0074\n",
      "Epoch 19/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0060 - mae: 0.0561 - mse: 0.0060\n",
      "Epoch 20/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0062 - mae: 0.0559 - mse: 0.0062\n",
      "Epoch 21/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0073 - mae: 0.0539 - mse: 0.0073\n",
      "Epoch 22/400\n",
      "2412/2412 [==============================] - 0s 88us/sample - loss: 0.0059 - mae: 0.0529 - mse: 0.0059\n",
      "Epoch 23/400\n",
      "2412/2412 [==============================] - 0s 90us/sample - loss: 0.0043 - mae: 0.0480 - mse: 0.0043\n",
      "Epoch 24/400\n",
      "2412/2412 [==============================] - 0s 88us/sample - loss: 0.0040 - mae: 0.0455 - mse: 0.0040\n",
      "Epoch 25/400\n",
      "2412/2412 [==============================] - 0s 90us/sample - loss: 0.0045 - mae: 0.0464 - mse: 0.0045\n",
      "Epoch 26/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0048 - mae: 0.0482 - mse: 0.0048\n",
      "Epoch 27/400\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0052 - mae: 0.0513 - mse: 0.0052\n",
      "Epoch 28/400\n",
      "2412/2412 [==============================] - 0s 90us/sample - loss: 0.0047 - mae: 0.0474 - mse: 0.0047\n",
      "Epoch 29/400\n",
      "2412/2412 [==============================] - 0s 89us/sample - loss: 0.0034 - mae: 0.0421 - mse: 0.0034\n",
      "Epoch 30/400\n",
      "2412/2412 [==============================] - 0s 90us/sample - loss: 0.0030 - mae: 0.0390 - mse: 0.0030\n",
      "Epoch 31/400\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0028 - mae: 0.0385 - mse: 0.0028\n",
      "Epoch 32/400\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0028 - mae: 0.0384 - mse: 0.0028\n",
      "Epoch 33/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0027 - mae: 0.0375 - mse: 0.0027\n",
      "Epoch 34/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0026 - mae: 0.0372 - mse: 0.0026\n",
      "Epoch 35/400\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0027 - mae: 0.0382 - mse: 0.0027\n",
      "Epoch 36/400\n",
      "2412/2412 [==============================] - 0s 90us/sample - loss: 0.0029 - mae: 0.0385 - mse: 0.0029\n",
      "Epoch 37/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0029 - mae: 0.0380 - mse: 0.0029\n",
      "Epoch 38/400\n",
      "2412/2412 [==============================] - 0s 91us/sample - loss: 0.0027 - mae: 0.0372 - mse: 0.0027\n",
      "Epoch 39/400\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0021 - mae: 0.0332 - mse: 0.0021\n",
      "Epoch 40/400\n",
      "2412/2412 [==============================] - 0s 126us/sample - loss: 0.0020 - mae: 0.0317 - mse: 0.0020\n",
      "Epoch 41/400\n",
      "2412/2412 [==============================] - 0s 117us/sample - loss: 0.0025 - mae: 0.0361 - mse: 0.0025\n",
      "Epoch 42/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 0.0023 - mae: 0.0338 - mse: 0.0023\n",
      "Epoch 43/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0021 - mae: 0.0333 - mse: 0.0021\n",
      "Epoch 44/400\n",
      "2412/2412 [==============================] - 0s 90us/sample - loss: 0.0022 - mae: 0.0335 - mse: 0.0022\n",
      "Epoch 45/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0023 - mae: 0.0337 - mse: 0.0023\n",
      "Epoch 46/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0020 - mae: 0.0323 - mse: 0.0020\n",
      "Epoch 47/400\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0017 - mae: 0.0302 - mse: 0.0017\n",
      "Epoch 48/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0017 - mae: 0.0299 - mse: 0.0017\n",
      "Epoch 49/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0019 - mae: 0.0317 - mse: 0.0019\n",
      "Epoch 50/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0020 - mae: 0.0323 - mse: 0.0020\n",
      "Epoch 51/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0023 - mae: 0.0324 - mse: 0.0023\n",
      "Epoch 52/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0022 - mae: 0.0331 - mse: 0.0022\n",
      "Epoch 53/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0024 - mae: 0.0354 - mse: 0.0024\n",
      "Epoch 54/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 0.0021 - mae: 0.0330 - mse: 0.0021\n",
      "Epoch 55/400\n",
      "2412/2412 [==============================] - 0s 127us/sample - loss: 0.0018 - mae: 0.0308 - mse: 0.0018\n",
      "Epoch 56/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0018 - mae: 0.0311 - mse: 0.0018\n",
      "Epoch 57/400\n",
      "2412/2412 [==============================] - 0s 115us/sample - loss: 0.0016 - mae: 0.0294 - mse: 0.0016\n",
      "Epoch 58/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 0.0016 - mae: 0.0297 - mse: 0.0016\n",
      "Epoch 59/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0016 - mae: 0.0288 - mse: 0.0016\n",
      "Epoch 60/400\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0015 - mae: 0.0280 - mse: 0.0015\n",
      "Epoch 61/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0018 - mae: 0.0313 - mse: 0.0018\n",
      "Epoch 62/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0015 - mae: 0.0286 - mse: 0.0015\n",
      "Epoch 63/400\n",
      "2412/2412 [==============================] - 0s 118us/sample - loss: 0.0017 - mae: 0.0307 - mse: 0.0017\n",
      "Epoch 64/400\n",
      "2412/2412 [==============================] - 0s 128us/sample - loss: 0.0014 - mae: 0.0281 - mse: 0.0014\n",
      "Epoch 65/400\n",
      "2412/2412 [==============================] - 0s 119us/sample - loss: 0.0015 - mae: 0.0288 - mse: 0.0015\n",
      "Epoch 66/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0017 - mae: 0.0309 - mse: 0.0017\n",
      "Epoch 67/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0016 - mae: 0.0292 - mse: 0.0016\n",
      "Epoch 68/400\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0021 - mae: 0.0328 - mse: 0.0021\n",
      "Epoch 69/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0018 - mae: 0.0312 - mse: 0.0018\n",
      "Epoch 70/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0015 - mae: 0.0285 - mse: 0.0015\n",
      "Epoch 71/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0013 - mae: 0.0262 - mse: 0.0013\n",
      "Epoch 72/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0011 - mae: 0.0243 - mse: 0.0011\n",
      "Epoch 73/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0012 - mae: 0.0260 - mse: 0.0012\n",
      "Epoch 74/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 0.0011 - mae: 0.0245 - mse: 0.0011\n",
      "Epoch 75/400\n",
      "2412/2412 [==============================] - 0s 121us/sample - loss: 0.0012 - mae: 0.0254 - mse: 0.0012\n",
      "Epoch 76/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0012 - mae: 0.0247 - mse: 0.0012\n",
      "Epoch 77/400\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0012 - mae: 0.0257 - mse: 0.0012\n",
      "Epoch 78/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0013 - mae: 0.0267 - mse: 0.0013\n",
      "Epoch 79/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0016 - mae: 0.0298 - mse: 0.0016\n",
      "Epoch 80/400\n",
      "2412/2412 [==============================] - 0s 120us/sample - loss: 0.0015 - mae: 0.0287 - mse: 0.0015\n",
      "Epoch 81/400\n",
      "2412/2412 [==============================] - 0s 124us/sample - loss: 0.0014 - mae: 0.0273 - mse: 0.0014\n",
      "Epoch 82/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 0.0016 - mae: 0.0294 - mse: 0.0016\n",
      "Epoch 83/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 0.0016 - mae: 0.0296 - mse: 0.0016\n",
      "Epoch 84/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0025 - mae: 0.0354 - mse: 0.0025\n",
      "Epoch 85/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0024 - mae: 0.0351 - mse: 0.0024\n",
      "Epoch 86/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 0.0026 - mae: 0.0370 - mse: 0.0026\n",
      "Epoch 87/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0022 - mae: 0.0342 - mse: 0.0022\n",
      "Epoch 88/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0022 - mae: 0.0339 - mse: 0.0022\n",
      "Epoch 89/400\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0042 - mae: 0.0410 - mse: 0.0042\n",
      "Epoch 90/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0070 - mae: 0.0482 - mse: 0.0070\n",
      "Epoch 91/400\n",
      "2412/2412 [==============================] - 0s 115us/sample - loss: 0.0064 - mae: 0.0468 - mse: 0.0064\n",
      "Epoch 92/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 0.0032 - mae: 0.0403 - mse: 0.0032\n",
      "Epoch 93/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 0.0022 - mae: 0.0325 - mse: 0.0022\n",
      "Epoch 94/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0013 - mae: 0.0268 - mse: 0.0013\n",
      "Epoch 95/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 9.6214e-04 - mae: 0.0229 - mse: 9.6214e-04\n",
      "Epoch 96/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0023 - mae: 0.0231 - mse: 0.0023\n",
      "Epoch 97/400\n",
      "2412/2412 [==============================] - 0s 117us/sample - loss: 0.0018 - mae: 0.0322 - mse: 0.0018\n",
      "Epoch 98/400\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 0.0011 - mae: 0.0247 - mse: 0.0011\n",
      "Epoch 99/400\n",
      "2412/2412 [==============================] - 0s 130us/sample - loss: 0.0011 - mae: 0.0224 - mse: 0.0011\n",
      "Epoch 100/400\n",
      "2412/2412 [==============================] - 0s 117us/sample - loss: 7.7399e-04 - mae: 0.0202 - mse: 7.7399e-04\n",
      "Epoch 101/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 6.7155e-04 - mae: 0.0189 - mse: 6.7155e-04\n",
      "Epoch 102/400\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 7.0179e-04 - mae: 0.0193 - mse: 7.0179e-04\n",
      "Epoch 103/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 6.4893e-04 - mae: 0.0190 - mse: 6.4893e-04\n",
      "Epoch 104/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 6.0131e-04 - mae: 0.0180 - mse: 6.0131e-04\n",
      "Epoch 105/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 6.6363e-04 - mae: 0.0187 - mse: 6.6363e-04\n",
      "Epoch 106/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 6.3157e-04 - mae: 0.0184 - mse: 6.3157e-04\n",
      "Epoch 107/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 5.4278e-04 - mae: 0.0169 - mse: 5.4278e-04\n",
      "Epoch 108/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 5.2589e-04 - mae: 0.0161 - mse: 5.2589e-04\n",
      "Epoch 109/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 5.1467e-04 - mae: 0.0167 - mse: 5.1467e-04\n",
      "Epoch 110/400\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 5.5752e-04 - mae: 0.0172 - mse: 5.5752e-04\n",
      "Epoch 111/400\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 6.5421e-04 - mae: 0.0188 - mse: 6.5421e-04\n",
      "Epoch 112/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 7.7611e-04 - mae: 0.0204 - mse: 7.7611e-04\n",
      "Epoch 113/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 7.1929e-04 - mae: 0.0199 - mse: 7.1929e-04\n",
      "Epoch 114/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 8.2729e-04 - mae: 0.0211 - mse: 8.2729e-04\n",
      "Epoch 115/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 8.6074e-04 - mae: 0.0213 - mse: 8.6074e-04\n",
      "Epoch 116/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 9.5838e-04 - mae: 0.0223 - mse: 9.5838e-04\n",
      "Epoch 117/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0012 - mae: 0.0250 - mse: 0.0012\n",
      "Epoch 118/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0011 - mae: 0.0252 - mse: 0.0011\n",
      "Epoch 119/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0012 - mae: 0.0255 - mse: 0.0012\n",
      "Epoch 120/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0012 - mae: 0.0248 - mse: 0.0012\n",
      "Epoch 121/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0012 - mae: 0.0256 - mse: 0.0012\n",
      "Epoch 122/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0011 - mae: 0.0239 - mse: 0.0011\n",
      "Epoch 123/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0012 - mae: 0.0248 - mse: 0.0012\n",
      "Epoch 124/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0012 - mae: 0.0250 - mse: 0.0012\n",
      "Epoch 125/400\n",
      "2412/2412 [==============================] - 0s 118us/sample - loss: 0.0012 - mae: 0.0255 - mse: 0.0012\n",
      "Epoch 126/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0011 - mae: 0.0244 - mse: 0.0011\n",
      "Epoch 127/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 9.7202e-04 - mae: 0.0229 - mse: 9.7202e-04\n",
      "Epoch 128/400\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 6.6190e-04 - mae: 0.0191 - mse: 6.6190e-04\n",
      "Epoch 129/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 6.6332e-04 - mae: 0.0191 - mse: 6.6332e-04\n",
      "Epoch 130/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 6.1186e-04 - mae: 0.0184 - mse: 6.1186e-04\n",
      "Epoch 131/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 7.0718e-04 - mae: 0.0190 - mse: 7.0718e-04\n",
      "Epoch 132/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 8.2319e-04 - mae: 0.0210 - mse: 8.2319e-04\n",
      "Epoch 133/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 8.5847e-04 - mae: 0.0215 - mse: 8.5847e-04\n",
      "Epoch 134/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 7.1885e-04 - mae: 0.0198 - mse: 7.1885e-04\n",
      "Epoch 135/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 7.2956e-04 - mae: 0.0197 - mse: 7.2956e-04\n",
      "Epoch 136/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 7.3693e-04 - mae: 0.0203 - mse: 7.3693e-04\n",
      "Epoch 137/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 8.5953e-04 - mae: 0.0217 - mse: 8.5953e-04\n",
      "Epoch 138/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412/2412 [==============================] - 0s 102us/sample - loss: 7.4985e-04 - mae: 0.0204 - mse: 7.4985e-04\n",
      "Epoch 139/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 7.1330e-04 - mae: 0.0199 - mse: 7.1330e-04\n",
      "Epoch 140/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 6.7857e-04 - mae: 0.0194 - mse: 6.7857e-04\n",
      "Epoch 141/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 6.0385e-04 - mae: 0.0182 - mse: 6.0385e-04\n",
      "Epoch 142/400\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 5.9336e-04 - mae: 0.0176 - mse: 5.9336e-04\n",
      "Epoch 143/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 6.8246e-04 - mae: 0.0194 - mse: 6.8246e-04\n",
      "Epoch 144/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 8.3579e-04 - mae: 0.0214 - mse: 8.3579e-04\n",
      "Epoch 145/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0016 - mae: 0.0300 - mse: 0.0016\n",
      "Epoch 146/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0023 - mae: 0.0349 - mse: 0.0023\n",
      "Epoch 147/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 0.0026 - mae: 0.0346 - mse: 0.0026\n",
      "Epoch 148/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0023 - mae: 0.0351 - mse: 0.0023\n",
      "Epoch 149/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0015 - mae: 0.0274 - mse: 0.0015\n",
      "Epoch 150/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0015 - mae: 0.0275 - mse: 0.0015\n",
      "Epoch 151/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0011 - mae: 0.0244 - mse: 0.0011\n",
      "Epoch 152/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 7.2004e-04 - mae: 0.0194 - mse: 7.2004e-04\n",
      "Epoch 153/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 6.8672e-04 - mae: 0.0192 - mse: 6.8672e-04\n",
      "Epoch 154/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 5.2411e-04 - mae: 0.0170 - mse: 5.2411e-04\n",
      "Epoch 155/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 5.0293e-04 - mae: 0.0163 - mse: 5.0293e-04\n",
      "Epoch 156/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 4.2741e-04 - mae: 0.0151 - mse: 4.2741e-04\n",
      "Epoch 157/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 5.3842e-04 - mae: 0.0169 - mse: 5.3842e-04\n",
      "Epoch 158/400\n",
      "2412/2412 [==============================] - 0s 121us/sample - loss: 4.1903e-04 - mae: 0.0152 - mse: 4.1903e-04\n",
      "Epoch 159/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 4.6624e-04 - mae: 0.0157 - mse: 4.6624e-04\n",
      "Epoch 160/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 4.6915e-04 - mae: 0.0157 - mse: 4.6915e-04\n",
      "Epoch 161/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 4.5785e-04 - mae: 0.0158 - mse: 4.5785e-04\n",
      "Epoch 162/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 6.0852e-04 - mae: 0.0180 - mse: 6.0852e-04\n",
      "Epoch 163/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 5.4950e-04 - mae: 0.0170 - mse: 5.4950e-04\n",
      "Epoch 164/400\n",
      "2412/2412 [==============================] - 0s 120us/sample - loss: 6.1015e-04 - mae: 0.0183 - mse: 6.1015e-04\n",
      "Epoch 165/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 6.1455e-04 - mae: 0.0179 - mse: 6.1455e-04\n",
      "Epoch 166/400\n",
      "2412/2412 [==============================] - 0s 123us/sample - loss: 0.0010 - mae: 0.0213 - mse: 0.0010\n",
      "Epoch 167/400\n",
      "2412/2412 [==============================] - 0s 120us/sample - loss: 0.0016 - mae: 0.0270 - mse: 0.0016\n",
      "Epoch 168/400\n",
      "2412/2412 [==============================] - 0s 119us/sample - loss: 0.0011 - mae: 0.0249 - mse: 0.0011\n",
      "Epoch 169/400\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 9.1329e-04 - mae: 0.0226 - mse: 9.1329e-04\n",
      "Epoch 170/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 6.6904e-04 - mae: 0.0188 - mse: 6.6904e-04\n",
      "Epoch 171/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 7.0613e-04 - mae: 0.0196 - mse: 7.0613e-04\n",
      "Epoch 172/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 5.3722e-04 - mae: 0.0171 - mse: 5.3722e-04\n",
      "Epoch 173/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 6.1946e-04 - mae: 0.0183 - mse: 6.1946e-04\n",
      "Epoch 174/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 6.6281e-04 - mae: 0.0192 - mse: 6.6281e-04\n",
      "Epoch 175/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 5.7093e-04 - mae: 0.0175 - mse: 5.7093e-04\n",
      "Epoch 176/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 5.8825e-04 - mae: 0.0180 - mse: 5.8825e-04\n",
      "Epoch 177/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 6.0933e-04 - mae: 0.0178 - mse: 6.0933e-04\n",
      "Epoch 178/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 5.5926e-04 - mae: 0.0171 - mse: 5.5926e-04\n",
      "Epoch 179/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 5.2941e-04 - mae: 0.0167 - mse: 5.2941e-04\n",
      "Epoch 180/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 5.3955e-04 - mae: 0.0173 - mse: 5.3955e-04\n",
      "Epoch 181/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 6.6391e-04 - mae: 0.0194 - mse: 6.6391e-04\n",
      "Epoch 182/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 7.9216e-04 - mae: 0.0211 - mse: 7.9216e-04\n",
      "Epoch 183/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0011 - mae: 0.0244 - mse: 0.0011\n",
      "Epoch 184/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 7.3202e-04 - mae: 0.0200 - mse: 7.3202e-04\n",
      "Epoch 185/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 6.4131e-04 - mae: 0.0186 - mse: 6.4131e-04\n",
      "Epoch 186/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 6.4106e-04 - mae: 0.0190 - mse: 6.4106e-04\n",
      "Epoch 187/400\n",
      "2412/2412 [==============================] - 0s 119us/sample - loss: 5.3631e-04 - mae: 0.0175 - mse: 5.3631e-04\n",
      "Epoch 188/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 6.0131e-04 - mae: 0.0179 - mse: 6.0131e-04\n",
      "Epoch 189/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 7.0608e-04 - mae: 0.0195 - mse: 7.0608e-04\n",
      "Epoch 190/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 8.4629e-04 - mae: 0.0207 - mse: 8.4629e-04\n",
      "Epoch 191/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 6.7717e-04 - mae: 0.0193 - mse: 6.7717e-04\n",
      "Epoch 192/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 6.7379e-04 - mae: 0.0183 - mse: 6.7379e-04\n",
      "Epoch 193/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 6.5633e-04 - mae: 0.0185 - mse: 6.5633e-04\n",
      "Epoch 194/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 8.2084e-04 - mae: 0.0207 - mse: 8.2084e-04\n",
      "Epoch 195/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 7.8211e-04 - mae: 0.0208 - mse: 7.8211e-04\n",
      "Epoch 196/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 7.8907e-04 - mae: 0.0209 - mse: 7.8907e-04\n",
      "Epoch 197/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 5.8610e-04 - mae: 0.0178 - mse: 5.8610e-04\n",
      "Epoch 198/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 5.2970e-04 - mae: 0.0169 - mse: 5.2970e-04\n",
      "Epoch 199/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 4.7520e-04 - mae: 0.0165 - mse: 4.7520e-04\n",
      "Epoch 200/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 3.6312e-04 - mae: 0.0139 - mse: 3.6312e-04\n",
      "Epoch 201/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 4.5759e-04 - mae: 0.0157 - mse: 4.5759e-04\n",
      "Epoch 202/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 4.3962e-04 - mae: 0.0153 - mse: 4.3962e-04\n",
      "Epoch 203/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412/2412 [==============================] - 0s 105us/sample - loss: 5.4156e-04 - mae: 0.0169 - mse: 5.4156e-04\n",
      "Epoch 204/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 6.1528e-04 - mae: 0.0182 - mse: 6.1528e-04\n",
      "Epoch 205/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 7.0225e-04 - mae: 0.0188 - mse: 7.0225e-04\n",
      "Epoch 206/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 8.7806e-04 - mae: 0.0220 - mse: 8.7806e-04\n",
      "Epoch 207/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 7.7911e-04 - mae: 0.0210 - mse: 7.7911e-04\n",
      "Epoch 208/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 5.5736e-04 - mae: 0.0178 - mse: 5.5736e-04\n",
      "Epoch 209/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 5.0365e-04 - mae: 0.0167 - mse: 5.0365e-04\n",
      "Epoch 210/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 4.5278e-04 - mae: 0.0158 - mse: 4.5278e-04\n",
      "Epoch 211/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 4.9030e-04 - mae: 0.0160 - mse: 4.9030e-04\n",
      "Epoch 212/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 4.6076e-04 - mae: 0.0159 - mse: 4.6076e-04\n",
      "Epoch 213/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 5.8811e-04 - mae: 0.0176 - mse: 5.8811e-04\n",
      "Epoch 214/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 6.3205e-04 - mae: 0.0183 - mse: 6.3205e-04\n",
      "Epoch 215/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 6.1152e-04 - mae: 0.0182 - mse: 6.1152e-04\n",
      "Epoch 216/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 6.2836e-04 - mae: 0.0183 - mse: 6.2836e-04\n",
      "Epoch 217/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 6.4815e-04 - mae: 0.0186 - mse: 6.4815e-04\n",
      "Epoch 218/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 6.9701e-04 - mae: 0.0192 - mse: 6.9701e-04\n",
      "Epoch 219/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 8.2803e-04 - mae: 0.0213 - mse: 8.2803e-04\n",
      "Epoch 220/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 0.0012 - mae: 0.0256 - mse: 0.0012\n",
      "Epoch 221/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 7.0352e-04 - mae: 0.0201 - mse: 7.0352e-04\n",
      "Epoch 222/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 6.4055e-04 - mae: 0.0188 - mse: 6.4055e-04\n",
      "Epoch 223/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 4.9021e-04 - mae: 0.0164 - mse: 4.9021e-04\n",
      "Epoch 224/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 4.8256e-04 - mae: 0.0162 - mse: 4.8256e-04\n",
      "Epoch 225/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 5.2476e-04 - mae: 0.0170 - mse: 5.2476e-04\n",
      "Epoch 226/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 4.4901e-04 - mae: 0.0156 - mse: 4.4901e-04\n",
      "Epoch 227/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 4.3994e-04 - mae: 0.0149 - mse: 4.3994e-04\n",
      "Epoch 228/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 5.0848e-04 - mae: 0.0162 - mse: 5.0848e-04\n",
      "Epoch 229/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 4.6692e-04 - mae: 0.0159 - mse: 4.6692e-04\n",
      "Epoch 230/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 4.0647e-04 - mae: 0.0146 - mse: 4.0647e-04\n",
      "Epoch 231/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 4.1055e-04 - mae: 0.0147 - mse: 4.1055e-04\n",
      "Epoch 232/400\n",
      "2412/2412 [==============================] - 0s 119us/sample - loss: 4.5968e-04 - mae: 0.0152 - mse: 4.5968e-04\n",
      "Epoch 233/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 4.8734e-04 - mae: 0.0163 - mse: 4.8734e-04\n",
      "Epoch 234/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.8689e-04 - mae: 0.0163 - mse: 4.8689e-04\n",
      "Epoch 235/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 4.8190e-04 - mae: 0.0161 - mse: 4.8190e-04\n",
      "Epoch 236/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 6.0435e-04 - mae: 0.0181 - mse: 6.0435e-04\n",
      "Epoch 237/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 5.9549e-04 - mae: 0.0178 - mse: 5.9549e-04\n",
      "Epoch 238/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 6.4552e-04 - mae: 0.0190 - mse: 6.4552e-04\n",
      "Epoch 239/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 7.2526e-04 - mae: 0.0200 - mse: 7.2526e-04\n",
      "Epoch 240/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 6.9547e-04 - mae: 0.0191 - mse: 6.9547e-04\n",
      "Epoch 241/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 7.6011e-04 - mae: 0.0202 - mse: 7.6011e-04\n",
      "Epoch 242/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 7.4514e-04 - mae: 0.0207 - mse: 7.4514e-04\n",
      "Epoch 243/400\n",
      "2412/2412 [==============================] - 0s 117us/sample - loss: 7.2546e-04 - mae: 0.0196 - mse: 7.2546e-04\n",
      "Epoch 244/400\n",
      "2412/2412 [==============================] - 0s 119us/sample - loss: 6.9344e-04 - mae: 0.0191 - mse: 6.9344e-04\n",
      "Epoch 245/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 6.0742e-04 - mae: 0.0180 - mse: 6.0742e-04\n",
      "Epoch 246/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 5.5411e-04 - mae: 0.0170 - mse: 5.5411e-04\n",
      "Epoch 247/400\n",
      "2412/2412 [==============================] - 0s 126us/sample - loss: 4.1890e-04 - mae: 0.0152 - mse: 4.1890e-04\n",
      "Epoch 248/400\n",
      "2412/2412 [==============================] - 0s 136us/sample - loss: 3.4963e-04 - mae: 0.0138 - mse: 3.4963e-04\n",
      "Epoch 249/400\n",
      "2412/2412 [==============================] - 0s 118us/sample - loss: 3.6536e-04 - mae: 0.0140 - mse: 3.6536e-04\n",
      "Epoch 250/400\n",
      "2412/2412 [==============================] - 0s 127us/sample - loss: 8.7110e-04 - mae: 0.0197 - mse: 8.7110e-04\n",
      "Epoch 251/400\n",
      "2412/2412 [==============================] - 0s 118us/sample - loss: 7.2997e-04 - mae: 0.0199 - mse: 7.2997e-04\n",
      "Epoch 252/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 6.1665e-04 - mae: 0.0185 - mse: 6.1665e-04\n",
      "Epoch 253/400\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 6.2044e-04 - mae: 0.0181 - mse: 6.2044e-04\n",
      "Epoch 254/400\n",
      "2412/2412 [==============================] - 0s 120us/sample - loss: 5.1855e-04 - mae: 0.0163 - mse: 5.1855e-04\n",
      "Epoch 255/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 5.0508e-04 - mae: 0.0166 - mse: 5.0508e-04\n",
      "Epoch 256/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 4.0410e-04 - mae: 0.0146 - mse: 4.0410e-04\n",
      "Epoch 257/400\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 3.4392e-04 - mae: 0.0133 - mse: 3.4392e-04\n",
      "Epoch 258/400\n",
      "2412/2412 [==============================] - 0s 120us/sample - loss: 3.7877e-04 - mae: 0.0143 - mse: 3.7877e-04\n",
      "Epoch 259/400\n",
      "2412/2412 [==============================] - 0s 123us/sample - loss: 3.8470e-04 - mae: 0.0144 - mse: 3.8470e-04\n",
      "Epoch 260/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 4.0923e-04 - mae: 0.0147 - mse: 4.0923e-04\n",
      "Epoch 261/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 3.8974e-04 - mae: 0.0144 - mse: 3.8974e-04\n",
      "Epoch 262/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 6.4397e-04 - mae: 0.0188 - mse: 6.4397e-04\n",
      "Epoch 263/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 5.2273e-04 - mae: 0.0170 - mse: 5.2273e-04\n",
      "Epoch 264/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 4.0998e-04 - mae: 0.0150 - mse: 4.0998e-04\n",
      "Epoch 265/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 4.6127e-04 - mae: 0.0156 - mse: 4.6127e-04\n",
      "Epoch 266/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 4.8558e-04 - mae: 0.0164 - mse: 4.8558e-04\n",
      "Epoch 267/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 4.2771e-04 - mae: 0.0155 - mse: 4.2771e-04\n",
      "Epoch 268/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412/2412 [==============================] - 0s 108us/sample - loss: 4.4808e-04 - mae: 0.0155 - mse: 4.4808e-04\n",
      "Epoch 269/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 5.4042e-04 - mae: 0.0171 - mse: 5.4042e-04\n",
      "Epoch 270/400\n",
      "2412/2412 [==============================] - 0s 117us/sample - loss: 4.9319e-04 - mae: 0.0163 - mse: 4.9319e-04\n",
      "Epoch 271/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 4.2395e-04 - mae: 0.0150 - mse: 4.2395e-04\n",
      "Epoch 272/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 5.1917e-04 - mae: 0.0169 - mse: 5.1917e-04\n",
      "Epoch 273/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 5.0876e-04 - mae: 0.0168 - mse: 5.0876e-04\n",
      "Epoch 274/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.7581e-04 - mae: 0.0160 - mse: 4.7581e-04\n",
      "Epoch 275/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 4.0550e-04 - mae: 0.0145 - mse: 4.0550e-04\n",
      "Epoch 276/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 4.3439e-04 - mae: 0.0154 - mse: 4.3439e-04\n",
      "Epoch 277/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 4.3554e-04 - mae: 0.0151 - mse: 4.3554e-04\n",
      "Epoch 278/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.5006e-04 - mae: 0.0151 - mse: 4.5006e-04\n",
      "Epoch 279/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.8242e-04 - mae: 0.0163 - mse: 4.8242e-04\n",
      "Epoch 280/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 4.3165e-04 - mae: 0.0153 - mse: 4.3165e-04\n",
      "Epoch 281/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 3.3660e-04 - mae: 0.0132 - mse: 3.3660e-04\n",
      "Epoch 282/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 4.0874e-04 - mae: 0.0146 - mse: 4.0874e-04\n",
      "Epoch 283/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 5.5819e-04 - mae: 0.0175 - mse: 5.5819e-04\n",
      "Epoch 284/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 5.7907e-04 - mae: 0.0181 - mse: 5.7907e-04\n",
      "Epoch 285/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 7.4538e-04 - mae: 0.0202 - mse: 7.4538e-04\n",
      "Epoch 286/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 5.5619e-04 - mae: 0.0174 - mse: 5.5619e-04\n",
      "Epoch 287/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 4.4455e-04 - mae: 0.0155 - mse: 4.4455e-04\n",
      "Epoch 288/400\n",
      "2412/2412 [==============================] - 0s 118us/sample - loss: 4.9412e-04 - mae: 0.0160 - mse: 4.9412e-04\n",
      "Epoch 289/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 6.0777e-04 - mae: 0.0179 - mse: 6.0777e-04\n",
      "Epoch 290/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 4.1337e-04 - mae: 0.0146 - mse: 4.1337e-04\n",
      "Epoch 291/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 4.0175e-04 - mae: 0.0145 - mse: 4.0175e-04\n",
      "Epoch 292/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 4.8368e-04 - mae: 0.0156 - mse: 4.8368e-04\n",
      "Epoch 293/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 6.7520e-04 - mae: 0.0187 - mse: 6.7520e-04\n",
      "Epoch 294/400\n",
      "2412/2412 [==============================] - 0s 122us/sample - loss: 7.6865e-04 - mae: 0.0202 - mse: 7.6865e-04\n",
      "Epoch 295/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 8.3399e-04 - mae: 0.0212 - mse: 8.3399e-04\n",
      "Epoch 296/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0010 - mae: 0.0211 - mse: 0.0010\n",
      "Epoch 297/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 7.9130e-04 - mae: 0.0211 - mse: 7.9130e-04\n",
      "Epoch 298/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 4.5638e-04 - mae: 0.0162 - mse: 4.5638e-04\n",
      "Epoch 299/400\n",
      "2412/2412 [==============================] - 0s 117us/sample - loss: 3.6450e-04 - mae: 0.0140 - mse: 3.6450e-04\n",
      "Epoch 300/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 2.9530e-04 - mae: 0.0127 - mse: 2.9530e-04\n",
      "Epoch 301/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 2.4414e-04 - mae: 0.0115 - mse: 2.4414e-04\n",
      "Epoch 302/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 1.9816e-04 - mae: 0.0099 - mse: 1.9816e-04\n",
      "Epoch 303/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 1.6768e-04 - mae: 0.0092 - mse: 1.6768e-04\n",
      "Epoch 304/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 2.5344e-04 - mae: 0.0116 - mse: 2.5344e-04\n",
      "Epoch 305/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 2.2236e-04 - mae: 0.0108 - mse: 2.2236e-04\n",
      "Epoch 306/400\n",
      "2412/2412 [==============================] - 0s 118us/sample - loss: 3.2682e-04 - mae: 0.0133 - mse: 3.2682e-04\n",
      "Epoch 307/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 3.4338e-04 - mae: 0.0135 - mse: 3.4338e-04\n",
      "Epoch 308/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 4.0064e-04 - mae: 0.0145 - mse: 4.0064e-04\n",
      "Epoch 309/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 4.9426e-04 - mae: 0.0161 - mse: 4.9426e-04\n",
      "Epoch 310/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 4.4827e-04 - mae: 0.0157 - mse: 4.4827e-04\n",
      "Epoch 311/400\n",
      "2412/2412 [==============================] - 0s 117us/sample - loss: 3.7525e-04 - mae: 0.0142 - mse: 3.7525e-04\n",
      "Epoch 312/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 3.4854e-04 - mae: 0.0135 - mse: 3.4854e-04\n",
      "Epoch 313/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 2.8610e-04 - mae: 0.0123 - mse: 2.8610e-04\n",
      "Epoch 314/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 3.4853e-04 - mae: 0.0132 - mse: 3.4853e-04\n",
      "Epoch 315/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 3.2515e-04 - mae: 0.0132 - mse: 3.2515e-04\n",
      "Epoch 316/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 3.6186e-04 - mae: 0.0140 - mse: 3.6186e-04\n",
      "Epoch 317/400\n",
      "2412/2412 [==============================] - 0s 117us/sample - loss: 3.6041e-04 - mae: 0.0140 - mse: 3.6041e-04\n",
      "Epoch 318/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 4.5100e-04 - mae: 0.0158 - mse: 4.5100e-04\n",
      "Epoch 319/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 4.1532e-04 - mae: 0.0151 - mse: 4.1532e-04\n",
      "Epoch 320/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 5.2591e-04 - mae: 0.0174 - mse: 5.2591e-04\n",
      "Epoch 321/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 8.0367e-04 - mae: 0.0209 - mse: 8.0367e-04\n",
      "Epoch 322/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 6.2299e-04 - mae: 0.0185 - mse: 6.2299e-04\n",
      "Epoch 323/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 6.6895e-04 - mae: 0.0190 - mse: 6.6895e-04\n",
      "Epoch 324/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 5.2691e-04 - mae: 0.0167 - mse: 5.2691e-04\n",
      "Epoch 325/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 3.4732e-04 - mae: 0.0136 - mse: 3.4732e-04\n",
      "Epoch 326/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 3.0015e-04 - mae: 0.0128 - mse: 3.0015e-04\n",
      "Epoch 327/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 2.6914e-04 - mae: 0.0121 - mse: 2.6914e-04\n",
      "Epoch 328/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 2.5379e-04 - mae: 0.0116 - mse: 2.5379e-04\n",
      "Epoch 329/400\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 2.8331e-04 - mae: 0.0123 - mse: 2.8331e-04\n",
      "Epoch 330/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 3.8286e-04 - mae: 0.0144 - mse: 3.8286e-04\n",
      "Epoch 331/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 4.5124e-04 - mae: 0.0155 - mse: 4.5124e-04\n",
      "Epoch 332/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 3.8720e-04 - mae: 0.0143 - mse: 3.8720e-04\n",
      "Epoch 333/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412/2412 [==============================] - 0s 102us/sample - loss: 3.8680e-04 - mae: 0.0142 - mse: 3.8680e-04\n",
      "Epoch 334/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 3.5652e-04 - mae: 0.0142 - mse: 3.5652e-04\n",
      "Epoch 335/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 3.3010e-04 - mae: 0.0135 - mse: 3.3010e-04\n",
      "Epoch 336/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 2.6407e-04 - mae: 0.0117 - mse: 2.6407e-04\n",
      "Epoch 337/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 3.0964e-04 - mae: 0.0131 - mse: 3.0964e-04\n",
      "Epoch 338/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 3.2071e-04 - mae: 0.0133 - mse: 3.2071e-04\n",
      "Epoch 339/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 3.1453e-04 - mae: 0.0129 - mse: 3.1453e-04\n",
      "Epoch 340/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 3.6376e-04 - mae: 0.0139 - mse: 3.6376e-04\n",
      "Epoch 341/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 3.3475e-04 - mae: 0.0136 - mse: 3.3475e-04\n",
      "Epoch 342/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 3.0082e-04 - mae: 0.0128 - mse: 3.0082e-04\n",
      "Epoch 343/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 2.2646e-04 - mae: 0.0109 - mse: 2.2646e-04\n",
      "Epoch 344/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 3.1663e-04 - mae: 0.0129 - mse: 3.1663e-04\n",
      "Epoch 345/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 3.4964e-04 - mae: 0.0135 - mse: 3.4964e-04\n",
      "Epoch 346/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 3.7589e-04 - mae: 0.0142 - mse: 3.7589e-04\n",
      "Epoch 347/400\n",
      "2412/2412 [==============================] - 0s 117us/sample - loss: 3.9732e-04 - mae: 0.0144 - mse: 3.9732e-04\n",
      "Epoch 348/400\n",
      "2412/2412 [==============================] - 0s 115us/sample - loss: 4.9210e-04 - mae: 0.0152 - mse: 4.9210e-04\n",
      "Epoch 349/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 6.9067e-04 - mae: 0.0187 - mse: 6.9067e-04\n",
      "Epoch 350/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 8.4674e-04 - mae: 0.0215 - mse: 8.4674e-04\n",
      "Epoch 351/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0030 - mae: 0.0293 - mse: 0.0030\n",
      "Epoch 352/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 0.0021 - mae: 0.0328 - mse: 0.0021\n",
      "Epoch 353/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 0.0017 - mae: 0.0300 - mse: 0.0017\n",
      "Epoch 354/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 9.3557e-04 - mae: 0.0220 - mse: 9.3557e-04\n",
      "Epoch 355/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 5.4047e-04 - mae: 0.0170 - mse: 5.4047e-04\n",
      "Epoch 356/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 5.6104e-04 - mae: 0.0156 - mse: 5.6104e-04\n",
      "Epoch 357/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 3.9786e-04 - mae: 0.0144 - mse: 3.9786e-04\n",
      "Epoch 358/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 2.6530e-04 - mae: 0.0118 - mse: 2.6530e-04\n",
      "Epoch 359/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 2.7244e-04 - mae: 0.0120 - mse: 2.7244e-04\n",
      "Epoch 360/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 2.1109e-04 - mae: 0.0105 - mse: 2.1109e-04\n",
      "Epoch 361/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 1.6909e-04 - mae: 0.0095 - mse: 1.6909e-04\n",
      "Epoch 362/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 1.2321e-04 - mae: 0.0081 - mse: 1.2321e-04\n",
      "Epoch 363/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 1.4285e-04 - mae: 0.0085 - mse: 1.4285e-04\n",
      "Epoch 364/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 1.4738e-04 - mae: 0.0084 - mse: 1.4738e-04\n",
      "Epoch 365/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 1.5966e-04 - mae: 0.0090 - mse: 1.5966e-04\n",
      "Epoch 366/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 1.2551e-04 - mae: 0.0077 - mse: 1.2551e-04\n",
      "Epoch 367/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 1.6073e-04 - mae: 0.0089 - mse: 1.6073e-04\n",
      "Epoch 368/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 2.0192e-04 - mae: 0.0102 - mse: 2.0192e-04\n",
      "Epoch 369/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 1.9297e-04 - mae: 0.0099 - mse: 1.9297e-04\n",
      "Epoch 370/400\n",
      "2412/2412 [==============================] - 0s 117us/sample - loss: 2.5568e-04 - mae: 0.0114 - mse: 2.5568e-04\n",
      "Epoch 371/400\n",
      "2412/2412 [==============================] - 0s 117us/sample - loss: 2.4825e-04 - mae: 0.0112 - mse: 2.4825e-04\n",
      "Epoch 372/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 3.7222e-04 - mae: 0.0142 - mse: 3.7222e-04\n",
      "Epoch 373/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 3.4584e-04 - mae: 0.0138 - mse: 3.4584e-04\n",
      "Epoch 374/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 3.1534e-04 - mae: 0.0130 - mse: 3.1534e-04\n",
      "Epoch 375/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 3.4718e-04 - mae: 0.0135 - mse: 3.4718e-04\n",
      "Epoch 376/400\n",
      "2412/2412 [==============================] - 0s 118us/sample - loss: 3.6709e-04 - mae: 0.0142 - mse: 3.6709e-04\n",
      "Epoch 377/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 3.3514e-04 - mae: 0.0137 - mse: 3.3514e-04\n",
      "Epoch 378/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 3.6735e-04 - mae: 0.0141 - mse: 3.6735e-04\n",
      "Epoch 379/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 3.4347e-04 - mae: 0.0136 - mse: 3.4347e-04\n",
      "Epoch 380/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 3.2590e-04 - mae: 0.0129 - mse: 3.2590e-04\n",
      "Epoch 381/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 3.7097e-04 - mae: 0.0142 - mse: 3.7097e-04\n",
      "Epoch 382/400\n",
      "2412/2412 [==============================] - 0s 115us/sample - loss: 3.7701e-04 - mae: 0.0139 - mse: 3.7701e-04\n",
      "Epoch 383/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 3.8609e-04 - mae: 0.0144 - mse: 3.8609e-04\n",
      "Epoch 384/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 5.1967e-04 - mae: 0.0168 - mse: 5.1967e-04\n",
      "Epoch 385/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 4.0394e-04 - mae: 0.0150 - mse: 4.0394e-04\n",
      "Epoch 386/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 2.6900e-04 - mae: 0.0123 - mse: 2.6900e-04\n",
      "Epoch 387/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 2.1435e-04 - mae: 0.0105 - mse: 2.1435e-04\n",
      "Epoch 388/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 2.2492e-04 - mae: 0.0108 - mse: 2.2492e-04\n",
      "Epoch 389/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 2.3453e-04 - mae: 0.0111 - mse: 2.3453e-04\n",
      "Epoch 390/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 2.3287e-04 - mae: 0.0113 - mse: 2.3287e-04\n",
      "Epoch 391/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 2.6264e-04 - mae: 0.0119 - mse: 2.6264e-04\n",
      "Epoch 392/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 3.0031e-04 - mae: 0.0124 - mse: 3.0031e-04\n",
      "Epoch 393/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 3.0373e-04 - mae: 0.0128 - mse: 3.0373e-04\n",
      "Epoch 394/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 2.9184e-04 - mae: 0.0128 - mse: 2.9184e-04\n",
      "Epoch 395/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 3.2277e-04 - mae: 0.0133 - mse: 3.2277e-04\n",
      "Epoch 396/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 4.0231e-04 - mae: 0.0144 - mse: 4.0231e-04\n",
      "Epoch 397/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 5.0031e-04 - mae: 0.0163 - mse: 5.0031e-04\n",
      "Epoch 398/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412/2412 [==============================] - 0s 102us/sample - loss: 4.7323e-04 - mae: 0.0162 - mse: 4.7323e-04\n",
      "Epoch 399/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 3.9910e-04 - mae: 0.0147 - mse: 3.9910e-04\n",
      "Epoch 400/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 4.7981e-04 - mae: 0.0146 - mse: 4.7981e-04\n",
      "269/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 960us/sample - loss: 0.0188 - mae: 0.0850 - mse: 0.0165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.08504735678434372\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV, StratifiedKFold, \\\n",
    "    cross_validate, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, \\\n",
    "    mean_absolute_error, make_scorer, brier_score_loss, roc_curve\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"s\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "\n",
    "\n",
    "__author__ = \"Dor Ma'ayan\"\n",
    "__email__ = \"grano@ifi.uzh.ch\"\n",
    "__license__ = \"MIT\"\n",
    "\n",
    "\n",
    "CSV_PATH = \"complete-frame.csv\"\n",
    "CSV_MINER_PATH = \"testminereffectiveness.csv\"\n",
    "DATA_DIR = \"results\"\n",
    "\n",
    "\n",
    "def label_rename1 (row):\n",
    "    return row['path_test'].split('/')[len(row['path_test'].split('/')) - 1].split('.')[0]\n",
    "\n",
    "def label_rename2 (row):\n",
    "    return row['path_src'].split('/')[len(row['path_src'].split('/')) - 1].split('.')[0]\n",
    "\n",
    "def load_quartile(frame):\n",
    "    low, high = frame.mutation.quantile([0.25,0.75])\n",
    "    frame_low = frame.query('mutation<{low}'.format(low=low))\n",
    "    frame_high = frame.query('mutation>{high}'.format(high=high))\n",
    "    frame_low['mutation'] = 0\n",
    "    frame_high['mutation'] = 1\n",
    "    frame = pd.concat([frame_low, frame_high], ignore_index=True)\n",
    "    frame = frame.sample(frac=1).reset_index(drop=True)\n",
    "    return frame;\n",
    "\n",
    "def load_frame():\n",
    "    \n",
    "    d = {'TestClassName' : 'ClassName',\n",
    "         'Vocabulary' : 'Vocabulary_prod',\n",
    "         'Word' : 'Word_prod', \n",
    "         'Non Whithe Characters' : 'Non Whithe Characters_prod',\n",
    "         'No. Methods' : 'No. Methods_prod',\n",
    "         'Special' : 'Special_prod',\n",
    "     'No. Method Invoctions' : 'No. Method Invoctions_prod',\n",
    "    'AST size' : 'AST size_prod', 'Max Depth' : 'Max Depth_prod',\n",
    "         'Deg2' : 'Deg2_prod',\n",
    "         'DegPerm' : 'DegPerm_prod',\n",
    "         'No. Break' : 'No. Break_prod',\n",
    "         'No. Continue' : 'No. Continue_prod',\n",
    "     'Avg Depth' : 'Avg Depth_prod', 'Dexterity' : 'Dexterity_prod',\n",
    "    'No. Expressions' : 'No. Expressions_prod', 'No. Try' : 'No. Try_prod', 'No. Catch' : 'No. Catch_prod',\n",
    "     'No. Loop' : 'No. Loop_prod', 'No. Conditions' : 'No. Conditions_prod', 'No. Else' : 'No. Else_prod'}\n",
    "    \n",
    "    \n",
    "    frame1 = pd.read_csv(CSV_PATH, sep=\",\")\n",
    "    frame1 = frame1.sample(frac=1).reset_index(drop=True)\n",
    "    frame1['TestClassName'] = frame1.apply(lambda row: label_rename1(row), axis=1)\n",
    "    frame1['ClassName'] = frame1.apply(lambda row: label_rename2(row), axis=1)\n",
    "        \n",
    "    \n",
    "    frame2 = pd.read_csv(CSV_MINER_PATH, sep=',')\n",
    "    \n",
    "    frame3 = pd.read_csv(CSV_MINER_PATH, sep=',')\n",
    "    frame3 = frame3.rename(columns = d)\n",
    "    frame3 = frame3.drop(['Bad API', 'Junit', 'Hamcrest', 'Mockito', 'Nº','Project'], axis=1)\n",
    "    \n",
    "    \n",
    "    frame = pd.merge(frame1, frame2, on='TestClassName')\n",
    "    \n",
    "    frame = pd.merge(frame, frame3, on='ClassName')\n",
    "    \n",
    "\n",
    "    frame = frame.drop(['project', 'module', 'path_test','test_name','path_src',\n",
    "                        'commit', 'class_name'], axis=1)\n",
    "    frame = frame.sample(frac=1).reset_index(drop=True)\n",
    "    frame = frame.dropna()\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def load_quartile(frame):\n",
    "    low, high = frame.mutation.quantile([0.25,0.75])\n",
    "    frame_low = frame.query('mutation<{low}'.format(low=low))\n",
    "    frame_high = frame.query('mutation>{high}'.format(high=high))\n",
    "    frame_low['mutation'] = 0\n",
    "    frame_high['mutation'] = 1\n",
    "    frame = pd.concat([frame_low, frame_high], ignore_index=True)\n",
    "    frame = frame.sample(frac=1).reset_index(drop=True)\n",
    "    return frame;\n",
    "\n",
    "\n",
    "\n",
    "def load_all_data(frame):\n",
    "    columns = ['isAssertionRoulette',\n",
    "       'isEagerTest', 'isLazyTest', 'isMysteryGuest',\n",
    "       'isSensitiveEquality', 'isResourceOptimism', 'isForTestersOnly',\n",
    "       'isIndirectTesting', 'LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod', 'LOC_test',\n",
    "       'HALSTEAD_test', 'RFC_test', 'CBO_test', 'MPC_test', 'IFC_test',\n",
    "       'DAC_test', 'DAC2_test', 'LCOM1_test', 'LCOM2_test', 'LCOM3_test',\n",
    "       'LCOM4_test', 'CONNECTIVITY_test', 'LCOM5_test', 'COH_test',\n",
    "       'TCC_test', 'LCC_test', 'ICH_test', 'WMC_test', 'NOA_test',\n",
    "       'NOPA_test', 'NOP_test', 'McCABE_test', 'BUSWEIMER_test',\n",
    "       'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability', 'test_readability', 'No. Methods', 'Vocabulary', 'Word',\n",
    "               'Special', 'Non Whithe Characters', 'No. Method Invoctions', 'AST size', 'Max Depth',\n",
    "               'Avg Depth', 'Deg2', 'DegPerm', 'Dexterity', 'No. Expressions', 'No. Try', 'No. Catch',\n",
    "               'No. Loop', 'No. Break', 'No. Continue', 'No. Conditions', 'No. Else', 'Bad API',\n",
    "               'Junit', 'Hamcrest', 'Mockito', 'No. Methods_prod', 'Vocabulary_prod', 'Word_prod',\n",
    "               'Special_prod', 'Non Whithe Characters_prod', 'No. Method Invoctions_prod', 'AST size_prod',\n",
    "               'Max Depth_prod', 'Avg Depth_prod', 'Deg2_prod', 'DegPerm_prod', 'Dexterity_prod',\n",
    "               'No. Expressions_prod', 'No. Try_prod', 'No. Catch_prod', 'No. Loop_prod', 'No. Break_prod',\n",
    "               'No. Continue_prod', 'No. Conditions_prod', 'No. Else_prod']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "def load_all_data_dynamic(frame):\n",
    "    columns = ['line_coverage', 'isAssertionRoulette',\n",
    "       'isEagerTest', 'isLazyTest', 'isMysteryGuest',\n",
    "       'isSensitiveEquality', 'isResourceOptimism', 'isForTestersOnly',\n",
    "       'isIndirectTesting', 'LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod', 'LOC_test',\n",
    "       'HALSTEAD_test', 'RFC_test', 'CBO_test', 'MPC_test', 'IFC_test',\n",
    "       'DAC_test', 'DAC2_test', 'LCOM1_test', 'LCOM2_test', 'LCOM3_test',\n",
    "       'LCOM4_test', 'CONNECTIVITY_test', 'LCOM5_test', 'COH_test',\n",
    "       'TCC_test', 'LCC_test', 'ICH_test', 'WMC_test', 'NOA_test',\n",
    "       'NOPA_test', 'NOP_test', 'McCABE_test', 'BUSWEIMER_test',\n",
    "       'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability', 'test_readability', 'No. Methods', 'Vocabulary', 'Word',\n",
    "               'Special', 'Non Whithe Characters', 'No. Method Invoctions', 'AST size', 'Max Depth',\n",
    "               'Avg Depth', 'Deg2', 'DegPerm', 'Dexterity', 'No. Expressions', 'No. Try', 'No. Catch',\n",
    "               'No. Loop', 'No. Break', 'No. Continue', 'No. Conditions', 'No. Else', 'Bad API',\n",
    "               'Junit', 'Hamcrest', 'Mockito', 'No. Methods_prod', 'Vocabulary_prod', 'Word_prod',\n",
    "               'Special_prod', 'Non Whithe Characters_prod', 'No. Method Invoctions_prod', 'AST size_prod',\n",
    "               'Max Depth_prod', 'Avg Depth_prod', 'Deg2_prod', 'DegPerm_prod', 'Dexterity_prod',\n",
    "               'No. Expressions_prod', 'No. Try_prod', 'No. Catch_prod', 'No. Loop_prod', 'No. Break_prod',\n",
    "               'No. Continue_prod', 'No. Conditions_prod', 'No. Else_prod']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "\n",
    "def load_all_their_data(frame):\n",
    "    columns = ['line_coverage', 'isAssertionRoulette',\n",
    "       'isEagerTest', 'isLazyTest', 'isMysteryGuest',\n",
    "       'isSensitiveEquality', 'isResourceOptimism', 'isForTestersOnly',\n",
    "       'isIndirectTesting', 'LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod', 'LOC_test',\n",
    "       'HALSTEAD_test', 'RFC_test', 'CBO_test', 'MPC_test', 'IFC_test',\n",
    "       'DAC_test', 'DAC2_test', 'LCOM1_test', 'LCOM2_test', 'LCOM3_test',\n",
    "       'LCOM4_test', 'CONNECTIVITY_test', 'LCOM5_test', 'COH_test',\n",
    "       'TCC_test', 'LCC_test', 'ICH_test', 'WMC_test', 'NOA_test',\n",
    "       'NOPA_test', 'NOP_test', 'McCABE_test', 'BUSWEIMER_test',\n",
    "       'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability', 'test_readability']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "def load_all_their_test_data(frame):\n",
    "    columns = ['isAssertionRoulette',\n",
    "       'isEagerTest', 'isLazyTest', 'isMysteryGuest',\n",
    "       'isSensitiveEquality', 'isResourceOptimism', 'isForTestersOnly',\n",
    "       'isIndirectTesting','LOC_test',\n",
    "       'HALSTEAD_test', 'RFC_test', 'CBO_test', 'MPC_test', 'IFC_test',\n",
    "       'DAC_test', 'DAC2_test', 'LCOM1_test', 'LCOM2_test', 'LCOM3_test',\n",
    "       'LCOM4_test', 'CONNECTIVITY_test', 'LCOM5_test', 'COH_test',\n",
    "       'TCC_test', 'LCC_test', 'ICH_test', 'WMC_test', 'NOA_test',\n",
    "       'NOPA_test', 'NOP_test', 'McCABE_test', 'BUSWEIMER_test', 'test_readability']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "def load_all_test_data(frame):\n",
    "    columns = ['isAssertionRoulette',\n",
    "       'isEagerTest', 'isLazyTest', 'isMysteryGuest',\n",
    "       'isSensitiveEquality', 'isResourceOptimism', 'isForTestersOnly',\n",
    "       'isIndirectTesting', 'LOC_test',\n",
    "       'HALSTEAD_test', 'RFC_test', 'CBO_test', 'MPC_test', 'IFC_test',\n",
    "       'DAC_test', 'DAC2_test', 'LCOM1_test', 'LCOM2_test', 'LCOM3_test',\n",
    "       'LCOM4_test', 'CONNECTIVITY_test', 'LCOM5_test', 'COH_test',\n",
    "       'TCC_test', 'LCC_test', 'ICH_test', 'WMC_test', 'NOA_test',\n",
    "       'NOPA_test', 'NOP_test', 'McCABE_test', 'BUSWEIMER_test',\n",
    "       'test_readability', 'No. Methods', 'Vocabulary', 'Word',\n",
    "               'Special', 'Non Whithe Characters', 'No. Method Invoctions', 'AST size', 'Max Depth',\n",
    "               'Avg Depth', 'Deg2', 'DegPerm', 'Dexterity', 'No. Expressions', 'No. Try', 'No. Catch',\n",
    "               'No. Loop', 'No. Break', 'No. Continue', 'No. Conditions', 'No. Else', 'Bad API',\n",
    "               'Junit', 'Hamcrest', 'Mockito']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "\n",
    "def load_all_production_data(frame):\n",
    "    columns = ['LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod',\n",
    "       'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability', 'No. Methods_prod', 'Vocabulary_prod', 'Word_prod',\n",
    "               'Special_prod', 'Non Whithe Characters_prod', 'No. Method Invoctions_prod', 'AST size_prod',\n",
    "               'Max Depth_prod', 'Avg Depth_prod', 'Deg2_prod', 'DegPerm_prod', 'Dexterity_prod',\n",
    "               'No. Expressions_prod', 'No. Try_prod', 'No. Catch_prod', 'No. Loop_prod', 'No. Break_prod',\n",
    "               'No. Continue_prod', 'No. Conditions_prod', 'No. Else_prod']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "\n",
    "def load_all_production_data_line_coverage(frame):\n",
    "    columns = ['LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod',\n",
    "       'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability', 'No. Methods_prod', 'Vocabulary_prod', 'Word_prod',\n",
    "               'Special_prod', 'Non Whithe Characters_prod', 'No. Method Invoctions_prod', 'AST size_prod',\n",
    "               'Max Depth_prod', 'Avg Depth_prod', 'Deg2_prod', 'DegPerm_prod', 'Dexterity_prod',\n",
    "               'No. Expressions_prod', 'No. Try_prod', 'No. Catch_prod', 'No. Loop_prod', 'No. Break_prod',\n",
    "               'No. Continue_prod', 'No. Conditions_prod', 'No. Else_prod']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.line_coverage], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "\n",
    "def load_all_their_production_data(frame):\n",
    "    columns = ['LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod', 'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "def get_scoring():\n",
    "    \"\"\"Returns the scores to evaluate the model\"\"\"\n",
    "    return dict(accuracy=make_scorer(accuracy_score),\n",
    "                precision=make_scorer(precision_score),\n",
    "                recall=make_scorer(recall_score),\n",
    "                f1_score=make_scorer(f1_score),\n",
    "                roc_auc_scorer=make_scorer(roc_auc_score),\n",
    "                mean_absolute_error=make_scorer(mean_absolute_error),\n",
    "                brier_score=make_scorer(brier_score_loss))\n",
    "\n",
    "\n",
    "frame = load_frame()\n",
    "data_x, data_y, number_of_features = load_all_data(frame)\n",
    "data_y = pd.concat([frame.mutation], axis = 1).round(2).values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_x)\n",
    "data_x = scaler.transform(data_x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.10)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(number_of_features, activation='relu', input_dim=number_of_features))\n",
    "model.add(keras.layers.Dense(40, activation='relu'))\n",
    "model.add(keras.layers.Dense(20, activation='relu'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae','mse'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=400, verbose=1) #, callbacks=[early_stopping_monitor])\n",
    "\n",
    "\n",
    "test_loss, test_mae, test_mse = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('MAE: {}'.format(test_mae))\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.concatenate(y_pred).tolist()\n",
    "y_testi = np.concatenate(y_test).tolist()\n",
    "plt.scatter(*zip(*list(zip(y_testi,y_pred))))\n",
    "plt.ylabel('Predicted')\n",
    "plt.xlabel('Real')\n",
    "plt.show()\n",
    "plt.savefig(\"foo.pdf\", bbox_inches='tight')\n",
    "plt.close()\n",
    "tau, p_value = stats.pearsonr(y_pred, y_testi) #stats.kendalltau(y_pred, y_testi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = zip(list(zip(y_testi,y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.62,\n",
       " 0.54,\n",
       " 0.14,\n",
       " 0.62,\n",
       " 0.72,\n",
       " 0.61,\n",
       " 0.54,\n",
       " 0.57,\n",
       " 0.01,\n",
       " 0.87,\n",
       " 0.91,\n",
       " 0.52,\n",
       " 1.0,\n",
       " 0.76,\n",
       " 0.45,\n",
       " 0.58,\n",
       " 0.88,\n",
       " 0.88,\n",
       " 0.93,\n",
       " 0.83,\n",
       " 0.79,\n",
       " 0.86,\n",
       " 0.29,\n",
       " 0.83,\n",
       " 0.71,\n",
       " 0.64,\n",
       " 0.45,\n",
       " 0.86,\n",
       " 0.92,\n",
       " 0.53,\n",
       " 0.88,\n",
       " 0.17,\n",
       " 0.81,\n",
       " 0.49,\n",
       " 0.79,\n",
       " 1.0,\n",
       " 0.55,\n",
       " 0.66,\n",
       " 1.0,\n",
       " 0.81,\n",
       " 0.04,\n",
       " 0.46,\n",
       " 0.33,\n",
       " 0.0,\n",
       " 0.55,\n",
       " 0.67,\n",
       " 0.93,\n",
       " 0.7,\n",
       " 0.76,\n",
       " 0.47,\n",
       " 0.94,\n",
       " 1.0,\n",
       " 0.37,\n",
       " 0.37,\n",
       " 0.9,\n",
       " 0.84,\n",
       " 0.47,\n",
       " 0.92,\n",
       " 0.62,\n",
       " 0.78,\n",
       " 0.64,\n",
       " 0.23,\n",
       " 0.61,\n",
       " 0.99,\n",
       " 0.45,\n",
       " 0.83,\n",
       " 0.87,\n",
       " 1.0,\n",
       " 0.55,\n",
       " 0.62,\n",
       " 0.48,\n",
       " 0.6,\n",
       " 0.36,\n",
       " 0.39,\n",
       " 1.0,\n",
       " 0.73,\n",
       " 0.37,\n",
       " 0.01,\n",
       " 0.73,\n",
       " 0.1,\n",
       " 0.81,\n",
       " 0.33,\n",
       " 0.17,\n",
       " 0.12,\n",
       " 0.6,\n",
       " 0.69,\n",
       " 0.75,\n",
       " 0.14,\n",
       " 0.61,\n",
       " 0.14,\n",
       " 0.77,\n",
       " 0.89,\n",
       " 0.82,\n",
       " 0.21,\n",
       " 0.62,\n",
       " 0.78,\n",
       " 0.44,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.7,\n",
       " 0.63,\n",
       " 1.0,\n",
       " 0.18,\n",
       " 0.81,\n",
       " 0.94,\n",
       " 0.83,\n",
       " 0.85,\n",
       " 1.0,\n",
       " 0.14,\n",
       " 0.52,\n",
       " 0.98,\n",
       " 0.65,\n",
       " 0.63,\n",
       " 0.58,\n",
       " 0.29,\n",
       " 0.68,\n",
       " 0.9,\n",
       " 0.65,\n",
       " 0.69,\n",
       " 0.12,\n",
       " 0.0,\n",
       " 0.89,\n",
       " 0.92,\n",
       " 0.67,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.55,\n",
       " 0.03,\n",
       " 0.59,\n",
       " 0.75,\n",
       " 1.0,\n",
       " 0.87,\n",
       " 0.48,\n",
       " 0.81,\n",
       " 0.56,\n",
       " 0.35,\n",
       " 0.49,\n",
       " 0.5,\n",
       " 0.67,\n",
       " 0.35,\n",
       " 0.03,\n",
       " 0.7,\n",
       " 0.86,\n",
       " 0.77,\n",
       " 0.52,\n",
       " 0.48,\n",
       " 1.0,\n",
       " 0.89,\n",
       " 1.0,\n",
       " 0.19,\n",
       " 0.36,\n",
       " 0.8,\n",
       " 0.93,\n",
       " 0.33,\n",
       " 0.82,\n",
       " 0.87,\n",
       " 0.28,\n",
       " 0.59,\n",
       " 0.13,\n",
       " 0.62,\n",
       " 0.28,\n",
       " 0.15,\n",
       " 0.91,\n",
       " 1.0,\n",
       " 0.56,\n",
       " 0.97,\n",
       " 0.78,\n",
       " 1.0,\n",
       " 0.79,\n",
       " 0.72,\n",
       " 0.92,\n",
       " 1.0,\n",
       " 0.46,\n",
       " 0.58,\n",
       " 0.48,\n",
       " 0.86,\n",
       " 0.2,\n",
       " 0.15,\n",
       " 0.81,\n",
       " 0.58,\n",
       " 1.0,\n",
       " 0.98,\n",
       " 0.02,\n",
       " 0.24,\n",
       " 0.92,\n",
       " 0.47,\n",
       " 0.96,\n",
       " 0.95,\n",
       " 0.73,\n",
       " 0.91,\n",
       " 0.48,\n",
       " 0.39,\n",
       " 0.65,\n",
       " 0.44,\n",
       " 0.78,\n",
       " 0.5,\n",
       " 0.93,\n",
       " 1.0,\n",
       " 0.19,\n",
       " 0.3,\n",
       " 0.58,\n",
       " 0.7,\n",
       " 0.57,\n",
       " 0.67,\n",
       " 0.04,\n",
       " 0.38,\n",
       " 0.19,\n",
       " 0.03,\n",
       " 0.67,\n",
       " 0.75,\n",
       " 1.0,\n",
       " 0.94,\n",
       " 0.44,\n",
       " 0.74,\n",
       " 0.71,\n",
       " 0.28,\n",
       " 0.7,\n",
       " 0.69,\n",
       " 0.54,\n",
       " 0.55,\n",
       " 0.95,\n",
       " 1.0,\n",
       " 0.39,\n",
       " 0.64,\n",
       " 0.02,\n",
       " 0.33,\n",
       " 0.73,\n",
       " 0.34,\n",
       " 0.9,\n",
       " 0.05,\n",
       " 0.73,\n",
       " 0.79,\n",
       " 0.32,\n",
       " 1.0,\n",
       " 0.96,\n",
       " 0.84,\n",
       " 0.64,\n",
       " 0.43,\n",
       " 1.0,\n",
       " 0.59,\n",
       " 1.0,\n",
       " 0.2,\n",
       " 0.61,\n",
       " 0.73,\n",
       " 0.77,\n",
       " 0.27,\n",
       " 0.75,\n",
       " 0.64,\n",
       " 0.99,\n",
       " 0.46,\n",
       " 0.53,\n",
       " 1.0,\n",
       " 0.84,\n",
       " 0.86,\n",
       " 0.25,\n",
       " 0.8,\n",
       " 0.55,\n",
       " 0.54,\n",
       " 0.97,\n",
       " 0.67,\n",
       " 0.84,\n",
       " 0.94,\n",
       " 0.41,\n",
       " 0.64,\n",
       " 0.85,\n",
       " 0.42,\n",
       " 0.69,\n",
       " 0.32]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9185934662818909,\n",
       " 0.8441446423530579,\n",
       " 0.5303391814231873,\n",
       " 0.10025182366371155,\n",
       " 0.7236329913139343,\n",
       " 0.7146546244621277,\n",
       " 0.5552636384963989,\n",
       " 0.5374302864074707,\n",
       " 0.5041123032569885,\n",
       " 0.06480896472930908,\n",
       " 0.9110493063926697,\n",
       " 0.9112964272499084,\n",
       " 0.49077093601226807,\n",
       " 1.0133906602859497,\n",
       " 0.8450546860694885,\n",
       " 0.3745728135108948,\n",
       " 0.5833929181098938,\n",
       " 0.8446992635726929,\n",
       " 0.827571451663971,\n",
       " 0.8440844416618347,\n",
       " 0.9654377102851868,\n",
       " 0.7181204557418823,\n",
       " 0.8598577976226807,\n",
       " 0.5907902717590332,\n",
       " 0.7961049675941467,\n",
       " 0.6825950741767883,\n",
       " 0.5378619432449341,\n",
       " 0.4288097023963928,\n",
       " 0.8289926648139954,\n",
       " 0.8466410040855408,\n",
       " 0.5399864912033081,\n",
       " 0.945216953754425,\n",
       " 0.1271478235721588,\n",
       " 0.8356310129165649,\n",
       " 0.4255664646625519,\n",
       " 0.9125548005104065,\n",
       " 0.7036222815513611,\n",
       " 0.5546596050262451,\n",
       " 0.6620858907699585,\n",
       " 1.0078785419464111,\n",
       " 0.7512553930282593,\n",
       " 0.10812120139598846,\n",
       " 0.48628491163253784,\n",
       " 0.25236833095550537,\n",
       " 0.12463824450969696,\n",
       " 0.5553385615348816,\n",
       " 0.5545620322227478,\n",
       " 0.8464043736457825,\n",
       " 0.6402687430381775,\n",
       " 0.8137052059173584,\n",
       " 0.44442272186279297,\n",
       " 1.0363258123397827,\n",
       " 1.0399060249328613,\n",
       " 0.39132094383239746,\n",
       " 0.37197786569595337,\n",
       " 0.8379665613174438,\n",
       " 0.7959146499633789,\n",
       " 0.5273385643959045,\n",
       " 0.9535775780677795,\n",
       " 0.6491994857788086,\n",
       " 0.8474549651145935,\n",
       " 0.53477942943573,\n",
       " 0.2377244383096695,\n",
       " 0.6383504271507263,\n",
       " 0.9761913418769836,\n",
       " 0.5153840780258179,\n",
       " 0.49335598945617676,\n",
       " 1.0306094884872437,\n",
       " 0.9329416155815125,\n",
       " 0.5669301152229309,\n",
       " 0.7739925980567932,\n",
       " 0.38261955976486206,\n",
       " 0.6763719916343689,\n",
       " 0.7846648097038269,\n",
       " 0.3094324469566345,\n",
       " 0.8288192749023438,\n",
       " 0.6781455278396606,\n",
       " 0.31318920850753784,\n",
       " 0.021260634064674377,\n",
       " 0.47583234310150146,\n",
       " 0.13098740577697754,\n",
       " 0.7990005016326904,\n",
       " 0.5632078051567078,\n",
       " 0.7667191624641418,\n",
       " 0.2267082929611206,\n",
       " 0.6489372253417969,\n",
       " 0.6455885767936707,\n",
       " 0.8186935186386108,\n",
       " 0.5599627494812012,\n",
       " 0.6577566266059875,\n",
       " 0.464594304561615,\n",
       " 0.7347249388694763,\n",
       " 0.8849130868911743,\n",
       " 0.6362195014953613,\n",
       " 0.2744612395763397,\n",
       " 0.5788575410842896,\n",
       " 0.8381280303001404,\n",
       " 0.4011662006378174,\n",
       " 1.027116298675537,\n",
       " 0.9920904040336609,\n",
       " 0.7522538900375366,\n",
       " 0.680637538433075,\n",
       " 1.0060991048812866,\n",
       " 0.22583743929862976,\n",
       " 0.5038740038871765,\n",
       " 0.9968450665473938,\n",
       " 0.8025664687156677,\n",
       " 0.7283543348312378,\n",
       " 0.9571841359138489,\n",
       " 0.16239717602729797,\n",
       " 0.6734054088592529,\n",
       " 0.9933911561965942,\n",
       " 0.5885801315307617,\n",
       " 0.823081910610199,\n",
       " 0.7686879634857178,\n",
       " 0.31556978821754456,\n",
       " 0.6327342987060547,\n",
       " 0.9255579113960266,\n",
       " 0.6019214987754822,\n",
       " 0.9418749213218689,\n",
       " 0.19547748565673828,\n",
       " 0.0037623345851898193,\n",
       " 0.7656746506690979,\n",
       " 0.9571251273155212,\n",
       " 0.612733781337738,\n",
       " 0.9899329543113708,\n",
       " 1.0107662677764893,\n",
       " 0.5453837513923645,\n",
       " 0.016460418701171875,\n",
       " 0.8742947578430176,\n",
       " 0.5790932178497314,\n",
       " 0.8614680171012878,\n",
       " 0.6552666425704956,\n",
       " 0.49386346340179443,\n",
       " 0.8210859894752502,\n",
       " 0.5376383662223816,\n",
       " 0.3766447901725769,\n",
       " 0.4765361547470093,\n",
       " 0.958676278591156,\n",
       " 0.8556209206581116,\n",
       " 0.16760480403900146,\n",
       " 0.06251996755599976,\n",
       " 0.7108085751533508,\n",
       " 0.874172031879425,\n",
       " 0.41020089387893677,\n",
       " 0.660036027431488,\n",
       " 0.42162084579467773,\n",
       " 0.9966417551040649,\n",
       " 0.8289855122566223,\n",
       " 0.91881263256073,\n",
       " 0.21541304886341095,\n",
       " 0.24465666711330414,\n",
       " 0.6625222563743591,\n",
       " 0.7995331883430481,\n",
       " 0.3126735985279083,\n",
       " 0.9074723720550537,\n",
       " 0.8980004787445068,\n",
       " 0.34411656856536865,\n",
       " 0.5733199715614319,\n",
       " 0.1562667191028595,\n",
       " 0.7824287414550781,\n",
       " 0.2654638886451721,\n",
       " 0.1623433232307434,\n",
       " 0.9139294028282166,\n",
       " 0.46874427795410156,\n",
       " 0.5390076637268066,\n",
       " 0.9662046432495117,\n",
       " 0.6930111050605774,\n",
       " 0.8921149373054504,\n",
       " 0.7495659589767456,\n",
       " 0.8393845558166504,\n",
       " 0.8884677886962891,\n",
       " 0.9612551331520081,\n",
       " 0.5092594027519226,\n",
       " 0.603885293006897,\n",
       " 0.8478065729141235,\n",
       " 0.8918829560279846,\n",
       " 0.23492218554019928,\n",
       " 0.16637198626995087,\n",
       " 0.8384034037590027,\n",
       " 0.5689505934715271,\n",
       " 0.9479280114173889,\n",
       " 1.0023860931396484,\n",
       " 0.043602749705314636,\n",
       " 0.26661550998687744,\n",
       " 0.8410618901252747,\n",
       " 0.50080406665802,\n",
       " 0.7785938382148743,\n",
       " 0.9301694631576538,\n",
       " 0.7250766158103943,\n",
       " 0.7256327271461487,\n",
       " 0.598225474357605,\n",
       " 0.5282045602798462,\n",
       " 0.6190545558929443,\n",
       " 0.711216151714325,\n",
       " 0.8213890790939331,\n",
       " 0.5484310388565063,\n",
       " 0.7894368171691895,\n",
       " 1.0638885498046875,\n",
       " 0.21547485888004303,\n",
       " 0.3369637131690979,\n",
       " 0.6108841896057129,\n",
       " 0.5778070092201233,\n",
       " 0.7407609820365906,\n",
       " 0.5528950095176697,\n",
       " 0.025818809866905212,\n",
       " 0.4587389826774597,\n",
       " 0.1078520268201828,\n",
       " -0.012833401560783386,\n",
       " 0.5773136615753174,\n",
       " 0.7561289668083191,\n",
       " 1.0070453882217407,\n",
       " 0.6788219809532166,\n",
       " 0.4968753457069397,\n",
       " 0.8369175791740417,\n",
       " 0.6317624449729919,\n",
       " 0.5418984889984131,\n",
       " 0.7223823070526123,\n",
       " 0.5371582508087158,\n",
       " 0.6501062512397766,\n",
       " 0.4592929780483246,\n",
       " 0.6688527464866638,\n",
       " 1.0361976623535156,\n",
       " 0.5299771428108215,\n",
       " 0.5853623151779175,\n",
       " 0.2821817994117737,\n",
       " 0.41369330883026123,\n",
       " 0.7476219534873962,\n",
       " 0.3570438623428345,\n",
       " 0.9239087104797363,\n",
       " 0.0750814825296402,\n",
       " 0.7531887292861938,\n",
       " 0.634691059589386,\n",
       " 0.2865663170814514,\n",
       " 1.052584171295166,\n",
       " 0.9717805981636047,\n",
       " 0.6759940385818481,\n",
       " 0.643718957901001,\n",
       " 0.2280268371105194,\n",
       " 1.0550987720489502,\n",
       " 0.5791688561439514,\n",
       " 0.9111398458480835,\n",
       " 0.23907144367694855,\n",
       " 0.7165027856826782,\n",
       " 0.7084503173828125,\n",
       " 0.9241910576820374,\n",
       " 0.20939098298549652,\n",
       " 0.5375838279724121,\n",
       " 0.654377818107605,\n",
       " 0.790567934513092,\n",
       " 0.6696147322654724,\n",
       " 0.5117819309234619,\n",
       " 0.9413658380508423,\n",
       " 0.704567551612854,\n",
       " 0.8593551516532898,\n",
       " 0.33292466402053833,\n",
       " 0.8173471093177795,\n",
       " 0.6056439876556396,\n",
       " 0.6526322364807129,\n",
       " 0.8964613080024719,\n",
       " 0.6881872415542603,\n",
       " 0.8377459049224854,\n",
       " 0.803331196308136,\n",
       " 0.3479432761669159,\n",
       " 0.6610926985740662,\n",
       " 0.8550531268119812,\n",
       " 0.38533759117126465,\n",
       " 0.30459922552108765,\n",
       " 0.6035229563713074]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "\n",
    "rows = zip(y_testi,y_pred)\n",
    "with open('returns-static.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in rows:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
