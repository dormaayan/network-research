{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2412, 110)\n",
      "Train on 2412 samples\n",
      "Epoch 1/400\n",
      "2412/2412 [==============================] - 1s 443us/sample - loss: 0.1590 - mae: 0.2892 - mse: 0.1590\n",
      "Epoch 2/400\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0617 - mae: 0.1856 - mse: 0.0617\n",
      "Epoch 3/400\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0466 - mae: 0.1612 - mse: 0.0466\n",
      "Epoch 4/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0368 - mae: 0.1424 - mse: 0.0368\n",
      "Epoch 5/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0309 - mae: 0.1309 - mse: 0.0309\n",
      "Epoch 6/400\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0260 - mae: 0.1221 - mse: 0.0260\n",
      "Epoch 7/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0244 - mae: 0.1153 - mse: 0.0244\n",
      "Epoch 8/400\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0217 - mae: 0.1089 - mse: 0.0217\n",
      "Epoch 9/400\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0254 - mae: 0.1126 - mse: 0.0254\n",
      "Epoch 10/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0194 - mae: 0.1017 - mse: 0.0194\n",
      "Epoch 11/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0164 - mae: 0.0959 - mse: 0.0164\n",
      "Epoch 12/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0156 - mae: 0.0927 - mse: 0.0156\n",
      "Epoch 13/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0171 - mae: 0.0939 - mse: 0.0171\n",
      "Epoch 14/400\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0154 - mae: 0.0889 - mse: 0.0154\n",
      "Epoch 15/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0145 - mae: 0.0865 - mse: 0.0145\n",
      "Epoch 16/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0127 - mae: 0.0819 - mse: 0.0127\n",
      "Epoch 17/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0138 - mae: 0.0830 - mse: 0.0138\n",
      "Epoch 18/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0122 - mae: 0.0797 - mse: 0.0122\n",
      "Epoch 19/400\n",
      "2412/2412 [==============================] - 0s 91us/sample - loss: 0.0099 - mae: 0.0721 - mse: 0.0099\n",
      "Epoch 20/400\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0093 - mae: 0.0697 - mse: 0.0093\n",
      "Epoch 21/400\n",
      "2412/2412 [==============================] - 0s 91us/sample - loss: 0.0095 - mae: 0.0697 - mse: 0.0095\n",
      "Epoch 22/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0096 - mae: 0.0671 - mse: 0.0096\n",
      "Epoch 23/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0090 - mae: 0.0673 - mse: 0.0090\n",
      "Epoch 24/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0086 - mae: 0.0669 - mse: 0.0086\n",
      "Epoch 25/400\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0073 - mae: 0.0626 - mse: 0.0073\n",
      "Epoch 26/400\n",
      "2412/2412 [==============================] - 0s 91us/sample - loss: 0.0061 - mae: 0.0566 - mse: 0.0061\n",
      "Epoch 27/400\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0057 - mae: 0.0560 - mse: 0.0057\n",
      "Epoch 28/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0051 - mae: 0.0514 - mse: 0.0051\n",
      "Epoch 29/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0048 - mae: 0.0503 - mse: 0.0048\n",
      "Epoch 30/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0056 - mae: 0.0504 - mse: 0.0056\n",
      "Epoch 31/400\n",
      "2412/2412 [==============================] - 0s 91us/sample - loss: 0.0055 - mae: 0.0526 - mse: 0.0055\n",
      "Epoch 32/400\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0065 - mae: 0.0568 - mse: 0.0065\n",
      "Epoch 33/400\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0050 - mae: 0.0496 - mse: 0.0050\n",
      "Epoch 34/400\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0052 - mae: 0.0509 - mse: 0.0052\n",
      "Epoch 35/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0059 - mae: 0.0537 - mse: 0.0059\n",
      "Epoch 36/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0048 - mae: 0.0503 - mse: 0.0048\n",
      "Epoch 37/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0040 - mae: 0.0457 - mse: 0.0040\n",
      "Epoch 38/400\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0037 - mae: 0.0433 - mse: 0.0037\n",
      "Epoch 39/400\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0035 - mae: 0.0423 - mse: 0.0035\n",
      "Epoch 40/400\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0033 - mae: 0.0420 - mse: 0.0033\n",
      "Epoch 41/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 0.0031 - mae: 0.0409 - mse: 0.0031\n",
      "Epoch 42/400\n",
      "2412/2412 [==============================] - 0s 120us/sample - loss: 0.0032 - mae: 0.0413 - mse: 0.0032\n",
      "Epoch 43/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 0.0035 - mae: 0.0435 - mse: 0.0035\n",
      "Epoch 44/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0034 - mae: 0.0424 - mse: 0.0034\n",
      "Epoch 45/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0046 - mae: 0.0458 - mse: 0.0046\n",
      "Epoch 46/400\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0049 - mae: 0.0504 - mse: 0.0049\n",
      "Epoch 47/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0058 - mae: 0.0541 - mse: 0.0058\n",
      "Epoch 48/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0057 - mae: 0.0524 - mse: 0.0057\n",
      "Epoch 49/400\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 0.0053 - mae: 0.0534 - mse: 0.0053\n",
      "Epoch 50/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 0.0034 - mae: 0.0434 - mse: 0.0034\n",
      "Epoch 51/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 0.0025 - mae: 0.0370 - mse: 0.0025\n",
      "Epoch 52/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0024 - mae: 0.0365 - mse: 0.0024\n",
      "Epoch 53/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0023 - mae: 0.0354 - mse: 0.0023\n",
      "Epoch 54/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0021 - mae: 0.0333 - mse: 0.0021\n",
      "Epoch 55/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0024 - mae: 0.0357 - mse: 0.0024\n",
      "Epoch 56/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0019 - mae: 0.0321 - mse: 0.0019\n",
      "Epoch 57/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0031 - mae: 0.0389 - mse: 0.0031\n",
      "Epoch 58/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0033 - mae: 0.0418 - mse: 0.0033\n",
      "Epoch 59/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0029 - mae: 0.0376 - mse: 0.0029\n",
      "Epoch 60/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 0.0024 - mae: 0.0355 - mse: 0.0024\n",
      "Epoch 61/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0021 - mae: 0.0342 - mse: 0.0021\n",
      "Epoch 62/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0019 - mae: 0.0326 - mse: 0.0019\n",
      "Epoch 63/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0021 - mae: 0.0341 - mse: 0.0021\n",
      "Epoch 64/400\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0022 - mae: 0.0348 - mse: 0.0022\n",
      "Epoch 65/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0022 - mae: 0.0342 - mse: 0.0022\n",
      "Epoch 66/400\n",
      "2412/2412 [==============================] - 0s 118us/sample - loss: 0.0018 - mae: 0.0312 - mse: 0.0018\n",
      "Epoch 67/400\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 0.0017 - mae: 0.0302 - mse: 0.0017\n",
      "Epoch 68/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0018 - mae: 0.0305 - mse: 0.0018\n",
      "Epoch 69/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0023 - mae: 0.0356 - mse: 0.0023\n",
      "Epoch 70/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0027 - mae: 0.0388 - mse: 0.0027\n",
      "Epoch 71/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0026 - mae: 0.0382 - mse: 0.0026\n",
      "Epoch 72/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0028 - mae: 0.0379 - mse: 0.0028\n",
      "Epoch 73/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0040 - mae: 0.0470 - mse: 0.0040\n",
      "Epoch 74/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 0.0034 - mae: 0.0432 - mse: 0.0034\n",
      "Epoch 75/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0027 - mae: 0.0390 - mse: 0.0027\n",
      "Epoch 76/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0026 - mae: 0.0380 - mse: 0.0026\n",
      "Epoch 77/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0024 - mae: 0.0359 - mse: 0.0024\n",
      "Epoch 78/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0020 - mae: 0.0327 - mse: 0.0020\n",
      "Epoch 79/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0019 - mae: 0.0327 - mse: 0.0019\n",
      "Epoch 80/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0023 - mae: 0.0353 - mse: 0.0023\n",
      "Epoch 81/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0031 - mae: 0.0386 - mse: 0.0031\n",
      "Epoch 82/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0030 - mae: 0.0406 - mse: 0.0030\n",
      "Epoch 83/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0024 - mae: 0.0359 - mse: 0.0024\n",
      "Epoch 84/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0019 - mae: 0.0324 - mse: 0.0019\n",
      "Epoch 85/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0019 - mae: 0.0318 - mse: 0.0019\n",
      "Epoch 86/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0019 - mae: 0.0327 - mse: 0.0019\n",
      "Epoch 87/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0017 - mae: 0.0306 - mse: 0.0017\n",
      "Epoch 88/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0017 - mae: 0.0309 - mse: 0.0017\n",
      "Epoch 89/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0018 - mae: 0.0305 - mse: 0.0018\n",
      "Epoch 90/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0018 - mae: 0.0313 - mse: 0.0018\n",
      "Epoch 91/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0018 - mae: 0.0314 - mse: 0.0018\n",
      "Epoch 92/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0018 - mae: 0.0314 - mse: 0.0018\n",
      "Epoch 93/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0018 - mae: 0.0311 - mse: 0.0018\n",
      "Epoch 94/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0078 - mae: 0.0551 - mse: 0.0078\n",
      "Epoch 95/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0063 - mae: 0.0581 - mse: 0.0063\n",
      "Epoch 96/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0078 - mae: 0.0599 - mse: 0.0078\n",
      "Epoch 97/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 0.0060 - mae: 0.0519 - mse: 0.0060\n",
      "Epoch 98/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0026 - mae: 0.0388 - mse: 0.0026\n",
      "Epoch 99/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0023 - mae: 0.0352 - mse: 0.0023\n",
      "Epoch 100/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0015 - mae: 0.0286 - mse: 0.0015\n",
      "Epoch 101/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0012 - mae: 0.0249 - mse: 0.0012\n",
      "Epoch 102/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0010 - mae: 0.0237 - mse: 0.0010\n",
      "Epoch 103/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 9.4293e-04 - mae: 0.0224 - mse: 9.4293e-04\n",
      "Epoch 104/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 8.5197e-04 - mae: 0.0216 - mse: 8.5197e-04\n",
      "Epoch 105/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 7.6436e-04 - mae: 0.0200 - mse: 7.6436e-04\n",
      "Epoch 106/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 7.2687e-04 - mae: 0.0197 - mse: 7.2687e-04\n",
      "Epoch 107/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 7.9824e-04 - mae: 0.0208 - mse: 7.9824e-04\n",
      "Epoch 108/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 8.0800e-04 - mae: 0.0212 - mse: 8.0800e-04\n",
      "Epoch 109/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 8.0585e-04 - mae: 0.0206 - mse: 8.0585e-04\n",
      "Epoch 110/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0012 - mae: 0.0255 - mse: 0.0012\n",
      "Epoch 111/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0011 - mae: 0.0241 - mse: 0.0011\n",
      "Epoch 112/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0013 - mae: 0.0266 - mse: 0.0013\n",
      "Epoch 113/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0015 - mae: 0.0290 - mse: 0.0015\n",
      "Epoch 114/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0014 - mae: 0.0278 - mse: 0.0014\n",
      "Epoch 115/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 0.0015 - mae: 0.0284 - mse: 0.0015\n",
      "Epoch 116/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0013 - mae: 0.0271 - mse: 0.0013\n",
      "Epoch 117/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0015 - mae: 0.0277 - mse: 0.0015\n",
      "Epoch 118/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0019 - mae: 0.0315 - mse: 0.0019\n",
      "Epoch 119/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0025 - mae: 0.0358 - mse: 0.0025\n",
      "Epoch 120/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0024 - mae: 0.0362 - mse: 0.0024\n",
      "Epoch 121/400\n",
      "2412/2412 [==============================] - 0s 120us/sample - loss: 0.0021 - mae: 0.0334 - mse: 0.0021\n",
      "Epoch 122/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 0.0018 - mae: 0.0309 - mse: 0.0018\n",
      "Epoch 123/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0016 - mae: 0.0293 - mse: 0.0016\n",
      "Epoch 124/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0012 - mae: 0.0259 - mse: 0.0012\n",
      "Epoch 125/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 9.9010e-04 - mae: 0.0236 - mse: 9.9010e-04\n",
      "Epoch 126/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 9.9857e-04 - mae: 0.0236 - mse: 9.9857e-04\n",
      "Epoch 127/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 0.0011 - mae: 0.0244 - mse: 0.0011\n",
      "Epoch 128/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0013 - mae: 0.0260 - mse: 0.0013\n",
      "Epoch 129/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0013 - mae: 0.0272 - mse: 0.0013\n",
      "Epoch 130/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0012 - mae: 0.0264 - mse: 0.0012\n",
      "Epoch 131/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0015 - mae: 0.0289 - mse: 0.0015\n",
      "Epoch 132/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0011 - mae: 0.0252 - mse: 0.0011\n",
      "Epoch 133/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 0.0010 - mae: 0.0247 - mse: 0.0010\n",
      "Epoch 134/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0011 - mae: 0.0251 - mse: 0.0011\n",
      "Epoch 135/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0011 - mae: 0.0237 - mse: 0.0011\n",
      "Epoch 136/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0012 - mae: 0.0261 - mse: 0.0012\n",
      "Epoch 137/400\n",
      "2412/2412 [==============================] - 0s 129us/sample - loss: 0.0012 - mae: 0.0256 - mse: 0.0012\n",
      "Epoch 138/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0011 - mae: 0.0247 - mse: 0.0011\n",
      "Epoch 139/400\n",
      "2412/2412 [==============================] - 0s 127us/sample - loss: 0.0013 - mae: 0.0264 - mse: 0.0013\n",
      "Epoch 140/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412/2412 [==============================] - 0s 124us/sample - loss: 0.0015 - mae: 0.0289 - mse: 0.0015\n",
      "Epoch 141/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0013 - mae: 0.0264 - mse: 0.0013\n",
      "Epoch 142/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0012 - mae: 0.0262 - mse: 0.0012\n",
      "Epoch 143/400\n",
      "2412/2412 [==============================] - 0s 121us/sample - loss: 0.0020 - mae: 0.0326 - mse: 0.0020\n",
      "Epoch 144/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0017 - mae: 0.0305 - mse: 0.0017\n",
      "Epoch 145/400\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 0.0017 - mae: 0.0301 - mse: 0.0017\n",
      "Epoch 146/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0015 - mae: 0.0300 - mse: 0.0015\n",
      "Epoch 147/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0014 - mae: 0.0283 - mse: 0.0014\n",
      "Epoch 148/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0015 - mae: 0.0283 - mse: 0.0015\n",
      "Epoch 149/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0013 - mae: 0.0269 - mse: 0.0013\n",
      "Epoch 150/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 0.0011 - mae: 0.0244 - mse: 0.0011\n",
      "Epoch 151/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 0.0012 - mae: 0.0260 - mse: 0.0012\n",
      "Epoch 152/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0013 - mae: 0.0271 - mse: 0.0013\n",
      "Epoch 153/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0015 - mae: 0.0287 - mse: 0.0015\n",
      "Epoch 154/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0019 - mae: 0.0319 - mse: 0.0019\n",
      "Epoch 155/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0017 - mae: 0.0308 - mse: 0.0017\n",
      "Epoch 156/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 0.0016 - mae: 0.0299 - mse: 0.0016\n",
      "Epoch 157/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 0.0018 - mae: 0.0312 - mse: 0.0018\n",
      "Epoch 158/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0013 - mae: 0.0265 - mse: 0.0013\n",
      "Epoch 159/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0011 - mae: 0.0255 - mse: 0.0011\n",
      "Epoch 160/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 8.9302e-04 - mae: 0.0223 - mse: 8.9302e-04\n",
      "Epoch 161/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 7.8496e-04 - mae: 0.0209 - mse: 7.8496e-04\n",
      "Epoch 162/400\n",
      "2412/2412 [==============================] - 0s 115us/sample - loss: 0.0011 - mae: 0.0249 - mse: 0.0011\n",
      "Epoch 163/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 9.3936e-04 - mae: 0.0226 - mse: 9.3936e-04\n",
      "Epoch 164/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 0.0015 - mae: 0.0272 - mse: 0.0015\n",
      "Epoch 165/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 0.0014 - mae: 0.0279 - mse: 0.0014\n",
      "Epoch 166/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 0.0010 - mae: 0.0237 - mse: 0.0010\n",
      "Epoch 167/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 0.0011 - mae: 0.0246 - mse: 0.0011\n",
      "Epoch 168/400\n",
      "2412/2412 [==============================] - 0s 118us/sample - loss: 0.0010 - mae: 0.0240 - mse: 0.0010\n",
      "Epoch 169/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 9.2535e-04 - mae: 0.0226 - mse: 9.2535e-04\n",
      "Epoch 170/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 8.8372e-04 - mae: 0.0218 - mse: 8.8372e-04\n",
      "Epoch 171/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 9.3670e-04 - mae: 0.0229 - mse: 9.3670e-04\n",
      "Epoch 172/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0011 - mae: 0.0245 - mse: 0.0011\n",
      "Epoch 173/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0011 - mae: 0.0243 - mse: 0.0011\n",
      "Epoch 174/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 0.0012 - mae: 0.0244 - mse: 0.0012\n",
      "Epoch 175/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0012 - mae: 0.0257 - mse: 0.0012\n",
      "Epoch 176/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0013 - mae: 0.0265 - mse: 0.0013\n",
      "Epoch 177/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0013 - mae: 0.0272 - mse: 0.0013\n",
      "Epoch 178/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0015 - mae: 0.0292 - mse: 0.0015\n",
      "Epoch 179/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0015 - mae: 0.0287 - mse: 0.0015\n",
      "Epoch 180/400\n",
      "2412/2412 [==============================] - 0s 117us/sample - loss: 0.0011 - mae: 0.0246 - mse: 0.0011\n",
      "Epoch 181/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0011 - mae: 0.0244 - mse: 0.0011\n",
      "Epoch 182/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 9.8195e-04 - mae: 0.0232 - mse: 9.8195e-04\n",
      "Epoch 183/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0011 - mae: 0.0242 - mse: 0.0011\n",
      "Epoch 184/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0012 - mae: 0.0246 - mse: 0.0012\n",
      "Epoch 185/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 9.8216e-04 - mae: 0.0231 - mse: 9.8216e-04\n",
      "Epoch 186/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 0.0010 - mae: 0.0242 - mse: 0.0010\n",
      "Epoch 187/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 9.7374e-04 - mae: 0.0230 - mse: 9.7374e-04\n",
      "Epoch 188/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 9.3611e-04 - mae: 0.0229 - mse: 9.3611e-04\n",
      "Epoch 189/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 8.1143e-04 - mae: 0.0213 - mse: 8.1143e-04\n",
      "Epoch 190/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 8.3605e-04 - mae: 0.0217 - mse: 8.3605e-04\n",
      "Epoch 191/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 8.2781e-04 - mae: 0.0209 - mse: 8.2781e-04\n",
      "Epoch 192/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 0.0011 - mae: 0.0241 - mse: 0.0011\n",
      "Epoch 193/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0010 - mae: 0.0242 - mse: 0.0010\n",
      "Epoch 194/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 9.0508e-04 - mae: 0.0229 - mse: 9.0508e-04\n",
      "Epoch 195/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 6.8409e-04 - mae: 0.0195 - mse: 6.8409e-04\n",
      "Epoch 196/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 6.2620e-04 - mae: 0.0188 - mse: 6.2620e-04\n",
      "Epoch 197/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 6.7336e-04 - mae: 0.0194 - mse: 6.7336e-04\n",
      "Epoch 198/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 7.6502e-04 - mae: 0.0206 - mse: 7.6502e-04\n",
      "Epoch 199/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0012 - mae: 0.0252 - mse: 0.0012\n",
      "Epoch 200/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0012 - mae: 0.0248 - mse: 0.0012\n",
      "Epoch 201/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 9.9327e-04 - mae: 0.0234 - mse: 9.9327e-04\n",
      "Epoch 202/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 8.4998e-04 - mae: 0.0219 - mse: 8.4998e-04\n",
      "Epoch 203/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 0.0013 - mae: 0.0263 - mse: 0.0013\n",
      "Epoch 204/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 0.0014 - mae: 0.0284 - mse: 0.0014\n",
      "Epoch 205/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0015 - mae: 0.0285 - mse: 0.0015\n",
      "Epoch 206/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0014 - mae: 0.0275 - mse: 0.0014\n",
      "Epoch 207/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0013 - mae: 0.0266 - mse: 0.0013\n",
      "Epoch 208/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0012 - mae: 0.0256 - mse: 0.0012\n",
      "Epoch 209/400\n",
      "2412/2412 [==============================] - 0s 115us/sample - loss: 0.0011 - mae: 0.0252 - mse: 0.0011\n",
      "Epoch 210/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 7.1381e-04 - mae: 0.0199 - mse: 7.1381e-04\n",
      "Epoch 211/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 6.1181e-04 - mae: 0.0187 - mse: 6.1181e-04\n",
      "Epoch 212/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.9620e-04 - mae: 0.0167 - mse: 4.9620e-04\n",
      "Epoch 213/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 5.0173e-04 - mae: 0.0168 - mse: 5.0173e-04\n",
      "Epoch 214/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 4.5202e-04 - mae: 0.0161 - mse: 4.5202e-04\n",
      "Epoch 215/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 4.2170e-04 - mae: 0.0155 - mse: 4.2170e-04\n",
      "Epoch 216/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 4.7876e-04 - mae: 0.0163 - mse: 4.7876e-04\n",
      "Epoch 217/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 6.7490e-04 - mae: 0.0194 - mse: 6.7490e-04\n",
      "Epoch 218/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 8.6791e-04 - mae: 0.0217 - mse: 8.6791e-04\n",
      "Epoch 219/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 7.7883e-04 - mae: 0.0211 - mse: 7.7883e-04\n",
      "Epoch 220/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 9.6932e-04 - mae: 0.0235 - mse: 9.6932e-04\n",
      "Epoch 221/400\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 9.8566e-04 - mae: 0.0235 - mse: 9.8566e-04\n",
      "Epoch 222/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0012 - mae: 0.0257 - mse: 0.0012\n",
      "Epoch 223/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0011 - mae: 0.0247 - mse: 0.0011\n",
      "Epoch 224/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0014 - mae: 0.0272 - mse: 0.0014\n",
      "Epoch 225/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0016 - mae: 0.0291 - mse: 0.0016\n",
      "Epoch 226/400\n",
      "2412/2412 [==============================] - 0s 115us/sample - loss: 0.0013 - mae: 0.0257 - mse: 0.0013\n",
      "Epoch 227/400\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 0.0013 - mae: 0.0267 - mse: 0.0013\n",
      "Epoch 228/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0013 - mae: 0.0262 - mse: 0.0013\n",
      "Epoch 229/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0011 - mae: 0.0245 - mse: 0.0011\n",
      "Epoch 230/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 8.1532e-04 - mae: 0.0216 - mse: 8.1532e-04\n",
      "Epoch 231/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 5.9513e-04 - mae: 0.0182 - mse: 5.9513e-04\n",
      "Epoch 232/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 5.3169e-04 - mae: 0.0171 - mse: 5.3169e-04\n",
      "Epoch 233/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 5.7873e-04 - mae: 0.0177 - mse: 5.7873e-04\n",
      "Epoch 234/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 7.5795e-04 - mae: 0.0203 - mse: 7.5795e-04\n",
      "Epoch 235/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 7.4006e-04 - mae: 0.0205 - mse: 7.4006e-04\n",
      "Epoch 236/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 8.8417e-04 - mae: 0.0219 - mse: 8.8417e-04\n",
      "Epoch 237/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 8.4440e-04 - mae: 0.0216 - mse: 8.4440e-04\n",
      "Epoch 238/400\n",
      "2412/2412 [==============================] - 0s 120us/sample - loss: 0.0011 - mae: 0.0224 - mse: 0.0011\n",
      "Epoch 239/400\n",
      "2412/2412 [==============================] - 0s 118us/sample - loss: 0.0018 - mae: 0.0286 - mse: 0.0018\n",
      "Epoch 240/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0035 - mae: 0.0408 - mse: 0.0035\n",
      "Epoch 241/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0026 - mae: 0.0378 - mse: 0.0026\n",
      "Epoch 242/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0017 - mae: 0.0310 - mse: 0.0017\n",
      "Epoch 243/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0010 - mae: 0.0243 - mse: 0.0010\n",
      "Epoch 244/400\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 8.5326e-04 - mae: 0.0217 - mse: 8.5326e-04\n",
      "Epoch 245/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 5.7839e-04 - mae: 0.0179 - mse: 5.7839e-04\n",
      "Epoch 246/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 4.4982e-04 - mae: 0.0157 - mse: 4.4982e-04\n",
      "Epoch 247/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 3.0811e-04 - mae: 0.0133 - mse: 3.0811e-04\n",
      "Epoch 248/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 2.5566e-04 - mae: 0.0121 - mse: 2.5566e-04\n",
      "Epoch 249/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 2.2539e-04 - mae: 0.0114 - mse: 2.2539e-04\n",
      "Epoch 250/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 1.9300e-04 - mae: 0.0104 - mse: 1.9300e-04\n",
      "Epoch 251/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 2.0561e-04 - mae: 0.0107 - mse: 2.0561e-04\n",
      "Epoch 252/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 2.2206e-04 - mae: 0.0109 - mse: 2.2206e-04\n",
      "Epoch 253/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 2.9163e-04 - mae: 0.0125 - mse: 2.9163e-04\n",
      "Epoch 254/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 3.7845e-04 - mae: 0.0143 - mse: 3.7845e-04\n",
      "Epoch 255/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 4.7723e-04 - mae: 0.0159 - mse: 4.7723e-04\n",
      "Epoch 256/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 7.9159e-04 - mae: 0.0205 - mse: 7.9159e-04\n",
      "Epoch 257/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0012 - mae: 0.0254 - mse: 0.0012\n",
      "Epoch 258/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0012 - mae: 0.0261 - mse: 0.0012\n",
      "Epoch 259/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0012 - mae: 0.0255 - mse: 0.0012\n",
      "Epoch 260/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 9.3391e-04 - mae: 0.0227 - mse: 9.3391e-04\n",
      "Epoch 261/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 7.2843e-04 - mae: 0.0202 - mse: 7.2843e-04\n",
      "Epoch 262/400\n",
      "2412/2412 [==============================] - 0s 124us/sample - loss: 6.5174e-04 - mae: 0.0190 - mse: 6.5174e-04\n",
      "Epoch 263/400\n",
      "2412/2412 [==============================] - 0s 117us/sample - loss: 6.9728e-04 - mae: 0.0196 - mse: 6.9728e-04\n",
      "Epoch 264/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 5.9597e-04 - mae: 0.0181 - mse: 5.9597e-04\n",
      "Epoch 265/400\n",
      "2412/2412 [==============================] - 0s 118us/sample - loss: 4.9467e-04 - mae: 0.0163 - mse: 4.9467e-04\n",
      "Epoch 266/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 4.1529e-04 - mae: 0.0153 - mse: 4.1529e-04\n",
      "Epoch 267/400\n",
      "2412/2412 [==============================] - 0s 122us/sample - loss: 5.6625e-04 - mae: 0.0179 - mse: 5.6625e-04\n",
      "Epoch 268/400\n",
      "2412/2412 [==============================] - 0s 117us/sample - loss: 5.3970e-04 - mae: 0.0175 - mse: 5.3970e-04\n",
      "Epoch 269/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 4.5756e-04 - mae: 0.0159 - mse: 4.5756e-04\n",
      "Epoch 270/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 5.1837e-04 - mae: 0.0171 - mse: 5.1837e-04\n",
      "Epoch 271/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 5.2136e-04 - mae: 0.0169 - mse: 5.2136e-04\n",
      "Epoch 272/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 6.2207e-04 - mae: 0.0185 - mse: 6.2207e-04\n",
      "Epoch 273/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 6.4812e-04 - mae: 0.0189 - mse: 6.4812e-04\n",
      "Epoch 274/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412/2412 [==============================] - 0s 110us/sample - loss: 6.8847e-04 - mae: 0.0195 - mse: 6.8847e-04\n",
      "Epoch 275/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 6.9240e-04 - mae: 0.0197 - mse: 6.9240e-04\n",
      "Epoch 276/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 6.6004e-04 - mae: 0.0192 - mse: 6.6004e-04\n",
      "Epoch 277/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 6.6968e-04 - mae: 0.0196 - mse: 6.6968e-04\n",
      "Epoch 278/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 7.0807e-04 - mae: 0.0200 - mse: 7.0807e-04\n",
      "Epoch 279/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 6.9790e-04 - mae: 0.0198 - mse: 6.9790e-04\n",
      "Epoch 280/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 7.4552e-04 - mae: 0.0204 - mse: 7.4552e-04\n",
      "Epoch 281/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 7.1709e-04 - mae: 0.0203 - mse: 7.1709e-04\n",
      "Epoch 282/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 5.9893e-04 - mae: 0.0182 - mse: 5.9893e-04\n",
      "Epoch 283/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 6.2828e-04 - mae: 0.0187 - mse: 6.2828e-04\n",
      "Epoch 284/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 5.4873e-04 - mae: 0.0172 - mse: 5.4873e-04\n",
      "Epoch 285/400\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 5.8225e-04 - mae: 0.0184 - mse: 5.8225e-04\n",
      "Epoch 286/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 6.9908e-04 - mae: 0.0199 - mse: 6.9908e-04\n",
      "Epoch 287/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 9.1559e-04 - mae: 0.0230 - mse: 9.1559e-04\n",
      "Epoch 288/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0011 - mae: 0.0241 - mse: 0.0011\n",
      "Epoch 289/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0010 - mae: 0.0228 - mse: 0.0010\n",
      "Epoch 290/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 0.0011 - mae: 0.0244 - mse: 0.0011\n",
      "Epoch 291/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 0.0012 - mae: 0.0250 - mse: 0.0012\n",
      "Epoch 292/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0039 - mae: 0.0379 - mse: 0.0039\n",
      "Epoch 293/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0032 - mae: 0.0375 - mse: 0.0032\n",
      "Epoch 294/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0020 - mae: 0.0313 - mse: 0.0020\n",
      "Epoch 295/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0013 - mae: 0.0256 - mse: 0.0013\n",
      "Epoch 296/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 7.8512e-04 - mae: 0.0204 - mse: 7.8512e-04\n",
      "Epoch 297/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 5.0616e-04 - mae: 0.0165 - mse: 5.0616e-04\n",
      "Epoch 298/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 3.9036e-04 - mae: 0.0144 - mse: 3.9036e-04\n",
      "Epoch 299/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 2.9965e-04 - mae: 0.0130 - mse: 2.9965e-04\n",
      "Epoch 300/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 2.2510e-04 - mae: 0.0114 - mse: 2.2510e-04\n",
      "Epoch 301/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 1.8675e-04 - mae: 0.0100 - mse: 1.8675e-04\n",
      "Epoch 302/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 1.5222e-04 - mae: 0.0093 - mse: 1.5222e-04\n",
      "Epoch 303/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 1.6648e-04 - mae: 0.0095 - mse: 1.6648e-04\n",
      "Epoch 304/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 1.7058e-04 - mae: 0.0096 - mse: 1.7058e-04\n",
      "Epoch 305/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 2.2882e-04 - mae: 0.0112 - mse: 2.2882e-04\n",
      "Epoch 306/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 2.5034e-04 - mae: 0.0116 - mse: 2.5034e-04\n",
      "Epoch 307/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.7321e-04 - mae: 0.0159 - mse: 4.7321e-04\n",
      "Epoch 308/400\n",
      "2412/2412 [==============================] - 0s 117us/sample - loss: 6.8227e-04 - mae: 0.0192 - mse: 6.8227e-04\n",
      "Epoch 309/400\n",
      "2412/2412 [==============================] - 0s 115us/sample - loss: 5.7646e-04 - mae: 0.0178 - mse: 5.7646e-04\n",
      "Epoch 310/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 5.6404e-04 - mae: 0.0174 - mse: 5.6404e-04\n",
      "Epoch 311/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 5.2541e-04 - mae: 0.0171 - mse: 5.2541e-04\n",
      "Epoch 312/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 6.0060e-04 - mae: 0.0180 - mse: 6.0060e-04\n",
      "Epoch 313/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 6.3471e-04 - mae: 0.0186 - mse: 6.3471e-04\n",
      "Epoch 314/400\n",
      "2412/2412 [==============================] - 0s 117us/sample - loss: 5.5915e-04 - mae: 0.0176 - mse: 5.5915e-04\n",
      "Epoch 315/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 5.3600e-04 - mae: 0.0174 - mse: 5.3600e-04\n",
      "Epoch 316/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.3570e-04 - mae: 0.0157 - mse: 4.3570e-04\n",
      "Epoch 317/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 5.0240e-04 - mae: 0.0169 - mse: 5.0240e-04\n",
      "Epoch 318/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 6.8112e-04 - mae: 0.0189 - mse: 6.8112e-04\n",
      "Epoch 319/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 9.8551e-04 - mae: 0.0228 - mse: 9.8551e-04\n",
      "Epoch 320/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 0.0013 - mae: 0.0250 - mse: 0.0013\n",
      "Epoch 321/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 0.0012 - mae: 0.0251 - mse: 0.0012\n",
      "Epoch 322/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 7.5665e-04 - mae: 0.0207 - mse: 7.5665e-04\n",
      "Epoch 323/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 6.6783e-04 - mae: 0.0190 - mse: 6.6783e-04\n",
      "Epoch 324/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 5.2126e-04 - mae: 0.0163 - mse: 5.2126e-04\n",
      "Epoch 325/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 4.4730e-04 - mae: 0.0156 - mse: 4.4730e-04\n",
      "Epoch 326/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 3.3000e-04 - mae: 0.0131 - mse: 3.3000e-04\n",
      "Epoch 327/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 3.5881e-04 - mae: 0.0137 - mse: 3.5881e-04\n",
      "Epoch 328/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.4641e-04 - mae: 0.0156 - mse: 4.4641e-04\n",
      "Epoch 329/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.7692e-04 - mae: 0.0160 - mse: 4.7692e-04\n",
      "Epoch 330/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.5077e-04 - mae: 0.0154 - mse: 4.5077e-04\n",
      "Epoch 331/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 4.5846e-04 - mae: 0.0152 - mse: 4.5846e-04\n",
      "Epoch 332/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 5.0474e-04 - mae: 0.0166 - mse: 5.0474e-04\n",
      "Epoch 333/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 4.8974e-04 - mae: 0.0161 - mse: 4.8974e-04\n",
      "Epoch 334/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 4.1059e-04 - mae: 0.0147 - mse: 4.1059e-04\n",
      "Epoch 335/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.0971e-04 - mae: 0.0151 - mse: 4.0971e-04\n",
      "Epoch 336/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.6809e-04 - mae: 0.0161 - mse: 4.6809e-04\n",
      "Epoch 337/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 4.3380e-04 - mae: 0.0155 - mse: 4.3380e-04\n",
      "Epoch 338/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 5.4777e-04 - mae: 0.0171 - mse: 5.4777e-04\n",
      "Epoch 339/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412/2412 [==============================] - 0s 109us/sample - loss: 7.0302e-04 - mae: 0.0197 - mse: 7.0302e-04\n",
      "Epoch 340/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 6.6784e-04 - mae: 0.0193 - mse: 6.6784e-04\n",
      "Epoch 341/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 6.5954e-04 - mae: 0.0193 - mse: 6.5954e-04\n",
      "Epoch 342/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 7.2752e-04 - mae: 0.0199 - mse: 7.2752e-04\n",
      "Epoch 343/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 8.3558e-04 - mae: 0.0215 - mse: 8.3558e-04\n",
      "Epoch 344/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 7.8461e-04 - mae: 0.0207 - mse: 7.8461e-04\n",
      "Epoch 345/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 6.6562e-04 - mae: 0.0193 - mse: 6.6562e-04\n",
      "Epoch 346/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.6309e-04 - mae: 0.0164 - mse: 4.6309e-04\n",
      "Epoch 347/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 4.3888e-04 - mae: 0.0157 - mse: 4.3888e-04\n",
      "Epoch 348/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 4.3318e-04 - mae: 0.0158 - mse: 4.3318e-04\n",
      "Epoch 349/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 3.6864e-04 - mae: 0.0144 - mse: 3.6864e-04\n",
      "Epoch 350/400\n",
      "2412/2412 [==============================] - 0s 119us/sample - loss: 3.3025e-04 - mae: 0.0137 - mse: 3.3025e-04\n",
      "Epoch 351/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 2.9667e-04 - mae: 0.0126 - mse: 2.9667e-04\n",
      "Epoch 352/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 3.4872e-04 - mae: 0.0135 - mse: 3.4872e-04\n",
      "Epoch 353/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 4.4850e-04 - mae: 0.0154 - mse: 4.4850e-04\n",
      "Epoch 354/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 3.9825e-04 - mae: 0.0145 - mse: 3.9825e-04\n",
      "Epoch 355/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 4.2905e-04 - mae: 0.0151 - mse: 4.2905e-04\n",
      "Epoch 356/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 5.3512e-04 - mae: 0.0168 - mse: 5.3512e-04\n",
      "Epoch 357/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 5.8252e-04 - mae: 0.0180 - mse: 5.8252e-04\n",
      "Epoch 358/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 6.6360e-04 - mae: 0.0193 - mse: 6.6360e-04\n",
      "Epoch 359/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 7.9543e-04 - mae: 0.0214 - mse: 7.9543e-04\n",
      "Epoch 360/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 9.4166e-04 - mae: 0.0232 - mse: 9.4166e-04\n",
      "Epoch 361/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0011 - mae: 0.0248 - mse: 0.0011\n",
      "Epoch 362/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 8.2828e-04 - mae: 0.0215 - mse: 8.2828e-04\n",
      "Epoch 363/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 6.1213e-04 - mae: 0.0182 - mse: 6.1213e-04\n",
      "Epoch 364/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 6.3017e-04 - mae: 0.0170 - mse: 6.3017e-04\n",
      "Epoch 365/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 5.2622e-04 - mae: 0.0166 - mse: 5.2622e-04\n",
      "Epoch 366/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.2859e-04 - mae: 0.0154 - mse: 4.2859e-04\n",
      "Epoch 367/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 4.5574e-04 - mae: 0.0152 - mse: 4.5574e-04\n",
      "Epoch 368/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 4.4226e-04 - mae: 0.0153 - mse: 4.4226e-04\n",
      "Epoch 369/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 3.8356e-04 - mae: 0.0147 - mse: 3.8356e-04\n",
      "Epoch 370/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 3.3780e-04 - mae: 0.0137 - mse: 3.3780e-04\n",
      "Epoch 371/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 3.2636e-04 - mae: 0.0137 - mse: 3.2636e-04\n",
      "Epoch 372/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 3.4317e-04 - mae: 0.0137 - mse: 3.4317e-04\n",
      "Epoch 373/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 3.7485e-04 - mae: 0.0146 - mse: 3.7485e-04\n",
      "Epoch 374/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 3.9599e-04 - mae: 0.0150 - mse: 3.9599e-04\n",
      "Epoch 375/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 4.6113e-04 - mae: 0.0163 - mse: 4.6113e-04\n",
      "Epoch 376/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 6.7538e-04 - mae: 0.0191 - mse: 6.7538e-04\n",
      "Epoch 377/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 8.1857e-04 - mae: 0.0216 - mse: 8.1857e-04\n",
      "Epoch 378/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 7.1572e-04 - mae: 0.0198 - mse: 7.1572e-04\n",
      "Epoch 379/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 6.0284e-04 - mae: 0.0186 - mse: 6.0284e-04\n",
      "Epoch 380/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 5.7836e-04 - mae: 0.0180 - mse: 5.7836e-04\n",
      "Epoch 381/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 5.1719e-04 - mae: 0.0169 - mse: 5.1719e-04\n",
      "Epoch 382/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 4.0511e-04 - mae: 0.0150 - mse: 4.0511e-04\n",
      "Epoch 383/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 4.3917e-04 - mae: 0.0155 - mse: 4.3917e-04\n",
      "Epoch 384/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.2257e-04 - mae: 0.0153 - mse: 4.2257e-04\n",
      "Epoch 385/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 4.3683e-04 - mae: 0.0158 - mse: 4.3683e-04\n",
      "Epoch 386/400\n",
      "2412/2412 [==============================] - 0s 115us/sample - loss: 4.8121e-04 - mae: 0.0163 - mse: 4.8121e-04\n",
      "Epoch 387/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 3.8180e-04 - mae: 0.0146 - mse: 3.8180e-04\n",
      "Epoch 388/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 3.9426e-04 - mae: 0.0148 - mse: 3.9426e-04\n",
      "Epoch 389/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.6343e-04 - mae: 0.0160 - mse: 4.6343e-04\n",
      "Epoch 390/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 4.1238e-04 - mae: 0.0152 - mse: 4.1238e-04\n",
      "Epoch 391/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 4.3751e-04 - mae: 0.0158 - mse: 4.3751e-04\n",
      "Epoch 392/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 3.9936e-04 - mae: 0.0151 - mse: 3.9936e-04\n",
      "Epoch 393/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 4.2457e-04 - mae: 0.0156 - mse: 4.2457e-04\n",
      "Epoch 394/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.6290e-04 - mae: 0.0161 - mse: 4.6290e-04\n",
      "Epoch 395/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 5.1984e-04 - mae: 0.0168 - mse: 5.1984e-04\n",
      "Epoch 396/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 5.1950e-04 - mae: 0.0169 - mse: 5.1950e-04\n",
      "Epoch 397/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 6.0114e-04 - mae: 0.0179 - mse: 6.0114e-04\n",
      "Epoch 398/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 6.7196e-04 - mae: 0.0193 - mse: 6.7196e-04\n",
      "Epoch 399/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 5.8385e-04 - mae: 0.0181 - mse: 5.8385e-04\n",
      "Epoch 400/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 4.8165e-04 - mae: 0.0161 - mse: 4.8165e-04\n",
      "269/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 897us/sample - loss: 0.0399 - mae: 0.1221 - mse: 0.0315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.12212907522916794\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV, StratifiedKFold, \\\n",
    "    cross_validate, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, \\\n",
    "    mean_absolute_error, make_scorer, brier_score_loss, roc_curve\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"s\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "\n",
    "\n",
    "__author__ = \"Dor Ma'ayan\"\n",
    "__email__ = \"grano@ifi.uzh.ch\"\n",
    "__license__ = \"MIT\"\n",
    "\n",
    "\n",
    "CSV_PATH = \"complete-frame.csv\"\n",
    "CSV_MINER_PATH = \"testminereffectiveness.csv\"\n",
    "DATA_DIR = \"results\"\n",
    "\n",
    "\n",
    "def label_rename1 (row):\n",
    "    return row['path_test'].split('/')[len(row['path_test'].split('/')) - 1].split('.')[0]\n",
    "\n",
    "def label_rename2 (row):\n",
    "    return row['path_src'].split('/')[len(row['path_src'].split('/')) - 1].split('.')[0]\n",
    "\n",
    "def load_quartile(frame):\n",
    "    low, high = frame.mutation.quantile([0.25,0.75])\n",
    "    frame_low = frame.query('mutation<{low}'.format(low=low))\n",
    "    frame_high = frame.query('mutation>{high}'.format(high=high))\n",
    "    frame_low['mutation'] = 0\n",
    "    frame_high['mutation'] = 1\n",
    "    frame = pd.concat([frame_low, frame_high], ignore_index=True)\n",
    "    frame = frame.sample(frac=1).reset_index(drop=True)\n",
    "    return frame;\n",
    "\n",
    "def load_frame():\n",
    "    \n",
    "    d = {'TestClassName' : 'ClassName',\n",
    "         'Vocabulary' : 'Vocabulary_prod',\n",
    "         'Word' : 'Word_prod', \n",
    "         'Non Whithe Characters' : 'Non Whithe Characters_prod',\n",
    "         'No. Methods' : 'No. Methods_prod',\n",
    "         'Special' : 'Special_prod',\n",
    "     'No. Method Invoctions' : 'No. Method Invoctions_prod',\n",
    "    'AST size' : 'AST size_prod', 'Max Depth' : 'Max Depth_prod',\n",
    "         'Deg2' : 'Deg2_prod',\n",
    "         'DegPerm' : 'DegPerm_prod',\n",
    "         'No. Break' : 'No. Break_prod',\n",
    "         'No. Continue' : 'No. Continue_prod',\n",
    "     'Avg Depth' : 'Avg Depth_prod', 'Dexterity' : 'Dexterity_prod',\n",
    "    'No. Expressions' : 'No. Expressions_prod', 'No. Try' : 'No. Try_prod', 'No. Catch' : 'No. Catch_prod',\n",
    "     'No. Loop' : 'No. Loop_prod', 'No. Conditions' : 'No. Conditions_prod', 'No. Else' : 'No. Else_prod'}\n",
    "    \n",
    "    \n",
    "    frame1 = pd.read_csv(CSV_PATH, sep=\",\")\n",
    "    frame1 = frame1.sample(frac=1).reset_index(drop=True)\n",
    "    frame1['TestClassName'] = frame1.apply(lambda row: label_rename1(row), axis=1)\n",
    "    frame1['ClassName'] = frame1.apply(lambda row: label_rename2(row), axis=1)\n",
    "        \n",
    "    \n",
    "    frame2 = pd.read_csv(CSV_MINER_PATH, sep=',')\n",
    "    \n",
    "    frame3 = pd.read_csv(CSV_MINER_PATH, sep=',')\n",
    "    frame3 = frame3.rename(columns = d)\n",
    "    frame3 = frame3.drop(['Bad API', 'Junit', 'Hamcrest', 'Mockito', 'Nº','Project'], axis=1)\n",
    "    \n",
    "    \n",
    "    frame = pd.merge(frame1, frame2, on='TestClassName')\n",
    "    \n",
    "    frame = pd.merge(frame, frame3, on='ClassName')\n",
    "    \n",
    "\n",
    "    frame = frame.drop(['project', 'module', 'path_test','test_name','path_src',\n",
    "                        'commit', 'class_name'], axis=1)\n",
    "    frame = frame.sample(frac=1).reset_index(drop=True)\n",
    "    frame = frame.dropna()\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def load_quartile(frame):\n",
    "    low, high = frame.mutation.quantile([0.25,0.75])\n",
    "    frame_low = frame.query('mutation<{low}'.format(low=low))\n",
    "    frame_high = frame.query('mutation>{high}'.format(high=high))\n",
    "    frame_low['mutation'] = 0\n",
    "    frame_high['mutation'] = 1\n",
    "    frame = pd.concat([frame_low, frame_high], ignore_index=True)\n",
    "    frame = frame.sample(frac=1).reset_index(drop=True)\n",
    "    return frame;\n",
    "\n",
    "\n",
    "\n",
    "def load_all_data(frame):\n",
    "    columns = ['isAssertionRoulette',\n",
    "       'isEagerTest', 'isLazyTest', 'isMysteryGuest',\n",
    "       'isSensitiveEquality', 'isResourceOptimism', 'isForTestersOnly',\n",
    "       'isIndirectTesting', 'LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod', 'LOC_test',\n",
    "       'HALSTEAD_test', 'RFC_test', 'CBO_test', 'MPC_test', 'IFC_test',\n",
    "       'DAC_test', 'DAC2_test', 'LCOM1_test', 'LCOM2_test', 'LCOM3_test',\n",
    "       'LCOM4_test', 'CONNECTIVITY_test', 'LCOM5_test', 'COH_test',\n",
    "       'TCC_test', 'LCC_test', 'ICH_test', 'WMC_test', 'NOA_test',\n",
    "       'NOPA_test', 'NOP_test', 'McCABE_test', 'BUSWEIMER_test',\n",
    "       'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability', 'test_readability', 'No. Methods', 'Vocabulary', 'Word',\n",
    "               'Special', 'Non Whithe Characters', 'No. Method Invoctions', 'AST size', 'Max Depth',\n",
    "               'Avg Depth', 'Deg2', 'DegPerm', 'Dexterity', 'No. Expressions', 'No. Try', 'No. Catch',\n",
    "               'No. Loop', 'No. Break', 'No. Continue', 'No. Conditions', 'No. Else', 'Bad API',\n",
    "               'Junit', 'Hamcrest', 'Mockito', 'No. Methods_prod', 'Vocabulary_prod', 'Word_prod',\n",
    "               'Special_prod', 'Non Whithe Characters_prod', 'No. Method Invoctions_prod', 'AST size_prod',\n",
    "               'Max Depth_prod', 'Avg Depth_prod', 'Deg2_prod', 'DegPerm_prod', 'Dexterity_prod',\n",
    "               'No. Expressions_prod', 'No. Try_prod', 'No. Catch_prod', 'No. Loop_prod', 'No. Break_prod',\n",
    "               'No. Continue_prod', 'No. Conditions_prod', 'No. Else_prod']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "def load_all_data_dynamic(frame):\n",
    "    columns = ['line_coverage', 'isAssertionRoulette',\n",
    "       'isEagerTest', 'isLazyTest', 'isMysteryGuest',\n",
    "       'isSensitiveEquality', 'isResourceOptimism', 'isForTestersOnly',\n",
    "       'isIndirectTesting', 'LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod', 'LOC_test',\n",
    "       'HALSTEAD_test', 'RFC_test', 'CBO_test', 'MPC_test', 'IFC_test',\n",
    "       'DAC_test', 'DAC2_test', 'LCOM1_test', 'LCOM2_test', 'LCOM3_test',\n",
    "       'LCOM4_test', 'CONNECTIVITY_test', 'LCOM5_test', 'COH_test',\n",
    "       'TCC_test', 'LCC_test', 'ICH_test', 'WMC_test', 'NOA_test',\n",
    "       'NOPA_test', 'NOP_test', 'McCABE_test', 'BUSWEIMER_test',\n",
    "       'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability', 'test_readability', 'No. Methods', 'Vocabulary', 'Word',\n",
    "               'Special', 'Non Whithe Characters', 'No. Method Invoctions', 'AST size', 'Max Depth',\n",
    "               'Avg Depth', 'Deg2', 'DegPerm', 'Dexterity', 'No. Expressions', 'No. Try', 'No. Catch',\n",
    "               'No. Loop', 'No. Break', 'No. Continue', 'No. Conditions', 'No. Else', 'Bad API',\n",
    "               'Junit', 'Hamcrest', 'Mockito', 'No. Methods_prod', 'Vocabulary_prod', 'Word_prod',\n",
    "               'Special_prod', 'Non Whithe Characters_prod', 'No. Method Invoctions_prod', 'AST size_prod',\n",
    "               'Max Depth_prod', 'Avg Depth_prod', 'Deg2_prod', 'DegPerm_prod', 'Dexterity_prod',\n",
    "               'No. Expressions_prod', 'No. Try_prod', 'No. Catch_prod', 'No. Loop_prod', 'No. Break_prod',\n",
    "               'No. Continue_prod', 'No. Conditions_prod', 'No. Else_prod']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "\n",
    "def load_all_their_data(frame):\n",
    "    columns = ['line_coverage', 'isAssertionRoulette',\n",
    "       'isEagerTest', 'isLazyTest', 'isMysteryGuest',\n",
    "       'isSensitiveEquality', 'isResourceOptimism', 'isForTestersOnly',\n",
    "       'isIndirectTesting', 'LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod', 'LOC_test',\n",
    "       'HALSTEAD_test', 'RFC_test', 'CBO_test', 'MPC_test', 'IFC_test',\n",
    "       'DAC_test', 'DAC2_test', 'LCOM1_test', 'LCOM2_test', 'LCOM3_test',\n",
    "       'LCOM4_test', 'CONNECTIVITY_test', 'LCOM5_test', 'COH_test',\n",
    "       'TCC_test', 'LCC_test', 'ICH_test', 'WMC_test', 'NOA_test',\n",
    "       'NOPA_test', 'NOP_test', 'McCABE_test', 'BUSWEIMER_test',\n",
    "       'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability', 'test_readability']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "def load_all_their_test_data(frame):\n",
    "    columns = ['isAssertionRoulette',\n",
    "       'isEagerTest', 'isLazyTest', 'isMysteryGuest',\n",
    "       'isSensitiveEquality', 'isResourceOptimism', 'isForTestersOnly',\n",
    "       'isIndirectTesting','LOC_test',\n",
    "       'HALSTEAD_test', 'RFC_test', 'CBO_test', 'MPC_test', 'IFC_test',\n",
    "       'DAC_test', 'DAC2_test', 'LCOM1_test', 'LCOM2_test', 'LCOM3_test',\n",
    "       'LCOM4_test', 'CONNECTIVITY_test', 'LCOM5_test', 'COH_test',\n",
    "       'TCC_test', 'LCC_test', 'ICH_test', 'WMC_test', 'NOA_test',\n",
    "       'NOPA_test', 'NOP_test', 'McCABE_test', 'BUSWEIMER_test', 'test_readability']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "def load_all_test_data(frame):\n",
    "    columns = ['isAssertionRoulette',\n",
    "       'isEagerTest', 'isLazyTest', 'isMysteryGuest',\n",
    "       'isSensitiveEquality', 'isResourceOptimism', 'isForTestersOnly',\n",
    "       'isIndirectTesting', 'LOC_test',\n",
    "       'HALSTEAD_test', 'RFC_test', 'CBO_test', 'MPC_test', 'IFC_test',\n",
    "       'DAC_test', 'DAC2_test', 'LCOM1_test', 'LCOM2_test', 'LCOM3_test',\n",
    "       'LCOM4_test', 'CONNECTIVITY_test', 'LCOM5_test', 'COH_test',\n",
    "       'TCC_test', 'LCC_test', 'ICH_test', 'WMC_test', 'NOA_test',\n",
    "       'NOPA_test', 'NOP_test', 'McCABE_test', 'BUSWEIMER_test',\n",
    "       'test_readability', 'No. Methods', 'Vocabulary', 'Word',\n",
    "               'Special', 'Non Whithe Characters', 'No. Method Invoctions', 'AST size', 'Max Depth',\n",
    "               'Avg Depth', 'Deg2', 'DegPerm', 'Dexterity', 'No. Expressions', 'No. Try', 'No. Catch',\n",
    "               'No. Loop', 'No. Break', 'No. Continue', 'No. Conditions', 'No. Else', 'Bad API',\n",
    "               'Junit', 'Hamcrest', 'Mockito']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "\n",
    "def load_all_production_data(frame):\n",
    "    columns = ['LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod',\n",
    "       'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability', 'No. Methods_prod', 'Vocabulary_prod', 'Word_prod',\n",
    "               'Special_prod', 'Non Whithe Characters_prod', 'No. Method Invoctions_prod', 'AST size_prod',\n",
    "               'Max Depth_prod', 'Avg Depth_prod', 'Deg2_prod', 'DegPerm_prod', 'Dexterity_prod',\n",
    "               'No. Expressions_prod', 'No. Try_prod', 'No. Catch_prod', 'No. Loop_prod', 'No. Break_prod',\n",
    "               'No. Continue_prod', 'No. Conditions_prod', 'No. Else_prod']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "\n",
    "def load_all_production_data_line_coverage(frame):\n",
    "    columns = ['LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod',\n",
    "       'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability', 'No. Methods_prod', 'Vocabulary_prod', 'Word_prod',\n",
    "               'Special_prod', 'Non Whithe Characters_prod', 'No. Method Invoctions_prod', 'AST size_prod',\n",
    "               'Max Depth_prod', 'Avg Depth_prod', 'Deg2_prod', 'DegPerm_prod', 'Dexterity_prod',\n",
    "               'No. Expressions_prod', 'No. Try_prod', 'No. Catch_prod', 'No. Loop_prod', 'No. Break_prod',\n",
    "               'No. Continue_prod', 'No. Conditions_prod', 'No. Else_prod']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.line_coverage], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "\n",
    "def load_all_their_production_data(frame):\n",
    "    columns = ['LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod', 'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "def get_scoring():\n",
    "    \"\"\"Returns the scores to evaluate the model\"\"\"\n",
    "    return dict(accuracy=make_scorer(accuracy_score),\n",
    "                precision=make_scorer(precision_score),\n",
    "                recall=make_scorer(recall_score),\n",
    "                f1_score=make_scorer(f1_score),\n",
    "                roc_auc_scorer=make_scorer(roc_auc_score),\n",
    "                mean_absolute_error=make_scorer(mean_absolute_error),\n",
    "                brier_score=make_scorer(brier_score_loss))\n",
    "\n",
    "\n",
    "frame = load_frame()\n",
    "data_x, data_y, number_of_features = load_all_data_dynamic(frame)\n",
    "data_y = pd.concat([frame.mutation], axis = 1).round(2).values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_x)\n",
    "data_x = scaler.transform(data_x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.10)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(number_of_features, activation='relu', input_dim=number_of_features))\n",
    "model.add(keras.layers.Dense(40, activation='relu'))\n",
    "model.add(keras.layers.Dense(20, activation='relu'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae','mse'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=400, verbose=1) #, callbacks=[early_stopping_monitor])\n",
    "\n",
    "\n",
    "test_loss, test_mae, test_mse = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('MAE: {}'.format(test_mae))\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.concatenate(y_pred).tolist()\n",
    "y_testi = np.concatenate(y_test).tolist()\n",
    "plt.scatter(*zip(*list(zip(y_testi,y_pred))))\n",
    "plt.ylabel('Predicted')\n",
    "plt.xlabel('Real')\n",
    "plt.show()\n",
    "plt.savefig(\"foo.pdf\", bbox_inches='tight')\n",
    "plt.close()\n",
    "tau, p_value = stats.pearsonr(y_pred, y_testi) #stats.kendalltau(y_pred, y_testi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = zip(list(zip(y_testi,y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.73,\n",
       " 0.31,\n",
       " 0.49,\n",
       " 0.01,\n",
       " 0.83,\n",
       " 0.83,\n",
       " 0.37,\n",
       " 0.58,\n",
       " 0.76,\n",
       " 0.72,\n",
       " 0.84,\n",
       " 0.51,\n",
       " 0.87,\n",
       " 0.92,\n",
       " 0.91,\n",
       " 0.93,\n",
       " 0.51,\n",
       " 1.0,\n",
       " 0.21,\n",
       " 0.44,\n",
       " 0.8,\n",
       " 0.53,\n",
       " 0.5,\n",
       " 0.86,\n",
       " 1.0,\n",
       " 0.31,\n",
       " 0.71,\n",
       " 0.71,\n",
       " 0.59,\n",
       " 0.76,\n",
       " 0.68,\n",
       " 0.19,\n",
       " 0.88,\n",
       " 0.03,\n",
       " 0.72,\n",
       " 0.57,\n",
       " 0.49,\n",
       " 0.14,\n",
       " 1.0,\n",
       " 0.75,\n",
       " 0.79,\n",
       " 0.06,\n",
       " 0.67,\n",
       " 0.71,\n",
       " 0.97,\n",
       " 0.42,\n",
       " 0.65,\n",
       " 0.44,\n",
       " 0.57,\n",
       " 0.88,\n",
       " 0.9,\n",
       " 0.52,\n",
       " 0.67,\n",
       " 0.97,\n",
       " 0.76,\n",
       " 0.93,\n",
       " 1.0,\n",
       " 0.39,\n",
       " 0.64,\n",
       " 1.0,\n",
       " 0.93,\n",
       " 0.5,\n",
       " 0.12,\n",
       " 0.79,\n",
       " 0.58,\n",
       " 0.4,\n",
       " 0.93,\n",
       " 0.77,\n",
       " 0.63,\n",
       " 0.47,\n",
       " 0.53,\n",
       " 0.48,\n",
       " 0.81,\n",
       " 0.79,\n",
       " 0.1,\n",
       " 0.39,\n",
       " 0.57,\n",
       " 0.73,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.53,\n",
       " 0.72,\n",
       " 0.48,\n",
       " 0.14,\n",
       " 0.67,\n",
       " 0.71,\n",
       " 1.0,\n",
       " 0.33,\n",
       " 1.0,\n",
       " 0.81,\n",
       " 1.0,\n",
       " 0.86,\n",
       " 0.5,\n",
       " 0.89,\n",
       " 0.18,\n",
       " 0.49,\n",
       " 0.67,\n",
       " 0.13,\n",
       " 0.5,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.73,\n",
       " 0.53,\n",
       " 0.83,\n",
       " 0.51,\n",
       " 0.8,\n",
       " 1.0,\n",
       " 0.96,\n",
       " 1.0,\n",
       " 0.66,\n",
       " 0.91,\n",
       " 0.8,\n",
       " 1.0,\n",
       " 0.8,\n",
       " 0.75,\n",
       " 0.52,\n",
       " 0.69,\n",
       " 0.93,\n",
       " 0.86,\n",
       " 0.89,\n",
       " 0.55,\n",
       " 0.5,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.43,\n",
       " 0.38,\n",
       " 0.53,\n",
       " 0.02,\n",
       " 0.71,\n",
       " 0.13,\n",
       " 0.54,\n",
       " 0.05,\n",
       " 0.67,\n",
       " 0.64,\n",
       " 0.96,\n",
       " 0.74,\n",
       " 1.0,\n",
       " 0.46,\n",
       " 0.84,\n",
       " 0.27,\n",
       " 0.74,\n",
       " 0.69,\n",
       " 0.99,\n",
       " 0.66,\n",
       " 0.09,\n",
       " 0.83,\n",
       " 0.8,\n",
       " 0.79,\n",
       " 0.8,\n",
       " 1.0,\n",
       " 0.86,\n",
       " 0.93,\n",
       " 0.15,\n",
       " 1.0,\n",
       " 0.88,\n",
       " 0.49,\n",
       " 0.86,\n",
       " 0.52,\n",
       " 0.7,\n",
       " 1.0,\n",
       " 0.85,\n",
       " 0.23,\n",
       " 0.29,\n",
       " 1.0,\n",
       " 0.1,\n",
       " 0.87,\n",
       " 0.87,\n",
       " 0.84,\n",
       " 0.57,\n",
       " 0.75,\n",
       " 0.64,\n",
       " 0.03,\n",
       " 0.75,\n",
       " 0.88,\n",
       " 0.71,\n",
       " 0.04,\n",
       " 0.79,\n",
       " 0.88,\n",
       " 0.65,\n",
       " 0.6,\n",
       " 0.86,\n",
       " 0.85,\n",
       " 0.45,\n",
       " 0.48,\n",
       " 0.47,\n",
       " 0.04,\n",
       " 0.47,\n",
       " 0.86,\n",
       " 0.79,\n",
       " 1.0,\n",
       " 0.5,\n",
       " 0.89,\n",
       " 0.03,\n",
       " 0.69,\n",
       " 1.0,\n",
       " 0.82,\n",
       " 0.51,\n",
       " 0.03,\n",
       " 0.51,\n",
       " 0.8,\n",
       " 0.91,\n",
       " 0.92,\n",
       " 0.48,\n",
       " 0.99,\n",
       " 0.78,\n",
       " 1.0,\n",
       " 0.38,\n",
       " 0.5,\n",
       " 0.49,\n",
       " 0.88,\n",
       " 1.0,\n",
       " 0.53,\n",
       " 0.77,\n",
       " 0.78,\n",
       " 0.39,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.77,\n",
       " 0.74,\n",
       " 0.47,\n",
       " 0.69,\n",
       " 0.87,\n",
       " 0.81,\n",
       " 0.61,\n",
       " 0.74,\n",
       " 0.69,\n",
       " 0.19,\n",
       " 0.8,\n",
       " 1.0,\n",
       " 0.97,\n",
       " 0.6,\n",
       " 1.0,\n",
       " 0.89,\n",
       " 0.5,\n",
       " 1.0,\n",
       " 0.37,\n",
       " 0.17,\n",
       " 0.82,\n",
       " 0.93,\n",
       " 0.32,\n",
       " 1.0,\n",
       " 0.72,\n",
       " 0.86,\n",
       " 0.78,\n",
       " 0.76,\n",
       " 0.97,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.74,\n",
       " 0.53,\n",
       " 0.4,\n",
       " 0.13,\n",
       " 0.18,\n",
       " 0.74,\n",
       " 0.67,\n",
       " 0.51,\n",
       " 0.02,\n",
       " 0.19,\n",
       " 0.92,\n",
       " 0.34,\n",
       " 0.07,\n",
       " 0.54,\n",
       " 0.48,\n",
       " 1.0,\n",
       " 0.55,\n",
       " 0.84,\n",
       " 0.27,\n",
       " 0.22]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9540941119194031,\n",
       " 0.19996562600135803,\n",
       " 0.414373517036438,\n",
       " 0.229050874710083,\n",
       " 0.9142104983329773,\n",
       " 0.8358315825462341,\n",
       " 0.6794190406799316,\n",
       " 0.6039409637451172,\n",
       " 0.6908938884735107,\n",
       " 1.1689366102218628,\n",
       " 1.0440309047698975,\n",
       " 0.888302206993103,\n",
       " 0.7197050452232361,\n",
       " 0.8100465536117554,\n",
       " 0.7912982702255249,\n",
       " 0.8210481405258179,\n",
       " 0.4771853983402252,\n",
       " 0.9514004588127136,\n",
       " 0.1658422350883484,\n",
       " 0.5166422724723816,\n",
       " 1.0044246912002563,\n",
       " 0.4665670692920685,\n",
       " 0.8983265161514282,\n",
       " 0.7170963883399963,\n",
       " 1.009155511856079,\n",
       " 0.278137743473053,\n",
       " 0.6602306365966797,\n",
       " 0.8026542663574219,\n",
       " 0.42810988426208496,\n",
       " 0.734984815120697,\n",
       " 0.42452871799468994,\n",
       " 0.4664139151573181,\n",
       " 0.8532953262329102,\n",
       " 0.1072126179933548,\n",
       " 0.40444523096084595,\n",
       " 0.5553426146507263,\n",
       " 0.4531833529472351,\n",
       " 0.8511621356010437,\n",
       " 0.783520519733429,\n",
       " 0.8396584391593933,\n",
       " 0.43414685130119324,\n",
       " 0.3297829329967499,\n",
       " 0.6740462779998779,\n",
       " 0.876352846622467,\n",
       " 0.794906735420227,\n",
       " 0.36208516359329224,\n",
       " 0.48875948786735535,\n",
       " 0.6654311418533325,\n",
       " 0.6424442529678345,\n",
       " 0.6230565309524536,\n",
       " 0.928501307964325,\n",
       " 0.5125570297241211,\n",
       " 0.5339690446853638,\n",
       " 0.9563368558883667,\n",
       " 0.45218944549560547,\n",
       " 0.8857372999191284,\n",
       " 1.0184085369110107,\n",
       " 0.8110393285751343,\n",
       " 0.576266884803772,\n",
       " 0.8126691579818726,\n",
       " 0.7955095171928406,\n",
       " 0.5233813524246216,\n",
       " 0.1524447202682495,\n",
       " 0.7654248476028442,\n",
       " 0.5330657362937927,\n",
       " 0.41148754954338074,\n",
       " 0.9573248028755188,\n",
       " 0.8247793912887573,\n",
       " 0.6410214900970459,\n",
       " 0.28356829285621643,\n",
       " 0.5119190216064453,\n",
       " 0.5506869554519653,\n",
       " 0.7255074977874756,\n",
       " 0.6756366491317749,\n",
       " 0.5356448292732239,\n",
       " 0.6660217046737671,\n",
       " 0.5743588209152222,\n",
       " 0.710097074508667,\n",
       " 0.8332473635673523,\n",
       " 1.012198805809021,\n",
       " 0.43622902035713196,\n",
       " 0.7252436876296997,\n",
       " 0.698281466960907,\n",
       " 0.13817369937896729,\n",
       " 0.8240379095077515,\n",
       " 0.778188943862915,\n",
       " 0.9590194821357727,\n",
       " 0.32920917868614197,\n",
       " 0.9832126498222351,\n",
       " 0.7397059798240662,\n",
       " 1.0714865922927856,\n",
       " 0.5936861038208008,\n",
       " 0.4619962275028229,\n",
       " 0.742464005947113,\n",
       " 0.4295116662979126,\n",
       " 0.47010987997055054,\n",
       " 0.7796087265014648,\n",
       " 0.38665467500686646,\n",
       " 0.4833625853061676,\n",
       " 0.9679307341575623,\n",
       " 1.090890645980835,\n",
       " 0.7835307717323303,\n",
       " 0.7679977416992188,\n",
       " 0.8097838163375854,\n",
       " 0.4596126973628998,\n",
       " 0.615520715713501,\n",
       " 1.0503228902816772,\n",
       " 0.9437887668609619,\n",
       " 0.9729141592979431,\n",
       " 0.7260195016860962,\n",
       " 0.8957334160804749,\n",
       " 0.6534479260444641,\n",
       " 1.0099871158599854,\n",
       " 0.6798970103263855,\n",
       " 0.5981262922286987,\n",
       " 0.4969010353088379,\n",
       " 0.9397411942481995,\n",
       " 0.7856831550598145,\n",
       " 0.8717634081840515,\n",
       " 1.0049753189086914,\n",
       " 0.4805806279182434,\n",
       " 0.5305747985839844,\n",
       " 0.6243990659713745,\n",
       " 1.0002436637878418,\n",
       " 0.9372368454933167,\n",
       " 0.8096256852149963,\n",
       " 0.38734322786331177,\n",
       " 0.645246684551239,\n",
       " 0.2870274782180786,\n",
       " 0.872728705406189,\n",
       " 0.37054669857025146,\n",
       " 0.5223822593688965,\n",
       " 0.1948411464691162,\n",
       " 0.5354421734809875,\n",
       " 0.4679878354072571,\n",
       " 0.8822724223136902,\n",
       " 0.729998767375946,\n",
       " 1.0451366901397705,\n",
       " 0.5312576293945312,\n",
       " 0.7516037821769714,\n",
       " 0.29748857021331787,\n",
       " 0.7739540338516235,\n",
       " 0.5574294924736023,\n",
       " 0.7581132054328918,\n",
       " 0.4614185094833374,\n",
       " -0.02090466022491455,\n",
       " 0.8728180527687073,\n",
       " 0.584107518196106,\n",
       " 0.6384229063987732,\n",
       " 0.7935578227043152,\n",
       " 1.0266900062561035,\n",
       " 0.7763420939445496,\n",
       " 0.8072412610054016,\n",
       " 0.17668995261192322,\n",
       " 0.9845515489578247,\n",
       " 0.8999035954475403,\n",
       " 0.48260626196861267,\n",
       " 0.540720522403717,\n",
       " 0.8476983904838562,\n",
       " 0.7586135864257812,\n",
       " 1.0044903755187988,\n",
       " 0.8843517303466797,\n",
       " 0.15625548362731934,\n",
       " 0.5454700589179993,\n",
       " 1.0702261924743652,\n",
       " 0.07963407784700394,\n",
       " 0.8370161056518555,\n",
       " 0.6780626773834229,\n",
       " 0.8203601241111755,\n",
       " 0.5551638007164001,\n",
       " 0.5540260672569275,\n",
       " 0.9233312010765076,\n",
       " 0.019964739680290222,\n",
       " 0.37891507148742676,\n",
       " 0.9093842506408691,\n",
       " 0.6644456386566162,\n",
       " 0.8113059997558594,\n",
       " 0.8271995782852173,\n",
       " 1.0655736923217773,\n",
       " 0.8691698908805847,\n",
       " 0.4713771343231201,\n",
       " 0.9646267294883728,\n",
       " 0.6478452682495117,\n",
       " 0.5940126180648804,\n",
       " 0.3191107213497162,\n",
       " 0.8406133651733398,\n",
       " 0.14219675958156586,\n",
       " 0.8360440135002136,\n",
       " 0.9104843735694885,\n",
       " 0.7374382019042969,\n",
       " 1.0166316032409668,\n",
       " 0.5249761343002319,\n",
       " 0.7621321082115173,\n",
       " 0.22685247659683228,\n",
       " 0.8145942091941833,\n",
       " 0.925548255443573,\n",
       " 0.814379870891571,\n",
       " 0.517033576965332,\n",
       " -0.02238672971725464,\n",
       " 0.48244157433509827,\n",
       " 0.6921818256378174,\n",
       " 0.7386057376861572,\n",
       " 0.5290439128875732,\n",
       " 0.4296192228794098,\n",
       " 0.724567711353302,\n",
       " 0.8133006691932678,\n",
       " 0.9927675127983093,\n",
       " 0.3191121220588684,\n",
       " 0.49425041675567627,\n",
       " 0.4538976550102234,\n",
       " 0.9664307832717896,\n",
       " 0.8669212460517883,\n",
       " 0.242337167263031,\n",
       " 0.6611489653587341,\n",
       " 0.8836202025413513,\n",
       " 0.3546580374240875,\n",
       " 0.994670569896698,\n",
       " 1.0408155918121338,\n",
       " 0.8058804869651794,\n",
       " 0.5587189197540283,\n",
       " 0.48043981194496155,\n",
       " 0.6857144832611084,\n",
       " 0.8660627603530884,\n",
       " 0.7140243649482727,\n",
       " 0.634731113910675,\n",
       " 0.36342984437942505,\n",
       " 0.5780291557312012,\n",
       " 0.2123539000749588,\n",
       " 0.8265118598937988,\n",
       " 0.997110903263092,\n",
       " 0.8666032552719116,\n",
       " 0.44210976362228394,\n",
       " 0.8272455930709839,\n",
       " 0.6490194201469421,\n",
       " 0.4505104124546051,\n",
       " 1.0270291566848755,\n",
       " 0.3565317392349243,\n",
       " 0.23989269137382507,\n",
       " 0.7415139079093933,\n",
       " 0.8070412278175354,\n",
       " 0.24698764085769653,\n",
       " 0.9738872051239014,\n",
       " 0.7289704084396362,\n",
       " 0.5314676761627197,\n",
       " 0.4474295377731323,\n",
       " 0.731137216091156,\n",
       " 0.7516973614692688,\n",
       " 0.7955453991889954,\n",
       " 0.9224777817726135,\n",
       " 0.7920414805412292,\n",
       " 0.6471875905990601,\n",
       " 0.5658500790596008,\n",
       " 0.2393716424703598,\n",
       " 0.20178279280662537,\n",
       " 0.4632266163825989,\n",
       " 0.8361448645591736,\n",
       " 0.29827386140823364,\n",
       " 0.14359167218208313,\n",
       " 0.1928878128528595,\n",
       " 0.43125343322753906,\n",
       " 0.6933055520057678,\n",
       " 0.2720504701137543,\n",
       " 0.5256104469299316,\n",
       " 0.47836941480636597,\n",
       " 1.001544713973999,\n",
       " 0.6261254549026489,\n",
       " 0.7946032285690308,\n",
       " 0.6653205752372742,\n",
       " 0.22140392661094666]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "\n",
    "rows = zip(y_testi,y_pred)\n",
    "with open('returns-dynamic.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in rows:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
