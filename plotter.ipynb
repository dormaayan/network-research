{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2412, 110)\n",
      "Train on 2412 samples\n",
      "Epoch 1/400\n",
      "2412/2412 [==============================] - 1s 424us/sample - loss: 0.1486 - mae: 0.2809 - mse: 0.1486\n",
      "Epoch 2/400\n",
      "2412/2412 [==============================] - 0s 88us/sample - loss: 0.0553 - mae: 0.1802 - mse: 0.0553\n",
      "Epoch 3/400\n",
      "2412/2412 [==============================] - 0s 88us/sample - loss: 0.0406 - mae: 0.1557 - mse: 0.0406\n",
      "Epoch 4/400\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0334 - mae: 0.1408 - mse: 0.0334\n",
      "Epoch 5/400\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0292 - mae: 0.1308 - mse: 0.0292\n",
      "Epoch 6/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0303 - mae: 0.1255 - mse: 0.0303\n",
      "Epoch 7/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0243 - mae: 0.1173 - mse: 0.0243\n",
      "Epoch 8/400\n",
      "2412/2412 [==============================] - 0s 90us/sample - loss: 0.0227 - mae: 0.1140 - mse: 0.0227\n",
      "Epoch 9/400\n",
      "2412/2412 [==============================] - 0s 89us/sample - loss: 0.0254 - mae: 0.1163 - mse: 0.0254\n",
      "Epoch 10/400\n",
      "2412/2412 [==============================] - 0s 88us/sample - loss: 0.0241 - mae: 0.1142 - mse: 0.0241\n",
      "Epoch 11/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0194 - mae: 0.1027 - mse: 0.0194\n",
      "Epoch 12/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0179 - mae: 0.0975 - mse: 0.0179\n",
      "Epoch 13/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0155 - mae: 0.0926 - mse: 0.0155\n",
      "Epoch 14/400\n",
      "2412/2412 [==============================] - 0s 88us/sample - loss: 0.0131 - mae: 0.0856 - mse: 0.0131\n",
      "Epoch 15/400\n",
      "2412/2412 [==============================] - 0s 89us/sample - loss: 0.0118 - mae: 0.0802 - mse: 0.0118\n",
      "Epoch 16/400\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0116 - mae: 0.0796 - mse: 0.0116\n",
      "Epoch 17/400\n",
      "2412/2412 [==============================] - 0s 89us/sample - loss: 0.0109 - mae: 0.0758 - mse: 0.0109\n",
      "Epoch 18/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0108 - mae: 0.0753 - mse: 0.0108\n",
      "Epoch 19/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0105 - mae: 0.0745 - mse: 0.0105\n",
      "Epoch 20/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0088 - mae: 0.0692 - mse: 0.0088\n",
      "Epoch 21/400\n",
      "2412/2412 [==============================] - 0s 90us/sample - loss: 0.0078 - mae: 0.0646 - mse: 0.0078\n",
      "Epoch 22/400\n",
      "2412/2412 [==============================] - 0s 88us/sample - loss: 0.0075 - mae: 0.0628 - mse: 0.0075\n",
      "Epoch 23/400\n",
      "2412/2412 [==============================] - 0s 91us/sample - loss: 0.0074 - mae: 0.0610 - mse: 0.0074\n",
      "Epoch 24/400\n",
      "2412/2412 [==============================] - 0s 91us/sample - loss: 0.0068 - mae: 0.0595 - mse: 0.0068\n",
      "Epoch 25/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0066 - mae: 0.0572 - mse: 0.0066\n",
      "Epoch 26/400\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0093 - mae: 0.0646 - mse: 0.0093\n",
      "Epoch 27/400\n",
      "2412/2412 [==============================] - 0s 87us/sample - loss: 0.0074 - mae: 0.0597 - mse: 0.0074\n",
      "Epoch 28/400\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0060 - mae: 0.0551 - mse: 0.0060\n",
      "Epoch 29/400\n",
      "2412/2412 [==============================] - 0s 91us/sample - loss: 0.0050 - mae: 0.0515 - mse: 0.0050\n",
      "Epoch 30/400\n",
      "2412/2412 [==============================] - 0s 89us/sample - loss: 0.0045 - mae: 0.0485 - mse: 0.0045\n",
      "Epoch 31/400\n",
      "2412/2412 [==============================] - 0s 91us/sample - loss: 0.0042 - mae: 0.0470 - mse: 0.0042\n",
      "Epoch 32/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0042 - mae: 0.0467 - mse: 0.0042\n",
      "Epoch 33/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0045 - mae: 0.0486 - mse: 0.0045\n",
      "Epoch 34/400\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0038 - mae: 0.0450 - mse: 0.0038\n",
      "Epoch 35/400\n",
      "2412/2412 [==============================] - 0s 91us/sample - loss: 0.0037 - mae: 0.0444 - mse: 0.0037\n",
      "Epoch 36/400\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0042 - mae: 0.0454 - mse: 0.0042\n",
      "Epoch 37/400\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0042 - mae: 0.0489 - mse: 0.0042\n",
      "Epoch 38/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0039 - mae: 0.0449 - mse: 0.0039\n",
      "Epoch 39/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 0.0041 - mae: 0.0458 - mse: 0.0041\n",
      "Epoch 40/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0043 - mae: 0.0458 - mse: 0.0043\n",
      "Epoch 41/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0044 - mae: 0.0485 - mse: 0.0044\n",
      "Epoch 42/400\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0057 - mae: 0.0500 - mse: 0.0057\n",
      "Epoch 43/400\n",
      "2412/2412 [==============================] - 0s 92us/sample - loss: 0.0060 - mae: 0.0545 - mse: 0.0060\n",
      "Epoch 44/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0047 - mae: 0.0502 - mse: 0.0047\n",
      "Epoch 45/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0042 - mae: 0.0450 - mse: 0.0042\n",
      "Epoch 46/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 0.0036 - mae: 0.0433 - mse: 0.0036\n",
      "Epoch 47/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0040 - mae: 0.0451 - mse: 0.0040\n",
      "Epoch 48/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0035 - mae: 0.0427 - mse: 0.0035\n",
      "Epoch 49/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0038 - mae: 0.0442 - mse: 0.0038\n",
      "Epoch 50/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0038 - mae: 0.0447 - mse: 0.0038\n",
      "Epoch 51/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0028 - mae: 0.0389 - mse: 0.0028\n",
      "Epoch 52/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0025 - mae: 0.0373 - mse: 0.0025\n",
      "Epoch 53/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0025 - mae: 0.0373 - mse: 0.0025\n",
      "Epoch 54/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0024 - mae: 0.0352 - mse: 0.0024\n",
      "Epoch 55/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0018 - mae: 0.0321 - mse: 0.0018\n",
      "Epoch 56/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0018 - mae: 0.0315 - mse: 0.0018\n",
      "Epoch 57/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0016 - mae: 0.0296 - mse: 0.0016\n",
      "Epoch 58/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0019 - mae: 0.0319 - mse: 0.0019\n",
      "Epoch 59/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0016 - mae: 0.0301 - mse: 0.0016\n",
      "Epoch 60/400\n",
      "2412/2412 [==============================] - 0s 94us/sample - loss: 0.0019 - mae: 0.0321 - mse: 0.0019\n",
      "Epoch 61/400\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0017 - mae: 0.0307 - mse: 0.0017\n",
      "Epoch 62/400\n",
      "2412/2412 [==============================] - 0s 93us/sample - loss: 0.0020 - mae: 0.0321 - mse: 0.0020\n",
      "Epoch 63/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0032 - mae: 0.0404 - mse: 0.0032\n",
      "Epoch 64/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0030 - mae: 0.0395 - mse: 0.0030\n",
      "Epoch 65/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0030 - mae: 0.0390 - mse: 0.0030\n",
      "Epoch 66/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0031 - mae: 0.0388 - mse: 0.0031\n",
      "Epoch 67/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0025 - mae: 0.0363 - mse: 0.0025\n",
      "Epoch 68/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0023 - mae: 0.0357 - mse: 0.0023\n",
      "Epoch 69/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0019 - mae: 0.0333 - mse: 0.0019\n",
      "Epoch 70/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0022 - mae: 0.0356 - mse: 0.0022\n",
      "Epoch 71/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0015 - mae: 0.0292 - mse: 0.0015\n",
      "Epoch 72/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0018 - mae: 0.0313 - mse: 0.0018\n",
      "Epoch 73/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0023 - mae: 0.0347 - mse: 0.0023\n",
      "Epoch 74/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0019 - mae: 0.0318 - mse: 0.0019\n",
      "Epoch 75/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0020 - mae: 0.0328 - mse: 0.0020\n",
      "Epoch 76/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0021 - mae: 0.0338 - mse: 0.0021\n",
      "Epoch 77/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0022 - mae: 0.0349 - mse: 0.0022\n",
      "Epoch 78/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0020 - mae: 0.0337 - mse: 0.0020\n",
      "Epoch 79/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0018 - mae: 0.0313 - mse: 0.0018\n",
      "Epoch 80/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0015 - mae: 0.0286 - mse: 0.0015\n",
      "Epoch 81/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0016 - mae: 0.0287 - mse: 0.0016\n",
      "Epoch 82/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0016 - mae: 0.0275 - mse: 0.0016\n",
      "Epoch 83/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0018 - mae: 0.0308 - mse: 0.0018\n",
      "Epoch 84/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0019 - mae: 0.0327 - mse: 0.0019\n",
      "Epoch 85/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0027 - mae: 0.0385 - mse: 0.0027\n",
      "Epoch 86/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0020 - mae: 0.0340 - mse: 0.0020\n",
      "Epoch 87/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0020 - mae: 0.0333 - mse: 0.0020\n",
      "Epoch 88/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0021 - mae: 0.0331 - mse: 0.0021\n",
      "Epoch 89/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0024 - mae: 0.0348 - mse: 0.0024\n",
      "Epoch 90/400\n",
      "2412/2412 [==============================] - 0s 95us/sample - loss: 0.0018 - mae: 0.0307 - mse: 0.0018\n",
      "Epoch 91/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0016 - mae: 0.0295 - mse: 0.0016\n",
      "Epoch 92/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 0.0018 - mae: 0.0318 - mse: 0.0018\n",
      "Epoch 93/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0015 - mae: 0.0281 - mse: 0.0015\n",
      "Epoch 94/400\n",
      "2412/2412 [==============================] - 0s 118us/sample - loss: 0.0020 - mae: 0.0326 - mse: 0.0020\n",
      "Epoch 95/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 0.0020 - mae: 0.0323 - mse: 0.0020\n",
      "Epoch 96/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0135 - mae: 0.0649 - mse: 0.0135\n",
      "Epoch 97/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0093 - mae: 0.0703 - mse: 0.0093\n",
      "Epoch 98/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0056 - mae: 0.0547 - mse: 0.0056\n",
      "Epoch 99/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0036 - mae: 0.0434 - mse: 0.0036\n",
      "Epoch 100/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0034 - mae: 0.0397 - mse: 0.0034\n",
      "Epoch 101/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0022 - mae: 0.0328 - mse: 0.0022\n",
      "Epoch 102/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0015 - mae: 0.0295 - mse: 0.0015\n",
      "Epoch 103/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 0.0013 - mae: 0.0269 - mse: 0.0013\n",
      "Epoch 104/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0011 - mae: 0.0252 - mse: 0.0011\n",
      "Epoch 105/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0010 - mae: 0.0238 - mse: 0.0010\n",
      "Epoch 106/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 7.8019e-04 - mae: 0.0210 - mse: 7.8019e-04\n",
      "Epoch 107/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 7.8968e-04 - mae: 0.0209 - mse: 7.8968e-04\n",
      "Epoch 108/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 7.3345e-04 - mae: 0.0203 - mse: 7.3345e-04\n",
      "Epoch 109/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 7.4981e-04 - mae: 0.0206 - mse: 7.4981e-04\n",
      "Epoch 110/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 8.8366e-04 - mae: 0.0221 - mse: 8.8366e-04\n",
      "Epoch 111/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 8.2175e-04 - mae: 0.0215 - mse: 8.2175e-04\n",
      "Epoch 112/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 8.5542e-04 - mae: 0.0216 - mse: 8.5542e-04\n",
      "Epoch 113/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 8.4519e-04 - mae: 0.0217 - mse: 8.4519e-04\n",
      "Epoch 114/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 9.5511e-04 - mae: 0.0225 - mse: 9.5511e-04\n",
      "Epoch 115/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0013 - mae: 0.0261 - mse: 0.0013\n",
      "Epoch 116/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0013 - mae: 0.0267 - mse: 0.0013\n",
      "Epoch 117/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0017 - mae: 0.0314 - mse: 0.0017\n",
      "Epoch 118/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0015 - mae: 0.0283 - mse: 0.0015\n",
      "Epoch 119/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 0.0014 - mae: 0.0280 - mse: 0.0014\n",
      "Epoch 120/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0013 - mae: 0.0263 - mse: 0.0013\n",
      "Epoch 121/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0018 - mae: 0.0302 - mse: 0.0018\n",
      "Epoch 122/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0022 - mae: 0.0347 - mse: 0.0022\n",
      "Epoch 123/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0021 - mae: 0.0339 - mse: 0.0021\n",
      "Epoch 124/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0029 - mae: 0.0393 - mse: 0.0029\n",
      "Epoch 125/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 0.0021 - mae: 0.0338 - mse: 0.0021\n",
      "Epoch 126/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0015 - mae: 0.0289 - mse: 0.0015\n",
      "Epoch 127/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 0.0013 - mae: 0.0271 - mse: 0.0013\n",
      "Epoch 128/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0011 - mae: 0.0247 - mse: 0.0011\n",
      "Epoch 129/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 8.1968e-04 - mae: 0.0212 - mse: 8.1968e-04\n",
      "Epoch 130/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 8.9948e-04 - mae: 0.0222 - mse: 8.9948e-04\n",
      "Epoch 131/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 8.9043e-04 - mae: 0.0222 - mse: 8.9043e-04\n",
      "Epoch 132/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 9.5224e-04 - mae: 0.0226 - mse: 9.5224e-04\n",
      "Epoch 133/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0013 - mae: 0.0257 - mse: 0.0013\n",
      "Epoch 134/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0013 - mae: 0.0261 - mse: 0.0013\n",
      "Epoch 135/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0011 - mae: 0.0245 - mse: 0.0011\n",
      "Epoch 136/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 0.0011 - mae: 0.0247 - mse: 0.0011\n",
      "Epoch 137/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 9.5904e-04 - mae: 0.0228 - mse: 9.5904e-04\n",
      "Epoch 138/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 8.5087e-04 - mae: 0.0215 - mse: 8.5087e-04\n",
      "Epoch 139/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 8.5433e-04 - mae: 0.0220 - mse: 8.5433e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 9.3991e-04 - mae: 0.0227 - mse: 9.3991e-04\n",
      "Epoch 141/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0013 - mae: 0.0266 - mse: 0.0013\n",
      "Epoch 142/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0015 - mae: 0.0292 - mse: 0.0015\n",
      "Epoch 143/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0016 - mae: 0.0291 - mse: 0.0016\n",
      "Epoch 144/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0014 - mae: 0.0275 - mse: 0.0014\n",
      "Epoch 145/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 0.0015 - mae: 0.0284 - mse: 0.0015\n",
      "Epoch 146/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0016 - mae: 0.0292 - mse: 0.0016\n",
      "Epoch 147/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0013 - mae: 0.0262 - mse: 0.0013\n",
      "Epoch 148/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0010 - mae: 0.0238 - mse: 0.0010\n",
      "Epoch 149/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0011 - mae: 0.0249 - mse: 0.0011\n",
      "Epoch 150/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 0.0013 - mae: 0.0258 - mse: 0.0013\n",
      "Epoch 151/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0016 - mae: 0.0287 - mse: 0.0016\n",
      "Epoch 152/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0017 - mae: 0.0289 - mse: 0.0017\n",
      "Epoch 153/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0015 - mae: 0.0283 - mse: 0.0015\n",
      "Epoch 154/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0021 - mae: 0.0306 - mse: 0.0021\n",
      "Epoch 155/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0017 - mae: 0.0281 - mse: 0.0017\n",
      "Epoch 156/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 0.0014 - mae: 0.0274 - mse: 0.0014\n",
      "Epoch 157/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0015 - mae: 0.0270 - mse: 0.0015\n",
      "Epoch 158/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0014 - mae: 0.0272 - mse: 0.0014\n",
      "Epoch 159/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0011 - mae: 0.0237 - mse: 0.0011\n",
      "Epoch 160/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 9.7562e-04 - mae: 0.0231 - mse: 9.7562e-04\n",
      "Epoch 161/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 9.6021e-04 - mae: 0.0232 - mse: 9.6021e-04\n",
      "Epoch 162/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 8.8828e-04 - mae: 0.0222 - mse: 8.8828e-04\n",
      "Epoch 163/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 9.8896e-04 - mae: 0.0230 - mse: 9.8896e-04\n",
      "Epoch 164/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0011 - mae: 0.0240 - mse: 0.0011\n",
      "Epoch 165/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 8.0421e-04 - mae: 0.0209 - mse: 8.0421e-04\n",
      "Epoch 166/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 7.0401e-04 - mae: 0.0195 - mse: 7.0401e-04\n",
      "Epoch 167/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 8.3656e-04 - mae: 0.0213 - mse: 8.3656e-04\n",
      "Epoch 168/400\n",
      "2412/2412 [==============================] - 0s 113us/sample - loss: 9.3401e-04 - mae: 0.0224 - mse: 9.3401e-04\n",
      "Epoch 169/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 8.4412e-04 - mae: 0.0210 - mse: 8.4412e-04\n",
      "Epoch 170/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 9.2220e-04 - mae: 0.0224 - mse: 9.2220e-04\n",
      "Epoch 171/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 0.0011 - mae: 0.0248 - mse: 0.0011\n",
      "Epoch 172/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0011 - mae: 0.0239 - mse: 0.0011\n",
      "Epoch 173/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0014 - mae: 0.0277 - mse: 0.0014\n",
      "Epoch 174/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0013 - mae: 0.0267 - mse: 0.0013\n",
      "Epoch 175/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0014 - mae: 0.0273 - mse: 0.0014\n",
      "Epoch 176/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0013 - mae: 0.0263 - mse: 0.0013\n",
      "Epoch 177/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0010 - mae: 0.0227 - mse: 0.0010\n",
      "Epoch 178/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0010 - mae: 0.0235 - mse: 0.0010\n",
      "Epoch 179/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 9.2209e-04 - mae: 0.0224 - mse: 9.2209e-04\n",
      "Epoch 180/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 7.8023e-04 - mae: 0.0207 - mse: 7.8023e-04\n",
      "Epoch 181/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 7.8546e-04 - mae: 0.0206 - mse: 7.8546e-04\n",
      "Epoch 182/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 8.5070e-04 - mae: 0.0216 - mse: 8.5070e-04\n",
      "Epoch 183/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0012 - mae: 0.0252 - mse: 0.0012\n",
      "Epoch 184/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0011 - mae: 0.0243 - mse: 0.0011\n",
      "Epoch 185/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 0.0031 - mae: 0.0275 - mse: 0.0031\n",
      "Epoch 186/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0023 - mae: 0.0350 - mse: 0.0023\n",
      "Epoch 187/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 0.0017 - mae: 0.0310 - mse: 0.0017\n",
      "Epoch 188/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 0.0017 - mae: 0.0299 - mse: 0.0017\n",
      "Epoch 189/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0022 - mae: 0.0338 - mse: 0.0022\n",
      "Epoch 190/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0030 - mae: 0.0366 - mse: 0.0030\n",
      "Epoch 191/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 0.0037 - mae: 0.0308 - mse: 0.0037\n",
      "Epoch 192/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 0.0024 - mae: 0.0339 - mse: 0.0024\n",
      "Epoch 193/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 0.0012 - mae: 0.0259 - mse: 0.0012\n",
      "Epoch 194/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 9.0304e-04 - mae: 0.0228 - mse: 9.0304e-04\n",
      "Epoch 195/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 6.4943e-04 - mae: 0.0188 - mse: 6.4943e-04\n",
      "Epoch 196/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 5.2033e-04 - mae: 0.0168 - mse: 5.2033e-04\n",
      "Epoch 197/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 9.8533e-04 - mae: 0.0211 - mse: 9.8533e-04\n",
      "Epoch 198/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 8.8522e-04 - mae: 0.0218 - mse: 8.8522e-04\n",
      "Epoch 199/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 7.3631e-04 - mae: 0.0204 - mse: 7.3631e-04\n",
      "Epoch 200/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 5.3478e-04 - mae: 0.0170 - mse: 5.3478e-04\n",
      "Epoch 201/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 4.5762e-04 - mae: 0.0159 - mse: 4.5762e-04\n",
      "Epoch 202/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 4.3477e-04 - mae: 0.0153 - mse: 4.3477e-04\n",
      "Epoch 203/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 4.1832e-04 - mae: 0.0148 - mse: 4.1832e-04\n",
      "Epoch 204/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 3.7443e-04 - mae: 0.0144 - mse: 3.7443e-04\n",
      "Epoch 205/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 4.8695e-04 - mae: 0.0162 - mse: 4.8695e-04\n",
      "Epoch 206/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 6.5646e-04 - mae: 0.0190 - mse: 6.5646e-04\n",
      "Epoch 207/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412/2412 [==============================] - 0s 103us/sample - loss: 7.1722e-04 - mae: 0.0197 - mse: 7.1722e-04\n",
      "Epoch 208/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 7.5451e-04 - mae: 0.0202 - mse: 7.5451e-04\n",
      "Epoch 209/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 7.2571e-04 - mae: 0.0199 - mse: 7.2571e-04\n",
      "Epoch 210/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 8.7793e-04 - mae: 0.0218 - mse: 8.7793e-04\n",
      "Epoch 211/400\n",
      "2412/2412 [==============================] - 0s 115us/sample - loss: 0.0012 - mae: 0.0247 - mse: 0.0012\n",
      "Epoch 212/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 8.6774e-04 - mae: 0.0222 - mse: 8.6774e-04\n",
      "Epoch 213/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 8.3766e-04 - mae: 0.0219 - mse: 8.3766e-04\n",
      "Epoch 214/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 9.6632e-04 - mae: 0.0233 - mse: 9.6632e-04\n",
      "Epoch 215/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 9.2066e-04 - mae: 0.0223 - mse: 9.2066e-04\n",
      "Epoch 216/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 9.2761e-04 - mae: 0.0225 - mse: 9.2761e-04\n",
      "Epoch 217/400\n",
      "2412/2412 [==============================] - 0s 115us/sample - loss: 7.7591e-04 - mae: 0.0207 - mse: 7.7591e-04\n",
      "Epoch 218/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 8.0140e-04 - mae: 0.0214 - mse: 8.0140e-04\n",
      "Epoch 219/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 8.6775e-04 - mae: 0.0216 - mse: 8.6775e-04\n",
      "Epoch 220/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 6.4365e-04 - mae: 0.0190 - mse: 6.4365e-04\n",
      "Epoch 221/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 6.3296e-04 - mae: 0.0190 - mse: 6.3296e-04\n",
      "Epoch 222/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 6.2092e-04 - mae: 0.0179 - mse: 6.2092e-04\n",
      "Epoch 223/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 5.0612e-04 - mae: 0.0167 - mse: 5.0612e-04\n",
      "Epoch 224/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 4.8036e-04 - mae: 0.0162 - mse: 4.8036e-04\n",
      "Epoch 225/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 5.5248e-04 - mae: 0.0177 - mse: 5.5248e-04\n",
      "Epoch 226/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 5.7157e-04 - mae: 0.0177 - mse: 5.7157e-04\n",
      "Epoch 227/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 7.1953e-04 - mae: 0.0200 - mse: 7.1953e-04\n",
      "Epoch 228/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 9.7803e-04 - mae: 0.0234 - mse: 9.7803e-04\n",
      "Epoch 229/400\n",
      "2412/2412 [==============================] - 0s 116us/sample - loss: 0.0010 - mae: 0.0238 - mse: 0.0010\n",
      "Epoch 230/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 8.4439e-04 - mae: 0.0220 - mse: 8.4439e-04\n",
      "Epoch 231/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 9.6558e-04 - mae: 0.0229 - mse: 9.6558e-04\n",
      "Epoch 232/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 8.9683e-04 - mae: 0.0227 - mse: 8.9683e-04\n",
      "Epoch 233/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 9.3246e-04 - mae: 0.0230 - mse: 9.3246e-04\n",
      "Epoch 234/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 0.0011 - mae: 0.0248 - mse: 0.0011\n",
      "Epoch 235/400\n",
      "2412/2412 [==============================] - 0s 118us/sample - loss: 0.0013 - mae: 0.0263 - mse: 0.0013\n",
      "Epoch 236/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 0.0010 - mae: 0.0238 - mse: 0.0010\n",
      "Epoch 237/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 8.5536e-04 - mae: 0.0215 - mse: 8.5537e-04\n",
      "Epoch 238/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 7.2740e-04 - mae: 0.0195 - mse: 7.2740e-04\n",
      "Epoch 239/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 7.1841e-04 - mae: 0.0195 - mse: 7.1841e-04\n",
      "Epoch 240/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 7.1637e-04 - mae: 0.0199 - mse: 7.1637e-04\n",
      "Epoch 241/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 7.8317e-04 - mae: 0.0207 - mse: 7.8317e-04\n",
      "Epoch 242/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 6.9178e-04 - mae: 0.0197 - mse: 6.9178e-04\n",
      "Epoch 243/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 6.0432e-04 - mae: 0.0182 - mse: 6.0432e-04\n",
      "Epoch 244/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 5.8233e-04 - mae: 0.0179 - mse: 5.8233e-04\n",
      "Epoch 245/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 5.6955e-04 - mae: 0.0172 - mse: 5.6955e-04\n",
      "Epoch 246/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 5.6307e-04 - mae: 0.0169 - mse: 5.6307e-04\n",
      "Epoch 247/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 6.2661e-04 - mae: 0.0183 - mse: 6.2661e-04\n",
      "Epoch 248/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 6.9049e-04 - mae: 0.0196 - mse: 6.9049e-04\n",
      "Epoch 249/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 7.8035e-04 - mae: 0.0197 - mse: 7.8035e-04\n",
      "Epoch 250/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 6.9097e-04 - mae: 0.0188 - mse: 6.9097e-04\n",
      "Epoch 251/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 6.8369e-04 - mae: 0.0196 - mse: 6.8369e-04\n",
      "Epoch 252/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 7.0707e-04 - mae: 0.0195 - mse: 7.0707e-04\n",
      "Epoch 253/400\n",
      "2412/2412 [==============================] - 0s 115us/sample - loss: 6.0586e-04 - mae: 0.0182 - mse: 6.0586e-04\n",
      "Epoch 254/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 6.9200e-04 - mae: 0.0196 - mse: 6.9200e-04\n",
      "Epoch 255/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 7.7020e-04 - mae: 0.0203 - mse: 7.7020e-04\n",
      "Epoch 256/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 7.1952e-04 - mae: 0.0201 - mse: 7.1952e-04\n",
      "Epoch 257/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 6.7674e-04 - mae: 0.0194 - mse: 6.7674e-04\n",
      "Epoch 258/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 6.8901e-04 - mae: 0.0196 - mse: 6.8901e-04\n",
      "Epoch 259/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 6.3835e-04 - mae: 0.0188 - mse: 6.3835e-04\n",
      "Epoch 260/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 6.7016e-04 - mae: 0.0191 - mse: 6.7016e-04\n",
      "Epoch 261/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 7.4152e-04 - mae: 0.0201 - mse: 7.4152e-04\n",
      "Epoch 262/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 7.6326e-04 - mae: 0.0206 - mse: 7.6326e-04\n",
      "Epoch 263/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 9.2213e-04 - mae: 0.0222 - mse: 9.2213e-04\n",
      "Epoch 264/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 8.3413e-04 - mae: 0.0215 - mse: 8.3413e-04\n",
      "Epoch 265/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 0.0010 - mae: 0.0240 - mse: 0.0010\n",
      "Epoch 266/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 7.8825e-04 - mae: 0.0211 - mse: 7.8825e-04\n",
      "Epoch 267/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 9.3984e-04 - mae: 0.0229 - mse: 9.3984e-04\n",
      "Epoch 268/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 9.2299e-04 - mae: 0.0226 - mse: 9.2299e-04\n",
      "Epoch 269/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 8.6229e-04 - mae: 0.0216 - mse: 8.6229e-04\n",
      "Epoch 270/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 8.4348e-04 - mae: 0.0211 - mse: 8.4348e-04\n",
      "Epoch 271/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 9.4312e-04 - mae: 0.0220 - mse: 9.4312e-04\n",
      "Epoch 272/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412/2412 [==============================] - 0s 112us/sample - loss: 9.5231e-04 - mae: 0.0232 - mse: 9.5231e-04\n",
      "Epoch 273/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 6.2498e-04 - mae: 0.0187 - mse: 6.2498e-04\n",
      "Epoch 274/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 6.1806e-04 - mae: 0.0186 - mse: 6.1806e-04\n",
      "Epoch 275/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 6.2133e-04 - mae: 0.0183 - mse: 6.2133e-04\n",
      "Epoch 276/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 6.3469e-04 - mae: 0.0173 - mse: 6.3469e-04\n",
      "Epoch 277/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 0.0018 - mae: 0.0240 - mse: 0.0018\n",
      "Epoch 278/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 0.0013 - mae: 0.0259 - mse: 0.0013\n",
      "Epoch 279/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0011 - mae: 0.0242 - mse: 0.0011\n",
      "Epoch 280/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0011 - mae: 0.0245 - mse: 0.0011\n",
      "Epoch 281/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 7.2565e-04 - mae: 0.0202 - mse: 7.2565e-04\n",
      "Epoch 282/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 4.8087e-04 - mae: 0.0161 - mse: 4.8087e-04\n",
      "Epoch 283/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 4.1682e-04 - mae: 0.0151 - mse: 4.1682e-04\n",
      "Epoch 284/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 4.1084e-04 - mae: 0.0147 - mse: 4.1084e-04\n",
      "Epoch 285/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 4.4624e-04 - mae: 0.0154 - mse: 4.4624e-04\n",
      "Epoch 286/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.7988e-04 - mae: 0.0161 - mse: 4.7988e-04\n",
      "Epoch 287/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.7384e-04 - mae: 0.0155 - mse: 4.7384e-04\n",
      "Epoch 288/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.1280e-04 - mae: 0.0151 - mse: 4.1280e-04\n",
      "Epoch 289/400\n",
      "2412/2412 [==============================] - 0s 115us/sample - loss: 4.1892e-04 - mae: 0.0147 - mse: 4.1892e-04\n",
      "Epoch 290/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 4.0665e-04 - mae: 0.0145 - mse: 4.0665e-04\n",
      "Epoch 291/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.3549e-04 - mae: 0.0155 - mse: 4.3549e-04\n",
      "Epoch 292/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 6.8525e-04 - mae: 0.0190 - mse: 6.8525e-04\n",
      "Epoch 293/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 8.2241e-04 - mae: 0.0215 - mse: 8.2241e-04\n",
      "Epoch 294/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0012 - mae: 0.0260 - mse: 0.0012\n",
      "Epoch 295/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 9.3696e-04 - mae: 0.0229 - mse: 9.3696e-04\n",
      "Epoch 296/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 7.0393e-04 - mae: 0.0193 - mse: 7.0393e-04\n",
      "Epoch 297/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 5.2064e-04 - mae: 0.0169 - mse: 5.2064e-04\n",
      "Epoch 298/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 4.6888e-04 - mae: 0.0159 - mse: 4.6888e-04\n",
      "Epoch 299/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 6.1055e-04 - mae: 0.0178 - mse: 6.1055e-04\n",
      "Epoch 300/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 6.3783e-04 - mae: 0.0183 - mse: 6.3783e-04\n",
      "Epoch 301/400\n",
      "2412/2412 [==============================] - 0s 111us/sample - loss: 9.0990e-04 - mae: 0.0207 - mse: 9.0990e-04\n",
      "Epoch 302/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 7.1054e-04 - mae: 0.0193 - mse: 7.1054e-04\n",
      "Epoch 303/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 6.1238e-04 - mae: 0.0179 - mse: 6.1238e-04\n",
      "Epoch 304/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 5.2267e-04 - mae: 0.0168 - mse: 5.2267e-04\n",
      "Epoch 305/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 4.5135e-04 - mae: 0.0157 - mse: 4.5135e-04\n",
      "Epoch 306/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 4.0661e-04 - mae: 0.0147 - mse: 4.0661e-04\n",
      "Epoch 307/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 3.6420e-04 - mae: 0.0139 - mse: 3.6420e-04\n",
      "Epoch 308/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 4.6250e-04 - mae: 0.0161 - mse: 4.6250e-04\n",
      "Epoch 309/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 4.4662e-04 - mae: 0.0158 - mse: 4.4662e-04\n",
      "Epoch 310/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 4.0290e-04 - mae: 0.0148 - mse: 4.0290e-04\n",
      "Epoch 311/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 4.8034e-04 - mae: 0.0163 - mse: 4.8034e-04\n",
      "Epoch 312/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 7.4865e-04 - mae: 0.0203 - mse: 7.4865e-04\n",
      "Epoch 313/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 7.2688e-04 - mae: 0.0200 - mse: 7.2688e-04\n",
      "Epoch 314/400\n",
      "2412/2412 [==============================] - 0s 112us/sample - loss: 7.8274e-04 - mae: 0.0213 - mse: 7.8274e-04\n",
      "Epoch 315/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 9.6027e-04 - mae: 0.0229 - mse: 9.6027e-04\n",
      "Epoch 316/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 0.0010 - mae: 0.0240 - mse: 0.0010\n",
      "Epoch 317/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 8.0056e-04 - mae: 0.0211 - mse: 8.0056e-04\n",
      "Epoch 318/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 6.9997e-04 - mae: 0.0198 - mse: 6.9997e-04\n",
      "Epoch 319/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 7.5355e-04 - mae: 0.0204 - mse: 7.5355e-04\n",
      "Epoch 320/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 6.4591e-04 - mae: 0.0184 - mse: 6.4591e-04\n",
      "Epoch 321/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.7832e-04 - mae: 0.0160 - mse: 4.7832e-04\n",
      "Epoch 322/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 3.9407e-04 - mae: 0.0148 - mse: 3.9407e-04\n",
      "Epoch 323/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 3.7964e-04 - mae: 0.0145 - mse: 3.7964e-04\n",
      "Epoch 324/400\n",
      "2412/2412 [==============================] - 0s 131us/sample - loss: 3.7994e-04 - mae: 0.0142 - mse: 3.7994e-04\n",
      "Epoch 325/400\n",
      "2412/2412 [==============================] - 0s 120us/sample - loss: 3.5412e-04 - mae: 0.0137 - mse: 3.5412e-04\n",
      "Epoch 326/400\n",
      "2412/2412 [==============================] - 1s 240us/sample - loss: 3.2523e-04 - mae: 0.0133 - mse: 3.2523e-04\n",
      "Epoch 327/400\n",
      "2412/2412 [==============================] - 0s 145us/sample - loss: 3.4226e-04 - mae: 0.0139 - mse: 3.4226e-04\n",
      "Epoch 328/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 3.8131e-04 - mae: 0.0146 - mse: 3.8131e-04\n",
      "Epoch 329/400\n",
      "2412/2412 [==============================] - 0s 125us/sample - loss: 4.5416e-04 - mae: 0.0160 - mse: 4.5416e-04\n",
      "Epoch 330/400\n",
      "2412/2412 [==============================] - 0s 133us/sample - loss: 5.4171e-04 - mae: 0.0172 - mse: 5.4171e-04\n",
      "Epoch 331/400\n",
      "2412/2412 [==============================] - 0s 119us/sample - loss: 7.1259e-04 - mae: 0.0198 - mse: 7.1259e-04\n",
      "Epoch 332/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 8.2387e-04 - mae: 0.0215 - mse: 8.2387e-04\n",
      "Epoch 333/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 7.2337e-04 - mae: 0.0199 - mse: 7.2337e-04\n",
      "Epoch 334/400\n",
      "2412/2412 [==============================] - 0s 120us/sample - loss: 6.9840e-04 - mae: 0.0196 - mse: 6.9840e-04\n",
      "Epoch 335/400\n",
      "2412/2412 [==============================] - 0s 115us/sample - loss: 6.8398e-04 - mae: 0.0190 - mse: 6.8398e-04\n",
      "Epoch 336/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 6.3547e-04 - mae: 0.0189 - mse: 6.3547e-04\n",
      "Epoch 337/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412/2412 [==============================] - 0s 100us/sample - loss: 6.9506e-04 - mae: 0.0192 - mse: 6.9506e-04\n",
      "Epoch 338/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 7.3077e-04 - mae: 0.0204 - mse: 7.3077e-04\n",
      "Epoch 339/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 6.3879e-04 - mae: 0.0189 - mse: 6.3879e-04\n",
      "Epoch 340/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 5.7149e-04 - mae: 0.0178 - mse: 5.7149e-04\n",
      "Epoch 341/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 5.1349e-04 - mae: 0.0167 - mse: 5.1349e-04\n",
      "Epoch 342/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 4.0370e-04 - mae: 0.0148 - mse: 4.0370e-04\n",
      "Epoch 343/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 3.8020e-04 - mae: 0.0147 - mse: 3.8020e-04\n",
      "Epoch 344/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 3.9190e-04 - mae: 0.0144 - mse: 3.9190e-04\n",
      "Epoch 345/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 4.6838e-04 - mae: 0.0157 - mse: 4.6838e-04\n",
      "Epoch 346/400\n",
      "2412/2412 [==============================] - 0s 114us/sample - loss: 6.0340e-04 - mae: 0.0183 - mse: 6.0340e-04\n",
      "Epoch 347/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 7.8940e-04 - mae: 0.0194 - mse: 7.8940e-04\n",
      "Epoch 348/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 0.0010 - mae: 0.0241 - mse: 0.0010\n",
      "Epoch 349/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 0.0012 - mae: 0.0244 - mse: 0.0012\n",
      "Epoch 350/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 8.9407e-04 - mae: 0.0220 - mse: 8.9407e-04\n",
      "Epoch 351/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 5.1253e-04 - mae: 0.0167 - mse: 5.1253e-04\n",
      "Epoch 352/400\n",
      "2412/2412 [==============================] - 0s 110us/sample - loss: 3.6821e-04 - mae: 0.0141 - mse: 3.6821e-04\n",
      "Epoch 353/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 3.8042e-04 - mae: 0.0146 - mse: 3.8042e-04\n",
      "Epoch 354/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 3.6968e-04 - mae: 0.0141 - mse: 3.6968e-04\n",
      "Epoch 355/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 3.5122e-04 - mae: 0.0135 - mse: 3.5122e-04\n",
      "Epoch 356/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 3.0053e-04 - mae: 0.0128 - mse: 3.0053e-04\n",
      "Epoch 357/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 2.9919e-04 - mae: 0.0122 - mse: 2.9919e-04\n",
      "Epoch 358/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 3.6278e-04 - mae: 0.0143 - mse: 3.6278e-04\n",
      "Epoch 359/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 4.6342e-04 - mae: 0.0157 - mse: 4.6342e-04\n",
      "Epoch 360/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 3.5790e-04 - mae: 0.0141 - mse: 3.5790e-04\n",
      "Epoch 361/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 4.3062e-04 - mae: 0.0150 - mse: 4.3062e-04\n",
      "Epoch 362/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 4.9021e-04 - mae: 0.0166 - mse: 4.9021e-04\n",
      "Epoch 363/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 4.5618e-04 - mae: 0.0157 - mse: 4.5618e-04\n",
      "Epoch 364/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 5.5443e-04 - mae: 0.0177 - mse: 5.5443e-04\n",
      "Epoch 365/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 6.6906e-04 - mae: 0.0189 - mse: 6.6906e-04\n",
      "Epoch 366/400\n",
      "2412/2412 [==============================] - 0s 108us/sample - loss: 5.9071e-04 - mae: 0.0179 - mse: 5.9071e-04\n",
      "Epoch 367/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 6.2312e-04 - mae: 0.0183 - mse: 6.2312e-04\n",
      "Epoch 368/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 5.0604e-04 - mae: 0.0165 - mse: 5.0604e-04\n",
      "Epoch 369/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 4.5915e-04 - mae: 0.0153 - mse: 4.5915e-04\n",
      "Epoch 370/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 4.3552e-04 - mae: 0.0152 - mse: 4.3552e-04\n",
      "Epoch 371/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 5.4505e-04 - mae: 0.0175 - mse: 5.4505e-04\n",
      "Epoch 372/400\n",
      "2412/2412 [==============================] - 0s 106us/sample - loss: 6.9954e-04 - mae: 0.0195 - mse: 6.9954e-04\n",
      "Epoch 373/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 7.3358e-04 - mae: 0.0198 - mse: 7.3358e-04\n",
      "Epoch 374/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 6.3267e-04 - mae: 0.0186 - mse: 6.3267e-04\n",
      "Epoch 375/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 6.0838e-04 - mae: 0.0182 - mse: 6.0838e-04\n",
      "Epoch 376/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 5.7378e-04 - mae: 0.0179 - mse: 5.7378e-04\n",
      "Epoch 377/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 4.9571e-04 - mae: 0.0161 - mse: 4.9571e-04\n",
      "Epoch 378/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 4.8655e-04 - mae: 0.0164 - mse: 4.8655e-04\n",
      "Epoch 379/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 4.3015e-04 - mae: 0.0152 - mse: 4.3015e-04\n",
      "Epoch 380/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 4.7089e-04 - mae: 0.0162 - mse: 4.7089e-04\n",
      "Epoch 381/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 3.7702e-04 - mae: 0.0142 - mse: 3.7702e-04\n",
      "Epoch 382/400\n",
      "2412/2412 [==============================] - 0s 96us/sample - loss: 4.2182e-04 - mae: 0.0153 - mse: 4.2182e-04\n",
      "Epoch 383/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 4.4565e-04 - mae: 0.0154 - mse: 4.4565e-04\n",
      "Epoch 384/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 4.6468e-04 - mae: 0.0155 - mse: 4.6468e-04\n",
      "Epoch 385/400\n",
      "2412/2412 [==============================] - 0s 103us/sample - loss: 4.9070e-04 - mae: 0.0161 - mse: 4.9070e-04\n",
      "Epoch 386/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 5.4822e-04 - mae: 0.0173 - mse: 5.4822e-04\n",
      "Epoch 387/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 4.6958e-04 - mae: 0.0160 - mse: 4.6958e-04\n",
      "Epoch 388/400\n",
      "2412/2412 [==============================] - 0s 102us/sample - loss: 4.3288e-04 - mae: 0.0154 - mse: 4.3288e-04\n",
      "Epoch 389/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 5.1547e-04 - mae: 0.0169 - mse: 5.1547e-04\n",
      "Epoch 390/400\n",
      "2412/2412 [==============================] - 0s 109us/sample - loss: 5.3496e-04 - mae: 0.0171 - mse: 5.3496e-04\n",
      "Epoch 391/400\n",
      "2412/2412 [==============================] - 0s 104us/sample - loss: 6.1180e-04 - mae: 0.0184 - mse: 6.1180e-04\n",
      "Epoch 392/400\n",
      "2412/2412 [==============================] - 0s 99us/sample - loss: 5.6131e-04 - mae: 0.0175 - mse: 5.6131e-04\n",
      "Epoch 393/400\n",
      "2412/2412 [==============================] - 0s 100us/sample - loss: 4.9913e-04 - mae: 0.0164 - mse: 4.9913e-04\n",
      "Epoch 394/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 5.6547e-04 - mae: 0.0173 - mse: 5.6547e-04\n",
      "Epoch 395/400\n",
      "2412/2412 [==============================] - 0s 101us/sample - loss: 7.3373e-04 - mae: 0.0199 - mse: 7.3373e-04\n",
      "Epoch 396/400\n",
      "2412/2412 [==============================] - 0s 107us/sample - loss: 6.1351e-04 - mae: 0.0182 - mse: 6.1351e-04\n",
      "Epoch 397/400\n",
      "2412/2412 [==============================] - 0s 105us/sample - loss: 4.3871e-04 - mae: 0.0156 - mse: 4.3871e-04\n",
      "Epoch 398/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 3.8642e-04 - mae: 0.0145 - mse: 3.8642e-04\n",
      "Epoch 399/400\n",
      "2412/2412 [==============================] - 0s 97us/sample - loss: 4.4149e-04 - mae: 0.0154 - mse: 4.4149e-04\n",
      "Epoch 400/400\n",
      "2412/2412 [==============================] - 0s 98us/sample - loss: 4.0038e-04 - mae: 0.0147 - mse: 4.0038e-04\n",
      "269/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 958us/sample - loss: 0.0240 - mae: 0.1225 - mse: 0.0293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.12246084213256836\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV, StratifiedKFold, \\\n",
    "    cross_validate, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, \\\n",
    "    mean_absolute_error, make_scorer, brier_score_loss, roc_curve\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"s\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "\n",
    "\n",
    "__author__ = \"Dor Ma'ayan\"\n",
    "__email__ = \"grano@ifi.uzh.ch\"\n",
    "__license__ = \"MIT\"\n",
    "\n",
    "\n",
    "CSV_PATH = \"complete-frame.csv\"\n",
    "CSV_MINER_PATH = \"testminereffectiveness.csv\"\n",
    "DATA_DIR = \"results\"\n",
    "\n",
    "\n",
    "def label_rename1 (row):\n",
    "    return row['path_test'].split('/')[len(row['path_test'].split('/')) - 1].split('.')[0]\n",
    "\n",
    "def label_rename2 (row):\n",
    "    return row['path_src'].split('/')[len(row['path_src'].split('/')) - 1].split('.')[0]\n",
    "\n",
    "def load_quartile(frame):\n",
    "    low, high = frame.mutation.quantile([0.25,0.75])\n",
    "    frame_low = frame.query('mutation<{low}'.format(low=low))\n",
    "    frame_high = frame.query('mutation>{high}'.format(high=high))\n",
    "    frame_low['mutation'] = 0\n",
    "    frame_high['mutation'] = 1\n",
    "    frame = pd.concat([frame_low, frame_high], ignore_index=True)\n",
    "    frame = frame.sample(frac=1).reset_index(drop=True)\n",
    "    return frame;\n",
    "\n",
    "def load_frame():\n",
    "    \n",
    "    d = {'TestClassName' : 'ClassName',\n",
    "         'Vocabulary' : 'Vocabulary_prod',\n",
    "         'Word' : 'Word_prod', \n",
    "         'Non Whithe Characters' : 'Non Whithe Characters_prod',\n",
    "         'No. Methods' : 'No. Methods_prod',\n",
    "         'Special' : 'Special_prod',\n",
    "     'No. Method Invoctions' : 'No. Method Invoctions_prod',\n",
    "    'AST size' : 'AST size_prod', 'Max Depth' : 'Max Depth_prod',\n",
    "         'Deg2' : 'Deg2_prod',\n",
    "         'DegPerm' : 'DegPerm_prod',\n",
    "         'No. Break' : 'No. Break_prod',\n",
    "         'No. Continue' : 'No. Continue_prod',\n",
    "     'Avg Depth' : 'Avg Depth_prod', 'Dexterity' : 'Dexterity_prod',\n",
    "    'No. Expressions' : 'No. Expressions_prod', 'No. Try' : 'No. Try_prod', 'No. Catch' : 'No. Catch_prod',\n",
    "     'No. Loop' : 'No. Loop_prod', 'No. Conditions' : 'No. Conditions_prod', 'No. Else' : 'No. Else_prod'}\n",
    "    \n",
    "    \n",
    "    frame1 = pd.read_csv(CSV_PATH, sep=\",\")\n",
    "    frame1 = frame1.sample(frac=1).reset_index(drop=True)\n",
    "    frame1['TestClassName'] = frame1.apply(lambda row: label_rename1(row), axis=1)\n",
    "    frame1['ClassName'] = frame1.apply(lambda row: label_rename2(row), axis=1)\n",
    "        \n",
    "    \n",
    "    frame2 = pd.read_csv(CSV_MINER_PATH, sep=',')\n",
    "    \n",
    "    frame3 = pd.read_csv(CSV_MINER_PATH, sep=',')\n",
    "    frame3 = frame3.rename(columns = d)\n",
    "    frame3 = frame3.drop(['Bad API', 'Junit', 'Hamcrest', 'Mockito', 'Nº','Project'], axis=1)\n",
    "    \n",
    "    \n",
    "    frame = pd.merge(frame1, frame2, on='TestClassName')\n",
    "    \n",
    "    frame = pd.merge(frame, frame3, on='ClassName')\n",
    "    \n",
    "\n",
    "    frame = frame.drop(['project', 'module', 'path_test','test_name','path_src',\n",
    "                        'commit', 'class_name'], axis=1)\n",
    "    frame = frame.sample(frac=1).reset_index(drop=True)\n",
    "    frame = frame.dropna()\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def load_quartile(frame):\n",
    "    low, high = frame.mutation.quantile([0.25,0.75])\n",
    "    frame_low = frame.query('mutation<{low}'.format(low=low))\n",
    "    frame_high = frame.query('mutation>{high}'.format(high=high))\n",
    "    frame_low['mutation'] = 0\n",
    "    frame_high['mutation'] = 1\n",
    "    frame = pd.concat([frame_low, frame_high], ignore_index=True)\n",
    "    frame = frame.sample(frac=1).reset_index(drop=True)\n",
    "    return frame;\n",
    "\n",
    "\n",
    "\n",
    "def load_all_data(frame):\n",
    "    columns = ['isAssertionRoulette',\n",
    "       'isEagerTest', 'isLazyTest', 'isMysteryGuest',\n",
    "       'isSensitiveEquality', 'isResourceOptimism', 'isForTestersOnly',\n",
    "       'isIndirectTesting', 'LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod', 'LOC_test',\n",
    "       'HALSTEAD_test', 'RFC_test', 'CBO_test', 'MPC_test', 'IFC_test',\n",
    "       'DAC_test', 'DAC2_test', 'LCOM1_test', 'LCOM2_test', 'LCOM3_test',\n",
    "       'LCOM4_test', 'CONNECTIVITY_test', 'LCOM5_test', 'COH_test',\n",
    "       'TCC_test', 'LCC_test', 'ICH_test', 'WMC_test', 'NOA_test',\n",
    "       'NOPA_test', 'NOP_test', 'McCABE_test', 'BUSWEIMER_test',\n",
    "       'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability', 'test_readability', 'No. Methods', 'Vocabulary', 'Word',\n",
    "               'Special', 'Non Whithe Characters', 'No. Method Invoctions', 'AST size', 'Max Depth',\n",
    "               'Avg Depth', 'Deg2', 'DegPerm', 'Dexterity', 'No. Expressions', 'No. Try', 'No. Catch',\n",
    "               'No. Loop', 'No. Break', 'No. Continue', 'No. Conditions', 'No. Else', 'Bad API',\n",
    "               'Junit', 'Hamcrest', 'Mockito', 'No. Methods_prod', 'Vocabulary_prod', 'Word_prod',\n",
    "               'Special_prod', 'Non Whithe Characters_prod', 'No. Method Invoctions_prod', 'AST size_prod',\n",
    "               'Max Depth_prod', 'Avg Depth_prod', 'Deg2_prod', 'DegPerm_prod', 'Dexterity_prod',\n",
    "               'No. Expressions_prod', 'No. Try_prod', 'No. Catch_prod', 'No. Loop_prod', 'No. Break_prod',\n",
    "               'No. Continue_prod', 'No. Conditions_prod', 'No. Else_prod']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "def load_all_data_dynamic(frame):\n",
    "    columns = ['line_coverage', 'isAssertionRoulette',\n",
    "       'isEagerTest', 'isLazyTest', 'isMysteryGuest',\n",
    "       'isSensitiveEquality', 'isResourceOptimism', 'isForTestersOnly',\n",
    "       'isIndirectTesting', 'LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod', 'LOC_test',\n",
    "       'HALSTEAD_test', 'RFC_test', 'CBO_test', 'MPC_test', 'IFC_test',\n",
    "       'DAC_test', 'DAC2_test', 'LCOM1_test', 'LCOM2_test', 'LCOM3_test',\n",
    "       'LCOM4_test', 'CONNECTIVITY_test', 'LCOM5_test', 'COH_test',\n",
    "       'TCC_test', 'LCC_test', 'ICH_test', 'WMC_test', 'NOA_test',\n",
    "       'NOPA_test', 'NOP_test', 'McCABE_test', 'BUSWEIMER_test',\n",
    "       'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability', 'test_readability', 'No. Methods', 'Vocabulary', 'Word',\n",
    "               'Special', 'Non Whithe Characters', 'No. Method Invoctions', 'AST size', 'Max Depth',\n",
    "               'Avg Depth', 'Deg2', 'DegPerm', 'Dexterity', 'No. Expressions', 'No. Try', 'No. Catch',\n",
    "               'No. Loop', 'No. Break', 'No. Continue', 'No. Conditions', 'No. Else', 'Bad API',\n",
    "               'Junit', 'Hamcrest', 'Mockito', 'No. Methods_prod', 'Vocabulary_prod', 'Word_prod',\n",
    "               'Special_prod', 'Non Whithe Characters_prod', 'No. Method Invoctions_prod', 'AST size_prod',\n",
    "               'Max Depth_prod', 'Avg Depth_prod', 'Deg2_prod', 'DegPerm_prod', 'Dexterity_prod',\n",
    "               'No. Expressions_prod', 'No. Try_prod', 'No. Catch_prod', 'No. Loop_prod', 'No. Break_prod',\n",
    "               'No. Continue_prod', 'No. Conditions_prod', 'No. Else_prod']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "\n",
    "def load_all_their_data(frame):\n",
    "    columns = ['line_coverage', 'isAssertionRoulette',\n",
    "       'isEagerTest', 'isLazyTest', 'isMysteryGuest',\n",
    "       'isSensitiveEquality', 'isResourceOptimism', 'isForTestersOnly',\n",
    "       'isIndirectTesting', 'LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod', 'LOC_test',\n",
    "       'HALSTEAD_test', 'RFC_test', 'CBO_test', 'MPC_test', 'IFC_test',\n",
    "       'DAC_test', 'DAC2_test', 'LCOM1_test', 'LCOM2_test', 'LCOM3_test',\n",
    "       'LCOM4_test', 'CONNECTIVITY_test', 'LCOM5_test', 'COH_test',\n",
    "       'TCC_test', 'LCC_test', 'ICH_test', 'WMC_test', 'NOA_test',\n",
    "       'NOPA_test', 'NOP_test', 'McCABE_test', 'BUSWEIMER_test',\n",
    "       'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability', 'test_readability']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "def load_all_their_test_data(frame):\n",
    "    columns = ['isAssertionRoulette',\n",
    "       'isEagerTest', 'isLazyTest', 'isMysteryGuest',\n",
    "       'isSensitiveEquality', 'isResourceOptimism', 'isForTestersOnly',\n",
    "       'isIndirectTesting','LOC_test',\n",
    "       'HALSTEAD_test', 'RFC_test', 'CBO_test', 'MPC_test', 'IFC_test',\n",
    "       'DAC_test', 'DAC2_test', 'LCOM1_test', 'LCOM2_test', 'LCOM3_test',\n",
    "       'LCOM4_test', 'CONNECTIVITY_test', 'LCOM5_test', 'COH_test',\n",
    "       'TCC_test', 'LCC_test', 'ICH_test', 'WMC_test', 'NOA_test',\n",
    "       'NOPA_test', 'NOP_test', 'McCABE_test', 'BUSWEIMER_test', 'test_readability']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "def load_all_test_data(frame):\n",
    "    columns = ['isAssertionRoulette',\n",
    "       'isEagerTest', 'isLazyTest', 'isMysteryGuest',\n",
    "       'isSensitiveEquality', 'isResourceOptimism', 'isForTestersOnly',\n",
    "       'isIndirectTesting', 'LOC_test',\n",
    "       'HALSTEAD_test', 'RFC_test', 'CBO_test', 'MPC_test', 'IFC_test',\n",
    "       'DAC_test', 'DAC2_test', 'LCOM1_test', 'LCOM2_test', 'LCOM3_test',\n",
    "       'LCOM4_test', 'CONNECTIVITY_test', 'LCOM5_test', 'COH_test',\n",
    "       'TCC_test', 'LCC_test', 'ICH_test', 'WMC_test', 'NOA_test',\n",
    "       'NOPA_test', 'NOP_test', 'McCABE_test', 'BUSWEIMER_test',\n",
    "       'test_readability', 'No. Methods', 'Vocabulary', 'Word',\n",
    "               'Special', 'Non Whithe Characters', 'No. Method Invoctions', 'AST size', 'Max Depth',\n",
    "               'Avg Depth', 'Deg2', 'DegPerm', 'Dexterity', 'No. Expressions', 'No. Try', 'No. Catch',\n",
    "               'No. Loop', 'No. Break', 'No. Continue', 'No. Conditions', 'No. Else', 'Bad API',\n",
    "               'Junit', 'Hamcrest', 'Mockito']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "\n",
    "def load_all_production_data(frame):\n",
    "    columns = ['LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod',\n",
    "       'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability', 'No. Methods_prod', 'Vocabulary_prod', 'Word_prod',\n",
    "               'Special_prod', 'Non Whithe Characters_prod', 'No. Method Invoctions_prod', 'AST size_prod',\n",
    "               'Max Depth_prod', 'Avg Depth_prod', 'Deg2_prod', 'DegPerm_prod', 'Dexterity_prod',\n",
    "               'No. Expressions_prod', 'No. Try_prod', 'No. Catch_prod', 'No. Loop_prod', 'No. Break_prod',\n",
    "               'No. Continue_prod', 'No. Conditions_prod', 'No. Else_prod']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "\n",
    "def load_all_production_data_line_coverage(frame):\n",
    "    columns = ['LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod',\n",
    "       'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability', 'No. Methods_prod', 'Vocabulary_prod', 'Word_prod',\n",
    "               'Special_prod', 'Non Whithe Characters_prod', 'No. Method Invoctions_prod', 'AST size_prod',\n",
    "               'Max Depth_prod', 'Avg Depth_prod', 'Deg2_prod', 'DegPerm_prod', 'Dexterity_prod',\n",
    "               'No. Expressions_prod', 'No. Try_prod', 'No. Catch_prod', 'No. Loop_prod', 'No. Break_prod',\n",
    "               'No. Continue_prod', 'No. Conditions_prod', 'No. Else_prod']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.line_coverage], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "\n",
    "def load_all_their_production_data(frame):\n",
    "    columns = ['LOC_prod', 'HALSTEAD_prod', 'RFC_prod',\n",
    "       'CBO_prod', 'MPC_prod', 'IFC_prod', 'DAC_prod', 'DAC2_prod',\n",
    "       'LCOM1_prod', 'LCOM2_prod', 'LCOM3_prod', 'LCOM4_prod',\n",
    "       'CONNECTIVITY_prod', 'LCOM5_prod', 'COH_prod', 'TCC_prod',\n",
    "       'LCC_prod', 'ICH_prod', 'WMC_prod', 'NOA_prod', 'NOPA_prod',\n",
    "       'NOP_prod', 'McCABE_prod', 'BUSWEIMER_prod', 'csm_CDSBP', 'csm_CC', 'csm_FD', 'csm_Blob', 'csm_SC', 'csm_MC',\n",
    "       'csm_LM', 'csm_FE', 'prod_readability']\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "    data_x = frame[columns].round(2)\n",
    "    data_y = pd.concat([frame.mutation], axis = 1)\n",
    "    return data_x, data_y, len(columns)\n",
    "\n",
    "def get_scoring():\n",
    "    \"\"\"Returns the scores to evaluate the model\"\"\"\n",
    "    return dict(accuracy=make_scorer(accuracy_score),\n",
    "                precision=make_scorer(precision_score),\n",
    "                recall=make_scorer(recall_score),\n",
    "                f1_score=make_scorer(f1_score),\n",
    "                roc_auc_scorer=make_scorer(roc_auc_score),\n",
    "                mean_absolute_error=make_scorer(mean_absolute_error),\n",
    "                brier_score=make_scorer(brier_score_loss))\n",
    "\n",
    "\n",
    "frame = load_frame()\n",
    "data_x, data_y, number_of_features = load_all_data(frame)\n",
    "data_y = pd.concat([frame.mutation], axis = 1).round(2).values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_x)\n",
    "data_x = scaler.transform(data_x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.10)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(number_of_features, activation='relu', input_dim=number_of_features))\n",
    "model.add(keras.layers.Dense(40, activation='relu'))\n",
    "model.add(keras.layers.Dense(20, activation='relu'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae','mse'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=400, verbose=1) #, callbacks=[early_stopping_monitor])\n",
    "\n",
    "\n",
    "test_loss, test_mae, test_mse = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('MAE: {}'.format(test_mae))\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.concatenate(y_pred).tolist()\n",
    "y_testi = np.concatenate(y_test).tolist()\n",
    "plt.scatter(*zip(*list(zip(y_testi,y_pred))))\n",
    "plt.ylabel('Predicted')\n",
    "plt.xlabel('Real')\n",
    "plt.show()\n",
    "plt.savefig(\"foo.pdf\", bbox_inches='tight')\n",
    "plt.close()\n",
    "tau, p_value = stats.pearsonr(y_pred, y_testi) #stats.kendalltau(y_pred, y_testi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = zip(list(zip(y_testi,y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.88,\n",
       " 0.68,\n",
       " 0.28,\n",
       " 0.8,\n",
       " 0.63,\n",
       " 0.53,\n",
       " 0.6,\n",
       " 0.98,\n",
       " 0.89,\n",
       " 0.91,\n",
       " 0.89,\n",
       " 0.85,\n",
       " 0.5,\n",
       " 1.0,\n",
       " 0.86,\n",
       " 0.8,\n",
       " 0.99,\n",
       " 0.79,\n",
       " 1.0,\n",
       " 0.59,\n",
       " 0.5,\n",
       " 0.53,\n",
       " 0.67,\n",
       " 1.0,\n",
       " 0.05,\n",
       " 0.33,\n",
       " 1.0,\n",
       " 0.5,\n",
       " 0.92,\n",
       " 0.32,\n",
       " 0.88,\n",
       " 0.86,\n",
       " 0.05,\n",
       " 0.75,\n",
       " 0.62,\n",
       " 0.59,\n",
       " 0.58,\n",
       " 0.29,\n",
       " 0.0,\n",
       " 0.44,\n",
       " 0.65,\n",
       " 0.8,\n",
       " 0.49,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.03,\n",
       " 0.1,\n",
       " 1.0,\n",
       " 0.77,\n",
       " 0.69,\n",
       " 0.95,\n",
       " 0.51,\n",
       " 0.7,\n",
       " 0.98,\n",
       " 0.89,\n",
       " 0.77,\n",
       " 0.22,\n",
       " 0.97,\n",
       " 0.74,\n",
       " 0.85,\n",
       " 0.93,\n",
       " 1.0,\n",
       " 0.76,\n",
       " 0.49,\n",
       " 0.81,\n",
       " 0.7,\n",
       " 0.83,\n",
       " 0.72,\n",
       " 0.49,\n",
       " 0.81,\n",
       " 0.76,\n",
       " 0.17,\n",
       " 0.75,\n",
       " 0.22,\n",
       " 0.58,\n",
       " 0.15,\n",
       " 0.45,\n",
       " 0.84,\n",
       " 0.86,\n",
       " 1.0,\n",
       " 0.48,\n",
       " 0.83,\n",
       " 0.66,\n",
       " 0.76,\n",
       " 0.19,\n",
       " 0.6,\n",
       " 0.37,\n",
       " 0.92,\n",
       " 0.7,\n",
       " 0.55,\n",
       " 0.52,\n",
       " 0.48,\n",
       " 0.46,\n",
       " 0.86,\n",
       " 0.77,\n",
       " 0.01,\n",
       " 0.52,\n",
       " 1.0,\n",
       " 0.39,\n",
       " 0.45,\n",
       " 0.71,\n",
       " 0.69,\n",
       " 0.94,\n",
       " 0.86,\n",
       " 1.0,\n",
       " 0.84,\n",
       " 0.23,\n",
       " 0.64,\n",
       " 0.78,\n",
       " 0.74,\n",
       " 1.0,\n",
       " 0.42,\n",
       " 0.78,\n",
       " 0.49,\n",
       " 0.42,\n",
       " 0.63,\n",
       " 0.38,\n",
       " 0.53,\n",
       " 0.5,\n",
       " 0.78,\n",
       " 1.0,\n",
       " 0.09,\n",
       " 0.15,\n",
       " 0.67,\n",
       " 0.66,\n",
       " 0.23,\n",
       " 0.8,\n",
       " 0.11,\n",
       " 0.93,\n",
       " 0.52,\n",
       " 0.88,\n",
       " 0.55,\n",
       " 1.0,\n",
       " 0.54,\n",
       " 0.47,\n",
       " 0.22,\n",
       " 0.62,\n",
       " 0.51,\n",
       " 0.66,\n",
       " 0.45,\n",
       " 0.87,\n",
       " 0.86,\n",
       " 0.04,\n",
       " 0.57,\n",
       " 0.22,\n",
       " 0.73,\n",
       " 1.0,\n",
       " 0.62,\n",
       " 0.66,\n",
       " 0.75,\n",
       " 0.44,\n",
       " 0.73,\n",
       " 0.41,\n",
       " 0.05,\n",
       " 0.67,\n",
       " 0.53,\n",
       " 0.96,\n",
       " 0.3,\n",
       " 1.0,\n",
       " 0.07,\n",
       " 0.5,\n",
       " 0.54,\n",
       " 0.79,\n",
       " 0.29,\n",
       " 0.04,\n",
       " 0.8,\n",
       " 0.7,\n",
       " 0.94,\n",
       " 0.53,\n",
       " 1.0,\n",
       " 0.19,\n",
       " 0.61,\n",
       " 0.47,\n",
       " 0.78,\n",
       " 1.0,\n",
       " 0.48,\n",
       " 0.95,\n",
       " 0.48,\n",
       " 0.83,\n",
       " 0.81,\n",
       " 0.33,\n",
       " 0.76,\n",
       " 0.78,\n",
       " 0.71,\n",
       " 0.1,\n",
       " 0.19,\n",
       " 0.97,\n",
       " 0.53,\n",
       " 0.67,\n",
       " 0.01,\n",
       " 0.71,\n",
       " 1.0,\n",
       " 0.92,\n",
       " 0.83,\n",
       " 0.61,\n",
       " 0.39,\n",
       " 0.29,\n",
       " 1.0,\n",
       " 0.86,\n",
       " 0.19,\n",
       " 0.6,\n",
       " 0.1,\n",
       " 0.54,\n",
       " 0.86,\n",
       " 0.05,\n",
       " 0.29,\n",
       " 0.81,\n",
       " 0.64,\n",
       " 0.8,\n",
       " 0.31,\n",
       " 1.0,\n",
       " 0.85,\n",
       " 0.76,\n",
       " 0.69,\n",
       " 0.77,\n",
       " 0.79,\n",
       " 0.46,\n",
       " 0.13,\n",
       " 0.48,\n",
       " 0.96,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.94,\n",
       " 0.79,\n",
       " 0.97,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.7,\n",
       " 0.78,\n",
       " 0.54,\n",
       " 0.76,\n",
       " 0.8,\n",
       " 0.58,\n",
       " 0.93,\n",
       " 0.45,\n",
       " 0.66,\n",
       " 0.84,\n",
       " 0.61,\n",
       " 0.52,\n",
       " 0.99,\n",
       " 0.4,\n",
       " 0.9,\n",
       " 0.29,\n",
       " 0.86,\n",
       " 0.19,\n",
       " 0.81,\n",
       " 0.74,\n",
       " 0.69,\n",
       " 0.91,\n",
       " 0.6,\n",
       " 0.89,\n",
       " 0.28,\n",
       " 0.87,\n",
       " 0.71,\n",
       " 0.74,\n",
       " 0.88,\n",
       " 0.37,\n",
       " 0.53,\n",
       " 0.67,\n",
       " 0.5,\n",
       " 0.49,\n",
       " 0.73,\n",
       " 0.82,\n",
       " 0.9,\n",
       " 0.22,\n",
       " 0.78,\n",
       " 0.48]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.701339602470398,\n",
       " 0.6811660528182983,\n",
       " 0.5560958385467529,\n",
       " 0.7347605228424072,\n",
       " 0.7715393304824829,\n",
       " 0.600234866142273,\n",
       " 0.6574651002883911,\n",
       " 0.8678652048110962,\n",
       " 0.9642412662506104,\n",
       " 0.8547234535217285,\n",
       " 0.8014798164367676,\n",
       " 0.8300817012786865,\n",
       " 0.5179041624069214,\n",
       " 0.7771919965744019,\n",
       " 0.9022994041442871,\n",
       " 0.8022595643997192,\n",
       " 0.7298210859298706,\n",
       " 0.7195295095443726,\n",
       " 1.015722393989563,\n",
       " 0.39811691641807556,\n",
       " 0.49374255537986755,\n",
       " 0.5887069702148438,\n",
       " 0.3722723126411438,\n",
       " 0.8083269596099854,\n",
       " 0.12761826813220978,\n",
       " 0.3251449167728424,\n",
       " 1.0053842067718506,\n",
       " 0.6612609624862671,\n",
       " 0.5741885304450989,\n",
       " 0.48485586047172546,\n",
       " 0.6661880016326904,\n",
       " 0.7198034524917603,\n",
       " 0.07557301223278046,\n",
       " 0.5436270236968994,\n",
       " 0.7708116769790649,\n",
       " 0.5545024275779724,\n",
       " 0.3595973253250122,\n",
       " 0.3234959542751312,\n",
       " 0.20701543986797333,\n",
       " 0.5786458253860474,\n",
       " 0.7028197050094604,\n",
       " 0.9229729175567627,\n",
       " 0.7111343145370483,\n",
       " 1.0072064399719238,\n",
       " 0.7823516130447388,\n",
       " 0.10935890674591064,\n",
       " 0.11395472288131714,\n",
       " 0.9700404405593872,\n",
       " 0.5953503847122192,\n",
       " 0.42769962549209595,\n",
       " 0.8121711015701294,\n",
       " 0.4627947211265564,\n",
       " 0.4083298146724701,\n",
       " 0.7325965166091919,\n",
       " 0.553910493850708,\n",
       " 0.7379682064056396,\n",
       " 0.20458519458770752,\n",
       " 0.7540353536605835,\n",
       " 0.7122184038162231,\n",
       " 0.8231496810913086,\n",
       " 0.8737856149673462,\n",
       " 1.0357617139816284,\n",
       " 0.9039293527603149,\n",
       " 0.5260996222496033,\n",
       " 0.5234220027923584,\n",
       " 0.5791181325912476,\n",
       " 0.8506512641906738,\n",
       " 0.41020333766937256,\n",
       " 0.5682022571563721,\n",
       " 0.7795556783676147,\n",
       " 0.6150678992271423,\n",
       " 0.7430880069732666,\n",
       " 0.2292344868183136,\n",
       " 0.21477437019348145,\n",
       " 0.47023382782936096,\n",
       " 0.3026205003261566,\n",
       " 0.42891883850097656,\n",
       " 0.7919950485229492,\n",
       " 0.8717138767242432,\n",
       " 0.884732723236084,\n",
       " 0.5208823680877686,\n",
       " 0.8409883975982666,\n",
       " 0.7049366235733032,\n",
       " 0.906029462814331,\n",
       " 0.4155561923980713,\n",
       " 0.8874703645706177,\n",
       " 0.3775613009929657,\n",
       " 0.7887827157974243,\n",
       " 0.7051063776016235,\n",
       " 0.5303161144256592,\n",
       " 0.4614824950695038,\n",
       " 0.3840062618255615,\n",
       " 0.3329806327819824,\n",
       " 0.5338600873947144,\n",
       " 0.35909175872802734,\n",
       " 0.02935880422592163,\n",
       " 0.8373820781707764,\n",
       " 1.0365593433380127,\n",
       " 0.39319556951522827,\n",
       " 0.7310751676559448,\n",
       " 0.6350319385528564,\n",
       " 0.5137856006622314,\n",
       " 0.8778622150421143,\n",
       " 0.7413989305496216,\n",
       " 0.8608242273330688,\n",
       " 0.8054277896881104,\n",
       " 0.2373981922864914,\n",
       " 0.6780812740325928,\n",
       " 0.7816709280014038,\n",
       " 0.6659187078475952,\n",
       " 1.0209163427352905,\n",
       " 0.32866793870925903,\n",
       " 1.0666483640670776,\n",
       " 0.27923721075057983,\n",
       " 0.6537824273109436,\n",
       " 1.0803678035736084,\n",
       " 0.3204103708267212,\n",
       " 0.8673490285873413,\n",
       " 0.5001736879348755,\n",
       " 0.8507577180862427,\n",
       " 0.7514357566833496,\n",
       " 0.108732670545578,\n",
       " 0.3257567286491394,\n",
       " 0.8660370111465454,\n",
       " 0.4899938106536865,\n",
       " 0.30735570192337036,\n",
       " 0.8255300521850586,\n",
       " 0.42325514554977417,\n",
       " 0.7205291986465454,\n",
       " 0.49927106499671936,\n",
       " 0.8552408218383789,\n",
       " 0.7815351486206055,\n",
       " 0.9880069494247437,\n",
       " 0.5312230587005615,\n",
       " 0.1808345913887024,\n",
       " 0.5185221433639526,\n",
       " 0.6215741634368896,\n",
       " 0.43075817823410034,\n",
       " 0.4212671220302582,\n",
       " 0.548478364944458,\n",
       " 0.7762688398361206,\n",
       " 0.8868849277496338,\n",
       " 0.1830822378396988,\n",
       " 0.7579660415649414,\n",
       " 0.22702936828136444,\n",
       " 0.729688286781311,\n",
       " 0.9711552858352661,\n",
       " 0.48869189620018005,\n",
       " 0.861838698387146,\n",
       " 0.6627330780029297,\n",
       " 0.3902950882911682,\n",
       " 0.7493818998336792,\n",
       " 0.416745662689209,\n",
       " 0.5056184530258179,\n",
       " 0.652072548866272,\n",
       " 0.5510009527206421,\n",
       " 1.0819531679153442,\n",
       " 0.5464318990707397,\n",
       " 1.1425422430038452,\n",
       " 0.6125236749649048,\n",
       " 0.6302964687347412,\n",
       " 0.567351222038269,\n",
       " 0.3828682005405426,\n",
       " 0.45764005184173584,\n",
       " 0.4540465474128723,\n",
       " 0.7833282947540283,\n",
       " 0.47046393156051636,\n",
       " 0.6200650930404663,\n",
       " 0.5115526914596558,\n",
       " 0.9786165952682495,\n",
       " 0.20516987144947052,\n",
       " 0.6342273950576782,\n",
       " 0.5536510348320007,\n",
       " 0.8733214139938354,\n",
       " 0.9779002666473389,\n",
       " 0.8594852685928345,\n",
       " 0.9236818552017212,\n",
       " 0.3148137331008911,\n",
       " 0.8421305418014526,\n",
       " 0.6548081636428833,\n",
       " 0.22970055043697357,\n",
       " 0.307329386472702,\n",
       " 0.742091178894043,\n",
       " 0.7461980581283569,\n",
       " 0.09438204020261765,\n",
       " 0.41906169056892395,\n",
       " 0.9062280654907227,\n",
       " 0.5757179856300354,\n",
       " 0.28417420387268066,\n",
       " -0.008049443364143372,\n",
       " 0.8375339508056641,\n",
       " 0.8554631471633911,\n",
       " 0.8661772012710571,\n",
       " 0.7967679500579834,\n",
       " 0.569207489490509,\n",
       " 0.7356784343719482,\n",
       " 0.32834216952323914,\n",
       " 0.9975464344024658,\n",
       " 0.9158222675323486,\n",
       " 0.1999579668045044,\n",
       " 0.6243455410003662,\n",
       " 0.48606815934181213,\n",
       " 0.5856194496154785,\n",
       " 0.7662423849105835,\n",
       " 0.4868345558643341,\n",
       " 0.2775154113769531,\n",
       " 0.6479488611221313,\n",
       " 0.4883531630039215,\n",
       " 0.7959128618240356,\n",
       " 0.6739580631256104,\n",
       " 1.0309160947799683,\n",
       " 0.8145512342453003,\n",
       " 0.4466146230697632,\n",
       " 0.642409086227417,\n",
       " 0.8102023601531982,\n",
       " 0.7760418653488159,\n",
       " 0.534804105758667,\n",
       " 0.2346680462360382,\n",
       " 0.40883010625839233,\n",
       " 0.8844510316848755,\n",
       " 0.9022912979125977,\n",
       " 1.0296258926391602,\n",
       " 0.001244857907295227,\n",
       " 1.030653476715088,\n",
       " 0.8212573528289795,\n",
       " 0.9375731945037842,\n",
       " 1.0554563999176025,\n",
       " 0.8074690103530884,\n",
       " 1.0293060541152954,\n",
       " 0.7403991222381592,\n",
       " 0.8017623424530029,\n",
       " 0.1523633748292923,\n",
       " 0.6208982467651367,\n",
       " 0.8137450218200684,\n",
       " 0.6314395666122437,\n",
       " 0.8330460786819458,\n",
       " 0.5438514947891235,\n",
       " 0.5922040939331055,\n",
       " 0.3979710638523102,\n",
       " 0.638347864151001,\n",
       " 0.592679500579834,\n",
       " 0.928960919380188,\n",
       " 0.22577258944511414,\n",
       " 0.9731941223144531,\n",
       " 0.4002346992492676,\n",
       " 0.8410595655441284,\n",
       " 0.35281920433044434,\n",
       " 0.9250138998031616,\n",
       " 0.850190281867981,\n",
       " 0.8164005279541016,\n",
       " 0.7420324087142944,\n",
       " 0.6712212562561035,\n",
       " 0.8074514865875244,\n",
       " 0.3231256306171417,\n",
       " 0.819283127784729,\n",
       " 0.9652748107910156,\n",
       " 0.8267070055007935,\n",
       " 0.796188473701477,\n",
       " 0.25688838958740234,\n",
       " 0.7984762191772461,\n",
       " 0.7727802991867065,\n",
       " 0.5912030935287476,\n",
       " 0.3238920271396637,\n",
       " 0.6304910182952881,\n",
       " 0.7010453939437866,\n",
       " 0.8538855314254761,\n",
       " 0.2227219194173813,\n",
       " 0.8091223239898682,\n",
       " 0.743681788444519]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "\n",
    "rows = zip(y_testi,y_pred)\n",
    "with open('returns-static.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in rows:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
